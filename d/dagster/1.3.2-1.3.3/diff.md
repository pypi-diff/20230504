# Comparing `tmp/dagster-1.3.2.tar.gz` & `tmp/dagster-1.3.3.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dagster-1.3.2.tar", last modified: Thu Apr 27 18:31:49 2023, max compression
+gzip compressed data, was "dagster-1.3.3.tar", last modified: Thu May  4 17:42:32 2023, max compression
```

## Comparing `dagster-1.3.2.tar` & `dagster-1.3.3.tar`

### file list

```diff
@@ -1,622 +1,622 @@
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.200454 dagster-1.3.2/
--rw-r--r--   0 root         (0) root         (0)      549 2023-04-27 18:30:33.000000 dagster-1.3.2/COPYING
--rw-r--r--   0 root         (0) root         (0)    11344 2023-04-27 18:30:33.000000 dagster-1.3.2/LICENSE
--rw-r--r--   0 root         (0) root         (0)      485 2023-04-27 18:30:33.000000 dagster-1.3.2/MANIFEST.in
--rw-r--r--   0 root         (0) root         (0)     8790 2023-04-27 18:31:49.200454 dagster-1.3.2/PKG-INFO
--rw-r--r--   0 root         (0) root         (0)     7167 2023-04-27 18:30:33.000000 dagster-1.3.2/README.md
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:48.808453 dagster-1.3.2/dagster/
--rw-r--r--   0 root         (0) root         (0)    25278 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/__init__.py
--rw-r--r--   0 root         (0) root         (0)       31 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/__main__.py
--rw-r--r--   0 root         (0) root         (0)     5456 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_annotations.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:48.872453 dagster-1.3.2/dagster/_api/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_api/__init__.py
--rw-r--r--   0 root         (0) root         (0)      731 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_api/get_server_id.py
--rw-r--r--   0 root         (0) root         (0)     2147 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_api/list_repositories.py
--rw-r--r--   0 root         (0) root         (0)      531 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_api/notebook_data.py
--rw-r--r--   0 root         (0) root         (0)     2965 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_api/snapshot_execution_plan.py
--rw-r--r--   0 root         (0) root         (0)     5479 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_api/snapshot_partition.py
--rw-r--r--   0 root         (0) root         (0)     1714 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_api/snapshot_pipeline.py
--rw-r--r--   0 root         (0) root         (0)     1668 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_api/snapshot_repository.py
--rw-r--r--   0 root         (0) root         (0)     2727 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_api/snapshot_schedule.py
--rw-r--r--   0 root         (0) root         (0)     2901 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_api/snapshot_sensor.py
--rw-r--r--   0 root         (0) root         (0)      478 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_builtins.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:48.872453 dagster-1.3.2/dagster/_check/
--rw-r--r--   0 root         (0) root         (0)     1352 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_check/README.md
--rw-r--r--   0 root         (0) root         (0)    51637 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_check/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:48.872453 dagster-1.3.2/dagster/_cli/
--rw-r--r--   0 root         (0) root         (0)     1101 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/__init__.py
--rw-r--r--   0 root         (0) root         (0)    27227 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/api.py
--rw-r--r--   0 root         (0) root         (0)     8207 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/asset.py
--rw-r--r--   0 root         (0) root         (0)     2325 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/config_scaffolder.py
--rw-r--r--   0 root         (0) root         (0)     3456 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/debug.py
--rw-r--r--   0 root         (0) root         (0)     5718 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/dev.py
--rw-r--r--   0 root         (0) root         (0)     2252 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/instance.py
--rw-r--r--   0 root         (0) root         (0)    30343 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/job.py
--rw-r--r--   0 root         (0) root         (0)     1695 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/load_handle.py
--rw-r--r--   0 root         (0) root         (0)     5852 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/project.py
--rw-r--r--   0 root         (0) root         (0)     5141 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/run.py
--rw-r--r--   0 root         (0) root         (0)    19909 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/schedule.py
--rw-r--r--   0 root         (0) root         (0)    15661 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/sensor.py
--rw-r--r--   0 root         (0) root         (0)     1409 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:48.872453 dagster-1.3.2/dagster/_cli/workspace/
--rw-r--r--   0 root         (0) root         (0)      180 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/workspace/__init__.py
--rw-r--r--   0 root         (0) root         (0)    28486 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_cli/workspace/cli_target.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:48.876453 dagster-1.3.2/dagster/_config/
--rw-r--r--   0 root         (0) root         (0)     3186 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3403 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/config_schema.py
--rw-r--r--   0 root         (0) root         (0)    14686 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/config_type.py
--rw-r--r--   0 root         (0) root         (0)    18799 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/errors.py
--rw-r--r--   0 root         (0) root         (0)     1783 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/evaluate_value_result.py
--rw-r--r--   0 root         (0) root         (0)    15269 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/field.py
--rw-r--r--   0 root         (0) root         (0)    17554 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/field_utils.py
--rw-r--r--   0 root         (0) root         (0)     9466 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/post_process.py
--rw-r--r--   0 root         (0) root         (0)      855 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/primitive_mapping.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:48.876453 dagster-1.3.2/dagster/_config/pythonic_config/
--rw-r--r--   0 root         (0) root         (0)    61210 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/pythonic_config/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1644 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/pythonic_config/attach_other_object_to_context.py
--rw-r--r--   0 root         (0) root         (0)     6217 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/pythonic_config/typing_utils.py
--rw-r--r--   0 root         (0) root         (0)      577 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/pythonic_config/utils.py
--rw-r--r--   0 root         (0) root         (0)    12143 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/snap.py
--rw-r--r--   0 root         (0) root         (0)     3267 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/source.py
--rw-r--r--   0 root         (0) root         (0)     3528 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/stack.py
--rw-r--r--   0 root         (0) root         (0)     7772 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/traversal_context.py
--rw-r--r--   0 root         (0) root         (0)     4167 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/type_printer.py
--rw-r--r--   0 root         (0) root         (0)    16671 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_config/validate.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:48.884453 dagster-1.3.2/dagster/_core/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/__init__.py
--rw-r--r--   0 root         (0) root         (0)      994 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/assets.py
--rw-r--r--   0 root         (0) root         (0)    13519 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/code_pointer.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:48.884453 dagster-1.3.2/dagster/_core/container_context/
--rw-r--r--   0 root         (0) root         (0)      184 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/container_context/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1277 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/container_context/config.py
--rw-r--r--   0 root         (0) root         (0)     2117 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/debug.py
--rw-r--r--   0 root         (0) root         (0)     3005 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/decorator_utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:48.968454 dagster-1.3.2/dagster/_core/definitions/
--rw-r--r--   0 root         (0) root         (0)     7771 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/__init__.py
--rw-r--r--   0 root         (0) root         (0)    28864 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/asset_graph.py
--rw-r--r--   0 root         (0) root         (0)    10704 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/asset_graph_subset.py
--rw-r--r--   0 root         (0) root         (0)    22695 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/asset_group.py
--rw-r--r--   0 root         (0) root         (0)     3817 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/asset_in.py
--rw-r--r--   0 root         (0) root         (0)    36853 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/asset_layer.py
--rw-r--r--   0 root         (0) root         (0)     5686 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/asset_out.py
--rw-r--r--   0 root         (0) root         (0)    47123 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/asset_reconciliation_sensor.py
--rw-r--r--   0 root         (0) root         (0)    17185 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/asset_selection.py
--rw-r--r--   0 root         (0) root         (0)     7164 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/asset_sensor_definition.py
--rw-r--r--   0 root         (0) root         (0)    60723 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/assets.py
--rw-r--r--   0 root         (0) root         (0)    24021 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/assets_job.py
--rw-r--r--   0 root         (0) root         (0)     3681 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/auto_materialize_policy.py
--rw-r--r--   0 root         (0) root         (0)    15537 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/cacheable_assets.py
--rw-r--r--   0 root         (0) root         (0)    45721 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/composition.py
--rw-r--r--   0 root         (0) root         (0)     4297 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/config.py
--rw-r--r--   0 root         (0) root         (0)    10877 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/configurable.py
--rw-r--r--   0 root         (0) root         (0)    20634 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/data_time.py
--rw-r--r--   0 root         (0) root         (0)    17905 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/data_version.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.028454 dagster-1.3.2/dagster/_core/definitions/decorators/
--rw-r--r--   0 root         (0) root         (0)      620 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/decorators/__init__.py
--rw-r--r--   0 root         (0) root         (0)    42322 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/decorators/asset_decorator.py
--rw-r--r--   0 root         (0) root         (0)     4915 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/decorators/config_mapping_decorator.py
--rw-r--r--   0 root         (0) root         (0)     8252 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/decorators/graph_decorator.py
--rw-r--r--   0 root         (0) root         (0)     9563 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/decorators/hook_decorator.py
--rw-r--r--   0 root         (0) root         (0)    10731 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/decorators/job_decorator.py
--rw-r--r--   0 root         (0) root         (0)    17810 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/decorators/op_decorator.py
--rw-r--r--   0 root         (0) root         (0)    14444 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/decorators/repository_decorator.py
--rw-r--r--   0 root         (0) root         (0)     8347 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/decorators/schedule_decorator.py
--rw-r--r--   0 root         (0) root         (0)    11914 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/decorators/sensor_decorator.py
--rw-r--r--   0 root         (0) root         (0)     6695 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/decorators/source_asset_decorator.py
--rw-r--r--   0 root         (0) root         (0)     5275 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/definition_config_schema.py
--rw-r--r--   0 root         (0) root         (0)    20546 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/definitions_class.py
--rw-r--r--   0 root         (0) root         (0)    39915 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/dependency.py
--rw-r--r--   0 root         (0) root         (0)    31185 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/events.py
--rw-r--r--   0 root         (0) root         (0)    21465 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/executor_definition.py
--rw-r--r--   0 root         (0) root         (0)    10548 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/external_asset_graph.py
--rw-r--r--   0 root         (0) root         (0)     8010 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/freshness_policy.py
--rw-r--r--   0 root         (0) root         (0)    16178 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/freshness_policy_sensor_definition.py
--rw-r--r--   0 root         (0) root         (0)    44593 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/graph_definition.py
--rw-r--r--   0 root         (0) root         (0)     6582 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/hook_definition.py
--rw-r--r--   0 root         (0) root         (0)     1515 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/hook_invocation.py
--rw-r--r--   0 root         (0) root         (0)     3205 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/inference.py
--rw-r--r--   0 root         (0) root         (0)    22927 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/input.py
--rw-r--r--   0 root         (0) root         (0)     5386 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/instigation_logger.py
--rw-r--r--   0 root         (0) root         (0)    53618 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/job_definition.py
--rw-r--r--   0 root         (0) root         (0)    18335 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/load_assets_from_modules.py
--rw-r--r--   0 root         (0) root         (0)     7372 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/logger_definition.py
--rw-r--r--   0 root         (0) root         (0)      641 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/logger_invocation.py
--rw-r--r--   0 root         (0) root         (0)     8841 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/materialize.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.028454 dagster-1.3.2/dagster/_core/definitions/metadata/
--rw-r--r--   0 root         (0) root         (0)    32315 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/metadata/__init__.py
--rw-r--r--   0 root         (0) root         (0)     8557 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/metadata/table.py
--rw-r--r--   0 root         (0) root         (0)    55735 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/multi_asset_sensor_definition.py
--rw-r--r--   0 root         (0) root         (0)    21561 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/multi_dimensional_partitions.py
--rw-r--r--   0 root         (0) root         (0)       82 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/no_step_launcher.py
--rw-r--r--   0 root         (0) root         (0)    11938 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/node_container.py
--rw-r--r--   0 root         (0) root         (0)     8044 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/node_definition.py
--rw-r--r--   0 root         (0) root         (0)     2867 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/observe.py
--rw-r--r--   0 root         (0) root         (0)    20633 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/op_definition.py
--rw-r--r--   0 root         (0) root         (0)    19242 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/op_invocation.py
--rw-r--r--   0 root         (0) root         (0)    18917 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/output.py
--rw-r--r--   0 root         (0) root         (0)    44192 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/partition.py
--rw-r--r--   0 root         (0) root         (0)      196 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/partition_key_range.py
--rw-r--r--   0 root         (0) root         (0)    46488 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/partition_mapping.py
--rw-r--r--   0 root         (0) root         (0)     8811 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/partitioned_schedule.py
--rw-r--r--   0 root         (0) root         (0)     5988 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/pipeline_base.py
--rw-r--r--   0 root         (0) root         (0)     3779 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/policy.py
--rw-r--r--   0 root         (0) root         (0)    30453 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/reconstruct.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.028454 dagster-1.3.2/dagster/_core/definitions/repository_definition/
--rw-r--r--   0 root         (0) root         (0)      654 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/repository_definition/__init__.py
--rw-r--r--   0 root         (0) root         (0)     6670 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/repository_definition/caching_index.py
--rw-r--r--   0 root         (0) root         (0)    18908 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/repository_definition/repository_data.py
--rw-r--r--   0 root         (0) root         (0)    18298 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/repository_definition/repository_data_builder.py
--rw-r--r--   0 root         (0) root         (0)    17823 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/repository_definition/repository_definition.py
--rw-r--r--   0 root         (0) root         (0)     1509 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/repository_definition/valid_definitions.py
--rw-r--r--   0 root         (0) root         (0)     5108 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/resolved_asset_deps.py
--rw-r--r--   0 root         (0) root         (0)     1336 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/resource_annotation.py
--rw-r--r--   0 root         (0) root         (0)    15501 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/resource_definition.py
--rw-r--r--   0 root         (0) root         (0)     5398 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/resource_invocation.py
--rw-r--r--   0 root         (0) root         (0)     7806 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/resource_requirement.py
--rw-r--r--   0 root         (0) root         (0)    24263 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/run_config.py
--rw-r--r--   0 root         (0) root         (0)     1455 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/run_config_schema.py
--rw-r--r--   0 root         (0) root         (0)    14975 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/run_request.py
--rw-r--r--   0 root         (0) root         (0)    38019 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/run_status_sensor_definition.py
--rw-r--r--   0 root         (0) root         (0)    35004 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/schedule_definition.py
--rw-r--r--   0 root         (0) root         (0)     5189 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/scoped_resources_builder.py
--rw-r--r--   0 root         (0) root         (0)    10753 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/selector.py
--rw-r--r--   0 root         (0) root         (0)    44498 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/sensor_definition.py
--rw-r--r--   0 root         (0) root         (0)    14153 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/source_asset.py
--rw-r--r--   0 root         (0) root         (0)     2339 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/step_launcher.py
--rw-r--r--   0 root         (0) root         (0)     1561 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/target.py
--rw-r--r--   0 root         (0) root         (0)      473 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/test_op_definition.py
--rw-r--r--   0 root         (0) root         (0)    10288 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/time_window_partition_mapping.py
--rw-r--r--   0 root         (0) root         (0)    74443 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/time_window_partitions.py
--rw-r--r--   0 root         (0) root         (0)    15962 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/unresolved_asset_job_definition.py
--rw-r--r--   0 root         (0) root         (0)     7992 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/utils.py
--rw-r--r--   0 root         (0) root         (0)     3103 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/definitions/version_strategy.py
--rw-r--r--   0 root         (0) root         (0)    25453 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/errors.py
--rw-r--r--   0 root         (0) root         (0)     6232 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/event_api.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.028454 dagster-1.3.2/dagster/_core/events/
--rw-r--r--   0 root         (0) root         (0)    65171 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/events/__init__.py
--rw-r--r--   0 root         (0) root         (0)     8250 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/events/log.py
--rw-r--r--   0 root         (0) root         (0)     1614 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/events/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.032454 dagster-1.3.2/dagster/_core/execution/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/__init__.py
--rw-r--r--   0 root         (0) root         (0)    39644 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/api.py
--rw-r--r--   0 root         (0) root         (0)    26566 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/asset_backfill.py
--rw-r--r--   0 root         (0) root         (0)    15096 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/backfill.py
--rw-r--r--   0 root         (0) root         (0)     6332 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/build_resources.py
--rw-r--r--   0 root         (0) root         (0)      224 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/bulk_actions.py
--rw-r--r--   0 root         (0) root         (0)     5587 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/compute_logs.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.032454 dagster-1.3.2/dagster/_core/execution/context/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/context/__init__.py
--rw-r--r--   0 root         (0) root         (0)    22172 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/context/compute.py
--rw-r--r--   0 root         (0) root         (0)    16287 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/context/hook.py
--rw-r--r--   0 root         (0) root         (0)     9568 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/context/init.py
--rw-r--r--   0 root         (0) root         (0)    27186 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/context/input.py
--rw-r--r--   0 root         (0) root         (0)    27472 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/context/invocation.py
--rw-r--r--   0 root         (0) root         (0)     3812 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/context/logger.py
--rw-r--r--   0 root         (0) root         (0)    34422 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/context/output.py
--rw-r--r--   0 root         (0) root         (0)    42790 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/context/system.py
--rw-r--r--   0 root         (0) root         (0)    18821 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/context_creation_pipeline.py
--rw-r--r--   0 root         (0) root         (0)     5225 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/execute_in_process.py
--rw-r--r--   0 root         (0) root         (0)     5428 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/execute_in_process_result.py
--rw-r--r--   0 root         (0) root         (0)     6480 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/execute_job_result.py
--rw-r--r--   0 root         (0) root         (0)     9184 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/execution_result.py
--rw-r--r--   0 root         (0) root         (0)     8758 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/host_mode.py
--rw-r--r--   0 root         (0) root         (0)    14509 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/job_backfill.py
--rw-r--r--   0 root         (0) root         (0)      998 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/memoization.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.036454 dagster-1.3.2/dagster/_core/execution/plan/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/__init__.py
--rw-r--r--   0 root         (0) root         (0)    23056 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/active.py
--rw-r--r--   0 root         (0) root         (0)     7299 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/compute.py
--rw-r--r--   0 root         (0) root         (0)    12571 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/compute_generator.py
--rw-r--r--   0 root         (0) root         (0)    16478 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/execute_plan.py
--rw-r--r--   0 root         (0) root         (0)    27413 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/execute_step.py
--rw-r--r--   0 root         (0) root         (0)    10211 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/external_step.py
--rw-r--r--   0 root         (0) root         (0)     3664 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/handle.py
--rw-r--r--   0 root         (0) root         (0)    38123 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/inputs.py
--rw-r--r--   0 root         (0) root         (0)     1159 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/local_external_step_main.py
--rw-r--r--   0 root         (0) root         (0)     5395 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/objects.py
--rw-r--r--   0 root         (0) root         (0)     7057 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/outputs.py
--rw-r--r--   0 root         (0) root         (0)    59748 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/plan.py
--rw-r--r--   0 root         (0) root         (0)      114 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/resume_retry.py
--rw-r--r--   0 root         (0) root         (0)    15617 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/state.py
--rw-r--r--   0 root         (0) root         (0)    16031 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/step.py
--rw-r--r--   0 root         (0) root         (0)     3799 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/plan/utils.py
--rw-r--r--   0 root         (0) root         (0)     1762 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/poll_compute_logs.py
--rw-r--r--   0 root         (0) root         (0)     8186 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/resolve_versions.py
--rw-r--r--   0 root         (0) root         (0)    19440 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/resources_init.py
--rw-r--r--   0 root         (0) root         (0)    25947 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/results.py
--rw-r--r--   0 root         (0) root         (0)     2104 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/retries.py
--rw-r--r--   0 root         (0) root         (0)     1652 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/run_cancellation_thread.py
--rw-r--r--   0 root         (0) root         (0)    10333 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/stats.py
--rw-r--r--   0 root         (0) root         (0)     1125 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/tags.py
--rw-r--r--   0 root         (0) root         (0)     1172 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/validate_run_config.py
--rw-r--r--   0 root         (0) root         (0)     1282 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/watch_orphans.py
--rw-r--r--   0 root         (0) root         (0)     4233 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/execution/with_resources.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.036454 dagster-1.3.2/dagster/_core/executor/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/executor/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1265 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/executor/base.py
--rw-r--r--   0 root         (0) root         (0)     5990 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/executor/child_process_executor.py
--rw-r--r--   0 root         (0) root         (0)     2855 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/executor/in_process.py
--rw-r--r--   0 root         (0) root         (0)     1610 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/executor/init.py
--rw-r--r--   0 root         (0) root         (0)    15407 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/executor/multiprocess.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.036454 dagster-1.3.2/dagster/_core/executor/step_delegating/
--rw-r--r--   0 root         (0) root         (0)      247 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/executor/step_delegating/__init__.py
--rw-r--r--   0 root         (0) root         (0)    14347 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/executor/step_delegating/step_delegating_executor.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.036454 dagster-1.3.2/dagster/_core/executor/step_delegating/step_handler/
--rw-r--r--   0 root         (0) root         (0)      152 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/executor/step_delegating/step_handler/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3090 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/executor/step_delegating/step_handler/base.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.040454 dagster-1.3.2/dagster/_core/host_representation/
--rw-r--r--   0 root         (0) root         (0)     2874 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/host_representation/__init__.py
--rw-r--r--   0 root         (0) root         (0)    33817 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/host_representation/code_location.py
--rw-r--r--   0 root         (0) root         (0)    32501 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/host_representation/external.py
--rw-r--r--   0 root         (0) root         (0)    68876 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/host_representation/external_data.py
--rw-r--r--   0 root         (0) root         (0)    11276 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/host_representation/grpc_server_registry.py
--rw-r--r--   0 root         (0) root         (0)     1487 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/host_representation/grpc_server_state_subscriber.py
--rw-r--r--   0 root         (0) root         (0)     4341 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/host_representation/handle.py
--rw-r--r--   0 root         (0) root         (0)     1716 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/host_representation/historical.py
--rw-r--r--   0 root         (0) root         (0)    17332 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/host_representation/origin.py
--rw-r--r--   0 root         (0) root         (0)     5205 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/host_representation/pipeline_index.py
--rw-r--r--   0 root         (0) root         (0)     3835 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/host_representation/represented.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.040454 dagster-1.3.2/dagster/_core/instance/
--rw-r--r--   0 root         (0) root         (0)   102984 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/instance/__init__.py
--rw-r--r--   0 root         (0) root         (0)    11577 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/instance/config.py
--rw-r--r--   0 root         (0) root         (0)    24318 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/instance/ref.py
--rw-r--r--   0 root         (0) root         (0)     4567 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/instance_for_test.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.040454 dagster-1.3.2/dagster/_core/launcher/
--rw-r--r--   0 root         (0) root         (0)      297 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/launcher/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3675 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/launcher/base.py
--rw-r--r--   0 root         (0) root         (0)     6413 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/launcher/default_run_launcher.py
--rw-r--r--   0 root         (0) root         (0)     1611 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/launcher/sync_in_memory_run_launcher.py
--rw-r--r--   0 root         (0) root         (0)      473 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/libraries.py
--rw-r--r--   0 root         (0) root         (0)    17327 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/log_manager.py
--rw-r--r--   0 root         (0) root         (0)     1029 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/nux.py
--rw-r--r--   0 root         (0) root         (0)     3657 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/origin.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.040454 dagster-1.3.2/dagster/_core/run_coordinator/
--rw-r--r--   0 root         (0) root         (0)      267 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/run_coordinator/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1915 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/run_coordinator/base.py
--rw-r--r--   0 root         (0) root         (0)     1931 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/run_coordinator/default_run_coordinator.py
--rw-r--r--   0 root         (0) root         (0)    11050 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/run_coordinator/queued_run_coordinator.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.044454 dagster-1.3.2/dagster/_core/scheduler/
--rw-r--r--   0 root         (0) root         (0)      534 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/scheduler/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1241 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/scheduler/execution.py
--rw-r--r--   0 root         (0) root         (0)    18194 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/scheduler/instigation.py
--rw-r--r--   0 root         (0) root         (0)     9410 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/scheduler/scheduler.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.044454 dagster-1.3.2/dagster/_core/secrets/
--rw-r--r--   0 root         (0) root         (0)       51 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/secrets/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1777 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/secrets/env_file.py
--rw-r--r--   0 root         (0) root         (0)      388 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/secrets/loader.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.044454 dagster-1.3.2/dagster/_core/selector/
--rw-r--r--   0 root         (0) root         (0)      305 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/selector/__init__.py
--rw-r--r--   0 root         (0) root         (0)    20291 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/selector/subset_selector.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.044454 dagster-1.3.2/dagster/_core/snap/
--rw-r--r--   0 root         (0) root         (0)     2847 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/snap/__init__.py
--rw-r--r--   0 root         (0) root         (0)      522 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/snap/config_types.py
--rw-r--r--   0 root         (0) root         (0)     3999 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/snap/dagster_types.py
--rw-r--r--   0 root         (0) root         (0)     9421 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/snap/dep_snapshot.py
--rw-r--r--   0 root         (0) root         (0)    12052 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/snap/execution_plan_snapshot.py
--rw-r--r--   0 root         (0) root         (0)     4495 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/snap/mode.py
--rw-r--r--   0 root         (0) root         (0)    14472 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/snap/node.py
--rw-r--r--   0 root         (0) root         (0)    16768 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/snap/pipeline_snapshot.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.108454 dagster-1.3.2/dagster/_core/storage/
--rw-r--r--   0 root         (0) root         (0)     3057 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/DEVELOPING.md
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.112454 dagster-1.3.2/dagster/_core/storage/alembic/
--rw-r--r--   0 root         (0) root         (0)     6676 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/README.md
--rw-r--r--   0 root         (0) root         (0)      687 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/env.py
--rw-r--r--   0 root         (0) root         (0)      494 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/script.py.mako
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.124454 dagster-1.3.2/dagster/_core/storage/alembic/versions/
--rw-r--r--   0 root         (0) root         (0)     3150 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/001_initial_1.py
--rw-r--r--   0 root         (0) root         (0)      311 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/001_initial_schedule.py
--rw-r--r--   0 root         (0) root         (0)     1353 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_postgres.py
--rw-r--r--   0 root         (0) root         (0)      598 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      972 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_postgres.py
--rw-r--r--   0 root         (0) root         (0)      972 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     2548 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/004_add_snapshots_to_run_storage.py
--rw-r--r--   0 root         (0) root         (0)     1405 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/005_add_asset_key_postgres.py
--rw-r--r--   0 root         (0) root         (0)     1405 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/005_add_asset_key_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     1130 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/006_scheduler_update_postgres.py
--rw-r--r--   0 root         (0) root         (0)      952 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/007_create_run_id_idx_postgres.py
--rw-r--r--   0 root         (0) root         (0)      952 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/007_create_run_id_idx_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      955 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/008_add_run_tags_index_postgres.py
--rw-r--r--   0 root         (0) root         (0)      955 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/008_add_run_tags_index_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     1170 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/009_add_partition_column_postgres.py
--rw-r--r--   0 root         (0) root         (0)     1170 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/009_add_partition_column_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     1729 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_postgres.py
--rw-r--r--   0 root         (0) root         (0)     1729 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     1146 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_postgres.py
--rw-r--r--   0 root         (0) root         (0)     1124 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_1.py
--rw-r--r--   0 root         (0) root         (0)     1142 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_2.py
--rw-r--r--   0 root         (0) root         (0)      416 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/012_0_10_0_create_new_run_tables_postgres.py
--rw-r--r--   0 root         (0) root         (0)      416 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/012_0_10_0_create_new_run_tables_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      434 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/013_0_10_0_create_new_event_log_tables_postgres.py
--rw-r--r--   0 root         (0) root         (0)      434 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/013_0_10_0_create_new_event_log_tables_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      431 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/014_0_10_0_create_new_schedule_tables_postgres.py
--rw-r--r--   0 root         (0) root         (0)      431 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/014_0_10_0_create_new_schedule_tables_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     3926 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_postgres.py
--rw-r--r--   0 root         (0) root         (0)     3926 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      408 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/016_add_bulk_actions_table_postgres.py
--rw-r--r--   0 root         (0) root         (0)      408 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/016_add_bulk_actions_table_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      935 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/017_add_run_status_index_postgres.py
--rw-r--r--   0 root         (0) root         (0)      935 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/017_add_run_status_index_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      325 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/017_initial_mysql.py
--rw-r--r--   0 root         (0) root         (0)      420 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/018_add_asset_tags_mysql.py
--rw-r--r--   0 root         (0) root         (0)      420 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/018_add_asset_tags_postgres.py
--rw-r--r--   0 root         (0) root         (0)      420 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/018_add_asset_tags_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     1569 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_postgres.py
--rw-r--r--   0 root         (0) root         (0)     1569 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      409 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/020_add_column_asset_body_mysql.py
--rw-r--r--   0 root         (0) root         (0)      409 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/020_add_column_asset_body_postgres.py
--rw-r--r--   0 root         (0) root         (0)      409 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/020_add_column_asset_body_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/021_add_column_mode_mysql.py
--rw-r--r--   0 root         (0) root         (0)     1031 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/021_add_column_mode_postgres.py
--rw-r--r--   0 root         (0) root         (0)     1033 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/021_add_column_mode_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      432 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/022_extract_asset_keys_index_columns_mysql.py
--rw-r--r--   0 root         (0) root         (0)      432 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/022_extract_asset_keys_index_columns_postgres.py
--rw-r--r--   0 root         (0) root         (0)      432 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/022_extract_asset_keys_index_columns_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      420 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/023_add_event_log_event_type_idx_mysql.py
--rw-r--r--   0 root         (0) root         (0)      420 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/023_add_event_log_event_type_idx_postgres.py
--rw-r--r--   0 root         (0) root         (0)      420 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/023_add_event_log_event_type_idx_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      530 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_mysql.py
--rw-r--r--   0 root         (0) root         (0)     1274 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_postgres.py
--rw-r--r--   0 root         (0) root         (0)     1274 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      403 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/025_add_range_index_mysql.py
--rw-r--r--   0 root         (0) root         (0)      403 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/025_add_range_index_postgres.py
--rw-r--r--   0 root         (0) root         (0)      403 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/025_add_range_index_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      634 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/026_convert_start_end_times_format_mysql.py
--rw-r--r--   0 root         (0) root         (0)      433 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/027_add_migration_table_mysql.py
--rw-r--r--   0 root         (0) root         (0)      433 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/027_add_migration_table_postgres.py
--rw-r--r--   0 root         (0) root         (0)      433 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/027_add_migration_table_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      409 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/028_add_instigators_table_mysql.py
--rw-r--r--   0 root         (0) root         (0)      409 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/028_add_instigators_table_postgres.py
--rw-r--r--   0 root         (0) root         (0)      409 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/028_add_instigators_table_sqlite.py
--rw-r--r--   0 root         (0) root         (0)      415 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/029_add_tick_selector_index_mysql.py
--rw-r--r--   0 root         (0) root         (0)      415 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/029_add_tick_selector_index_postgres.py
--rw-r--r--   0 root         (0) root         (0)      415 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/029_add_tick_selector_index_sqlite.py
--rw-r--r--   0 root         (0) root         (0)     1892 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/030_add_columns_action_type_and_selector_id_.py
--rw-r--r--   0 root         (0) root         (0)      957 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/031_add_kvs_table.py
--rw-r--r--   0 root         (0) root         (0)      498 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/032_rebuild_event_indexes.py
--rw-r--r--   0 root         (0) root         (0)     1950 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/033_add_asset_event_tags_table.py
--rw-r--r--   0 root         (0) root         (0)      428 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/034_add_cached_status_data_column.py
--rw-r--r--   0 root         (0) root         (0)      426 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/035_add_run_job_index.py
--rw-r--r--   0 root         (0) root         (0)     1536 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/036_add_dynamic_partitions_table.py
--rw-r--r--   0 root         (0) root         (0)     2480 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/037_d9092588866f_add_primary_key_cols.py
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/alembic/versions/__init__.py
--rw-r--r--   0 root         (0) root         (0)     7205 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/asset_value_loader.py
--rw-r--r--   0 root         (0) root         (0)     1215 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/base_storage.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.124454 dagster-1.3.2/dagster/_core/storage/branching/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/branching/__init__.py
--rw-r--r--   0 root         (0) root         (0)     4304 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/branching/branching_io_manager.py
--rw-r--r--   0 root         (0) root         (0)     8073 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/captured_log_manager.py
--rw-r--r--   0 root         (0) root         (0)    16259 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/cloud_storage_compute_log_manager.py
--rw-r--r--   0 root         (0) root         (0)     9579 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/compute_log_manager.py
--rw-r--r--   0 root         (0) root         (0)     1863 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/config.py
--rw-r--r--   0 root         (0) root         (0)      417 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/daemon_cursor.py
--rw-r--r--   0 root         (0) root         (0)    11544 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/db_io_manager.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.124454 dagster-1.3.2/dagster/_core/storage/event_log/
--rw-r--r--   0 root         (0) root         (0)      742 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/event_log/__init__.py
--rw-r--r--   0 root         (0) root         (0)    14277 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/event_log/base.py
--rw-r--r--   0 root         (0) root         (0)     3630 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/event_log/in_memory.py
--rw-r--r--   0 root         (0) root         (0)     7211 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/event_log/migration.py
--rw-r--r--   0 root         (0) root         (0)     7820 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/event_log/polling_event_watcher.py
--rw-r--r--   0 root         (0) root         (0)     5090 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/event_log/schema.py
--rw-r--r--   0 root         (0) root         (0)    77841 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/event_log/sql_event_log.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.124454 dagster-1.3.2/dagster/_core/storage/event_log/sqlite/
--rw-r--r--   0 root         (0) root         (0)      200 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/event_log/sqlite/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.124454 dagster-1.3.2/dagster/_core/storage/event_log/sqlite/alembic/
--rw-r--r--   0 root         (0) root         (0)     1040 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/event_log/sqlite/alembic/alembic.ini
--rw-r--r--   0 root         (0) root         (0)     7409 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/event_log/sqlite/consolidated_sqlite_event_log.py
--rw-r--r--   0 root         (0) root         (0)    18951 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/event_log/sqlite/sqlite_event_log.py
--rw-r--r--   0 root         (0) root         (0)    10912 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/file_manager.py
--rw-r--r--   0 root         (0) root         (0)    13227 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/fs_io_manager.py
--rw-r--r--   0 root         (0) root         (0)     8915 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/input_manager.py
--rw-r--r--   0 root         (0) root         (0)    10638 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/io_manager.py
--rw-r--r--   0 root         (0) root         (0)    26262 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/legacy_storage.py
--rw-r--r--   0 root         (0) root         (0)    17376 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/local_compute_log_manager.py
--rw-r--r--   0 root         (0) root         (0)      876 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/mem_io_manager.py
--rw-r--r--   0 root         (0) root         (0)     4293 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/memoizable_io_manager.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.124454 dagster-1.3.2/dagster/_core/storage/migration/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/migration/__init__.py
--rw-r--r--   0 root         (0) root         (0)    14469 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/migration/utils.py
--rw-r--r--   0 root         (0) root         (0)     3190 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/noop_compute_log_manager.py
--rw-r--r--   0 root         (0) root         (0)     2361 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/output_manager.py
--rw-r--r--   0 root         (0) root         (0)    23190 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/partition_status_cache.py
--rw-r--r--   0 root         (0) root         (0)    23821 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/pipeline_run.py
--rw-r--r--   0 root         (0) root         (0)     2121 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/root.py
--rw-r--r--   0 root         (0) root         (0)     8509 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/root_input_manager.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.128454 dagster-1.3.2/dagster/_core/storage/runs/
--rw-r--r--   0 root         (0) root         (0)      386 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/runs/__init__.py
--rw-r--r--   0 root         (0) root         (0)    15584 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/runs/base.py
--rw-r--r--   0 root         (0) root         (0)     2347 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/runs/in_memory.py
--rw-r--r--   0 root         (0) root         (0)     8629 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/runs/migration.py
--rw-r--r--   0 root         (0) root         (0)     5982 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/runs/schema.py
--rw-r--r--   0 root         (0) root         (0)    46629 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/runs/sql_run_storage.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.128454 dagster-1.3.2/dagster/_core/storage/runs/sqlite/
--rw-r--r--   0 root         (0) root         (0)       69 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/runs/sqlite/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.128454 dagster-1.3.2/dagster/_core/storage/runs/sqlite/alembic/
--rw-r--r--   0 root         (0) root         (0)     1040 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/runs/sqlite/alembic/alembic.ini
--rw-r--r--   0 root         (0) root         (0)     6822 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/runs/sqlite/sqlite_run_storage.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.128454 dagster-1.3.2/dagster/_core/storage/schedules/
--rw-r--r--   0 root         (0) root         (0)      272 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/schedules/__init__.py
--rw-r--r--   0 root         (0) root         (0)     5344 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/schedules/base.py
--rw-r--r--   0 root         (0) root         (0)     4095 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/schedules/migration.py
--rw-r--r--   0 root         (0) root         (0)     2776 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/schedules/schema.py
--rw-r--r--   0 root         (0) root         (0)    19749 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/schedules/sql_schedule_storage.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.128454 dagster-1.3.2/dagster/_core/storage/schedules/sqlite/
--rw-r--r--   0 root         (0) root         (0)       84 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/schedules/sqlite/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.128454 dagster-1.3.2/dagster/_core/storage/schedules/sqlite/alembic/
--rw-r--r--   0 root         (0) root         (0)     1039 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/schedules/sqlite/alembic/alembic.ini
--rw-r--r--   0 root         (0) root         (0)     3664 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/schedules/sqlite/sqlite_schedule_storage.py
--rw-r--r--   0 root         (0) root         (0)     7375 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/sql.py
--rw-r--r--   0 root         (0) root         (0)      926 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/sqlite.py
--rw-r--r--   0 root         (0) root         (0)     4863 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/sqlite_storage.py
--rw-r--r--   0 root         (0) root         (0)     3073 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/tags.py
--rw-r--r--   0 root         (0) root         (0)     1128 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/temp_file_manager.py
--rw-r--r--   0 root         (0) root         (0)    10435 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/storage/upath_io_manager.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.128454 dagster-1.3.2/dagster/_core/system_config/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/system_config/__init__.py
--rw-r--r--   0 root         (0) root         (0)    14174 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/system_config/composite_descent.py
--rw-r--r--   0 root         (0) root         (0)    14920 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/system_config/objects.py
--rw-r--r--   0 root         (0) root         (0)    28122 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/telemetry.py
--rw-r--r--   0 root         (0) root         (0)     4824 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/telemetry_upload.py
--rw-r--r--   0 root         (0) root         (0)    18689 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/test_utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.128454 dagster-1.3.2/dagster/_core/types/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/types/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3163 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/types/builtin_config_schemas.py
--rw-r--r--   0 root         (0) root         (0)     7393 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/types/config_schema.py
--rw-r--r--   0 root         (0) root         (0)    35761 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/types/dagster_type.py
--rw-r--r--   0 root         (0) root         (0)     3579 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/types/decorator.py
--rw-r--r--   0 root         (0) root         (0)     1846 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/types/loadable_target_origin.py
--rw-r--r--   0 root         (0) root         (0)     1027 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/types/primitive_mapping.py
--rw-r--r--   0 root         (0) root         (0)     4881 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/types/python_dict.py
--rw-r--r--   0 root         (0) root         (0)     2836 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/types/python_set.py
--rw-r--r--   0 root         (0) root         (0)     3712 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/types/python_tuple.py
--rw-r--r--   0 root         (0) root         (0)     1772 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/types/transform_typing.py
--rw-r--r--   0 root         (0) root         (0)     1438 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/utility_solids.py
--rw-r--r--   0 root         (0) root         (0)     4003 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.132454 dagster-1.3.2/dagster/_core/workspace/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/workspace/__init__.py
--rw-r--r--   0 root         (0) root         (0)     5432 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/workspace/autodiscovery.py
--rw-r--r--   0 root         (0) root         (0)     3478 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/workspace/config_schema.py
--rw-r--r--   0 root         (0) root         (0)    26661 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/workspace/context.py
--rw-r--r--   0 root         (0) root         (0)    11881 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/workspace/load.py
--rw-r--r--   0 root         (0) root         (0)     4684 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/workspace/load_target.py
--rw-r--r--   0 root         (0) root         (0)     3952 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/workspace/permissions.py
--rw-r--r--   0 root         (0) root         (0)     1912 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_core/workspace/workspace.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.132454 dagster-1.3.2/dagster/_daemon/
--rw-r--r--   0 root         (0) root         (0)     1930 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/__init__.py
--rw-r--r--   0 root         (0) root         (0)       30 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/__main__.py
--rw-r--r--   0 root         (0) root         (0)     5314 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/asset_daemon.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.188454 dagster-1.3.2/dagster/_daemon/auto_run_reexecution/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/auto_run_reexecution/__init__.py
--rw-r--r--   0 root         (0) root         (0)     6882 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/auto_run_reexecution/auto_run_reexecution.py
--rw-r--r--   0 root         (0) root         (0)     9124 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/auto_run_reexecution/event_log_consumer.py
--rw-r--r--   0 root         (0) root         (0)     1936 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/backfill.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.188454 dagster-1.3.2/dagster/_daemon/cli/
--rw-r--r--   0 root         (0) root         (0)     4422 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/cli/__init__.py
--rw-r--r--   0 root         (0) root         (0)    17726 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/controller.py
--rw-r--r--   0 root         (0) root         (0)    10457 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/daemon.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.188454 dagster-1.3.2/dagster/_daemon/monitoring/
--rw-r--r--   0 root         (0) root         (0)      215 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/monitoring/__init__.py
--rw-r--r--   0 root         (0) root         (0)     8371 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/monitoring/monitoring_daemon.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.188454 dagster-1.3.2/dagster/_daemon/run_coordinator/
--rw-r--r--   0 root         (0) root         (0)      100 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/run_coordinator/__init__.py
--rw-r--r--   0 root         (0) root         (0)    16312 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/run_coordinator/queued_run_coordinator_daemon.py
--rw-r--r--   0 root         (0) root         (0)    35637 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/sensor.py
--rw-r--r--   0 root         (0) root         (0)     2860 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/types.py
--rw-r--r--   0 root         (0) root         (0)     6639 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_daemon/workspace.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.188454 dagster-1.3.2/dagster/_experimental/
--rw-r--r--   0 root         (0) root         (0)      300 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_experimental/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.188454 dagster-1.3.2/dagster/_generate/
--rw-r--r--   0 root         (0) root         (0)      253 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_generate/__init__.py
--rw-r--r--   0 root         (0) root         (0)     2695 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_generate/download.py
--rw-r--r--   0 root         (0) root         (0)     4805 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_generate/generate.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:48.804453 dagster-1.3.2/dagster/_generate/templates/
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.188454 dagster-1.3.2/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.188454 dagster-1.3.2/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER/
--rw-r--r--   0 root         (0) root         (0)      175 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER/__init__.py
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER/assets.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.188454 dagster-1.3.2/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER_tests/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER_tests/__init__.py
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER_tests/test_assets.py.tmpl
--rw-r--r--   0 root         (0) root         (0)      137 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/pyproject.toml.tmpl
--rw-r--r--   0 root         (0) root         (0)       43 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/setup.cfg.tmpl
--rw-r--r--   0 root         (0) root         (0)      285 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/setup.py.tmpl
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.188454 dagster-1.3.2/dagster/_generate/templates/PROJECT_NAME_PLACEHOLDER/
--rw-r--r--   0 root         (0) root         (0)     1753 2023-04-27 18:30:33.000000 dagster-1.3.2/dagster/_generate/templates/PROJECT_NAME_PLACEHOLDER/README.md
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.188454 dagster-1.3.2/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.188454 dagster-1.3.2/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/
--rw-r--r--   0 root         (0) root         (0)       40 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/__init__.py.tmpl
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/assets.py
--rw-r--r--   0 root         (0) root         (0)      164 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/repository.py.tmpl
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.188454 dagster-1.3.2/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER_tests/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER_tests/__init__.py
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER_tests/test_assets.py.tmpl
--rw-r--r--   0 root         (0) root         (0)       80 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/pyproject.toml
--rw-r--r--   0 root         (0) root         (0)       34 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/setup.cfg.tmpl
--rw-r--r--   0 root         (0) root         (0)      267 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/setup.py.tmpl
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.192454 dagster-1.3.2/dagster/_grpc/
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.192454 dagster-1.3.2/dagster/_grpc/__generated__/
--rw-r--r--   0 root         (0) root         (0)      178 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_grpc/__generated__/__init__.py
--rw-r--r--   0 root         (0) root         (0)    11665 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_grpc/__generated__/api_pb2.py
--rw-r--r--   0 root         (0) root         (0)    38179 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_grpc/__generated__/api_pb2_grpc.py
--rw-r--r--   0 root         (0) root         (0)     2071 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_grpc/__init__.py
--rw-r--r--   0 root         (0) root         (0)       89 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_grpc/__main__.py
--rw-r--r--   0 root         (0) root         (0)    18538 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_grpc/client.py
--rw-r--r--   0 root         (0) root         (0)     4202 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_grpc/compile.py
--rw-r--r--   0 root         (0) root         (0)    22220 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_grpc/impl.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.192454 dagster-1.3.2/dagster/_grpc/protos/
--rw-r--r--   0 root         (0) root         (0)     5394 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_grpc/protos/api.proto
--rw-r--r--   0 root         (0) root         (0)    52639 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_grpc/server.py
--rw-r--r--   0 root         (0) root         (0)     5301 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_grpc/server_watcher.py
--rw-r--r--   0 root         (0) root         (0)    26204 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_grpc/types.py
--rw-r--r--   0 root         (0) root         (0)     2323 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_grpc/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.192454 dagster-1.3.2/dagster/_legacy/
--rw-r--r--   0 root         (0) root         (0)      468 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_legacy/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.192454 dagster-1.3.2/dagster/_loggers/
--rw-r--r--   0 root         (0) root         (0)     3781 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_loggers/__init__.py
--rw-r--r--   0 root         (0) root         (0)     3269 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_module_alias_map.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.192454 dagster-1.3.2/dagster/_scheduler/
--rw-r--r--   0 root         (0) root         (0)        0 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_scheduler/__init__.py
--rw-r--r--   0 root         (0) root         (0)    31924 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_scheduler/scheduler.py
--rw-r--r--   0 root         (0) root         (0)     1388 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_scheduler/stale.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.192454 dagster-1.3.2/dagster/_serdes/
--rw-r--r--   0 root         (0) root         (0)      629 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_serdes/__init__.py
--rw-r--r--   0 root         (0) root         (0)     8004 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_serdes/config_class.py
--rw-r--r--   0 root         (0) root         (0)      142 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_serdes/errors.py
--rw-r--r--   0 root         (0) root         (0)     7467 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_serdes/ipc.py
--rw-r--r--   0 root         (0) root         (0)    37037 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_serdes/serdes.py
--rw-r--r--   0 root         (0) root         (0)      674 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_serdes/utils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.192454 dagster-1.3.2/dagster/_seven/
--rw-r--r--   0 root         (0) root         (0)     5496 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_seven/__init__.py
--rw-r--r--   0 root         (0) root         (0)      553 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_seven/abc.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.192454 dagster-1.3.2/dagster/_seven/compat/
--rw-r--r--   0 root         (0) root         (0)      105 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_seven/compat/__init__.py
--rw-r--r--   0 root         (0) root         (0)     1160 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_seven/compat/pendulum.py
--rw-r--r--   0 root         (0) root         (0)      383 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_seven/json.py
--rw-r--r--   0 root         (0) root         (0)      354 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_seven/temp_dir.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.196454 dagster-1.3.2/dagster/_utils/
--rw-r--r--   0 root         (0) root         (0)    23212 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/__init__.py
--rw-r--r--   0 root         (0) root         (0)     8667 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/alert.py
--rw-r--r--   0 root         (0) root         (0)     6965 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/backcompat.py
--rw-r--r--   0 root         (0) root         (0)     2250 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/backoff.py
--rw-r--r--   0 root         (0) root         (0)     4116 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/cached_method.py
--rw-r--r--   0 root         (0) root         (0)    23704 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/caching_instance_queryer.py
--rw-r--r--   0 root         (0) root         (0)     2630 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/dagster_type.py
--rw-r--r--   0 root         (0) root         (0)     4094 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/error.py
--rw-r--r--   0 root         (0) root         (0)     1346 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/external.py
--rw-r--r--   0 root         (0) root         (0)      883 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/forked_pdb.py
--rw-r--r--   0 root         (0) root         (0)     2470 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/hosted_user_process.py
--rw-r--r--   0 root         (0) root         (0)     2796 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/indenting_printer.py
--rw-r--r--   0 root         (0) root         (0)     3227 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/interrupts.py
--rw-r--r--   0 root         (0) root         (0)     9813 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/log.py
--rw-r--r--   0 root         (0) root         (0)     2313 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/merger.py
--rw-r--r--   0 root         (0) root         (0)     1507 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/net.py
--rw-r--r--   0 root         (0) root         (0)      208 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/partitions.py
--rw-r--r--   0 root         (0) root         (0)    11139 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/schedules.py
--rw-r--r--   0 root         (0) root         (0)     3290 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/tags.py
--rw-r--r--   0 root         (0) root         (0)     1820 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/temp_file.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.196454 dagster-1.3.2/dagster/_utils/test/
--rw-r--r--   0 root         (0) root         (0)    10463 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/test/__init__.py
--rw-r--r--   0 root         (0) root         (0)      119 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/test/hello_world_defs.py
--rw-r--r--   0 root         (0) root         (0)      214 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/test/hello_world_repository.py
--rw-r--r--   0 root         (0) root         (0)     8622 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/test/mysql_instance.py
--rw-r--r--   0 root         (0) root         (0)      256 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/test/named_hello_world_repository.py
--rw-r--r--   0 root         (0) root         (0)     9330 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/test/postgres_instance.py
--rw-r--r--   0 root         (0) root         (0)    23902 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/test/schedule_storage.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:49.200454 dagster-1.3.2/dagster/_utils/test/toys/
--rw-r--r--   0 root         (0) root         (0)       83 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/test/toys/__init__.py
--rw-r--r--   0 root         (0) root         (0)       84 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/test/toys/single_repository.py
--rw-r--r--   0 root         (0) root         (0)     2004 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/timing.py
--rw-r--r--   0 root         (0) root         (0)      170 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/types.py
--rw-r--r--   0 root         (0) root         (0)     3334 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/typing_api.py
--rw-r--r--   0 root         (0) root         (0)     4915 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/_utils/yaml_utils.py
--rw-r--r--   0 root         (0) root         (0)        8 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/py.typed
--rw-r--r--   0 root         (0) root         (0)       22 2023-04-27 18:30:34.000000 dagster-1.3.2/dagster/version.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2023-04-27 18:31:48.808453 dagster-1.3.2/dagster.egg-info/
--rw-r--r--   0 root         (0) root         (0)     8790 2023-04-27 18:31:47.000000 dagster-1.3.2/dagster.egg-info/PKG-INFO
--rw-r--r--   0 root         (0) root         (0)    24867 2023-04-27 18:31:48.000000 dagster-1.3.2/dagster.egg-info/SOURCES.txt
--rw-r--r--   0 root         (0) root         (0)        1 2023-04-27 18:31:47.000000 dagster-1.3.2/dagster.egg-info/dependency_links.txt
--rw-r--r--   0 root         (0) root         (0)       86 2023-04-27 18:31:47.000000 dagster-1.3.2/dagster.egg-info/entry_points.txt
--rw-r--r--   0 root         (0) root         (0)     1290 2023-04-27 18:31:47.000000 dagster-1.3.2/dagster.egg-info/requires.txt
--rw-r--r--   0 root         (0) root         (0)        8 2023-04-27 18:31:47.000000 dagster-1.3.2/dagster.egg-info/top_level.txt
--rw-r--r--   0 root         (0) root         (0)      154 2023-04-27 18:31:49.200454 dagster-1.3.2/setup.cfg
--rw-r--r--   0 root         (0) root         (0)     6429 2023-04-27 18:30:35.000000 dagster-1.3.2/setup.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.720379 dagster-1.3.3/
+-rw-r--r--   0 root         (0) root         (0)      549 2023-05-04 17:42:13.000000 dagster-1.3.3/COPYING
+-rw-r--r--   0 root         (0) root         (0)    11344 2023-05-04 17:42:13.000000 dagster-1.3.3/LICENSE
+-rw-r--r--   0 root         (0) root         (0)      485 2023-05-04 17:42:13.000000 dagster-1.3.3/MANIFEST.in
+-rw-r--r--   0 root         (0) root         (0)     8790 2023-05-04 17:42:32.720379 dagster-1.3.3/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)     7167 2023-05-04 17:42:13.000000 dagster-1.3.3/README.md
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.660379 dagster-1.3.3/dagster/
+-rw-r--r--   0 root         (0) root         (0)    25858 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/__init__.py
+-rw-r--r--   0 root         (0) root         (0)       31 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/__main__.py
+-rw-r--r--   0 root         (0) root         (0)     5456 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_annotations.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.660379 dagster-1.3.3/dagster/_api/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_api/__init__.py
+-rw-r--r--   0 root         (0) root         (0)      731 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_api/get_server_id.py
+-rw-r--r--   0 root         (0) root         (0)     2147 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_api/list_repositories.py
+-rw-r--r--   0 root         (0) root         (0)      531 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_api/notebook_data.py
+-rw-r--r--   0 root         (0) root         (0)     2900 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_api/snapshot_execution_plan.py
+-rw-r--r--   0 root         (0) root         (0)     1639 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_api/snapshot_job.py
+-rw-r--r--   0 root         (0) root         (0)     5479 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_api/snapshot_partition.py
+-rw-r--r--   0 root         (0) root         (0)     1668 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_api/snapshot_repository.py
+-rw-r--r--   0 root         (0) root         (0)     2727 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_api/snapshot_schedule.py
+-rw-r--r--   0 root         (0) root         (0)     2901 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_api/snapshot_sensor.py
+-rw-r--r--   0 root         (0) root         (0)      478 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_builtins.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.660379 dagster-1.3.3/dagster/_check/
+-rw-r--r--   0 root         (0) root         (0)     1352 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_check/README.md
+-rw-r--r--   0 root         (0) root         (0)    51637 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_check/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.664379 dagster-1.3.3/dagster/_cli/
+-rw-r--r--   0 root         (0) root         (0)     1101 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    26765 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/api.py
+-rw-r--r--   0 root         (0) root         (0)     8186 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/asset.py
+-rw-r--r--   0 root         (0) root         (0)     2300 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/config_scaffolder.py
+-rw-r--r--   0 root         (0) root         (0)     3533 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/debug.py
+-rw-r--r--   0 root         (0) root         (0)     5718 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/dev.py
+-rw-r--r--   0 root         (0) root         (0)     2252 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/instance.py
+-rw-r--r--   0 root         (0) root         (0)    29862 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/job.py
+-rw-r--r--   0 root         (0) root         (0)     1695 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/load_handle.py
+-rw-r--r--   0 root         (0) root         (0)     5852 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/project.py
+-rw-r--r--   0 root         (0) root         (0)     5135 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/run.py
+-rw-r--r--   0 root         (0) root         (0)    19909 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/schedule.py
+-rw-r--r--   0 root         (0) root         (0)    15661 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/sensor.py
+-rw-r--r--   0 root         (0) root         (0)     1409 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.664379 dagster-1.3.3/dagster/_cli/workspace/
+-rw-r--r--   0 root         (0) root         (0)      180 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/workspace/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    28391 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_cli/workspace/cli_target.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.664379 dagster-1.3.3/dagster/_config/
+-rw-r--r--   0 root         (0) root         (0)     3186 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3403 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/config_schema.py
+-rw-r--r--   0 root         (0) root         (0)    14686 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/config_type.py
+-rw-r--r--   0 root         (0) root         (0)    18799 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/errors.py
+-rw-r--r--   0 root         (0) root         (0)     1783 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/evaluate_value_result.py
+-rw-r--r--   0 root         (0) root         (0)    15269 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/field.py
+-rw-r--r--   0 root         (0) root         (0)    16886 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/field_utils.py
+-rw-r--r--   0 root         (0) root         (0)     9466 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/post_process.py
+-rw-r--r--   0 root         (0) root         (0)      855 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/primitive_mapping.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.664379 dagster-1.3.3/dagster/_config/pythonic_config/
+-rw-r--r--   0 root         (0) root         (0)    70752 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/pythonic_config/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1644 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/pythonic_config/attach_other_object_to_context.py
+-rw-r--r--   0 root         (0) root         (0)     6217 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/pythonic_config/typing_utils.py
+-rw-r--r--   0 root         (0) root         (0)      577 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/pythonic_config/utils.py
+-rw-r--r--   0 root         (0) root         (0)    12143 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/snap.py
+-rw-r--r--   0 root         (0) root         (0)     3267 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/source.py
+-rw-r--r--   0 root         (0) root         (0)     3528 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/stack.py
+-rw-r--r--   0 root         (0) root         (0)     7772 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/traversal_context.py
+-rw-r--r--   0 root         (0) root         (0)     4167 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/type_printer.py
+-rw-r--r--   0 root         (0) root         (0)    16671 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_config/validate.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.668379 dagster-1.3.3/dagster/_core/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/__init__.py
+-rw-r--r--   0 root         (0) root         (0)      994 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/assets.py
+-rw-r--r--   0 root         (0) root         (0)    13645 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/code_pointer.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.668379 dagster-1.3.3/dagster/_core/container_context/
+-rw-r--r--   0 root         (0) root         (0)      184 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/container_context/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1277 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/container_context/config.py
+-rw-r--r--   0 root         (0) root         (0)     2310 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/debug.py
+-rw-r--r--   0 root         (0) root         (0)     3005 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/decorator_utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.676379 dagster-1.3.3/dagster/_core/definitions/
+-rw-r--r--   0 root         (0) root         (0)     7626 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    28864 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/asset_graph.py
+-rw-r--r--   0 root         (0) root         (0)    10704 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/asset_graph_subset.py
+-rw-r--r--   0 root         (0) root         (0)     3817 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/asset_in.py
+-rw-r--r--   0 root         (0) root         (0)    36842 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/asset_layer.py
+-rw-r--r--   0 root         (0) root         (0)     5686 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/asset_out.py
+-rw-r--r--   0 root         (0) root         (0)    47123 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/asset_reconciliation_sensor.py
+-rw-r--r--   0 root         (0) root         (0)    17185 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/asset_selection.py
+-rw-r--r--   0 root         (0) root         (0)     7164 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/asset_sensor_definition.py
+-rw-r--r--   0 root         (0) root         (0)    64928 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/assets.py
+-rw-r--r--   0 root         (0) root         (0)    24005 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/assets_job.py
+-rw-r--r--   0 root         (0) root         (0)     3681 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/auto_materialize_policy.py
+-rw-r--r--   0 root         (0) root         (0)    16105 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/cacheable_assets.py
+-rw-r--r--   0 root         (0) root         (0)    45671 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/composition.py
+-rw-r--r--   0 root         (0) root         (0)     4287 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/config.py
+-rw-r--r--   0 root         (0) root         (0)    10845 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/configurable.py
+-rw-r--r--   0 root         (0) root         (0)    20633 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/data_time.py
+-rw-r--r--   0 root         (0) root         (0)    17905 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/data_version.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.676379 dagster-1.3.3/dagster/_core/definitions/decorators/
+-rw-r--r--   0 root         (0) root         (0)      620 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/decorators/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    42826 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/decorators/asset_decorator.py
+-rw-r--r--   0 root         (0) root         (0)     4915 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/decorators/config_mapping_decorator.py
+-rw-r--r--   0 root         (0) root         (0)     8250 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/decorators/graph_decorator.py
+-rw-r--r--   0 root         (0) root         (0)     9444 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/decorators/hook_decorator.py
+-rw-r--r--   0 root         (0) root         (0)    10676 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/decorators/job_decorator.py
+-rw-r--r--   0 root         (0) root         (0)    17845 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/decorators/op_decorator.py
+-rw-r--r--   0 root         (0) root         (0)    14396 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/decorators/repository_decorator.py
+-rw-r--r--   0 root         (0) root         (0)     8656 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/decorators/schedule_decorator.py
+-rw-r--r--   0 root         (0) root         (0)    11936 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/decorators/sensor_decorator.py
+-rw-r--r--   0 root         (0) root         (0)     6695 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/decorators/source_asset_decorator.py
+-rw-r--r--   0 root         (0) root         (0)     5275 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/definition_config_schema.py
+-rw-r--r--   0 root         (0) root         (0)    20546 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/definitions_class.py
+-rw-r--r--   0 root         (0) root         (0)    39903 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/dependency.py
+-rw-r--r--   0 root         (0) root         (0)    31182 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/events.py
+-rw-r--r--   0 root         (0) root         (0)    21013 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/executor_definition.py
+-rw-r--r--   0 root         (0) root         (0)    10548 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/external_asset_graph.py
+-rw-r--r--   0 root         (0) root         (0)     8010 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/freshness_policy.py
+-rw-r--r--   0 root         (0) root         (0)    16178 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/freshness_policy_sensor_definition.py
+-rw-r--r--   0 root         (0) root         (0)    44758 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/graph_definition.py
+-rw-r--r--   0 root         (0) root         (0)     6546 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/hook_definition.py
+-rw-r--r--   0 root         (0) root         (0)     1515 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/hook_invocation.py
+-rw-r--r--   0 root         (0) root         (0)     3205 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/inference.py
+-rw-r--r--   0 root         (0) root         (0)    22898 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/input.py
+-rw-r--r--   0 root         (0) root         (0)     5386 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/instigation_logger.py
+-rw-r--r--   0 root         (0) root         (0)     5816 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/job_base.py
+-rw-r--r--   0 root         (0) root         (0)    55438 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/job_definition.py
+-rw-r--r--   0 root         (0) root         (0)    20308 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/load_assets_from_modules.py
+-rw-r--r--   0 root         (0) root         (0)     6845 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/logger_definition.py
+-rw-r--r--   0 root         (0) root         (0)      636 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/logger_invocation.py
+-rw-r--r--   0 root         (0) root         (0)     8841 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/materialize.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.676379 dagster-1.3.3/dagster/_core/definitions/metadata/
+-rw-r--r--   0 root         (0) root         (0)    32319 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/metadata/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     8557 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/metadata/table.py
+-rw-r--r--   0 root         (0) root         (0)    55971 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/multi_asset_sensor_definition.py
+-rw-r--r--   0 root         (0) root         (0)    20758 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/multi_dimensional_partitions.py
+-rw-r--r--   0 root         (0) root         (0)       82 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/no_step_launcher.py
+-rw-r--r--   0 root         (0) root         (0)    11927 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/node_container.py
+-rw-r--r--   0 root         (0) root         (0)     8041 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/node_definition.py
+-rw-r--r--   0 root         (0) root         (0)     2867 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/observe.py
+-rw-r--r--   0 root         (0) root         (0)    22629 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/op_definition.py
+-rw-r--r--   0 root         (0) root         (0)    19256 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/op_invocation.py
+-rw-r--r--   0 root         (0) root         (0)    18908 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/output.py
+-rw-r--r--   0 root         (0) root         (0)    37618 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/partition.py
+-rw-r--r--   0 root         (0) root         (0)      196 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/partition_key_range.py
+-rw-r--r--   0 root         (0) root         (0)    46488 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/partition_mapping.py
+-rw-r--r--   0 root         (0) root         (0)     8811 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/partitioned_schedule.py
+-rw-r--r--   0 root         (0) root         (0)     3779 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/policy.py
+-rw-r--r--   0 root         (0) root         (0)    30198 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/reconstruct.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.676379 dagster-1.3.3/dagster/_core/definitions/repository_definition/
+-rw-r--r--   0 root         (0) root         (0)      654 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/repository_definition/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6670 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/repository_definition/caching_index.py
+-rw-r--r--   0 root         (0) root         (0)    18856 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/repository_definition/repository_data.py
+-rw-r--r--   0 root         (0) root         (0)    17401 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/repository_definition/repository_data_builder.py
+-rw-r--r--   0 root         (0) root         (0)    16972 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/repository_definition/repository_definition.py
+-rw-r--r--   0 root         (0) root         (0)     1479 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/repository_definition/valid_definitions.py
+-rw-r--r--   0 root         (0) root         (0)     5108 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/resolved_asset_deps.py
+-rw-r--r--   0 root         (0) root         (0)     1336 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/resource_annotation.py
+-rw-r--r--   0 root         (0) root         (0)    16162 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/resource_definition.py
+-rw-r--r--   0 root         (0) root         (0)     5398 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/resource_invocation.py
+-rw-r--r--   0 root         (0) root         (0)     7806 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/resource_requirement.py
+-rw-r--r--   0 root         (0) root         (0)    24309 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/run_config.py
+-rw-r--r--   0 root         (0) root         (0)     1445 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/run_config_schema.py
+-rw-r--r--   0 root         (0) root         (0)    14601 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/run_request.py
+-rw-r--r--   0 root         (0) root         (0)    38400 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/run_status_sensor_definition.py
+-rw-r--r--   0 root         (0) root         (0)    36722 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/schedule_definition.py
+-rw-r--r--   0 root         (0) root         (0)     5189 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/scoped_resources_builder.py
+-rw-r--r--   0 root         (0) root         (0)    10722 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/selector.py
+-rw-r--r--   0 root         (0) root         (0)    46040 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/sensor_definition.py
+-rw-r--r--   0 root         (0) root         (0)    14250 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/source_asset.py
+-rw-r--r--   0 root         (0) root         (0)     2298 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/step_launcher.py
+-rw-r--r--   0 root         (0) root         (0)     1541 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/target.py
+-rw-r--r--   0 root         (0) root         (0)      473 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/test_op_definition.py
+-rw-r--r--   0 root         (0) root         (0)    10288 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/time_window_partition_mapping.py
+-rw-r--r--   0 root         (0) root         (0)    74641 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/time_window_partitions.py
+-rw-r--r--   0 root         (0) root         (0)    15645 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/unresolved_asset_job_definition.py
+-rw-r--r--   0 root         (0) root         (0)     7992 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/utils.py
+-rw-r--r--   0 root         (0) root         (0)     2930 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/definitions/version_strategy.py
+-rw-r--r--   0 root         (0) root         (0)    25453 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/errors.py
+-rw-r--r--   0 root         (0) root         (0)     6232 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/event_api.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.680379 dagster-1.3.3/dagster/_core/events/
+-rw-r--r--   0 root         (0) root         (0)    64981 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/events/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7783 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/events/log.py
+-rw-r--r--   0 root         (0) root         (0)     1614 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/events/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.680379 dagster-1.3.3/dagster/_core/execution/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    38808 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/api.py
+-rw-r--r--   0 root         (0) root         (0)    29354 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/asset_backfill.py
+-rw-r--r--   0 root         (0) root         (0)    14156 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/backfill.py
+-rw-r--r--   0 root         (0) root         (0)     6326 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/build_resources.py
+-rw-r--r--   0 root         (0) root         (0)      224 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/bulk_actions.py
+-rw-r--r--   0 root         (0) root         (0)     5587 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/compute_logs.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.684379 dagster-1.3.3/dagster/_core/execution/context/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/context/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    21992 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/context/compute.py
+-rw-r--r--   0 root         (0) root         (0)    15991 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/context/hook.py
+-rw-r--r--   0 root         (0) root         (0)     9369 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/context/init.py
+-rw-r--r--   0 root         (0) root         (0)    26841 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/context/input.py
+-rw-r--r--   0 root         (0) root         (0)    27417 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/context/invocation.py
+-rw-r--r--   0 root         (0) root         (0)     3164 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/context/logger.py
+-rw-r--r--   0 root         (0) root         (0)    33975 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/context/output.py
+-rw-r--r--   0 root         (0) root         (0)    44193 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/context/system.py
+-rw-r--r--   0 root         (0) root         (0)    18549 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/context_creation_job.py
+-rw-r--r--   0 root         (0) root         (0)     5149 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/execute_in_process.py
+-rw-r--r--   0 root         (0) root         (0)     5427 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/execute_in_process_result.py
+-rw-r--r--   0 root         (0) root         (0)     6479 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/execute_job_result.py
+-rw-r--r--   0 root         (0) root         (0)     9183 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/execution_result.py
+-rw-r--r--   0 root         (0) root         (0)     8643 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/host_mode.py
+-rw-r--r--   0 root         (0) root         (0)    14467 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/job_backfill.py
+-rw-r--r--   0 root         (0) root         (0)      998 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/memoization.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.684379 dagster-1.3.3/dagster/_core/execution/plan/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    23031 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/active.py
+-rw-r--r--   0 root         (0) root         (0)     7279 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/compute.py
+-rw-r--r--   0 root         (0) root         (0)    12550 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/compute_generator.py
+-rw-r--r--   0 root         (0) root         (0)    16275 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/execute_plan.py
+-rw-r--r--   0 root         (0) root         (0)    27355 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/execute_step.py
+-rw-r--r--   0 root         (0) root         (0)    10051 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/external_step.py
+-rw-r--r--   0 root         (0) root         (0)     3664 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/handle.py
+-rw-r--r--   0 root         (0) root         (0)    37831 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/inputs.py
+-rw-r--r--   0 root         (0) root         (0)     1159 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/local_external_step_main.py
+-rw-r--r--   0 root         (0) root         (0)     5395 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/objects.py
+-rw-r--r--   0 root         (0) root         (0)     7057 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/outputs.py
+-rw-r--r--   0 root         (0) root         (0)    59386 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/plan.py
+-rw-r--r--   0 root         (0) root         (0)      114 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/resume_retry.py
+-rw-r--r--   0 root         (0) root         (0)    15616 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/state.py
+-rw-r--r--   0 root         (0) root         (0)    15920 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/step.py
+-rw-r--r--   0 root         (0) root         (0)     3796 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/plan/utils.py
+-rw-r--r--   0 root         (0) root         (0)     1762 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/poll_compute_logs.py
+-rw-r--r--   0 root         (0) root         (0)     8186 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/resolve_versions.py
+-rw-r--r--   0 root         (0) root         (0)    19377 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/resources_init.py
+-rw-r--r--   0 root         (0) root         (0)    25847 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/results.py
+-rw-r--r--   0 root         (0) root         (0)     2104 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/retries.py
+-rw-r--r--   0 root         (0) root         (0)     1651 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/run_cancellation_thread.py
+-rw-r--r--   0 root         (0) root         (0)    10329 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/stats.py
+-rw-r--r--   0 root         (0) root         (0)     1125 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/tags.py
+-rw-r--r--   0 root         (0) root         (0)     1172 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/validate_run_config.py
+-rw-r--r--   0 root         (0) root         (0)     1282 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/watch_orphans.py
+-rw-r--r--   0 root         (0) root         (0)     4233 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/execution/with_resources.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.684379 dagster-1.3.3/dagster/_core/executor/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/executor/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1265 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/executor/base.py
+-rw-r--r--   0 root         (0) root         (0)     5990 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/executor/child_process_executor.py
+-rw-r--r--   0 root         (0) root         (0)     2840 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/executor/in_process.py
+-rw-r--r--   0 root         (0) root         (0)     1509 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/executor/init.py
+-rw-r--r--   0 root         (0) root         (0)    15667 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/executor/multiprocess.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.684379 dagster-1.3.3/dagster/_core/executor/step_delegating/
+-rw-r--r--   0 root         (0) root         (0)      247 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/executor/step_delegating/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    14328 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/executor/step_delegating/step_delegating_executor.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.688379 dagster-1.3.3/dagster/_core/executor/step_delegating/step_handler/
+-rw-r--r--   0 root         (0) root         (0)      152 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/executor/step_delegating/step_handler/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3078 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/executor/step_delegating/step_handler/base.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.688379 dagster-1.3.3/dagster/_core/host_representation/
+-rw-r--r--   0 root         (0) root         (0)     2789 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/host_representation/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    33528 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/host_representation/code_location.py
+-rw-r--r--   0 root         (0) root         (0)    32103 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/host_representation/external.py
+-rw-r--r--   0 root         (0) root         (0)    69385 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/host_representation/external_data.py
+-rw-r--r--   0 root         (0) root         (0)    11276 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/host_representation/grpc_server_registry.py
+-rw-r--r--   0 root         (0) root         (0)     1487 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/host_representation/grpc_server_state_subscriber.py
+-rw-r--r--   0 root         (0) root         (0)     4333 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/host_representation/handle.py
+-rw-r--r--   0 root         (0) root         (0)     1581 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/host_representation/historical.py
+-rw-r--r--   0 root         (0) root         (0)     4850 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/host_representation/job_index.py
+-rw-r--r--   0 root         (0) root         (0)    17368 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/host_representation/origin.py
+-rw-r--r--   0 root         (0) root         (0)     3606 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/host_representation/represented.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.688379 dagster-1.3.3/dagster/_core/instance/
+-rw-r--r--   0 root         (0) root         (0)   102059 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/instance/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    11577 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/instance/config.py
+-rw-r--r--   0 root         (0) root         (0)    24318 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/instance/ref.py
+-rw-r--r--   0 root         (0) root         (0)     4567 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/instance_for_test.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.688379 dagster-1.3.3/dagster/_core/launcher/
+-rw-r--r--   0 root         (0) root         (0)      297 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/launcher/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3639 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/launcher/base.py
+-rw-r--r--   0 root         (0) root         (0)     6628 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/launcher/default_run_launcher.py
+-rw-r--r--   0 root         (0) root         (0)     1586 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/launcher/sync_in_memory_run_launcher.py
+-rw-r--r--   0 root         (0) root         (0)      473 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/libraries.py
+-rw-r--r--   0 root         (0) root         (0)    17249 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/log_manager.py
+-rw-r--r--   0 root         (0) root         (0)     1029 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/nux.py
+-rw-r--r--   0 root         (0) root         (0)     3691 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/origin.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.688379 dagster-1.3.3/dagster/_core/run_coordinator/
+-rw-r--r--   0 root         (0) root         (0)      267 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/run_coordinator/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2005 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/run_coordinator/base.py
+-rw-r--r--   0 root         (0) root         (0)     1922 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/run_coordinator/default_run_coordinator.py
+-rw-r--r--   0 root         (0) root         (0)    11030 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/run_coordinator/queued_run_coordinator.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.688379 dagster-1.3.3/dagster/_core/scheduler/
+-rw-r--r--   0 root         (0) root         (0)      534 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/scheduler/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1241 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/scheduler/execution.py
+-rw-r--r--   0 root         (0) root         (0)    18194 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/scheduler/instigation.py
+-rw-r--r--   0 root         (0) root         (0)     9410 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/scheduler/scheduler.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.692379 dagster-1.3.3/dagster/_core/secrets/
+-rw-r--r--   0 root         (0) root         (0)       51 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/secrets/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1777 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/secrets/env_file.py
+-rw-r--r--   0 root         (0) root         (0)      388 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/secrets/loader.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.692379 dagster-1.3.3/dagster/_core/selector/
+-rw-r--r--   0 root         (0) root         (0)      305 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/selector/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    20251 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/selector/subset_selector.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.692379 dagster-1.3.3/dagster/_core/snap/
+-rw-r--r--   0 root         (0) root         (0)     2815 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/snap/__init__.py
+-rw-r--r--   0 root         (0) root         (0)      494 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/snap/config_types.py
+-rw-r--r--   0 root         (0) root         (0)     3999 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/snap/dagster_types.py
+-rw-r--r--   0 root         (0) root         (0)     9421 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/snap/dep_snapshot.py
+-rw-r--r--   0 root         (0) root         (0)    12099 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/snap/execution_plan_snapshot.py
+-rw-r--r--   0 root         (0) root         (0)    16629 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/snap/job_snapshot.py
+-rw-r--r--   0 root         (0) root         (0)     4495 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/snap/mode.py
+-rw-r--r--   0 root         (0) root         (0)    14452 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/snap/node.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.696379 dagster-1.3.3/dagster/_core/storage/
+-rw-r--r--   0 root         (0) root         (0)     3057 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/DEVELOPING.md
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.696379 dagster-1.3.3/dagster/_core/storage/alembic/
+-rw-r--r--   0 root         (0) root         (0)     6676 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/README.md
+-rw-r--r--   0 root         (0) root         (0)      687 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/env.py
+-rw-r--r--   0 root         (0) root         (0)      494 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/script.py.mako
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.704379 dagster-1.3.3/dagster/_core/storage/alembic/versions/
+-rw-r--r--   0 root         (0) root         (0)     3150 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/001_initial_1.py
+-rw-r--r--   0 root         (0) root         (0)      311 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/001_initial_schedule.py
+-rw-r--r--   0 root         (0) root         (0)     1353 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      598 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      972 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      972 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     2548 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/004_add_snapshots_to_run_storage.py
+-rw-r--r--   0 root         (0) root         (0)     1405 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/005_add_asset_key_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     1405 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/005_add_asset_key_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     1130 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/006_scheduler_update_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      952 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/007_create_run_id_idx_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      952 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/007_create_run_id_idx_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      955 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/008_add_run_tags_index_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      955 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/008_add_run_tags_index_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     1170 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/009_add_partition_column_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     1170 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/009_add_partition_column_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     1729 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     1729 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     1146 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     1124 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_1.py
+-rw-r--r--   0 root         (0) root         (0)     1142 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_2.py
+-rw-r--r--   0 root         (0) root         (0)      416 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/012_0_10_0_create_new_run_tables_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      416 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/012_0_10_0_create_new_run_tables_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      434 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/013_0_10_0_create_new_event_log_tables_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      434 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/013_0_10_0_create_new_event_log_tables_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      431 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/014_0_10_0_create_new_schedule_tables_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      431 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/014_0_10_0_create_new_schedule_tables_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     3926 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     3926 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      408 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/016_add_bulk_actions_table_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      408 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/016_add_bulk_actions_table_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      935 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/017_add_run_status_index_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      935 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/017_add_run_status_index_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      325 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/017_initial_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      420 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/018_add_asset_tags_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      420 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/018_add_asset_tags_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      420 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/018_add_asset_tags_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     1569 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     1569 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      409 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/020_add_column_asset_body_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      409 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/020_add_column_asset_body_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      409 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/020_add_column_asset_body_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/021_add_column_mode_mysql.py
+-rw-r--r--   0 root         (0) root         (0)     1031 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/021_add_column_mode_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/021_add_column_mode_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      432 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/022_extract_asset_keys_index_columns_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      432 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/022_extract_asset_keys_index_columns_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      432 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/022_extract_asset_keys_index_columns_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      420 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/023_add_event_log_event_type_idx_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      420 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/023_add_event_log_event_type_idx_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      420 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/023_add_event_log_event_type_idx_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      530 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_mysql.py
+-rw-r--r--   0 root         (0) root         (0)     1274 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_postgres.py
+-rw-r--r--   0 root         (0) root         (0)     1274 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      403 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/025_add_range_index_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      403 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/025_add_range_index_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      403 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/025_add_range_index_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      634 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/026_convert_start_end_times_format_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      433 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/027_add_migration_table_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      433 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/027_add_migration_table_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      433 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/027_add_migration_table_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      409 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/028_add_instigators_table_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      409 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/028_add_instigators_table_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      409 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/028_add_instigators_table_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)      415 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/029_add_tick_selector_index_mysql.py
+-rw-r--r--   0 root         (0) root         (0)      415 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/029_add_tick_selector_index_postgres.py
+-rw-r--r--   0 root         (0) root         (0)      415 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/029_add_tick_selector_index_sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     1892 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/030_add_columns_action_type_and_selector_id_.py
+-rw-r--r--   0 root         (0) root         (0)      957 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/031_add_kvs_table.py
+-rw-r--r--   0 root         (0) root         (0)      498 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/032_rebuild_event_indexes.py
+-rw-r--r--   0 root         (0) root         (0)     1950 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/033_add_asset_event_tags_table.py
+-rw-r--r--   0 root         (0) root         (0)      428 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/034_add_cached_status_data_column.py
+-rw-r--r--   0 root         (0) root         (0)      426 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/035_add_run_job_index.py
+-rw-r--r--   0 root         (0) root         (0)     1536 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/036_add_dynamic_partitions_table.py
+-rw-r--r--   0 root         (0) root         (0)     2480 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/037_d9092588866f_add_primary_key_cols.py
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/alembic/versions/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     7205 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/asset_value_loader.py
+-rw-r--r--   0 root         (0) root         (0)     1215 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/base_storage.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.704379 dagster-1.3.3/dagster/_core/storage/branching/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/branching/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4304 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/branching/branching_io_manager.py
+-rw-r--r--   0 root         (0) root         (0)     8736 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/captured_log_manager.py
+-rw-r--r--   0 root         (0) root         (0)    16247 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/cloud_storage_compute_log_manager.py
+-rw-r--r--   0 root         (0) root         (0)     9545 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/compute_log_manager.py
+-rw-r--r--   0 root         (0) root         (0)     1863 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/config.py
+-rw-r--r--   0 root         (0) root         (0)      417 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/daemon_cursor.py
+-rw-r--r--   0 root         (0) root         (0)    23527 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/dagster_run.py
+-rw-r--r--   0 root         (0) root         (0)    11544 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/db_io_manager.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.704379 dagster-1.3.3/dagster/_core/storage/event_log/
+-rw-r--r--   0 root         (0) root         (0)      742 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/event_log/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    14274 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/event_log/base.py
+-rw-r--r--   0 root         (0) root         (0)     3630 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/event_log/in_memory.py
+-rw-r--r--   0 root         (0) root         (0)     7211 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/event_log/migration.py
+-rw-r--r--   0 root         (0) root         (0)     7776 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/event_log/polling_event_watcher.py
+-rw-r--r--   0 root         (0) root         (0)     5090 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/event_log/schema.py
+-rw-r--r--   0 root         (0) root         (0)    78141 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/event_log/sql_event_log.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.704379 dagster-1.3.3/dagster/_core/storage/event_log/sqlite/
+-rw-r--r--   0 root         (0) root         (0)      200 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/event_log/sqlite/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.704379 dagster-1.3.3/dagster/_core/storage/event_log/sqlite/alembic/
+-rw-r--r--   0 root         (0) root         (0)     1040 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/event_log/sqlite/alembic/alembic.ini
+-rw-r--r--   0 root         (0) root         (0)     7408 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/event_log/sqlite/consolidated_sqlite_event_log.py
+-rw-r--r--   0 root         (0) root         (0)    18950 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/event_log/sqlite/sqlite_event_log.py
+-rw-r--r--   0 root         (0) root         (0)    10912 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/file_manager.py
+-rw-r--r--   0 root         (0) root         (0)    13217 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/fs_io_manager.py
+-rw-r--r--   0 root         (0) root         (0)     8915 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/input_manager.py
+-rw-r--r--   0 root         (0) root         (0)    10638 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/io_manager.py
+-rw-r--r--   0 root         (0) root         (0)    26162 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/legacy_storage.py
+-rw-r--r--   0 root         (0) root         (0)    17301 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/local_compute_log_manager.py
+-rw-r--r--   0 root         (0) root         (0)      876 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/mem_io_manager.py
+-rw-r--r--   0 root         (0) root         (0)     4293 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/memoizable_io_manager.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.704379 dagster-1.3.3/dagster/_core/storage/migration/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/migration/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    14469 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/migration/utils.py
+-rw-r--r--   0 root         (0) root         (0)     3186 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/noop_compute_log_manager.py
+-rw-r--r--   0 root         (0) root         (0)     2361 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/output_manager.py
+-rw-r--r--   0 root         (0) root         (0)    23189 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/partition_status_cache.py
+-rw-r--r--   0 root         (0) root         (0)     2121 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/root.py
+-rw-r--r--   0 root         (0) root         (0)     8509 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/root_input_manager.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.704379 dagster-1.3.3/dagster/_core/storage/runs/
+-rw-r--r--   0 root         (0) root         (0)      386 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/runs/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    15454 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/runs/base.py
+-rw-r--r--   0 root         (0) root         (0)     2291 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/runs/in_memory.py
+-rw-r--r--   0 root         (0) root         (0)     8635 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/runs/migration.py
+-rw-r--r--   0 root         (0) root         (0)     5982 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/runs/schema.py
+-rw-r--r--   0 root         (0) root         (0)    46394 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/runs/sql_run_storage.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.704379 dagster-1.3.3/dagster/_core/storage/runs/sqlite/
+-rw-r--r--   0 root         (0) root         (0)       69 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/runs/sqlite/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.704379 dagster-1.3.3/dagster/_core/storage/runs/sqlite/alembic/
+-rw-r--r--   0 root         (0) root         (0)     1040 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/runs/sqlite/alembic/alembic.ini
+-rw-r--r--   0 root         (0) root         (0)     6822 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/runs/sqlite/sqlite_run_storage.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.708379 dagster-1.3.3/dagster/_core/storage/schedules/
+-rw-r--r--   0 root         (0) root         (0)      272 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/schedules/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5344 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/schedules/base.py
+-rw-r--r--   0 root         (0) root         (0)     4095 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/schedules/migration.py
+-rw-r--r--   0 root         (0) root         (0)     2776 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/schedules/schema.py
+-rw-r--r--   0 root         (0) root         (0)    19749 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/schedules/sql_schedule_storage.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.708379 dagster-1.3.3/dagster/_core/storage/schedules/sqlite/
+-rw-r--r--   0 root         (0) root         (0)       84 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/schedules/sqlite/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.708379 dagster-1.3.3/dagster/_core/storage/schedules/sqlite/alembic/
+-rw-r--r--   0 root         (0) root         (0)     1039 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/schedules/sqlite/alembic/alembic.ini
+-rw-r--r--   0 root         (0) root         (0)     3664 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/schedules/sqlite/sqlite_schedule_storage.py
+-rw-r--r--   0 root         (0) root         (0)     7375 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/sql.py
+-rw-r--r--   0 root         (0) root         (0)      926 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/sqlite.py
+-rw-r--r--   0 root         (0) root         (0)     4863 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/sqlite_storage.py
+-rw-r--r--   0 root         (0) root         (0)     3085 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/tags.py
+-rw-r--r--   0 root         (0) root         (0)     1128 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/temp_file_manager.py
+-rw-r--r--   0 root         (0) root         (0)    11346 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/storage/upath_io_manager.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.708379 dagster-1.3.3/dagster/_core/system_config/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/system_config/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    13981 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/system_config/composite_descent.py
+-rw-r--r--   0 root         (0) root         (0)    14855 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/system_config/objects.py
+-rw-r--r--   0 root         (0) root         (0)    27932 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/telemetry.py
+-rw-r--r--   0 root         (0) root         (0)     4824 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/telemetry_upload.py
+-rw-r--r--   0 root         (0) root         (0)    18920 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/test_utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.708379 dagster-1.3.3/dagster/_core/types/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/types/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3163 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/types/builtin_config_schemas.py
+-rw-r--r--   0 root         (0) root         (0)     7298 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/types/config_schema.py
+-rw-r--r--   0 root         (0) root         (0)    35761 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/types/dagster_type.py
+-rw-r--r--   0 root         (0) root         (0)     3579 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/types/decorator.py
+-rw-r--r--   0 root         (0) root         (0)     1846 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/types/loadable_target_origin.py
+-rw-r--r--   0 root         (0) root         (0)     1027 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/types/primitive_mapping.py
+-rw-r--r--   0 root         (0) root         (0)     4881 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/types/python_dict.py
+-rw-r--r--   0 root         (0) root         (0)     2836 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/types/python_set.py
+-rw-r--r--   0 root         (0) root         (0)     3712 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/types/python_tuple.py
+-rw-r--r--   0 root         (0) root         (0)     1772 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/types/transform_typing.py
+-rw-r--r--   0 root         (0) root         (0)     1438 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/utility_ops.py
+-rw-r--r--   0 root         (0) root         (0)     4003 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.712379 dagster-1.3.3/dagster/_core/workspace/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/workspace/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     4722 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/workspace/autodiscovery.py
+-rw-r--r--   0 root         (0) root         (0)     3478 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/workspace/config_schema.py
+-rw-r--r--   0 root         (0) root         (0)    26620 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/workspace/context.py
+-rw-r--r--   0 root         (0) root         (0)    11881 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/workspace/load.py
+-rw-r--r--   0 root         (0) root         (0)     4684 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/workspace/load_target.py
+-rw-r--r--   0 root         (0) root         (0)     3952 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/workspace/permissions.py
+-rw-r--r--   0 root         (0) root         (0)     1912 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_core/workspace/workspace.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.712379 dagster-1.3.3/dagster/_daemon/
+-rw-r--r--   0 root         (0) root         (0)     1930 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/__init__.py
+-rw-r--r--   0 root         (0) root         (0)       30 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/__main__.py
+-rw-r--r--   0 root         (0) root         (0)     5235 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/asset_daemon.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.712379 dagster-1.3.3/dagster/_daemon/auto_run_reexecution/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/auto_run_reexecution/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6828 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/auto_run_reexecution/auto_run_reexecution.py
+-rw-r--r--   0 root         (0) root         (0)     9123 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/auto_run_reexecution/event_log_consumer.py
+-rw-r--r--   0 root         (0) root         (0)     1936 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/backfill.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.712379 dagster-1.3.3/dagster/_daemon/cli/
+-rw-r--r--   0 root         (0) root         (0)     4422 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/cli/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    17726 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/controller.py
+-rw-r--r--   0 root         (0) root         (0)    10457 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/daemon.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.712379 dagster-1.3.3/dagster/_daemon/monitoring/
+-rw-r--r--   0 root         (0) root         (0)      215 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/monitoring/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     8365 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/monitoring/monitoring_daemon.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.712379 dagster-1.3.3/dagster/_daemon/run_coordinator/
+-rw-r--r--   0 root         (0) root         (0)      100 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/run_coordinator/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    16247 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/run_coordinator/queued_run_coordinator_daemon.py
+-rw-r--r--   0 root         (0) root         (0)    36568 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/sensor.py
+-rw-r--r--   0 root         (0) root         (0)     2860 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/types.py
+-rw-r--r--   0 root         (0) root         (0)     6639 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_daemon/workspace.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.712379 dagster-1.3.3/dagster/_experimental/
+-rw-r--r--   0 root         (0) root         (0)      300 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_experimental/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.712379 dagster-1.3.3/dagster/_generate/
+-rw-r--r--   0 root         (0) root         (0)      253 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2695 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/download.py
+-rw-r--r--   0 root         (0) root         (0)     4805 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/generate.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.656379 dagster-1.3.3/dagster/_generate/templates/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.712379 dagster-1.3.3/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.712379 dagster-1.3.3/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER/
+-rw-r--r--   0 root         (0) root         (0)      175 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER/__init__.py
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER/assets.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.712379 dagster-1.3.3/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER_tests/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER_tests/__init__.py
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/CODE_LOCATION_NAME_PLACEHOLDER_tests/test_assets.py.tmpl
+-rw-r--r--   0 root         (0) root         (0)      137 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/pyproject.toml.tmpl
+-rw-r--r--   0 root         (0) root         (0)       43 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/setup.cfg.tmpl
+-rw-r--r--   0 root         (0) root         (0)      285 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/CODE_LOCATION_NAME_PLACEHOLDER/setup.py.tmpl
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.712379 dagster-1.3.3/dagster/_generate/templates/PROJECT_NAME_PLACEHOLDER/
+-rw-r--r--   0 root         (0) root         (0)     1753 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/PROJECT_NAME_PLACEHOLDER/README.md
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.712379 dagster-1.3.3/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.716379 dagster-1.3.3/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/
+-rw-r--r--   0 root         (0) root         (0)       40 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/__init__.py.tmpl
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/assets.py
+-rw-r--r--   0 root         (0) root         (0)      164 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER/repository.py.tmpl
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.716379 dagster-1.3.3/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER_tests/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER_tests/__init__.py
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/REPO_NAME_PLACEHOLDER_tests/test_assets.py.tmpl
+-rw-r--r--   0 root         (0) root         (0)       80 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/pyproject.toml
+-rw-r--r--   0 root         (0) root         (0)       34 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/setup.cfg.tmpl
+-rw-r--r--   0 root         (0) root         (0)      267 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_generate/templates/REPO_NAME_PLACEHOLDER/setup.py.tmpl
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.716379 dagster-1.3.3/dagster/_grpc/
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.716379 dagster-1.3.3/dagster/_grpc/__generated__/
+-rw-r--r--   0 root         (0) root         (0)      178 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_grpc/__generated__/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    11665 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_grpc/__generated__/api_pb2.py
+-rw-r--r--   0 root         (0) root         (0)    38179 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_grpc/__generated__/api_pb2_grpc.py
+-rw-r--r--   0 root         (0) root         (0)     2051 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_grpc/__init__.py
+-rw-r--r--   0 root         (0) root         (0)       89 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_grpc/__main__.py
+-rw-r--r--   0 root         (0) root         (0)    18501 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_grpc/client.py
+-rw-r--r--   0 root         (0) root         (0)     4202 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_grpc/compile.py
+-rw-r--r--   0 root         (0) root         (0)    22000 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_grpc/impl.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.716379 dagster-1.3.3/dagster/_grpc/protos/
+-rw-r--r--   0 root         (0) root         (0)     5394 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_grpc/protos/api.proto
+-rw-r--r--   0 root         (0) root         (0)    55354 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_grpc/server.py
+-rw-r--r--   0 root         (0) root         (0)     5301 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_grpc/server_watcher.py
+-rw-r--r--   0 root         (0) root         (0)    26359 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_grpc/types.py
+-rw-r--r--   0 root         (0) root         (0)     2323 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_grpc/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.716379 dagster-1.3.3/dagster/_legacy/
+-rw-r--r--   0 root         (0) root         (0)      438 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_legacy/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.716379 dagster-1.3.3/dagster/_loggers/
+-rw-r--r--   0 root         (0) root         (0)     3781 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_loggers/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     3269 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_module_alias_map.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.716379 dagster-1.3.3/dagster/_scheduler/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_scheduler/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    31794 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_scheduler/scheduler.py
+-rw-r--r--   0 root         (0) root         (0)     1361 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_scheduler/stale.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.716379 dagster-1.3.3/dagster/_serdes/
+-rw-r--r--   0 root         (0) root         (0)      629 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_serdes/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     8004 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_serdes/config_class.py
+-rw-r--r--   0 root         (0) root         (0)      142 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_serdes/errors.py
+-rw-r--r--   0 root         (0) root         (0)     7467 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_serdes/ipc.py
+-rw-r--r--   0 root         (0) root         (0)    37037 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_serdes/serdes.py
+-rw-r--r--   0 root         (0) root         (0)      674 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_serdes/utils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.716379 dagster-1.3.3/dagster/_seven/
+-rw-r--r--   0 root         (0) root         (0)     5496 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_seven/__init__.py
+-rw-r--r--   0 root         (0) root         (0)      553 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_seven/abc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.716379 dagster-1.3.3/dagster/_seven/compat/
+-rw-r--r--   0 root         (0) root         (0)      105 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_seven/compat/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     1160 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_seven/compat/pendulum.py
+-rw-r--r--   0 root         (0) root         (0)      383 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_seven/json.py
+-rw-r--r--   0 root         (0) root         (0)      354 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_seven/temp_dir.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.720379 dagster-1.3.3/dagster/_utils/
+-rw-r--r--   0 root         (0) root         (0)    23319 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     8741 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/alert.py
+-rw-r--r--   0 root         (0) root         (0)     6965 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/backcompat.py
+-rw-r--r--   0 root         (0) root         (0)     2250 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/backoff.py
+-rw-r--r--   0 root         (0) root         (0)     4116 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/cached_method.py
+-rw-r--r--   0 root         (0) root         (0)    23668 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/caching_instance_queryer.py
+-rw-r--r--   0 root         (0) root         (0)     2563 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/dagster_type.py
+-rw-r--r--   0 root         (0) root         (0)     4094 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/error.py
+-rw-r--r--   0 root         (0) root         (0)     1273 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/external.py
+-rw-r--r--   0 root         (0) root         (0)      883 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/forked_pdb.py
+-rw-r--r--   0 root         (0) root         (0)     2372 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/hosted_user_process.py
+-rw-r--r--   0 root         (0) root         (0)     2796 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/indenting_printer.py
+-rw-r--r--   0 root         (0) root         (0)      344 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/internal_init.py
+-rw-r--r--   0 root         (0) root         (0)     3227 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/interrupts.py
+-rw-r--r--   0 root         (0) root         (0)     9813 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/log.py
+-rw-r--r--   0 root         (0) root         (0)     2313 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/merger.py
+-rw-r--r--   0 root         (0) root         (0)     1507 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/net.py
+-rw-r--r--   0 root         (0) root         (0)      208 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/partitions.py
+-rw-r--r--   0 root         (0) root         (0)    12340 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/schedules.py
+-rw-r--r--   0 root         (0) root         (0)     3289 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/tags.py
+-rw-r--r--   0 root         (0) root         (0)     1820 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/temp_file.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.720379 dagster-1.3.3/dagster/_utils/test/
+-rw-r--r--   0 root         (0) root         (0)    10412 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/test/__init__.py
+-rw-r--r--   0 root         (0) root         (0)      119 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/test/hello_world_defs.py
+-rw-r--r--   0 root         (0) root         (0)      214 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/test/hello_world_repository.py
+-rw-r--r--   0 root         (0) root         (0)     8622 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/test/mysql_instance.py
+-rw-r--r--   0 root         (0) root         (0)      256 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/test/named_hello_world_repository.py
+-rw-r--r--   0 root         (0) root         (0)     9330 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/test/postgres_instance.py
+-rw-r--r--   0 root         (0) root         (0)    23902 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/test/schedule_storage.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.720379 dagster-1.3.3/dagster/_utils/test/toys/
+-rw-r--r--   0 root         (0) root         (0)       83 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/test/toys/__init__.py
+-rw-r--r--   0 root         (0) root         (0)       84 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/test/toys/single_repository.py
+-rw-r--r--   0 root         (0) root         (0)     2004 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/timing.py
+-rw-r--r--   0 root         (0) root         (0)      170 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/types.py
+-rw-r--r--   0 root         (0) root         (0)     3334 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/typing_api.py
+-rw-r--r--   0 root         (0) root         (0)     4915 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/_utils/yaml_utils.py
+-rw-r--r--   0 root         (0) root         (0)        8 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/py.typed
+-rw-r--r--   0 root         (0) root         (0)       22 2023-05-04 17:42:13.000000 dagster-1.3.3/dagster/version.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2023-05-04 17:42:32.660379 dagster-1.3.3/dagster.egg-info/
+-rw-r--r--   0 root         (0) root         (0)     8790 2023-05-04 17:42:32.000000 dagster-1.3.3/dagster.egg-info/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)    24829 2023-05-04 17:42:32.000000 dagster-1.3.3/dagster.egg-info/SOURCES.txt
+-rw-r--r--   0 root         (0) root         (0)        1 2023-05-04 17:42:32.000000 dagster-1.3.3/dagster.egg-info/dependency_links.txt
+-rw-r--r--   0 root         (0) root         (0)       86 2023-05-04 17:42:32.000000 dagster-1.3.3/dagster.egg-info/entry_points.txt
+-rw-r--r--   0 root         (0) root         (0)     1301 2023-05-04 17:42:32.000000 dagster-1.3.3/dagster.egg-info/requires.txt
+-rw-r--r--   0 root         (0) root         (0)        8 2023-05-04 17:42:32.000000 dagster-1.3.3/dagster.egg-info/top_level.txt
+-rw-r--r--   0 root         (0) root         (0)      154 2023-05-04 17:42:32.724379 dagster-1.3.3/setup.cfg
+-rw-r--r--   0 root         (0) root         (0)     6432 2023-05-04 17:42:14.000000 dagster-1.3.3/setup.py
```

### Comparing `dagster-1.3.2/COPYING` & `dagster-1.3.3/COPYING`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/LICENSE` & `dagster-1.3.3/LICENSE`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/PKG-INFO` & `dagster-1.3.3/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: dagster
-Version: 1.3.2
+Version: 1.3.3
 Summary: The data orchestration platform built for productivity.
 Author: Elementl
 Author-email: hello@elementl.com
 License: Apache-2.0
 Project-URL: Homepage, https://dagster.io
 Project-URL: GitHub, https://github.com/dagster-io/dagster
 Project-URL: Changelog, https://github.com/dagster-io/dagster/releases
```

### Comparing `dagster-1.3.2/README.md` & `dagster-1.3.3/README.md`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/__init__.py` & `dagster-1.3.3/dagster/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -17,14 +17,19 @@
             "dagster.experimental": "dagster._experimental",
             "dagster.generate": "dagster._generate",
             "dagster.grpc": "dagster._grpc",
             "dagster.loggers": "dagster._loggers",
             "dagster.serdes": "dagster._serdes",
             "dagster.seven": "dagster._seven",
             "dagster.utils": "dagster._utils",
+            # Added in 1.3.4 for backcompat when `_core.storage.pipeline_run` was renamed to
+            # `_core.storage.dagster_run`. This was necessary because some docs (incorrectly)
+            # demonstarted a direct import from `dagster._core.storage.pipeline_run` instead of
+            # using the top-level import.
+            "dagster._core.storage.pipeline_run": "dagster.core.storage.dagster_run",
         }
     ),
 )
 
 # ########################
 # ##### NOTES ON IMPORT FORMAT
 # ########################
@@ -445,15 +450,25 @@
 from dagster._core.execution.with_resources import with_resources as with_resources
 from dagster._core.executor.base import Executor as Executor
 from dagster._core.executor.init import InitExecutorContext as InitExecutorContext
 from dagster._core.instance import DagsterInstance as DagsterInstance
 from dagster._core.instance_for_test import instance_for_test as instance_for_test
 from dagster._core.launcher.default_run_launcher import DefaultRunLauncher as DefaultRunLauncher
 from dagster._core.log_manager import DagsterLogManager as DagsterLogManager
+from dagster._core.run_coordinator.queued_run_coordinator import (
+    QueuedRunCoordinator as QueuedRunCoordinator,
+    SubmitRunContext as SubmitRunContext,
+)
 from dagster._core.storage.asset_value_loader import AssetValueLoader as AssetValueLoader
+from dagster._core.storage.dagster_run import (
+    DagsterRun as DagsterRun,
+    DagsterRunStatus as DagsterRunStatus,
+    RunRecord as RunRecord,
+    RunsFilter as RunsFilter,
+)
 from dagster._core.storage.file_manager import (
     FileHandle as FileHandle,
     LocalFileHandle as LocalFileHandle,
     local_file_manager as local_file_manager,
 )
 from dagster._core.storage.fs_io_manager import (
     FilesystemIOManager as FilesystemIOManager,
@@ -470,20 +485,14 @@
     io_manager as io_manager,
 )
 from dagster._core.storage.mem_io_manager import (
     InMemoryIOManager as InMemoryIOManager,
     mem_io_manager as mem_io_manager,
 )
 from dagster._core.storage.memoizable_io_manager import MemoizableIOManager as MemoizableIOManager
-from dagster._core.storage.pipeline_run import (
-    DagsterRun as DagsterRun,
-    DagsterRunStatus as DagsterRunStatus,
-    RunRecord as RunRecord,
-    RunsFilter as RunsFilter,
-)
 from dagster._core.storage.root_input_manager import (
     RootInputManager as RootInputManager,
     RootInputManagerDefinition as RootInputManagerDefinition,
     root_input_manager as root_input_manager,
 )
 from dagster._core.storage.tags import (
     MAX_RUNTIME_SECONDS_TAG as MAX_RUNTIME_SECONDS_TAG,
@@ -511,15 +520,17 @@
     default_system_loggers as default_system_loggers,
     json_console_logger as json_console_logger,
 )
 from dagster._serdes.serdes import (
     deserialize_value as deserialize_value,
     serialize_value as serialize_value,
 )
-from dagster._utils import file_relative_path as file_relative_path
+from dagster._utils import (
+    file_relative_path as file_relative_path,
+)
 from dagster._utils.alert import (
     make_email_on_run_failure_sensor as make_email_on_run_failure_sensor,
 )
 from dagster._utils.backcompat import ExperimentalWarning as ExperimentalWarning
 from dagster._utils.dagster_type import check_dagster_type as check_dagster_type
 from dagster._utils.log import get_dagster_logger as get_dagster_logger
 from dagster.version import __version__ as __version__
```

### Comparing `dagster-1.3.2/dagster/_annotations.py` & `dagster-1.3.3/dagster/_annotations.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_api/get_server_id.py` & `dagster-1.3.3/dagster/_api/get_server_id.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_api/list_repositories.py` & `dagster-1.3.3/dagster/_api/list_repositories.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_api/notebook_data.py` & `dagster-1.3.3/dagster/_api/notebook_data.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_api/snapshot_execution_plan.py` & `dagster-1.3.3/dagster/_api/snapshot_execution_plan.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,61 +1,61 @@
 from typing import TYPE_CHECKING, AbstractSet, Any, Mapping, Optional, Sequence
 
 import dagster._check as check
 from dagster._core.definitions.events import AssetKey
 from dagster._core.errors import DagsterUserCodeProcessError
 from dagster._core.execution.plan.state import KnownExecutionState
 from dagster._core.host_representation.external_data import DEFAULT_MODE_NAME
-from dagster._core.host_representation.origin import ExternalPipelineOrigin
+from dagster._core.host_representation.origin import ExternalJobOrigin
 from dagster._core.instance import DagsterInstance
 from dagster._core.snap.execution_plan_snapshot import (
     ExecutionPlanSnapshot,
     ExecutionPlanSnapshotErrorData,
 )
 from dagster._grpc.types import ExecutionPlanSnapshotArgs
 from dagster._serdes import deserialize_value
 
 if TYPE_CHECKING:
     from dagster._grpc.client import DagsterGrpcClient
 
 
 def sync_get_external_execution_plan_grpc(
     api_client: "DagsterGrpcClient",
-    pipeline_origin: ExternalPipelineOrigin,
+    job_origin: ExternalJobOrigin,
     run_config: Mapping[str, Any],
-    pipeline_snapshot_id: str,
+    job_snapshot_id: str,
     asset_selection: Optional[AbstractSet[AssetKey]] = None,
     solid_selection: Optional[Sequence[str]] = None,
     step_keys_to_execute: Optional[Sequence[str]] = None,
     known_state: Optional[KnownExecutionState] = None,
     instance: Optional[DagsterInstance] = None,
 ) -> ExecutionPlanSnapshot:
     from dagster._grpc.client import DagsterGrpcClient
 
     check.inst_param(api_client, "api_client", DagsterGrpcClient)
-    check.inst_param(pipeline_origin, "pipeline_origin", ExternalPipelineOrigin)
+    check.inst_param(job_origin, "job_origin", ExternalJobOrigin)
     solid_selection = check.opt_sequence_param(solid_selection, "solid_selection", of_type=str)
     asset_selection = check.opt_nullable_set_param(
         asset_selection, "asset_selection", of_type=AssetKey
     )
     run_config = check.mapping_param(run_config, "run_config", key_type=str)
     check.opt_nullable_sequence_param(step_keys_to_execute, "step_keys_to_execute", of_type=str)
-    check.str_param(pipeline_snapshot_id, "pipeline_snapshot_id")
+    check.str_param(job_snapshot_id, "job_snapshot_id")
     check.opt_inst_param(known_state, "known_state", KnownExecutionState)
     check.opt_inst_param(instance, "instance", DagsterInstance)
 
     result = deserialize_value(
         api_client.execution_plan_snapshot(
             execution_plan_snapshot_args=ExecutionPlanSnapshotArgs(
-                pipeline_origin=pipeline_origin,
+                job_origin=job_origin,
                 solid_selection=solid_selection,
                 run_config=run_config,
                 mode=DEFAULT_MODE_NAME,
                 step_keys_to_execute=step_keys_to_execute,
-                pipeline_snapshot_id=pipeline_snapshot_id,
+                job_snapshot_id=job_snapshot_id,
                 known_state=known_state,
                 instance_ref=instance.get_ref() if instance and instance.is_persistent else None,
                 asset_selection=asset_selection,
             )
         ),
         (ExecutionPlanSnapshot, ExecutionPlanSnapshotErrorData),
     )
```

### Comparing `dagster-1.3.2/dagster/_api/snapshot_partition.py` & `dagster-1.3.3/dagster/_api/snapshot_partition.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_api/snapshot_repository.py` & `dagster-1.3.3/dagster/_api/snapshot_repository.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_api/snapshot_schedule.py` & `dagster-1.3.3/dagster/_api/snapshot_schedule.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_api/snapshot_sensor.py` & `dagster-1.3.3/dagster/_api/snapshot_sensor.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_check/README.md` & `dagster-1.3.3/dagster/_check/README.md`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_check/__init__.py` & `dagster-1.3.3/dagster/_check/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_cli/__init__.py` & `dagster-1.3.3/dagster/_cli/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_cli/api.py` & `dagster-1.3.3/dagster/_cli/api.py`

 * *Files 7% similar despite different names*

```diff
@@ -15,31 +15,31 @@
     get_working_directory_from_kwargs,
     python_origin_target_argument,
 )
 from dagster._core.definitions.metadata import MetadataValue
 from dagster._core.errors import DagsterExecutionInterruptedError
 from dagster._core.events import DagsterEvent, DagsterEventType, EngineEventData
 from dagster._core.execution.api import create_execution_plan, execute_plan_iterator
-from dagster._core.execution.context_creation_pipeline import create_context_free_log_manager
+from dagster._core.execution.context_creation_job import create_context_free_log_manager
 from dagster._core.execution.run_cancellation_thread import start_run_cancellation_thread
 from dagster._core.instance import DagsterInstance, InstanceRef
 from dagster._core.origin import (
     DEFAULT_DAGSTER_ENTRY_POINT,
-    PipelinePythonOrigin,
+    JobPythonOrigin,
     get_python_environment_entry_point,
 )
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._core.types.loadable_target_origin import LoadableTargetOrigin
 from dagster._core.utils import coerce_valid_log_level
 from dagster._grpc import DagsterGrpcClient, DagsterGrpcServer
 from dagster._grpc.impl import core_execute_run
 from dagster._grpc.types import ExecuteRunArgs, ExecuteStepArgs, ResumeRunArgs
 from dagster._serdes import deserialize_value, serialize_value
 from dagster._utils.error import serializable_error_info_from_exc_info
-from dagster._utils.hosted_user_process import recon_pipeline_from_origin
+from dagster._utils.hosted_user_process import recon_job_from_origin
 from dagster._utils.interrupts import capture_interrupts
 from dagster._utils.log import configure_loggers
 
 
 @click.group(name="api", hidden=True)
 def api_cli():
     """[INTERNAL] These commands are intended to support internal use cases. Users should generally
@@ -66,68 +66,66 @@
         ) as instance:
             buffer = []
 
             def send_to_buffer(event):
                 buffer.append(serialize_value(event))
 
             return_code = _execute_run_command_body(
-                args.pipeline_run_id,
+                args.run_id,
                 instance,
                 send_to_buffer,
                 set_exit_code_on_failure=args.set_exit_code_on_failure or False,
             )
 
             for line in buffer:
                 click.echo(line)
 
             if return_code != 0:
                 sys.exit(return_code)
 
 
 def _execute_run_command_body(
-    pipeline_run_id: str,
+    run_id: str,
     instance: DagsterInstance,
     write_stream_fn: Callable[[DagsterEvent], Any],
     set_exit_code_on_failure: bool,
 ) -> int:
     if instance.should_start_background_run_thread:
         cancellation_thread, cancellation_thread_shutdown_event = start_run_cancellation_thread(
-            instance, pipeline_run_id
+            instance, run_id
         )
     else:
         cancellation_thread, cancellation_thread_shutdown_event = None, None
 
-    pipeline_run: DagsterRun = check.not_none(
-        instance.get_run_by_id(pipeline_run_id),
-        f"Pipeline run with id '{pipeline_run_id}' not found for run execution.",
+    dagster_run = check.not_none(
+        instance.get_run_by_id(run_id),
+        f"Run with id '{run_id}' not found for run execution.",
     )
 
     check.inst(
-        pipeline_run.pipeline_code_origin,
-        PipelinePythonOrigin,
-        f"Pipeline run with id '{pipeline_run_id}' does not include an origin.",
+        dagster_run.job_code_origin,
+        JobPythonOrigin,
+        f"Run with id '{run_id}' does not include an origin.",
     )
 
-    recon_pipeline = recon_pipeline_from_origin(
-        cast(PipelinePythonOrigin, pipeline_run.pipeline_code_origin)
-    )
+    recon_job = recon_job_from_origin(cast(JobPythonOrigin, dagster_run.job_code_origin))
 
     pid = os.getpid()
     instance.report_engine_event(
         f"Started process for run (pid: {pid}).",
-        pipeline_run,
+        dagster_run,
         EngineEventData.in_process(pid),
     )
 
     run_worker_failed = 0
 
     try:
         for event in core_execute_run(
-            recon_pipeline,
-            pipeline_run,
+            recon_job,
+            dagster_run,
             instance,
             inject_env_vars=True,
         ):
             write_stream_fn(event)
             if event.event_type == DagsterEventType.PIPELINE_FAILURE:
                 run_worker_failed = True
     except:
@@ -139,20 +137,20 @@
             cancellation_thread = check.not_none(cancellation_thread)
             cancellation_thread_shutdown_event.set()
             if cancellation_thread.is_alive():
                 cancellation_thread.join(timeout=15)
                 if cancellation_thread.is_alive():
                     instance.report_engine_event(
                         "Cancellation thread did not shutdown gracefully",
-                        pipeline_run,
+                        dagster_run,
                     )
 
         instance.report_engine_event(
             f"Process for run exited (pid: {pid}).",
-            pipeline_run,
+            dagster_run,
         )
 
     return 1 if (run_worker_failed and set_exit_code_on_failure) else 0
 
 
 @api_cli.command(
     name="resume_run",
@@ -173,66 +171,64 @@
         ) as instance:
             buffer = []
 
             def send_to_buffer(event):
                 buffer.append(serialize_value(event))
 
             return_code = _resume_run_command_body(
-                args.pipeline_run_id,
+                args.run_id,
                 instance,
                 send_to_buffer,
                 set_exit_code_on_failure=args.set_exit_code_on_failure or False,
             )
 
             for line in buffer:
                 click.echo(line)
 
             if return_code != 0:
                 sys.exit(return_code)
 
 
 def _resume_run_command_body(
-    pipeline_run_id: Optional[str],
+    run_id: Optional[str],
     instance: DagsterInstance,
     write_stream_fn: Callable[[DagsterEvent], Any],
     set_exit_code_on_failure: bool,
 ):
     if instance.should_start_background_run_thread:
         cancellation_thread, cancellation_thread_shutdown_event = start_run_cancellation_thread(
-            instance, pipeline_run_id
+            instance, run_id
         )
     else:
         cancellation_thread, cancellation_thread_shutdown_event = None, None
-    pipeline_run = check.not_none(
-        instance.get_run_by_id(pipeline_run_id),  # type: ignore
-        f"Pipeline run with id '{pipeline_run_id}' not found for run execution.",
+    dagster_run = check.not_none(
+        instance.get_run_by_id(run_id),  # type: ignore
+        f"Run with id '{run_id}' not found for run execution.",
     )
     check.inst(
-        pipeline_run.pipeline_code_origin,
-        PipelinePythonOrigin,
-        f"Pipeline run with id '{pipeline_run_id}' does not include an origin.",
+        dagster_run.job_code_origin,
+        JobPythonOrigin,
+        f"Run with id '{run_id}' does not include an origin.",
     )
 
-    recon_pipeline = recon_pipeline_from_origin(
-        cast(PipelinePythonOrigin, pipeline_run.pipeline_code_origin)
-    )
+    recon_job = recon_job_from_origin(cast(JobPythonOrigin, dagster_run.job_code_origin))
 
     pid = os.getpid()
     instance.report_engine_event(
-        f"Started process for resuming pipeline (pid: {pid}).",
-        pipeline_run,
+        f"Started process for resuming job (pid: {pid}).",
+        dagster_run,
         EngineEventData.in_process(pid),
     )
 
     run_worker_failed = False
 
     try:
         for event in core_execute_run(
-            recon_pipeline,
-            pipeline_run,
+            recon_job,
+            dagster_run,
             instance,
             resume_from_failure=True,
             inject_env_vars=True,
         ):
             write_stream_fn(event)
             if event.event_type == DagsterEventType.PIPELINE_FAILURE:
                 run_worker_failed = True
@@ -246,76 +242,76 @@
             cancellation_thread = check.not_none(cancellation_thread)
             cancellation_thread_shutdown_event.set()
             if cancellation_thread.is_alive():
                 cancellation_thread.join(timeout=15)
                 if cancellation_thread.is_alive():
                     instance.report_engine_event(
                         "Cancellation thread did not shutdown gracefully",
-                        pipeline_run,
+                        dagster_run,
                     )
         instance.report_engine_event(
-            f"Process for pipeline exited (pid: {pid}).",
-            pipeline_run,
+            f"Process for job exited (pid: {pid}).",
+            dagster_run,
         )
 
     return 1 if (run_worker_failed and set_exit_code_on_failure) else 0
 
 
-def get_step_stats_by_key(instance, pipeline_run, step_keys_to_execute):
+def get_step_stats_by_key(instance, dagster_run, step_keys_to_execute):
     # When using the k8s executor, there whould only ever be one step key
-    step_stats = instance.get_run_step_stats(pipeline_run.run_id, step_keys=step_keys_to_execute)
+    step_stats = instance.get_run_step_stats(dagster_run.run_id, step_keys=step_keys_to_execute)
     step_stats_by_key = {step_stat.step_key: step_stat for step_stat in step_stats}
     return step_stats_by_key
 
 
-def verify_step(instance, pipeline_run, retry_state, step_keys_to_execute):
-    step_stats_by_key = get_step_stats_by_key(instance, pipeline_run, step_keys_to_execute)
+def verify_step(instance, dagster_run, retry_state, step_keys_to_execute):
+    step_stats_by_key = get_step_stats_by_key(instance, dagster_run, step_keys_to_execute)
 
     for step_key in step_keys_to_execute:
         step_stat_for_key = step_stats_by_key.get(step_key)
         current_attempt = retry_state.get_attempt_count(step_key) + 1
 
         # When using the k8s executor, it is possible to get into an edge case when deleting
         # a step pod. K8s will restart the pod immediately even though we don't want it to.
         # Pod can be deleted manually or due to or node failures (for example, when running on
         # a spot instance that is evicted).
         #
         # If we encounter one of the error cases below, we exit with a success exit code
         # so that we don't cause the "Encountered failed job pods" error.
         #
         # Instead, the step will be marked as being in an unknown state by the executor and the
-        # pipeline will fail accordingly.
+        # job will fail accordingly.
         if current_attempt == 1 and step_stat_for_key:
             # If this is the first attempt, there shouldn't be any step stats for this
             # event yet.
             instance.report_engine_event(
                 "Attempted to run {step_key} again even though it was already started. "
                 "Exiting to prevent re-running the step.".format(step_key=step_key),
-                pipeline_run,
+                dagster_run,
             )
             return False
         elif current_attempt > 1 and step_stat_for_key:
             # If this is a retry, then the number of previous attempts should be exactly one less
             # than the current attempt
 
             if step_stat_for_key.attempts != current_attempt - 1:
                 instance.report_engine_event(
                     "Attempted to run retry attempt {current_attempt} for step {step_key} again "
                     "even though it was already started. Exiting to prevent re-running "
                     "the step.".format(current_attempt=current_attempt, step_key=step_key),
-                    pipeline_run,
+                    dagster_run,
                 )
                 return False
         elif current_attempt > 1 and not step_stat_for_key:
             instance.report_engine_event(
                 "Attempting to retry attempt {current_attempt} for step {step_key} "
                 "but there is no record of the original attempt".format(
                     current_attempt=current_attempt, step_key=step_key
                 ),
-                pipeline_run,
+                dagster_run,
             )
             return False
 
     return True
 
 
 @api_cli.command(
@@ -345,125 +341,123 @@
         args = deserialize_value(input_json, ExecuteStepArgs)
 
         with (
             DagsterInstance.from_ref(args.instance_ref)
             if args.instance_ref
             else DagsterInstance.get()
         ) as instance:
-            pipeline_run = instance.get_run_by_id(args.pipeline_run_id)
+            dagster_run = instance.get_run_by_id(args.run_id)
 
             buff = []
 
             for event in _execute_step_command_body(
                 args,
                 instance,
-                pipeline_run,
+                dagster_run,
             ):
                 buff.append(serialize_value(event))
 
             for line in buff:
                 click.echo(line)
 
 
 def _execute_step_command_body(
-    args: ExecuteStepArgs, instance: DagsterInstance, pipeline_run: DagsterRun
+    args: ExecuteStepArgs, instance: DagsterInstance, dagster_run: DagsterRun
 ):
     single_step_key = (
         args.step_keys_to_execute[0]
         if args.step_keys_to_execute and len(args.step_keys_to_execute) == 1
         else None
     )
     try:
         check.inst(
-            pipeline_run,
+            dagster_run,
             DagsterRun,
-            f"Pipeline run with id '{args.pipeline_run_id}' not found for step execution",
+            f"Run with id '{args.run_id}' not found for step execution",
         )
         check.inst(
-            pipeline_run.pipeline_code_origin,
-            PipelinePythonOrigin,
-            f"Pipeline run with id '{args.pipeline_run_id}' does not include an origin.",
+            dagster_run.job_code_origin,
+            JobPythonOrigin,
+            f"Run with id '{args.run_id}' does not include an origin.",
         )
 
         location_name = (
-            pipeline_run.external_pipeline_origin.location_name
-            if pipeline_run.external_pipeline_origin
+            dagster_run.external_job_origin.location_name
+            if dagster_run.external_job_origin
             else None
         )
 
         instance.inject_env_vars(location_name)
 
-        log_manager = create_context_free_log_manager(instance, pipeline_run)
+        log_manager = create_context_free_log_manager(instance, dagster_run)
 
         yield DagsterEvent.step_worker_started(
             log_manager,
-            pipeline_run.pipeline_name,
+            dagster_run.job_name,
             message="Step worker started"
             + (f' for "{single_step_key}".' if single_step_key else "."),
             metadata={"pid": MetadataValue.text(str(os.getpid()))},
             step_key=single_step_key,
         )
 
         if args.should_verify_step:
             success = verify_step(
                 instance,
-                pipeline_run,
+                dagster_run,
                 check.not_none(args.known_state).get_retry_state(),
                 args.step_keys_to_execute,
             )
             if not success:
                 return
 
-        if pipeline_run.has_repository_load_data:
+        if dagster_run.has_repository_load_data:
             repository_load_data = instance.get_execution_plan_snapshot(
-                check.not_none(pipeline_run.execution_plan_snapshot_id)
+                check.not_none(dagster_run.execution_plan_snapshot_id)
             ).repository_load_data
         else:
             repository_load_data = None
 
-        recon_pipeline = (
-            recon_pipeline_from_origin(
-                cast(PipelinePythonOrigin, pipeline_run.pipeline_code_origin)
-            )
+        recon_job = (
+            recon_job_from_origin(cast(JobPythonOrigin, dagster_run.job_code_origin))
             .with_repository_load_data(repository_load_data)
-            .subset_for_execution_from_existing_pipeline(
-                pipeline_run.solids_to_execute, pipeline_run.asset_selection
+            .subset_for_execution_from_existing_job(
+                dagster_run.solids_to_execute, dagster_run.asset_selection
             )
         )
 
         execution_plan = create_execution_plan(
-            recon_pipeline,
-            run_config=pipeline_run.run_config,
+            recon_job,
+            run_config=dagster_run.run_config,
             step_keys_to_execute=args.step_keys_to_execute,
             known_state=args.known_state,
             repository_load_data=repository_load_data,
         )
 
         yield from execute_plan_iterator(
             execution_plan,
-            recon_pipeline,
-            pipeline_run,
+            recon_job,
+            dagster_run,
             instance,
-            run_config=pipeline_run.run_config,
+            run_config=dagster_run.run_config,
             retry_mode=args.retry_mode,
         )
     except (KeyboardInterrupt, DagsterExecutionInterruptedError):
         yield instance.report_engine_event(
             message="Step execution terminated by interrupt",
-            pipeline_run=pipeline_run,
+            dagster_run=dagster_run,
             step_key=single_step_key,
         )
         raise
     except Exception:
         yield instance.report_engine_event(
             (
                 "An exception was thrown during step execution that is likely a framework error,"
                 " rather than an error in user code."
             ),
-            pipeline_run,
+            dagster_run,
             EngineEventData.engine_error(serializable_error_info_from_exc_info(sys.exc_info())),
             step_key=single_step_key,
         )
         raise
 
 
 @api_cli.command(name="grpc", help="Serve the Dagster inter-process API over GRPC")
```

### Comparing `dagster-1.3.2/dagster/_cli/asset.py` & `dagster-1.3.3/dagster/_cli/asset.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,19 +7,19 @@
     get_repository_python_origin_from_kwargs,
     python_origin_target_argument,
 )
 from dagster._core.definitions.events import AssetKey
 from dagster._core.errors import DagsterInvalidSubsetError
 from dagster._core.execution.api import execute_job
 from dagster._core.instance import DagsterInstance
-from dagster._core.origin import PipelinePythonOrigin
+from dagster._core.origin import JobPythonOrigin
 from dagster._core.selector.subset_selector import parse_asset_selection
 from dagster._core.telemetry import telemetry_wrapper
 from dagster._utils.hosted_user_process import (
-    recon_pipeline_from_origin,
+    recon_job_from_origin,
     recon_repository_from_origin,
 )
 from dagster._utils.interrupts import capture_interrupts
 
 from .utils import get_instance_for_service
 
 
@@ -56,16 +56,16 @@
     # placed into the same implicit job, because of their conflicting PartitionsDefinitions.
     if implicit_job_def is None:
         raise DagsterInvalidSubsetError(
             "All selected assets must share the same PartitionsDefinition or have no"
             " PartitionsDefinition"
         )
 
-    reconstructable_job = recon_pipeline_from_origin(
-        PipelinePythonOrigin(implicit_job_def.name, repository_origin=repository_origin)
+    reconstructable_job = recon_job_from_origin(
+        JobPythonOrigin(implicit_job_def.name, repository_origin=repository_origin)
     )
     partition = kwargs.get("partition")
     if partition:
         partitions_def = implicit_job_def.partitions_def
         if partitions_def is None or all(
             implicit_job_def.asset_layer.partitions_def_for_asset(asset_key) is None
             for asset_key in asset_keys
@@ -82,15 +82,14 @@
 
 
 @asset_cli.command(name="list", help="List assets")
 @python_origin_target_argument
 @click.option("--select", help="Asset selection to target", required=False)
 def asset_list_command(**kwargs):
     repository_origin = get_repository_python_origin_from_kwargs(kwargs)
-
     recon_repo = recon_repository_from_origin(repository_origin)
     repo_def = recon_repo.get_definition()
 
     select = kwargs.get("select")
     if select is not None:
         asset_keys = parse_asset_selection(
             assets_defs=list(repo_def.assets_defs_by_key.values()),
```

### Comparing `dagster-1.3.2/dagster/_cli/config_scaffolder.py` & `dagster-1.3.3/dagster/_cli/config_scaffolder.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 from typing import Optional
 
 from dagster import _check as check
 from dagster._config import ConfigType, ConfigTypeKind
 from dagster._core.definitions import JobDefinition
 
 
-def scaffold_pipeline_config(
-    pipeline_def: JobDefinition,
+def scaffold_job_config(
+    job_def: JobDefinition,
     skip_non_required: bool = True,
     mode: Optional[str] = None,
 ):
-    check.inst_param(pipeline_def, "pipeline_def", JobDefinition)
+    check.inst_param(job_def, "job_def", JobDefinition)
     check.bool_param(skip_non_required, "skip_non_required")
 
-    env_config_type = pipeline_def.run_config_schema.config_type
+    env_config_type = job_def.run_config_schema.config_type
 
     env_dict = {}
 
     for env_field_name, env_field in env_config_type.fields.items():  # type: ignore
         if skip_non_required and not env_field.is_required:
             continue
```

### Comparing `dagster-1.3.2/dagster/_cli/debug.py` & `dagster-1.3.3/dagster/_cli/debug.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,29 +1,29 @@
 from gzip import GzipFile
-from typing import Tuple
+from typing import List, Tuple
 
 import click
 from tqdm import tqdm
 
 from dagster import DagsterInstance
 from dagster._core.debug import DebugRunPayload
-from dagster._core.storage.pipeline_run import DagsterRunStatus, RunsFilter
+from dagster._core.storage.dagster_run import DagsterRunStatus, RunsFilter
 from dagster._serdes import deserialize_value
 
 
 def _recent_failed_runs_text(instance):
     lines = []
     runs = instance.get_runs(
         limit=5,
         filters=RunsFilter(statuses=[DagsterRunStatus.FAILURE, DagsterRunStatus.CANCELED]),
     )
     if len(runs) <= 0:
         return ""
     for run in runs:
-        lines.append(f"{run.run_id:<50}{run.pipeline_name:<50}{run.status:<20}")
+        lines.append(f"{run.run_id:<50}{run.job_name:<50}{run.status:<20}")
     return "Recently failed runs:\n{}".format("\n".join(lines))
 
 
 def export_run(instance, run, output_file):
     debug_payload = DebugRunPayload.build(instance, run)
     with GzipFile(output_file, "wb") as file:
         click.echo(f"Exporting run_id '{run.run_id}' to gzip output file {output_file}.")
@@ -62,34 +62,34 @@
 
 
 @debug_cli.command(
     name="import", help="Import the relevant artifacts from debug files in to the current instance."
 )
 @click.argument("input_files", nargs=-1, type=click.Path(exists=True))
 def import_command(input_files: Tuple[str, ...]):
-    debug_payloads = []
+    debug_payloads: List[DebugRunPayload] = []
     for input_file in input_files:
         with GzipFile(input_file, "rb") as file:
             blob = file.read().decode("utf-8")
             debug_payload = deserialize_value(blob, DebugRunPayload)
             debug_payloads.append(debug_payload)
 
     with DagsterInstance.get() as instance:
         for debug_payload in debug_payloads:
-            run = debug_payload.pipeline_run
+            run = debug_payload.dagster_run
             click.echo(f"Importing run {run.run_id} (Dagster: {debug_payload.version})")
-            if not instance.has_snapshot(run.execution_plan_snapshot_id):
+            if not instance.has_snapshot(run.execution_plan_snapshot_id):  # type: ignore  # (possible none)
                 instance.add_snapshot(
                     debug_payload.execution_plan_snapshot,
                     run.execution_plan_snapshot_id,
                 )
-            if not instance.has_snapshot(run.pipeline_snapshot_id):
+            if not instance.has_snapshot(run.job_snapshot_id):  # type: ignore  # (possible none)
                 instance.add_snapshot(
-                    debug_payload.pipeline_snapshot,
-                    run.pipeline_snapshot_id,
+                    debug_payload.job_snapshot,
+                    run.job_snapshot_id,
                 )
 
             if not instance.has_run(run.run_id):
                 instance.add_run(run)
 
                 for event in tqdm(debug_payload.event_list):
                     instance.store_event(event)
```

### Comparing `dagster-1.3.2/dagster/_cli/dev.py` & `dagster-1.3.3/dagster/_cli/dev.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_cli/instance.py` & `dagster-1.3.3/dagster/_cli/instance.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_cli/job.py` & `dagster-1.3.3/dagster/_cli/job.py`

 * *Files 19% similar despite different names*

```diff
@@ -25,48 +25,48 @@
     job_repository_target_argument,
     job_target_argument,
     python_job_config_argument,
     python_job_target_argument,
 )
 from dagster._core.definitions import JobDefinition
 from dagster._core.definitions.reconstruct import ReconstructableJob
-from dagster._core.definitions.selector import PipelineSelector
+from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.definitions.utils import validate_tags
 from dagster._core.errors import DagsterBackfillFailedError
 from dagster._core.execution.api import create_execution_plan, execute_job
 from dagster._core.execution.backfill import BulkActionStatus, PartitionBackfill
 from dagster._core.execution.execution_result import ExecutionResult
 from dagster._core.execution.job_backfill import create_backfill_run
 from dagster._core.host_representation import (
     CodeLocation,
-    ExternalPipeline,
+    ExternalJob,
     ExternalRepository,
     RepositoryHandle,
 )
 from dagster._core.host_representation.external_data import (
     ExternalPartitionNamesData,
     ExternalPartitionSetExecutionParamData,
 )
 from dagster._core.instance import DagsterInstance
-from dagster._core.snap import NodeInvocationSnap, PipelineSnapshot
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.snap import JobSnapshot, NodeInvocationSnap
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._core.storage.tags import MEMOIZED_RUN_TAG
 from dagster._core.telemetry import log_external_repo_stats, telemetry_wrapper
 from dagster._core.utils import make_new_backfill_id
 from dagster._core.workspace.workspace import IWorkspace
 from dagster._seven import IS_WINDOWS, JSONDecodeError, json
 from dagster._utils import DEFAULT_WORKSPACE_YAML_FILENAME, PrintFn
 from dagster._utils.error import serializable_error_info_from_exc_info
-from dagster._utils.hosted_user_process import recon_pipeline_from_origin
+from dagster._utils.hosted_user_process import recon_job_from_origin
 from dagster._utils.indenting_printer import IndentingPrinter
 from dagster._utils.interrupts import capture_interrupts
 from dagster._utils.merger import merge_dicts
 from dagster._utils.yaml_utils import dump_run_config_yaml, load_yaml_from_glob_list
 
-from .config_scaffolder import scaffold_pipeline_config
+from .config_scaffolder import scaffold_job_config
 from .utils import get_instance_for_service
 
 T = TypeVar("T")
 T_Callable = TypeVar("T_Callable", bound=Callable[..., Any])
 
 
 @click.group(name="job")
@@ -106,16 +106,16 @@
                 first = False
 
                 print_fn(job_title)
                 if job.description:
                     print_fn("Description:")
                     print_fn(format_description(job.description, indent=" " * 4))
                 print_fn("Ops: (Execution Order)")
-                for solid_name in job.pipeline_snapshot.node_names_in_topological_order:
-                    print_fn("    " + solid_name)
+                for node_name in job.job_snapshot.node_names_in_topological_order:
+                    print_fn("    " + node_name)
 
 
 def get_job_in_same_python_env_instructions(command_name):
     return (
         "This commands targets a job. The job can be specified in a number of ways:\n\n1. dagster"
         " job {command_name} -f /path/to/file.py -a define_some_job\n\n2. dagster job"
         " {command_name} -m a_module.submodule -a define_some_job\n\n3. dagster job {command_name}"
@@ -148,59 +148,59 @@
 
 
 def execute_print_command(instance, verbose, cli_args, print_fn):
     with get_external_job_from_kwargs(
         instance,
         version=dagster_version,
         kwargs=cli_args,
-    ) as external_pipeline:
-        pipeline_snapshot = external_pipeline.pipeline_snapshot
+    ) as external_job:
+        job_snapshot = external_job.job_snapshot
 
         if verbose:
             print_job(
-                pipeline_snapshot,
+                job_snapshot,
                 print_fn=print_fn,
             )
         else:
             print_ops(
-                pipeline_snapshot,
+                job_snapshot,
                 print_fn=print_fn,
             )
 
 
 def print_ops(
-    pipeline_snapshot: PipelineSnapshot,
+    job_snapshot: JobSnapshot,
     print_fn: Callable[..., Any],
 ):
-    check.inst_param(pipeline_snapshot, "pipeline", PipelineSnapshot)
+    check.inst_param(job_snapshot, "job_snapshot", JobSnapshot)
     check.callable_param(print_fn, "print_fn")
 
     printer = IndentingPrinter(indent_level=2, printer=print_fn)
-    printer.line(f"Job: {pipeline_snapshot.name}")
+    printer.line(f"Job: {job_snapshot.name}")
 
     printer.line("Ops")
-    for solid in pipeline_snapshot.dep_structure_snapshot.node_invocation_snaps:
+    for node in job_snapshot.dep_structure_snapshot.node_invocation_snaps:
         with printer.with_indent():
-            printer.line(f"Op: {solid.node_name}")
+            printer.line(f"Op: {node.node_name}")
 
 
 def print_job(
-    pipeline_snapshot: PipelineSnapshot,
+    job_snapshot: JobSnapshot,
     print_fn: Callable[..., Any],
 ):
-    check.inst_param(pipeline_snapshot, "pipeline", PipelineSnapshot)
+    check.inst_param(job_snapshot, "job_snapshot", JobSnapshot)
     check.callable_param(print_fn, "print_fn")
     printer = IndentingPrinter(indent_level=2, printer=print_fn)
-    printer.line(f"Job: {pipeline_snapshot.name}")
-    print_description(printer, pipeline_snapshot.description)
+    printer.line(f"Job: {job_snapshot.name}")
+    print_description(printer, job_snapshot.description)
 
     printer.line("Ops")
-    for solid in pipeline_snapshot.dep_structure_snapshot.node_invocation_snaps:
+    for node in job_snapshot.dep_structure_snapshot.node_invocation_snaps:
         with printer.with_indent():
-            print_op(printer, pipeline_snapshot, solid)
+            print_op(printer, job_snapshot, node)
 
 
 def print_description(printer, desc):
     with printer.with_indent():
         if desc:
             printer.line("Description:")
             with printer.with_indent():
@@ -215,29 +215,29 @@
     wrapper = textwrap.TextWrapper(initial_indent="", subsequent_indent=indent)
     filled = wrapper.fill(dedented)
     return filled
 
 
 def print_op(
     printer: IndentingPrinter,
-    pipeline_snapshot: PipelineSnapshot,
-    solid_invocation_snap: NodeInvocationSnap,
+    job_snapshot: JobSnapshot,
+    node_invocation_snap: NodeInvocationSnap,
 ) -> None:
-    check.inst_param(pipeline_snapshot, "pipeline_snapshot", PipelineSnapshot)
-    check.inst_param(solid_invocation_snap, "solid_invocation_snap", NodeInvocationSnap)
-    printer.line(f"Op: {solid_invocation_snap.node_name}")
+    check.inst_param(job_snapshot, "job_snapshot", JobSnapshot)
+    check.inst_param(node_invocation_snap, "node_invocation_snap", NodeInvocationSnap)
+    printer.line(f"Op: {node_invocation_snap.node_name}")
     with printer.with_indent():
         printer.line("Inputs:")
-        for input_dep_snap in solid_invocation_snap.input_dep_snaps:
+        for input_dep_snap in node_invocation_snap.input_dep_snaps:
             with printer.with_indent():
                 printer.line(f"Input: {input_dep_snap.input_name}")
 
         printer.line("Outputs:")
-        for output_def_snap in pipeline_snapshot.get_node_def_snap(
-            solid_invocation_snap.node_def_name
+        for output_def_snap in job_snapshot.get_node_def_snap(
+            node_invocation_snap.node_def_name
         ).output_def_snaps:
             printer.line(output_def_snap.name)
 
 
 @job_cli.command(
     name="list_versions",
     help="Display the freshness of memoized results for the given job.\n\n{instructions}".format(
@@ -255,15 +255,15 @@
     check.inst_param(instance, "instance", DagsterInstance)
 
     config = list(
         check.opt_tuple_param(cast(Tuple[str, ...], kwargs.get("config")), "config", of_type=str)
     )
 
     job_origin = get_job_python_origin_from_kwargs(kwargs)
-    job = recon_pipeline_from_origin(job_origin)
+    job = recon_job_from_origin(job_origin)
     run_config = get_run_config_from_file_list(config)
 
     memoized_plan = create_execution_plan(
         job,
         run_config=run_config,
         instance_ref=instance.get_ref(),
         tags={MEMOIZED_RUN_TAG: "true"},
@@ -321,21 +321,21 @@
 
     config = list(
         check.opt_tuple_param(cast(Tuple[str, ...], kwargs.get("config")), "config", of_type=str)
     )
 
     tags = get_tags_from_args(kwargs)
 
-    pipeline_origin = get_job_python_origin_from_kwargs(kwargs)
-    pipeline = recon_pipeline_from_origin(pipeline_origin)
-    solid_selection = get_solid_selection_from_args(kwargs)
-    result = do_execute_command(pipeline, instance, config, tags, solid_selection)
+    job_origin = get_job_python_origin_from_kwargs(kwargs)
+    recon_job = recon_job_from_origin(job_origin)
+    op_selection = get_op_selection_from_args(kwargs)
+    result = do_execute_command(recon_job, instance, config, tags, op_selection)
 
     if not result.success:
-        raise click.ClickException(f"Pipeline run {result.run_id} resulted in failure.")
+        raise click.ClickException(f"Run {result.run_id} resulted in failure.")
 
     return result
 
 
 def get_tags_from_args(kwargs: ClickArgMapping) -> Mapping[str, str]:
     if kwargs.get("tags") is None:
         return {}
@@ -377,20 +377,20 @@
                     serializable_error_info_from_exc_info(sys.exc_info()).to_string(),
                 )
             )
     else:
         check.failed("Unhandled case getting config from kwargs")
 
 
-def get_solid_selection_from_args(kwargs: ClickArgMapping) -> Optional[Sequence[str]]:
-    solid_selection_str = kwargs.get("solid_selection")
-    if not isinstance(solid_selection_str, str):
+def get_op_selection_from_args(kwargs: ClickArgMapping) -> Optional[Sequence[str]]:
+    op_selection_str = kwargs.get("solid_selection")
+    if not isinstance(op_selection_str, str):
         return None
 
-    return [ele.strip() for ele in solid_selection_str.split(",")] if solid_selection_str else None
+    return [ele.strip() for ele in op_selection_str.split(",")] if op_selection_str else None
 
 
 def do_execute_command(
     recon_job: ReconstructableJob,
     instance: DagsterInstance,
     config: Optional[Sequence[str]],
     tags: Optional[Mapping[str, str]] = None,
@@ -442,125 +442,125 @@
     config = get_config_from_args(kwargs)
 
     with get_workspace_from_kwargs(instance, version=dagster_version, kwargs=kwargs) as workspace:
         code_location = get_code_location_from_workspace(workspace, kwargs.get("location"))
         external_repo = get_external_repository_from_code_location(
             code_location, cast(Optional[str], kwargs.get("repository"))
         )
-        external_pipeline = get_external_job_from_external_repo(
+        external_job = get_external_job_from_external_repo(
             external_repo,
             cast(Optional[str], kwargs.get("job_name")),
         )
 
         log_external_repo_stats(
             instance=instance,
-            external_pipeline=external_pipeline,
+            external_job=external_job,
             external_repo=external_repo,
             source="pipeline_launch_command",
         )
 
         if preset and config:
             raise click.UsageError("Can not use --preset with -c / --config / --config-json.")
 
         run_tags = get_tags_from_args(kwargs)
 
-        solid_selection = get_solid_selection_from_args(kwargs)
+        solid_selection = get_op_selection_from_args(kwargs)
 
-        pipeline_run = _create_external_pipeline_run(
+        dagster_run = _create_external_run(
             instance=instance,
             code_location=code_location,
             external_repo=external_repo,
-            external_pipeline=external_pipeline,
+            external_job=external_job,
             run_config=config,
             tags=run_tags,
             solid_selection=solid_selection,
             run_id=cast(Optional[str], kwargs.get("run_id")),
         )
 
-        return instance.submit_run(pipeline_run.run_id, workspace)
+        return instance.submit_run(dagster_run.run_id, workspace)
 
 
-def _create_external_pipeline_run(
+def _create_external_run(
     instance: DagsterInstance,
     code_location: CodeLocation,
     external_repo: ExternalRepository,
-    external_pipeline: ExternalPipeline,
+    external_job: ExternalJob,
     run_config: Mapping[str, object],
     tags: Optional[Mapping[str, str]],
     solid_selection: Optional[Sequence[str]],
     run_id: Optional[str],
 ) -> DagsterRun:
     check.inst_param(instance, "instance", DagsterInstance)
     check.inst_param(code_location, "code_location", CodeLocation)
     check.inst_param(external_repo, "external_repo", ExternalRepository)
-    check.inst_param(external_pipeline, "external_pipeline", ExternalPipeline)
+    check.inst_param(external_job, "external_job", ExternalJob)
     check.opt_mapping_param(run_config, "run_config", key_type=str)
 
     check.opt_mapping_param(tags, "tags", key_type=str)
     check.opt_sequence_param(solid_selection, "solid_selection", of_type=str)
     check.opt_str_param(run_id, "run_id")
 
-    run_config, tags, solid_selection = _check_execute_external_pipeline_args(
-        external_pipeline,
+    run_config, tags, solid_selection = _check_execute_external_job_args(
+        external_job,
         run_config,
         tags,
         solid_selection,
     )
 
-    pipeline_name = external_pipeline.name
-    pipeline_selector = PipelineSelector(
+    job_name = external_job.name
+    job_subset_selector = JobSubsetSelector(
         location_name=code_location.name,
         repository_name=external_repo.name,
-        pipeline_name=pipeline_name,
+        job_name=job_name,
         solid_selection=solid_selection,
     )
 
-    external_pipeline = code_location.get_external_pipeline(pipeline_selector)
+    external_job = code_location.get_external_job(job_subset_selector)
 
     external_execution_plan = code_location.get_external_execution_plan(
-        external_pipeline,
+        external_job,
         run_config,
         step_keys_to_execute=None,
         known_state=None,
         instance=instance,
     )
     execution_plan_snapshot = external_execution_plan.execution_plan_snapshot
 
     return instance.create_run(
-        pipeline_name=pipeline_name,
+        job_name=job_name,
         run_id=run_id,
         run_config=run_config,
-        solids_to_execute=external_pipeline.solids_to_execute,
+        solids_to_execute=external_job.solids_to_execute,
         step_keys_to_execute=execution_plan_snapshot.step_keys_to_execute,
         solid_selection=solid_selection,
         status=None,
         root_run_id=None,
         parent_run_id=None,
         tags=tags,
-        pipeline_snapshot=external_pipeline.pipeline_snapshot,
+        job_snapshot=external_job.job_snapshot,
         execution_plan_snapshot=execution_plan_snapshot,
-        parent_pipeline_snapshot=external_pipeline.parent_pipeline_snapshot,
-        external_pipeline_origin=external_pipeline.get_external_origin(),
-        pipeline_code_origin=external_pipeline.get_python_origin(),
+        parent_job_snapshot=external_job.parent_job_snapshot,
+        external_job_origin=external_job.get_external_origin(),
+        job_code_origin=external_job.get_python_origin(),
         asset_selection=None,
     )
 
 
-def _check_execute_external_pipeline_args(
-    external_pipeline: ExternalPipeline,
+def _check_execute_external_job_args(
+    external_job: ExternalJob,
     run_config: Mapping[str, object],
     tags: Optional[Mapping[str, str]],
     solid_selection: Optional[Sequence[str]],
 ) -> Tuple[Mapping[str, object], Mapping[str, str], Optional[Sequence[str]]]:
-    check.inst_param(external_pipeline, "external_pipeline", ExternalPipeline)
+    check.inst_param(external_job, "external_job", ExternalJob)
     run_config = check.opt_mapping_param(run_config, "run_config")
 
     tags = check.opt_mapping_param(tags, "tags", key_type=str)
     check.opt_sequence_param(solid_selection, "solid_selection", of_type=str)
-    tags = merge_dicts(external_pipeline.tags, tags)
+    tags = merge_dicts(external_job.tags, tags)
 
     return (
         run_config,
         validate_tags(tags),
         solid_selection,
     )
 
@@ -574,30 +574,30 @@
 @python_job_target_argument
 @click.option("--print-only-required", default=False, is_flag=True)
 def job_scaffold_command(**kwargs):
     execute_scaffold_command(kwargs, click.echo)
 
 
 def execute_scaffold_command(cli_args, print_fn):
-    pipeline_origin = get_job_python_origin_from_kwargs(cli_args)
-    pipeline = recon_pipeline_from_origin(pipeline_origin)
+    job_origin = get_job_python_origin_from_kwargs(cli_args)
+    job = recon_job_from_origin(job_origin)
     skip_non_required = cli_args["print_only_required"]
-    do_scaffold_command(pipeline.get_definition(), print_fn, skip_non_required)
+    do_scaffold_command(job.get_definition(), print_fn, skip_non_required)
 
 
 def do_scaffold_command(
-    pipeline_def: JobDefinition,
+    job_def: JobDefinition,
     printer: Callable[..., Any],
     skip_non_required: bool,
 ):
-    check.inst_param(pipeline_def, "pipeline_def", JobDefinition)
+    check.inst_param(job_def, "job_def", JobDefinition)
     check.callable_param(printer, "printer")
     check.bool_param(skip_non_required, "skip_non_required")
 
-    config_dict = scaffold_pipeline_config(pipeline_def, skip_non_required=skip_non_required)
+    config_dict = scaffold_job_config(job_def, skip_non_required=skip_non_required)
     yaml_string = dump_run_config_yaml(config_dict)
     printer(yaml_string)
 
 
 @job_cli.command(
     name="backfill",
     help="Backfill a partitioned job.\n\n{instructions}".format(
@@ -673,15 +673,15 @@
 
     noprompt = cli_args.get("noprompt")
 
     job_partition_set = next(
         (
             external_partition_set
             for external_partition_set in external_repo.get_external_partition_sets()
-            if external_partition_set.pipeline_name == external_job.name
+            if external_partition_set.job_name == external_job.name
         ),
         None,
     )
 
     if not job_partition_set:
         raise click.UsageError(f"Job `{external_job.name}` is not partitioned.")
 
@@ -747,24 +747,24 @@
                 backfill_job.with_status(BulkActionStatus.FAILED).with_error(error_info)
             )
             raise DagsterBackfillFailedError(f"Backfill failed: {error_info}")
 
         assert isinstance(partition_execution_data, ExternalPartitionSetExecutionParamData)
 
         for partition_data in partition_execution_data.partition_data:
-            pipeline_run = create_backfill_run(
+            dagster_run = create_backfill_run(
                 instance,
                 code_location,
                 external_job,
                 job_partition_set,
                 backfill_job,
                 partition_data,
             )
-            if pipeline_run:
-                instance.submit_run(pipeline_run.run_id, workspace)
+            if dagster_run:
+                instance.submit_run(dagster_run.run_id, workspace)
 
         instance.add_backfill(backfill_job.with_status(BulkActionStatus.COMPLETED))
 
         print_fn(f"Launched backfill job `{backfill_id}`")
 
     else:
         print_fn("Aborted!")
```

### Comparing `dagster-1.3.2/dagster/_cli/load_handle.py` & `dagster-1.3.3/dagster/_cli/load_handle.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_cli/project.py` & `dagster-1.3.3/dagster/_cli/project.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_cli/run.py` & `dagster-1.3.3/dagster/_cli/run.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,15 +13,15 @@
 
 @run_cli.command(name="list", help="List the runs in the current Dagster instance.")
 @click.option("--limit", help="Only list a specified number of runs", default=None, type=int)
 def run_list_command(limit):
     with DagsterInstance.get() as instance:
         for run in instance.get_runs(limit=limit):
             click.echo(f"Run: {run.run_id}")
-            click.echo(f"     Job: {run.pipeline_name}")
+            click.echo(f"     Job: {run.job_name}")
 
 
 @run_cli.command(
     name="delete",
     help="Delete a run by id and its associated event logs. Warning: Cannot be undone",
 )
 @click.option("--force", "-f", is_flag=True, default=False, help="Skip prompt to delete run.")
@@ -81,15 +81,15 @@
     "--from",
     "-f",
     "from_label",
     help="The repository from which to migrate (format: <repository_name>@<location_name>)",
 )
 @job_target_argument
 def run_migrate_command(from_label, **kwargs):
-    from dagster._core.storage.pipeline_run import RunsFilter
+    from dagster._core.storage.dagster_run import RunsFilter
     from dagster._core.storage.runs.sql_run_storage import SqlRunStorage
     from dagster._core.storage.tags import REPOSITORY_LABEL_TAG
 
     if not from_label:
         raise click.UsageError("Must specify a --from repository label")
 
     if not is_valid_repo_label(from_label):
```

### Comparing `dagster-1.3.2/dagster/_cli/schedule.py` & `dagster-1.3.3/dagster/_cli/schedule.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_cli/sensor.py` & `dagster-1.3.3/dagster/_cli/sensor.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_cli/utils.py` & `dagster-1.3.3/dagster/_cli/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_cli/workspace/cli_target.py` & `dagster-1.3.3/dagster/_cli/workspace/cli_target.py`

 * *Files 3% similar despite different names*

```diff
@@ -27,15 +27,15 @@
 from dagster._core.definitions.reconstruct import repository_def_from_target_def
 from dagster._core.definitions.repository_definition import RepositoryDefinition
 from dagster._core.host_representation.code_location import CodeLocation
 from dagster._core.host_representation.external import ExternalRepository
 from dagster._core.instance import DagsterInstance
 from dagster._core.origin import (
     DEFAULT_DAGSTER_ENTRY_POINT,
-    PipelinePythonOrigin,
+    JobPythonOrigin,
     RepositoryPythonOrigin,
 )
 from dagster._core.workspace.context import WorkspaceRequestContext
 from dagster._core.workspace.load_target import (
     CompositeTarget,
     EmptyWorkspaceTarget,
     GrpcServerTarget,
@@ -48,15 +48,15 @@
 )
 from dagster._grpc.utils import get_loadable_targets
 from dagster._utils.hosted_user_process import recon_repository_from_origin
 
 if TYPE_CHECKING:
     from dagster._core.workspace.context import WorkspaceProcessContext
 
-from dagster._core.host_representation.external import ExternalPipeline
+from dagster._core.host_representation.external import ExternalJob
 
 WORKSPACE_TARGET_WARNING = (
     "Can only use ONE of --workspace/-w, --python-file/-f, --module-name/-m, --grpc-port,"
     " --grpc-socket."
 )
 
 T_Callable = TypeVar("T_Callable", bound=Callable[..., Any])
@@ -523,39 +523,39 @@
 
 def job_target_argument(f: T_Callable) -> T_Callable:
     from dagster._cli.job import apply_click_params
 
     return apply_click_params(job_repository_target_argument(f), job_option())
 
 
-def get_job_python_origin_from_kwargs(kwargs: ClickArgMapping) -> PipelinePythonOrigin:
+def get_job_python_origin_from_kwargs(kwargs: ClickArgMapping) -> JobPythonOrigin:
     repository_origin = get_repository_python_origin_from_kwargs(kwargs)
     provided_name = kwargs.get("job_name")
 
     recon_repo = recon_repository_from_origin(repository_origin)
     repo_definition = recon_repo.get_definition()
 
-    job_names = set(repo_definition.pipeline_names)  # pipeline (all) vs job (non legacy)
+    job_names = set(repo_definition.job_names)  # job (all) vs job (non legacy)
 
     if provided_name is None and len(job_names) == 1:
-        pipeline_name = next(iter(job_names))
+        job_name = next(iter(job_names))
     elif provided_name is None:
         raise click.UsageError(
             "Must provide --job as there is more than one job "
             f"in {repo_definition.name}. Options are: {_sorted_quoted(job_names)}."
         )
     elif provided_name not in job_names:
         raise click.UsageError(
             f'Job "{provided_name}" not found in repository "{repo_definition.name}" '
             f"Found {_sorted_quoted(job_names)} instead."
         )
     else:
-        pipeline_name = provided_name
+        job_name = provided_name
 
-    return PipelinePythonOrigin(pipeline_name, repository_origin=repository_origin)
+    return JobPythonOrigin(job_name, repository_origin=repository_origin)
 
 
 def _get_code_pointer_dict_from_kwargs(kwargs: ClickArgMapping) -> Mapping[str, CodePointer]:
     python_file = check.opt_str_elem(kwargs, "python_file")
     module_name = check.opt_str_elem(kwargs, "module_name")
     package_name = check.opt_str_elem(kwargs, "package_name")
     working_directory = get_working_directory_from_kwargs(kwargs)
@@ -767,43 +767,43 @@
         provided_repo_name = check.opt_str_elem(kwargs, "repository")
         yield get_external_repository_from_code_location(code_location, provided_repo_name)
 
 
 def get_external_job_from_external_repo(
     external_repo: ExternalRepository,
     provided_name: Optional[str],
-) -> ExternalPipeline:
+) -> ExternalJob:
     check.inst_param(external_repo, "external_repo", ExternalRepository)
     check.opt_str_param(provided_name, "provided_name")
 
-    external_pipelines = {ep.name: ep for ep in (external_repo.get_all_external_jobs())}
+    external_jobs = {ep.name: ep for ep in (external_repo.get_all_external_jobs())}
 
-    check.invariant(external_pipelines)
+    check.invariant(external_jobs)
 
-    if provided_name is None and len(external_pipelines) == 1:
-        return next(iter(external_pipelines.values()))
+    if provided_name is None and len(external_jobs) == 1:
+        return next(iter(external_jobs.values()))
 
     if provided_name is None:
         raise click.UsageError(
             "Must provide --job as there is more than one job "
-            f"in {external_repo.name}. Options are: {_sorted_quoted(external_pipelines.keys())}."
+            f"in {external_repo.name}. Options are: {_sorted_quoted(external_jobs.keys())}."
         )
 
-    if provided_name not in external_pipelines:
+    if provided_name not in external_jobs:
         raise click.UsageError(
             f'Job "{provided_name}" not found in repository "{external_repo.name}". '
-            f"Found {_sorted_quoted(external_pipelines.keys())} instead."
+            f"Found {_sorted_quoted(external_jobs.keys())} instead."
         )
 
-    return external_pipelines[provided_name]
+    return external_jobs[provided_name]
 
 
 @contextmanager
 def get_external_job_from_kwargs(instance: DagsterInstance, version: str, kwargs: ClickArgMapping):
-    # Instance isn't strictly required to load an ExternalPipeline, but is included
+    # Instance isn't strictly required to load an ExternalJob, but is included
     # to satisfy the WorkspaceProcessContext / WorkspaceRequestContext requirements
     with get_external_repository_from_kwargs(instance, version, kwargs) as external_repo:
         provided_name = check.opt_str_elem(kwargs, "job_name")
         yield get_external_job_from_external_repo(external_repo, provided_name)
 
 
 def _sorted_quoted(strings: Iterable[str]) -> str:
```

### Comparing `dagster-1.3.2/dagster/_config/__init__.py` & `dagster-1.3.3/dagster/_config/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/config_schema.py` & `dagster-1.3.3/dagster/_config/config_schema.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/config_type.py` & `dagster-1.3.3/dagster/_config/config_type.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/errors.py` & `dagster-1.3.3/dagster/_config/errors.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/evaluate_value_result.py` & `dagster-1.3.3/dagster/_config/evaluate_value_result.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/field.py` & `dagster-1.3.3/dagster/_config/field.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/field_utils.py` & `dagster-1.3.3/dagster/_config/field_utils.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 # encoding: utf-8
 import hashlib
-from enum import Enum
 from typing import TYPE_CHECKING, Any, Dict, Iterator, List, Mapping, Sequence
 
 import dagster._check as check
 from dagster._annotations import public
 from dagster._core.errors import DagsterInvalidConfigDefinitionError
 
 from .config_type import Array, ConfigType, ConfigTypeKind
@@ -456,46 +455,26 @@
 
     if isinstance(potential_field, Field):
         return potential_field
 
     return Field(_convert_potential_type(original_root, potential_field, stack))
 
 
-def _config_dictionary_from_values_inner(obj: Any):
-    from dagster._config.pythonic_config import Config
-
-    if isinstance(obj, dict):
-        return {k: _config_dictionary_from_values_inner(v) for k, v in obj.items() if v is not None}
-    elif isinstance(obj, list):
-        return [_config_dictionary_from_values_inner(v) for v in obj]
-    elif isinstance(obj, EnvVar):
-        return {"env": str(obj)}
-    elif isinstance(obj, IntEnvVar):
-        return {"env": obj.name}
-    elif isinstance(obj, Config):
-        return {
-            k: _config_dictionary_from_values_inner(v)
-            for k, v in obj._as_config_dict().items()  # noqa: SLF001
-        }
-    elif isinstance(obj, Enum):
-        return obj.name
-
-    return obj
-
-
 def config_dictionary_from_values(
     values: Mapping[str, Any], config_field: "Field"
 ) -> Dict[str, Any]:
     """Converts a set of config values into a dictionary representation,
     in particular converting EnvVar objects into Dagster config inputs
     and processing data structures such as dicts, lists, and structured Config classes.
     """
     assert ConfigTypeKind.is_shape(config_field.config_type.kind)
 
-    return check.is_dict(_config_dictionary_from_values_inner(values))
+    from dagster._config.pythonic_config import _config_value_to_dict_representation
+
+    return check.is_dict(_config_value_to_dict_representation(None, values))
 
 
 class IntEnvVar(int):
     """Class used to represent an environment variable in the Dagster config system.
 
     The environment variable will be resolved to an int value when the config is
     loaded.
```

### Comparing `dagster-1.3.2/dagster/_config/post_process.py` & `dagster-1.3.3/dagster/_config/post_process.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/primitive_mapping.py` & `dagster-1.3.3/dagster/_config/primitive_mapping.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/pythonic_config/__init__.py` & `dagster-1.3.3/dagster/_config/pythonic_config/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,17 @@
+import contextlib
 import inspect
 import re
 from enum import Enum
 from typing import (
     AbstractSet,
     Any,
     Callable,
     Dict,
+    Generator,
     Generic,
     Iterable,
     Mapping,
     NamedTuple,
     Optional,
     Set,
     Type,
@@ -21,22 +23,31 @@
 from pydantic import ConstrainedFloat, ConstrainedInt, ConstrainedStr
 from typing_extensions import TypeAlias, TypeGuard, get_args
 
 from dagster import (
     Enum as DagsterEnum,
     Field as DagsterField,
 )
-from dagster._config.config_type import Array, ConfigFloatInstance, ConfigType, EnumValue, Noneable
+from dagster._config.config_type import (
+    Array,
+    ConfigFloatInstance,
+    ConfigType,
+    EnumValue,
+    Noneable,
+)
 from dagster._config.field_utils import config_dictionary_from_values
 from dagster._config.post_process import resolve_defaults
-from dagster._config.pythonic_config.typing_utils import TypecheckAllowPartialResourceInitParams
+from dagster._config.pythonic_config.typing_utils import (
+    TypecheckAllowPartialResourceInitParams,
+)
 from dagster._config.source import BoolSource, IntSource, StringSource
 from dagster._config.validate import process_config, validate_config
 from dagster._core.decorator_utils import get_function_params
 from dagster._core.definitions.definition_config_schema import (
+    CoercableToConfigSchema,
     ConfiguredDefinitionConfigSchema,
     DefinitionConfigSchema,
 )
 from dagster._core.errors import (
     DagsterInvalidConfigDefinitionError,
     DagsterInvalidConfigError,
     DagsterInvalidDefinitionError,
@@ -57,15 +68,21 @@
     class cached_property:
         pass
 
 
 from abc import ABC, abstractmethod
 
 from pydantic import BaseModel, Extra
-from pydantic.fields import SHAPE_DICT, SHAPE_LIST, SHAPE_MAPPING, SHAPE_SINGLETON, ModelField
+from pydantic.fields import (
+    SHAPE_DICT,
+    SHAPE_LIST,
+    SHAPE_MAPPING,
+    SHAPE_SINGLETON,
+    ModelField,
+)
 
 import dagster._check as check
 from dagster import Field, Selector, Shape
 from dagster._config.field_utils import (
     FIELD_NO_DEFAULT_PROVIDED,
     Map,
     Permissive,
@@ -196,39 +213,66 @@
         the appropriate config classes. For example, discriminated unions are represented
         in Dagster config as dicts with a single key, which is the discriminator value.
         """
         modified_data = {}
         for key, value in config_dict.items():
             field = self.__fields__.get(key)
             if field and field.field_info.discriminator:
-                nested_items = list(check.is_dict(value).items())
+                nested_dict = value
+
+                discriminator_key = check.not_none(field.discriminator_key)
+                if isinstance(value, Config):
+                    nested_dict = _discriminated_union_config_dict_to_selector_config_dict(
+                        discriminator_key,
+                        value._get_non_none_public_field_values(),  # noqa: SLF001
+                    )
+
+                nested_items = list(check.is_dict(nested_dict).items())
                 check.invariant(
-                    len(nested_items) == 1, "Discriminated union must have exactly one key"
+                    len(nested_items) == 1,
+                    "Discriminated union must have exactly one key",
                 )
                 discriminated_value, nested_values = nested_items[0]
 
                 modified_data[key] = {
                     **nested_values,
-                    field.discriminator_key: discriminated_value,
+                    discriminator_key: discriminated_value,
                 }
             else:
                 modified_data[key] = value
         super().__init__(**modified_data)
 
-    def _as_config_dict(self) -> Mapping[str, Any]:
+    def _convert_to_config_dictionary(self) -> Mapping[str, Any]:
+        """Converts this Config object to a Dagster config dictionary, in the same format as the dictionary
+        accepted as run config or as YAML in the launchpad.
+
+        Inner fields are recursively converted to dictionaries, meaning nested config objects
+        or EnvVars will be converted to the appropriate dictionary representation.
+        """
+        public_fields = self._get_non_none_public_field_values()
+        return {
+            k: _config_value_to_dict_representation(self.__fields__.get(k), v)
+            for k, v in public_fields.items()
+        }
+
+    def _get_non_none_public_field_values(self) -> Mapping[str, Any]:
         """Returns a dictionary representation of this config object,
-        ignoring any private fields.
+        ignoring any private fields, and any optional fields that are None.
+
+        Inner fields are returned as-is in the dictionary,
+        meaning any nested config objects will be returned as config objects, not dictionaries.
         """
         output = {}
         for key, value in self.__dict__.items():
             if self._is_field_internal(key):
                 continue
             field = self.__fields__.get(key)
             if field and value is None and not _is_pydantic_field_required(field):
                 continue
+
             if field:
                 output[field.alias] = value
             else:
                 output[key] = value
         return output
 
     @classmethod
@@ -241,14 +285,61 @@
         """Converts the config structure represented by this class into a dictionary of dagster.Fields.
         This is useful when interacting with legacy code that expects a dictionary of fields but you
         want the source of truth to be a config class.
         """
         return cast(Shape, cls.to_config_schema().as_field().config_type).fields
 
 
+def _discriminated_union_config_dict_to_selector_config_dict(
+    discriminator_key: str, config_dict: Mapping[str, Any]
+):
+    """Remaps a config dictionary which is a member of a discriminated union to
+    the appropriate structure for a Dagster config selector.
+
+    A discriminated union with key "my_key" and value "my_value" will be represented
+    as {"my_key": "my_value", "my_field": "my_field_value"}. When converted to a selector,
+    this should be represented as {"my_value": {"my_field": "my_field_value"}}.
+    """
+    updated_dict = dict(config_dict)
+    discriminator_value = updated_dict.pop(discriminator_key)
+    wrapped_dict = {discriminator_value: updated_dict}
+    return wrapped_dict
+
+
+def _config_value_to_dict_representation(field: Optional[ModelField], value: Any):
+    """Converts a config value to a dictionary representation. If a field is provided, it will be used
+    to determine the appropriate dictionary representation in the case of discriminated unions.
+    """
+    from dagster._config.field_utils import EnvVar, IntEnvVar
+
+    if isinstance(value, dict):
+        return {k: _config_value_to_dict_representation(None, v) for k, v in value.items()}
+    elif isinstance(value, list):
+        return [_config_value_to_dict_representation(None, v) for v in value]
+    elif isinstance(value, EnvVar):
+        return {"env": str(value)}
+    elif isinstance(value, IntEnvVar):
+        return {"env": value.name}
+    if isinstance(value, Config):
+        if field and field.discriminator_key:
+            return {
+                k: v
+                for k, v in _discriminated_union_config_dict_to_selector_config_dict(
+                    field.discriminator_key,
+                    value._convert_to_config_dictionary(),  # noqa: SLF001
+                ).items()
+            }
+        else:
+            return {k: v for k, v in value._convert_to_config_dictionary().items()}  # noqa: SLF001
+    elif isinstance(value, Enum):
+        return value.name
+
+    return value
+
+
 class PermissiveConfig(Config):
     """Subclass of :py:class:`Config` that allows arbitrary extra fields. This is useful for
     config classes which may have open-ended inputs.
 
     Example definition:
 
     .. code-block:: python
@@ -305,15 +396,16 @@
         # we can apply "additional" defaults by actually invoking
         # the config machinery. Meaning we pass the new_additional_default_values
         # and then resolve the existing defaults over them. This preserves the default
         # values that are not specified in new_additional_default_values and then
         # applies the new value as the default value of the field in question.
         defaults_processed_evr = resolve_defaults(field.config_type, additional_default_values)
         check.invariant(
-            defaults_processed_evr.success, "Since validation passed, this should always work."
+            defaults_processed_evr.success,
+            "Since validation passed, this should always work.",
         )
         default_to_pass = defaults_processed_evr.value
         return copy_with_default(field, default_to_pass)
     else:
         return copy_with_default(field, additional_default_values)
 
 
@@ -448,15 +540,17 @@
     """Wrapper around a ResourceDefinition which helps the inner resource resolve its required
     resource keys. This is useful for resources which may hold nested resources. At construction
     time, they are unaware of the resource keys of their nested resources - the resource id to
     key mapping is used to resolve this.
     """
 
     def __init__(
-        self, resource: ResourceDefinition, resource_id_to_key_mapping: Dict[ResourceId, str]
+        self,
+        resource: ResourceDefinition,
+        resource_id_to_key_mapping: Dict[ResourceId, str],
     ):
         self._resource = resource
         self._resource_id_to_key_mapping = resource_id_to_key_mapping
 
         ResourceDefinition.__init__(
             self,
             resource_fn=self.setup_context_resources_and_call,
@@ -493,15 +587,17 @@
         return self._resource
 
 
 class IOManagerWithKeyMapping(ResourceWithKeyMapping, IOManagerDefinition):
     """Version of ResourceWithKeyMapping wrapper that also implements IOManagerDefinition."""
 
     def __init__(
-        self, resource: ResourceDefinition, resource_id_to_key_mapping: Dict[ResourceId, str]
+        self,
+        resource: ResourceDefinition,
+        resource_id_to_key_mapping: Dict[ResourceId, str],
     ):
         ResourceWithKeyMapping.__init__(self, resource, resource_id_to_key_mapping)
         IOManagerDefinition.__init__(
             self, resource_fn=self.resource_fn, config_schema=resource.config_schema
         )
 
 
@@ -541,15 +637,17 @@
         resource_fn: ResourceFunction,
         config_schema: Any,
         description: Optional[str],
         resolve_resource_keys: Callable[[Mapping[int, str]], AbstractSet[str]],
         nested_resources: Mapping[str, CoercibleToResource],
     ):
         super().__init__(
-            resource_fn=resource_fn, config_schema=config_schema, description=description
+            resource_fn=resource_fn,
+            config_schema=config_schema,
+            description=description,
         )
         self._resolve_resource_keys = resolve_resource_keys
         self._nested_resources = nested_resources
 
     @property
     def nested_resources(
         self,
@@ -566,17 +664,33 @@
     def __init__(
         self,
         resource_fn: ResourceFunction,
         config_schema: Any,
         description: Optional[str],
         resolve_resource_keys: Callable[[Mapping[int, str]], AbstractSet[str]],
         nested_resources: Mapping[str, CoercibleToResource],
+        input_config_schema: Optional[Union[CoercableToConfigSchema, Type[Config]]] = None,
+        output_config_schema: Optional[Union[CoercableToConfigSchema, Type[Config]]] = None,
     ):
+        input_config_schema_resolved: CoercableToConfigSchema = (
+            cast(Type[Config], input_config_schema).to_config_schema()
+            if safe_is_subclass(input_config_schema, Config)
+            else cast(CoercableToConfigSchema, input_config_schema)
+        )
+        output_config_schema_resolved: CoercableToConfigSchema = (
+            cast(Type[Config], output_config_schema).to_config_schema()
+            if safe_is_subclass(output_config_schema, Config)
+            else cast(CoercableToConfigSchema, output_config_schema)
+        )
         super().__init__(
-            resource_fn=resource_fn, config_schema=config_schema, description=description
+            resource_fn=resource_fn,
+            config_schema=config_schema,
+            description=description,
+            input_config_schema=input_config_schema_resolved,
+            output_config_schema=output_config_schema_resolved,
         )
         self._resolve_resource_keys = resolve_resource_keys
         self._nested_resources = nested_resources
 
     @property
     def nested_resources(
         self,
@@ -629,15 +743,15 @@
             connection_uri: str
 
             def create_resource(self, _init_context) -> Database:
                 # For example Database could be from a third-party library or require expensive setup.
                 # Or you could just prefer to separate the concerns of configuration and runtime representation
                 return Database(self.connection_uri)
 
-    To use a resource created by a factory in a pipeline, you must use the Resource type annotation.
+    To use a resource created by a factory in a job, you must use the Resource type annotation.
 
     Example usage:
 
     .. code-block:: python
 
         @asset
         def asset_that_uses_database(database: ResourceParam[Database]):
@@ -660,15 +774,17 @@
 
         # Populate config values
         Config.__init__(self, **{**data_without_resources, **resource_pointers})
 
         # We pull the values from the Pydantic config object, which may cast values
         # to the correct type under the hood - useful in particular for enums
         casted_data_without_resources = {
-            k: v for k, v in self._as_config_dict().items() if k in data_without_resources
+            k: v
+            for k, v in self._convert_to_config_dictionary().items()
+            if k in data_without_resources
         }
         resolved_config_dict = config_dictionary_from_values(casted_data_without_resources, schema)
 
         self._state__internal__ = ConfigurableResourceFactoryState(
             # We keep track of any resources we depend on which are not fully configured
             # so that we can retrieve them at runtime
             nested_partial_resources={
@@ -698,18 +814,32 @@
     def _nested_resources(self):
         return self._state__internal__.nested_resources
 
     @property
     def _resolved_config_dict(self):
         return self._state__internal__.resolved_config_dict
 
+    @classmethod
+    def _is_cm_resource_cls(cls: Type["ConfigurableResourceFactory"]) -> bool:
+        return (
+            cls.yield_for_execution != ConfigurableResourceFactory.yield_for_execution
+            or cls.teardown_after_execution != ConfigurableResourceFactory.teardown_after_execution
+        )
+
+    @property
+    def _is_cm_resource(self) -> bool:
+        return self.__class__._is_cm_resource_cls()  # noqa: SLF001
+
+    def _get_initialize_and_run_fn(self) -> Callable:
+        return self._initialize_and_run_cm if self._is_cm_resource else self._initialize_and_run
+
     @cached_method
     def get_resource_definition(self) -> ConfigurableResourceFactoryResourceDefinition:
         return ConfigurableResourceFactoryResourceDefinition(
-            resource_fn=self._initialize_and_run,
+            resource_fn=self._get_initialize_and_run_fn(),
             config_schema=self._config_schema,
             description=self.__doc__,
             resolve_resource_keys=self._resolve_required_resource_keys,
             nested_resources=self.nested_resources,
         )
 
     @abstractmethod
@@ -738,15 +868,15 @@
     ) -> "ConfigurableResourceFactory[TResValue]":
         """Returns a new instance of the resource with the given values.
         Used when initializing a resource at runtime.
         """
         # Since Resource extends BaseModel and is a dataclass, we know that the
         # signature of any __init__ method will always consist of the fields
         # of this class. We can therefore safely pass in the values as kwargs.
-        out = self.__class__(**{**self._as_config_dict(), **values})
+        out = self.__class__(**{**self._get_non_none_public_field_values(), **values})
         out._state__internal__ = out._state__internal__._replace(  # noqa: SLF001
             resource_context=self._state__internal__.resource_context
         )
         return out
 
     def _resolve_and_update_env_vars(self) -> "ConfigurableResourceFactory[TResValue]":
         """Processes the config dictionary to resolve any EnvVar values. This is called at runtime
@@ -756,17 +886,18 @@
         Returns a new instance of the resource.
         """
         post_processed_data = _process_config_values(
             self._schema, self._resolved_config_dict, self.__class__.__name__
         )
         return self._with_updated_values(post_processed_data)
 
+    @contextlib.contextmanager
     def _resolve_and_update_nested_resources(
         self, context: InitResourceContext
-    ) -> "ConfigurableResourceFactory[TResValue]":
+    ) -> Generator["ConfigurableResourceFactory[TResValue]", None, None]:
         """Updates any nested resources with the resource values from the context.
         In this case, populating partially configured resources or
         resources that return plain Python types.
 
         Returns a new instance of the resource.
         """
         partial_resources_to_update: Dict[str, Any] = {}
@@ -785,74 +916,152 @@
             )
             partial_resources_to_update = {
                 attr_name: context_with_mapping.resources_by_id[id(resource)]
                 for attr_name, resource in self._nested_partial_resources.items()
             }
 
         # Also evaluate any resources that are not partial
-        resources_to_update, _ = separate_resource_params(self.__dict__)
-        resources_to_update = {
-            attr_name: _call_resource_fn_with_default(coerce_to_resource(resource), context)
-            for attr_name, resource in resources_to_update.items()
-            if attr_name not in partial_resources_to_update
-        }
+        with contextlib.ExitStack() as stack:
+            resources_to_update, _ = separate_resource_params(self.__dict__)
+            resources_to_update = {
+                attr_name: _call_resource_fn_with_default(
+                    stack, coerce_to_resource(resource), context
+                )
+                for attr_name, resource in resources_to_update.items()
+                if attr_name not in partial_resources_to_update
+            }
 
-        to_update = {**resources_to_update, **partial_resources_to_update}
-        return self._with_updated_values(to_update)
+            to_update = {**resources_to_update, **partial_resources_to_update}
+            yield self._with_updated_values(to_update)
 
     def with_resource_context(
         self, resource_context: InitResourceContext
     ) -> "ConfigurableResourceFactory[TResValue]":
         """Returns a new instance of the resource with the given resource init context bound."""
         # This utility is used to create a copy of this resource, without adjusting
         # any values in this case
         copy = self._with_updated_values({})
         copy._state__internal__ = copy._state__internal__._replace(  # noqa: SLF001
             resource_context=resource_context
         )
         return copy
 
     def _initialize_and_run(self, context: InitResourceContext) -> TResValue:
-        updated_resource = (
-            self._resolve_and_update_nested_resources(context)  # noqa: SLF001
-            .with_resource_context(context)
-            ._resolve_and_update_env_vars()
-        )
+        with self._resolve_and_update_nested_resources(context) as has_nested_resource:
+            updated_resource = has_nested_resource.with_resource_context(  # noqa: SLF001
+                context
+            )._resolve_and_update_env_vars()
 
-        return updated_resource._create_object_fn(context)  # noqa: SLF001
+            updated_resource.setup_for_execution(context)
+            return updated_resource.create_resource(context)
 
-    def _create_object_fn(self, context: InitResourceContext) -> TResValue:
-        return self.create_resource(context)
+    @contextlib.contextmanager
+    def _initialize_and_run_cm(
+        self, context: InitResourceContext
+    ) -> Generator[TResValue, None, None]:
+        with self._resolve_and_update_nested_resources(context) as has_nested_resource:
+            updated_resource = has_nested_resource.with_resource_context(  # noqa: SLF001
+                context
+            )._resolve_and_update_env_vars()
+
+            with updated_resource.yield_for_execution(context) as value:
+                yield value
+
+    def setup_for_execution(self, context: InitResourceContext) -> None:
+        """Optionally override this method to perform any pre-execution steps
+        needed before the resource is used in execution.
+        """
+        pass
+
+    def teardown_after_execution(self, context: InitResourceContext) -> None:
+        """Optionally override this method to perform any post-execution steps
+        needed after the resource is used in execution.
+
+        teardown_after_execution will be called even if any part of the run fails.
+        It will not be called if setup_for_execution fails.
+        """
+        pass
+
+    @contextlib.contextmanager
+    def yield_for_execution(self, context: InitResourceContext) -> Generator[TResValue, None, None]:
+        """Optionally override this method to perform any lifecycle steps
+        before or after the resource is used in execution. By default, calls
+        setup_for_execution before yielding, and teardown_after_execution after yielding.
+
+        Note that if you override this method and want setup_for_execution or
+        teardown_after_execution to be called, you must invoke them yourself.
+        """
+        self.setup_for_execution(context)
+        try:
+            yield self.create_resource(context)
+        finally:
+            self.teardown_after_execution(context)
 
     def get_resource_context(self) -> InitResourceContext:
         """Returns the context that this resource was initialized with."""
         return check.not_none(
             self._state__internal__.resource_context,
             additional_message="Attempted to get context before resource was initialized.",
         )
 
     @classmethod
     def from_resource_context(cls, context: InitResourceContext) -> TResValue:
         """Creates a new instance of this resource from a populated InitResourceContext.
         Useful when creating a resource from a function-based resource, for backwards
         compatibility purposes.
 
+        For resources that have custom teardown behavior, use from_resource_context_cm instead.
+
         Example usage:
 
         .. code-block:: python
 
             class MyResource(ConfigurableResource):
                 my_str: str
 
             @resource(config_schema=MyResource.to_config_schema())
             def my_resource(context: InitResourceContext) -> MyResource:
                 return MyResource.from_resource_context(context)
 
         """
-        return cls(**context.resource_config or {})._create_object_fn(context)  # noqa: SLF001
+        check.invariant(
+            not cls._is_cm_resource_cls(),
+            (
+                "Use from_resource_context_cm for resources which have custom teardown behavior,"
+                " e.g. overriding yield_for_execution or teardown_after_execution"
+            ),
+        )
+        return cls(**context.resource_config or {})._initialize_and_run(context)  # noqa: SLF001
+
+    @classmethod
+    @contextlib.contextmanager
+    def from_resource_context_cm(
+        cls, context: InitResourceContext
+    ) -> Generator[TResValue, None, None]:
+        """Context which generates a new instance of this resource from a populated InitResourceContext.
+        Useful when creating a resource from a function-based resource, for backwards
+        compatibility purposes. Handles custom teardown behavior.
+
+        Example usage:
+
+        .. code-block:: python
+
+            class MyResource(ConfigurableResource):
+                my_str: str
+
+            @resource(config_schema=MyResource.to_config_schema())
+            def my_resource(context: InitResourceContext) -> Generator[MyResource, None, None]:
+                with MyResource.from_resource_context_cm(context) as my_resource:
+                    yield my_resource
+
+        """
+        with cls(**context.resource_config or {})._initialize_and_run_cm(  # noqa: SLF001
+            context
+        ) as value:
+            yield value
 
 
 class ConfigurableResource(ConfigurableResourceFactory[TResValue]):
     """Base class for Dagster resources that utilize structured config.
 
     This class is a subclass of both :py:class:`ResourceDefinition` and :py:class:`Config`.
 
@@ -916,23 +1125,25 @@
 
 
 class PartialResource(Generic[TResValue], AllowDelayedDependencies, MakeConfigCacheable):
     data: Dict[str, Any]
     resource_cls: Type[ConfigurableResourceFactory[TResValue]]
 
     def __init__(
-        self, resource_cls: Type[ConfigurableResourceFactory[TResValue]], data: Dict[str, Any]
+        self,
+        resource_cls: Type[ConfigurableResourceFactory[TResValue]],
+        data: Dict[str, Any],
     ):
         resource_pointers, _data_without_resources = separate_resource_params(data)
 
         MakeConfigCacheable.__init__(self, data=data, resource_cls=resource_cls)  # type: ignore  # extends BaseModel, takes kwargs
 
         def resource_fn(context: InitResourceContext):
             instantiated = resource_cls(**context.resource_config, **data)
-            return instantiated._initialize_and_run(context)  # noqa: SLF001
+            return instantiated._get_initialize_and_run_fn()(context)  # noqa: SLF001
 
         self._state__internal__ = PartialResourceState(
             # We keep track of any resources we depend on which are not fully configured
             # so that we can retrieve them at runtime
             nested_partial_resources={
                 k: v for k, v in resource_pointers.items() if (not _is_fully_configured(v))
             },
@@ -1088,54 +1299,76 @@
         ConfigurableResourceFactory.__init__(self, **data)
 
     @abstractmethod
     def create_io_manager(self, context) -> TIOManagerValue:
         """Implement as one would implement a @io_manager decorator function."""
         raise NotImplementedError()
 
-    def _create_object_fn(self, context: InitResourceContext) -> TIOManagerValue:
-        return self.create_io_manager(context)
-
     def create_resource(self, context: InitResourceContext) -> TIOManagerValue:
-        # I/O manager factories execute a different code path that does not
-        # call create_resource
-        raise NotImplementedError()
+        return self.create_io_manager(context)
 
     @classmethod
     def configure_at_launch(cls: "Type[Self]", **kwargs) -> "PartialIOManager[Self]":
         """Returns a partially initialized copy of the IO manager, with remaining config fields
         set at runtime.
         """
         return PartialIOManager(cls, data=kwargs)
 
     @cached_method
     def get_resource_definition(self) -> ConfigurableIOManagerFactoryResourceDefinition:
         return ConfigurableIOManagerFactoryResourceDefinition(
-            resource_fn=self._initialize_and_run,
+            resource_fn=self._get_initialize_and_run_fn(),
             config_schema=self._config_schema,
             description=self.__doc__,
             resolve_resource_keys=self._resolve_required_resource_keys,
             nested_resources=self.nested_resources,
+            input_config_schema=self.__class__.input_config_schema(),
+            output_config_schema=self.__class__.output_config_schema(),
         )
 
+    @classmethod
+    def input_config_schema(
+        cls,
+    ) -> Optional[Union[CoercableToConfigSchema, Type[Config]]]:
+        return None
+
+    @classmethod
+    def output_config_schema(
+        cls,
+    ) -> Optional[Union[CoercableToConfigSchema, Type[Config]]]:
+        return None
+
 
 class PartialIOManager(Generic[TResValue], PartialResource[TResValue]):
     def __init__(
-        self, resource_cls: Type[ConfigurableResourceFactory[TResValue]], data: Dict[str, Any]
+        self,
+        resource_cls: Type[ConfigurableResourceFactory[TResValue]],
+        data: Dict[str, Any],
     ):
         PartialResource.__init__(self, resource_cls, data)
 
     @cached_method
     def get_resource_definition(self) -> ConfigurableIOManagerFactoryResourceDefinition:
+        input_config_schema = None
+        output_config_schema = None
+        if safe_is_subclass(self.resource_cls, ConfigurableIOManagerFactory):
+            factory_cls: Type[ConfigurableIOManagerFactory] = cast(
+                Type[ConfigurableIOManagerFactory], self.resource_cls
+            )
+            input_config_schema = factory_cls.input_config_schema()
+            output_config_schema = factory_cls.output_config_schema()
+
         return ConfigurableIOManagerFactoryResourceDefinition(
             resource_fn=self._state__internal__.resource_fn,
             config_schema=self._state__internal__.config_schema,
             description=self._state__internal__.description,
             resolve_resource_keys=self._resolve_required_resource_keys,
             nested_resources=self._state__internal__.nested_resources,
+            input_config_schema=input_config_schema,
+            output_config_schema=output_config_schema,
         )
 
 
 class ConfigurableIOManager(ConfigurableIOManagerFactory, IOManager):
     """Base class for Dagster IO managers that utilize structured config.
 
     This class is a subclass of both :py:class:`IOManagerDefinition`, :py:class:`Config`,
@@ -1179,15 +1412,17 @@
     IntSource: int,
     BoolSource: bool,
     ConfigFloatInstance: float,
 }
 
 
 def _wrap_config_type(
-    shape_type: PydanticShapeType, key_type: Optional[ConfigType], config_type: ConfigType
+    shape_type: PydanticShapeType,
+    key_type: Optional[ConfigType],
+    config_type: ConfigType,
 ) -> ConfigType:
     """Based on a Pydantic shape type, wraps a config type in the appropriate Dagster config wrapper.
     For example, if the shape type is a Pydantic list, the config type will be wrapped in an Array.
     """
     if shape_type == SHAPE_SINGLETON:
         return config_type
     elif shape_type == SHAPE_LIST:
@@ -1329,14 +1564,15 @@
         return BoolSource
     else:
         return convert_potential_field(potential_dagster_type).config_type
 
 
 def _is_pydantic_field_required(pydantic_field: ModelField) -> bool:
     # required is of type BoolUndefined = Union[bool, UndefinedType] in Pydantic
+
     if isinstance(pydantic_field.required, bool):
         return pydantic_field.required
 
     raise Exception(
         "pydantic.field.required is their UndefinedType sentinel value which we "
         "do not fully understand the semantics of right now. For the time being going "
         "to throw an error to figure see when we actually encounter this state."
@@ -1522,24 +1758,35 @@
     """
     return SeparatedResourceParams(
         resources={k: v for k, v in data.items() if is_coercible_to_resource(v)},
         non_resources={k: v for k, v in data.items() if not is_coercible_to_resource(v)},
     )
 
 
-def _call_resource_fn_with_default(obj: ResourceDefinition, context: InitResourceContext) -> Any:
+def _call_resource_fn_with_default(
+    stack: contextlib.ExitStack, obj: ResourceDefinition, context: InitResourceContext
+) -> Any:
     if isinstance(obj.config_schema, ConfiguredDefinitionConfigSchema):
         value = cast(Dict[str, Any], obj.config_schema.resolve_config({}).value)
         context = context.replace_config(value["config"])
     elif obj.config_schema.default_provided:
         context = context.replace_config(obj.config_schema.default_value)
-    if has_at_least_one_parameter(obj.resource_fn):
-        return cast(ResourceFunctionWithContext, obj.resource_fn)(context)
+
+    is_fn_generator = inspect.isgenerator(obj.resource_fn) or isinstance(
+        obj.resource_fn, contextlib.ContextDecorator
+    )
+    if has_at_least_one_parameter(obj.resource_fn):  # type: ignore[unreachable]
+        result = cast(ResourceFunctionWithContext, obj.resource_fn)(context)
+    else:
+        result = cast(ResourceFunctionWithoutContext, obj.resource_fn)()
+
+    if is_fn_generator:
+        return stack.enter_context(cast(contextlib.AbstractContextManager, result))
     else:
-        return cast(ResourceFunctionWithoutContext, obj.resource_fn)()
+        return result
 
 
 LateBoundTypesForResourceTypeChecking.set_actual_types_for_type_checking(
     resource_dep_type=ResourceDependency,
     resource_type=ConfigurableResourceFactory,
     partial_resource_type=PartialResource,
 )
```

### Comparing `dagster-1.3.2/dagster/_config/pythonic_config/attach_other_object_to_context.py` & `dagster-1.3.3/dagster/_config/pythonic_config/attach_other_object_to_context.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/pythonic_config/typing_utils.py` & `dagster-1.3.3/dagster/_config/pythonic_config/typing_utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/pythonic_config/utils.py` & `dagster-1.3.3/dagster/_config/pythonic_config/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/snap.py` & `dagster-1.3.3/dagster/_config/snap.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/source.py` & `dagster-1.3.3/dagster/_config/source.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/stack.py` & `dagster-1.3.3/dagster/_config/stack.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/traversal_context.py` & `dagster-1.3.3/dagster/_config/traversal_context.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/type_printer.py` & `dagster-1.3.3/dagster/_config/type_printer.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_config/validate.py` & `dagster-1.3.3/dagster/_config/validate.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/assets.py` & `dagster-1.3.3/dagster/_core/assets.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/code_pointer.py` & `dagster-1.3.3/dagster/_core/code_pointer.py`

 * *Files 2% similar despite different names*

```diff
@@ -183,21 +183,24 @@
                 self=self
             )
         else:
             return "{self.python_file}::{self.fn_name}".format(self=self)
 
 
 def _load_target_from_module(module: ModuleType, fn_name: str, error_suffix: str) -> object:
-    from dagster._core.definitions import AssetGroup
+    from dagster._core.definitions.load_assets_from_modules import (
+        assets_from_modules,
+    )
     from dagster._core.workspace.autodiscovery import LOAD_ALL_ASSETS
 
     if fn_name == LOAD_ALL_ASSETS:
         # LOAD_ALL_ASSETS is a special symbol that's returned when, instead of loading a particular
         # attribute, we should load all the assets in the module.
-        return AssetGroup.from_modules([module])
+        module_assets, module_source_assets, _ = assets_from_modules([module])
+        return [*module_assets, *module_source_assets]
     else:
         if not hasattr(module, fn_name):
             raise DagsterInvariantViolationError(f"{fn_name} not found {error_suffix}")
 
         return getattr(module, fn_name)
 
 
@@ -312,15 +315,15 @@
 
     def describe(self) -> str:
         return "reconstructable using {module}.{fn_name}".format(
             module=self.reconstructor_pointer.module, fn_name=self.reconstructor_pointer.fn_name
         )
 
     # Allow this to be hashed for use in `lru_cache`. This is needed because:
-    # - `ReconstructablePipeline` uses `lru_cache`
-    # - `ReconstructablePipeline` has a `ReconstructableRepository` attribute
+    # - `ReconstructableJob` uses `lru_cache`
+    # - `ReconstructableJob` has a `ReconstructableRepository` attribute
     # - `ReconstructableRepository` has a `CodePointer` attribute
     # - `CustomCodePointer` has collection attributes that are unhashable by default
     def __hash__(self) -> int:
         if not hasattr(self, "_hash"):
             self._hash = hash_collection(self)
         return self._hash
```

### Comparing `dagster-1.3.2/dagster/_core/container_context/config.py` & `dagster-1.3.3/dagster/_core/container_context/config.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/debug.py` & `dagster-1.3.3/dagster/_core/debug.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,59 +1,63 @@
 from typing import NamedTuple, Sequence
 
 import dagster._check as check
 from dagster._core.events.log import EventLogEntry
-from dagster._core.snap import ExecutionPlanSnapshot, PipelineSnapshot
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.instance import DagsterInstance
+from dagster._core.snap import ExecutionPlanSnapshot, JobSnapshot
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._serdes import serialize_value, whitelist_for_serdes
 
 
-@whitelist_for_serdes
+@whitelist_for_serdes(
+    storage_field_names={
+        "dagster_run": "pipeline_run",
+        "job_snapshot": "pipeline_snapshot",
+    }
+)
 class DebugRunPayload(
     NamedTuple(
         "_DebugRunPayload",
         [
             ("version", str),
-            ("pipeline_run", DagsterRun),
+            ("dagster_run", DagsterRun),
             ("event_list", Sequence[EventLogEntry]),
-            ("pipeline_snapshot", PipelineSnapshot),
+            ("job_snapshot", JobSnapshot),
             ("execution_plan_snapshot", ExecutionPlanSnapshot),
         ],
     )
 ):
     def __new__(
         cls,
         version: str,
-        pipeline_run: DagsterRun,
+        dagster_run: DagsterRun,
         event_list: Sequence[EventLogEntry],
-        pipeline_snapshot: PipelineSnapshot,
+        job_snapshot: JobSnapshot,
         execution_plan_snapshot: ExecutionPlanSnapshot,
     ):
         return super(DebugRunPayload, cls).__new__(
             cls,
             version=check.str_param(version, "version"),
-            pipeline_run=check.inst_param(pipeline_run, "pipeline_run", DagsterRun),
+            dagster_run=check.inst_param(dagster_run, "dagster_run", DagsterRun),
             event_list=check.sequence_param(event_list, "event_list", EventLogEntry),
-            pipeline_snapshot=check.inst_param(
-                pipeline_snapshot, "pipeline_snapshot", PipelineSnapshot
-            ),
+            job_snapshot=check.inst_param(job_snapshot, "job_snapshot", JobSnapshot),
             execution_plan_snapshot=check.inst_param(
                 execution_plan_snapshot, "execution_plan_snapshot", ExecutionPlanSnapshot
             ),
         )
 
     @classmethod
-    def build(cls, instance, run):
+    def build(cls, instance: DagsterInstance, run: DagsterRun) -> "DebugRunPayload":
         from dagster import __version__ as dagster_version
 
         return cls(
             version=dagster_version,
-            pipeline_run=run,
+            dagster_run=run,
             event_list=instance.all_logs(run.run_id),
-            pipeline_snapshot=instance.get_pipeline_snapshot(run.pipeline_snapshot_id),
+            job_snapshot=instance.get_job_snapshot(run.job_snapshot_id),  # type: ignore  # (possible none)
             execution_plan_snapshot=instance.get_execution_plan_snapshot(
-                run.execution_plan_snapshot_id
+                run.execution_plan_snapshot_id  # type: ignore  # (possible none)
             ),
         )
 
     def write(self, output_file):
         return output_file.write(serialize_value(self).encode("utf-8"))
```

### Comparing `dagster-1.3.2/dagster/_core/decorator_utils.py` & `dagster-1.3.3/dagster/_core/decorator_utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/__init__.py` & `dagster-1.3.3/dagster/_core/definitions/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -33,14 +33,15 @@
 from .hook_definition import HookDefinition as HookDefinition
 from .input import (
     GraphIn as GraphIn,
     In as In,
     InputDefinition as InputDefinition,
     InputMapping as InputMapping,
 )
+from .job_base import IJob as IJob
 from .logger_definition import (
     LoggerDefinition as LoggerDefinition,
     build_init_logger_context as build_init_logger_context,
     logger as logger,
 )
 from .metadata import (
     BoolMetadataValue as BoolMetadataValue,
@@ -70,19 +71,17 @@
     DynamicOut as DynamicOut,
     DynamicOutputDefinition as DynamicOutputDefinition,
     GraphOut as GraphOut,
     Out as Out,
     OutputDefinition as OutputDefinition,
     OutputMapping as OutputMapping,
 )
-from .pipeline_base import IPipeline as IPipeline
 from .reconstruct import (
-    ReconstructablePipeline as ReconstructablePipeline,
+    ReconstructableJob as ReconstructableJob,
     build_reconstructable_job as build_reconstructable_job,
-    build_reconstructable_pipeline as build_reconstructable_pipeline,
     reconstructable as reconstructable,
 )
 from .repository_definition import (
     RepositoryData as RepositoryData,
     RepositoryDefinition as RepositoryDefinition,
 )
 from .resolved_asset_deps import ResolvedAssetDependencies as ResolvedAssetDependencies
@@ -111,15 +110,14 @@
 from .sensor_definition import (
     DefaultSensorStatus as DefaultSensorStatus,
     SensorDefinition as SensorDefinition,
     SensorEvaluationContext as SensorEvaluationContext,
 )
 
 # isort: split
-from .asset_group import AssetGroup as AssetGroup
 from .asset_in import AssetIn as AssetIn
 from .asset_out import AssetOut as AssetOut
 from .asset_selection import AssetSelection as AssetSelection
 from .assets import AssetsDefinition as AssetsDefinition
 from .assets_job import build_assets_job as build_assets_job
 from .decorators import (
     asset as asset,
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/asset_graph.py` & `dagster-1.3.3/dagster/_core/definitions/asset_graph.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/asset_graph_subset.py` & `dagster-1.3.3/dagster/_core/definitions/asset_graph_subset.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/asset_in.py` & `dagster-1.3.3/dagster/_core/definitions/asset_in.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/asset_layer.py` & `dagster-1.3.3/dagster/_core/definitions/asset_layer.py`

 * *Files 0% similar despite different names*

```diff
@@ -350,15 +350,15 @@
     dep_node_set_by_asset_key: Dict[AssetKey, Set[NodeHandle]] = {}
     for asset_key, dep_node_handles in dep_nodes_by_asset_key.items():
         dep_node_set_by_asset_key[asset_key] = set(dep_node_handles)
     return dep_node_set_by_asset_key, dep_node_outputs_by_asset_key
 
 
 class AssetLayer:
-    """Stores all of the asset-related information for a Dagster job / pipeline. Maps each
+    """Stores all of the asset-related information for a Dagster job. Maps each
     input / output in the underlying graph to the asset it represents (if any), and records the
     dependencies between each asset.
 
     Args:
         asset_key_by_node_input_handle (Mapping[NodeInputHandle, AssetOutputInfo], optional): A mapping
             from a unique input in the underlying graph to the associated AssetKey that it loads from.
         asset_info_by_node_output_handle (Mapping[NodeOutputHandle, AssetOutputInfo], optional): A mapping
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/asset_out.py` & `dagster-1.3.3/dagster/_core/definitions/asset_out.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/asset_reconciliation_sensor.py` & `dagster-1.3.3/dagster/_core/definitions/asset_reconciliation_sensor.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/asset_selection.py` & `dagster-1.3.3/dagster/_core/definitions/asset_selection.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/asset_sensor_definition.py` & `dagster-1.3.3/dagster/_core/definitions/asset_sensor_definition.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/assets.py` & `dagster-1.3.3/dagster/_core/definitions/assets.py`

 * *Files 2% similar despite different names*

```diff
@@ -18,19 +18,22 @@
 
 import dagster._check as check
 from dagster._annotations import public
 from dagster._core.decorator_utils import get_function_params
 from dagster._core.definitions.asset_layer import get_dep_node_handles_of_graph_backed_asset
 from dagster._core.definitions.auto_materialize_policy import AutoMaterializePolicy
 from dagster._core.definitions.freshness_policy import FreshnessPolicy
+from dagster._core.definitions.input import In
 from dagster._core.definitions.metadata import ArbitraryMetadataMapping
 from dagster._core.definitions.time_window_partition_mapping import TimeWindowPartitionMapping
 from dagster._core.definitions.time_window_partitions import TimeWindowPartitionsDefinition
 from dagster._core.errors import DagsterInvalidDefinitionError, DagsterInvalidInvocationError
 from dagster._core.selector.subset_selector import SelectionTree
+from dagster._core.types.dagster_type import Nothing
+from dagster._utils import IHasInternalInit
 from dagster._utils.backcompat import (
     ExperimentalWarning,
     deprecation_warning,
     experimental_arg_warning,
 )
 from dagster._utils.merger import merge_dicts
 
@@ -56,25 +59,19 @@
 
 if TYPE_CHECKING:
     from dagster._core.execution.context.compute import OpExecutionContext
 
     from .graph_definition import GraphDefinition
 
 
-class AssetsDefinition(ResourceAddable):
+class AssetsDefinition(ResourceAddable, IHasInternalInit):
     """Defines a set of assets that are produced by the same op or graph.
 
     AssetsDefinitions are typically not instantiated directly, but rather produced using the
     :py:func:`@asset <asset>` or :py:func:`@multi_asset <multi_asset>` decorators.
-
-    Attributes:
-        asset_deps (Mapping[AssetKey, AbstractSet[AssetKey]]): Maps assets that are produced by this
-            definition to assets that they depend on. The dependencies can be either "internal",
-            meaning that they refer to other assets that are produced by this definition, or
-            "external", meaning that they refer to assets that aren't produced by this definition.
     """
 
     _node_def: NodeDefinition
     _keys_by_input_name: Mapping[str, AssetKey]
     _keys_by_output_name: Mapping[str, AssetKey]
     _partitions_def: Optional[PartitionsDefinition]
     _partition_mappings: Mapping[AssetKey, PartitionMapping]
@@ -233,46 +230,81 @@
             "auto_materialize_policies_by_key",
             key_type=AssetKey,
             value_type=AutoMaterializePolicy,
         )
 
         _validate_self_deps(
             input_keys=self._keys_by_input_name.values(),
-            output_keys=self._keys_by_output_name.values(),
+            output_keys=self._selected_asset_keys,
             partition_mappings=self._partition_mappings,
         )
 
+    @staticmethod
+    def dagster_internal_init(
+        *,
+        keys_by_input_name: Mapping[str, AssetKey],
+        keys_by_output_name: Mapping[str, AssetKey],
+        node_def: NodeDefinition,
+        partitions_def: Optional[PartitionsDefinition],
+        partition_mappings: Optional[Mapping[AssetKey, PartitionMapping]],
+        asset_deps: Optional[Mapping[AssetKey, AbstractSet[AssetKey]]],
+        selected_asset_keys: Optional[AbstractSet[AssetKey]],
+        can_subset: bool,
+        resource_defs: Optional[Mapping[str, object]],
+        group_names_by_key: Optional[Mapping[AssetKey, str]],
+        metadata_by_key: Optional[Mapping[AssetKey, ArbitraryMetadataMapping]],
+        freshness_policies_by_key: Optional[Mapping[AssetKey, FreshnessPolicy]],
+        auto_materialize_policies_by_key: Optional[Mapping[AssetKey, AutoMaterializePolicy]],
+        descriptions_by_key: Optional[Mapping[AssetKey, str]],
+    ) -> "AssetsDefinition":
+        return AssetsDefinition(
+            keys_by_input_name=keys_by_input_name,
+            keys_by_output_name=keys_by_output_name,
+            node_def=node_def,
+            partitions_def=partitions_def,
+            partition_mappings=partition_mappings,
+            asset_deps=asset_deps,
+            selected_asset_keys=selected_asset_keys,
+            can_subset=can_subset,
+            resource_defs=resource_defs,
+            group_names_by_key=group_names_by_key,
+            metadata_by_key=metadata_by_key,
+            freshness_policies_by_key=freshness_policies_by_key,
+            auto_materialize_policies_by_key=auto_materialize_policies_by_key,
+            descriptions_by_key=descriptions_by_key,
+        )
+
     def __call__(self, *args: object, **kwargs: object) -> object:
         from dagster._core.definitions.decorators.op_decorator import DecoratedOpFunction
         from dagster._core.execution.context.compute import OpExecutionContext
 
         from .graph_definition import GraphDefinition
 
         if isinstance(self.node_def, GraphDefinition):
             return self._node_def(*args, **kwargs)
-        solid_def = self.op
+        op_def = self.op
         provided_context: Optional[OpExecutionContext] = None
         if len(args) > 0 and isinstance(args[0], OpExecutionContext):
             provided_context = _build_invocation_context_with_included_resources(self, args[0])
             new_args = [provided_context, *args[1:]]
-            return solid_def(*new_args, **kwargs)
+            return op_def(*new_args, **kwargs)
         elif (
-            isinstance(solid_def.compute_fn, DecoratedOpFunction)
-            and solid_def.compute_fn.has_context_arg()
+            isinstance(op_def.compute_fn, DecoratedOpFunction)
+            and op_def.compute_fn.has_context_arg()
         ):
-            context_param_name = get_function_params(solid_def.compute_fn.decorated_fn)[0].name
+            context_param_name = get_function_params(op_def.compute_fn.decorated_fn)[0].name
             if context_param_name in kwargs:
                 provided_context = _build_invocation_context_with_included_resources(
                     self, cast(OpExecutionContext, kwargs[context_param_name])
                 )
                 new_kwargs = dict(kwargs)
                 new_kwargs[context_param_name] = provided_context
-                return solid_def(*args, **new_kwargs)
+                return op_def(*args, **new_kwargs)
 
-        return solid_def(*args, **kwargs)
+        return op_def(*args, **kwargs)
 
     @public
     @staticmethod
     def from_graph(
         graph_def: "GraphDefinition",
         *,
         keys_by_input_name: Optional[Mapping[str, AssetKey]] = None,
@@ -526,15 +558,15 @@
                 keys_by_output_name_with_prefix[output_name]: group_name
                 for output_name, group_name in group_names_by_output_name.items()
                 if group_name is not None
             }
         else:
             group_names_by_key = None
 
-        return AssetsDefinition(
+        return AssetsDefinition.dagster_internal_init(
             keys_by_input_name=keys_by_input_name,
             keys_by_output_name=keys_by_output_name_with_prefix,
             node_def=node_def,
             asset_deps=transformed_internal_asset_deps or None,
             partitions_def=check.opt_inst_param(
                 partitions_def,
                 "partitions_def",
@@ -573,14 +605,15 @@
                 keys_by_output_name_with_prefix[output_name]: description
                 for output_name, description in descriptions_by_output_name.items()
                 if description is not None
             }
             if descriptions_by_output_name
             else None,
             can_subset=can_subset,
+            selected_asset_keys=None,  # node has no subselection info
         )
 
     @public
     @property
     def can_subset(self) -> bool:
         return self._can_subset
 
@@ -607,14 +640,19 @@
     @property
     def node_def(self) -> NodeDefinition:
         return self._node_def
 
     @public
     @property
     def asset_deps(self) -> Mapping[AssetKey, AbstractSet[AssetKey]]:
+        """Maps assets that are produced by this definition to assets that they depend on. The
+        dependencies can be either "internal", meaning that they refer to other assets that are
+        produced by this definition, or "external", meaning that they refer to assets that aren't
+        produced by this definition.
+        """
         return self._asset_deps
 
     @property
     def input_names(self) -> Iterable[str]:
         return self.keys_by_input_name.keys()
 
     @public
@@ -839,15 +877,15 @@
                 ] = replaced_auto_materialize_policy
 
         replaced_descriptions_by_key = {
             output_asset_key_replacements.get(key, key): description
             for key, description in self._descriptions_by_key.items()
         }
 
-        return self.__class__(
+        return __class__.dagster_internal_init(
             keys_by_input_name={
                 input_name: input_asset_key_replacements.get(key, key)
                 for input_name, key in self._keys_by_input_name.items()
             },
             keys_by_output_name={
                 output_name: output_asset_key_replacements.get(key, key)
                 for output_name, key in self._keys_by_output_name.items()
@@ -883,14 +921,73 @@
                 for key, value in self.metadata_by_key.items()
             },
             freshness_policies_by_key=replaced_freshness_policies_by_key,
             auto_materialize_policies_by_key=replaced_auto_materialize_policies_by_key,
             descriptions_by_key=replaced_descriptions_by_key,
         )
 
+    def _subset_op_backed_asset(
+        self, asset_subselection: AbstractSet[AssetKey]
+    ) -> "AssetsDefinition":
+        """Creates a new AssetsDefinition which will only materialize the given asset keys. In some
+        cases, this subset will have a new set of root assets, which were previously produced within
+        the subset itself. In this case, we will create new inputs for those assets, and generate a
+        new copy of the op with the new inputs.
+        """
+        # the set of keys that are not selected but are upstream of the selected keys
+        input_keys = {
+            dep_key for key in asset_subselection for dep_key in self.asset_deps[key]
+        }.difference(asset_subselection)
+        ins = {}
+
+        input_names_by_key = {v: k for k, v in self.keys_by_input_name.items()}
+        output_names_by_key = {v: k for k, v in self.keys_by_output_name.items()}
+        op_valid = True
+        for input_key in input_keys:
+            input_name = input_names_by_key.get(input_key)
+            if input_name is None:
+                # there is no input existing for this key, meaning this is something that is produced
+                # within the op if it is not subsetted. this requires us to create a new input, and
+                # therefore a new copy of the underlying op.
+                op_valid = False
+                output_name = output_names_by_key[input_key]
+                ins[output_name] = In(Nothing)
+                input_names_by_key[input_key] = output_name
+            else:
+                # just copy over existing input
+                ins[input_name] = self.op.ins[input_name]
+
+        # must create a new copy of the op
+        if op_valid:
+            op_def = self.op
+        else:
+            # create a hash of the selected keys to generate a unique name for this subsetted op
+            suffix = hashlib.md5((str(list(sorted(asset_subselection)))).encode()).hexdigest()[-5:]
+            op_def = self.op.with_replaced_properties(
+                name=f"{self.op.name}_subset_{suffix}", ins=ins
+            )
+
+        return AssetsDefinition.dagster_internal_init(
+            keys_by_input_name={**{v: k for k, v in input_names_by_key.items()}},
+            # keep track of the original mapping
+            keys_by_output_name=self.node_keys_by_output_name,
+            node_def=op_def,
+            partitions_def=self.partitions_def,
+            partition_mappings=self._partition_mappings,
+            asset_deps=self._asset_deps,
+            can_subset=self.can_subset,
+            selected_asset_keys=asset_subselection,
+            resource_defs=self.resource_defs,
+            group_names_by_key=self.group_names_by_key,
+            metadata_by_key=self.metadata_by_key,
+            freshness_policies_by_key=self.freshness_policies_by_key,
+            auto_materialize_policies_by_key=self.auto_materialize_policies_by_key,
+            descriptions_by_key=self.descriptions_by_key,
+        )
+
     def _subset_graph_backed_asset(
         self,
         selected_asset_keys: AbstractSet[AssetKey],
     ):
         from dagster._core.definitions.graph_definition import GraphDefinition
         from dagster._core.selector.subset_selector import (
             convert_dot_separated_string_to_selection_tree,
@@ -979,47 +1076,33 @@
             # occurs. This is the same behavior as multi-asset subsetting.
 
             subsetted_asset_deps = {
                 out_asset_key: set(self._keys_by_input_name.values())
                 for out_asset_key in subsetted_keys_by_output_name.values()
             }
 
-            return AssetsDefinition(
+            return AssetsDefinition.dagster_internal_init(
                 keys_by_input_name=subsetted_keys_by_input_name,
                 keys_by_output_name=subsetted_keys_by_output_name,
                 node_def=subsetted_node,
                 partitions_def=self.partitions_def,
                 partition_mappings=self._partition_mappings,
                 asset_deps=subsetted_asset_deps,
                 can_subset=self.can_subset,
                 selected_asset_keys=selected_asset_keys & self.keys,
                 resource_defs=self.resource_defs,
                 group_names_by_key=self.group_names_by_key,
                 metadata_by_key=self.metadata_by_key,
                 freshness_policies_by_key=self.freshness_policies_by_key,
                 auto_materialize_policies_by_key=self.auto_materialize_policies_by_key,
+                descriptions_by_key=self.descriptions_by_key,
             )
         else:
             # multi_asset subsetting
-            return AssetsDefinition(
-                # keep track of the original mapping
-                keys_by_input_name=self._keys_by_input_name,
-                keys_by_output_name=self._keys_by_output_name,
-                node_def=self.node_def,
-                partitions_def=self.partitions_def,
-                partition_mappings=self._partition_mappings,
-                asset_deps=self._asset_deps,
-                can_subset=self.can_subset,
-                selected_asset_keys=asset_subselection,
-                resource_defs=self.resource_defs,
-                group_names_by_key=self.group_names_by_key,
-                metadata_by_key=self.metadata_by_key,
-                freshness_policies_by_key=self.freshness_policies_by_key,
-                auto_materialize_policies_by_key=self.auto_materialize_policies_by_key,
-            )
+            return self._subset_op_backed_asset(asset_subselection)
 
     @public
     def to_source_assets(self) -> Sequence[SourceAsset]:
         """Returns a SourceAsset for each asset in this definition.
 
         Each produced SourceAsset will have the same key, metadata, io_manager_key, etc. as the
         corresponding asset
@@ -1141,28 +1224,29 @@
         )
         relevant_resource_defs = {
             key: resource_def
             for key, resource_def in merged_resource_defs.items()
             if key in relevant_keys
         }
 
-        return AssetsDefinition(
+        return AssetsDefinition.dagster_internal_init(
             keys_by_input_name=self._keys_by_input_name,
             keys_by_output_name=self._keys_by_output_name,
             node_def=self.node_def,
             partitions_def=self._partitions_def,
             partition_mappings=self._partition_mappings,
             asset_deps=self._asset_deps,
             selected_asset_keys=self._selected_asset_keys,
             can_subset=self._can_subset,
             resource_defs=relevant_resource_defs,
             group_names_by_key=self.group_names_by_key,
             metadata_by_key=self.metadata_by_key,
             freshness_policies_by_key=self.freshness_policies_by_key,
             auto_materialize_policies_by_key=self.auto_materialize_policies_by_key,
+            descriptions_by_key=self.descriptions_by_key,
         )
 
 
 def _infer_keys_by_input_names(
     node_def: Union["GraphDefinition", OpDefinition], keys_by_input_name: Mapping[str, AssetKey]
 ) -> Mapping[str, AssetKey]:
     all_input_names = [input_def.name for input_def in node_def.input_defs]
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/assets_job.py` & `dagster-1.3.3/dagster/_core/definitions/assets_job.py`

 * *Files 1% similar despite different names*

```diff
@@ -109,19 +109,19 @@
 def build_assets_job(
     name: str,
     assets: Sequence[AssetsDefinition],
     source_assets: Optional[Sequence[Union[SourceAsset, AssetsDefinition]]] = None,
     resource_defs: Optional[Mapping[str, object]] = None,
     description: Optional[str] = None,
     config: Optional[
-        Union[ConfigMapping, Mapping[str, object], PartitionedConfig[object], "RunConfig"]
+        Union[ConfigMapping, Mapping[str, object], PartitionedConfig, "RunConfig"]
     ] = None,
     tags: Optional[Mapping[str, str]] = None,
     executor_def: Optional[ExecutorDefinition] = None,
-    partitions_def: Optional[PartitionsDefinition[object]] = None,
+    partitions_def: Optional[PartitionsDefinition] = None,
     _asset_selection_data: Optional[AssetSelectionData] = None,
 ) -> JobDefinition:
     """Builds a job that materializes the given assets.
 
     The dependencies between the ops in the job are determined by the asset dependencies defined
     in the metadata on the provided asset nodes.
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/auto_materialize_policy.py` & `dagster-1.3.3/dagster/_core/definitions/auto_materialize_policy.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/cacheable_assets.py` & `dagster-1.3.3/dagster/_core/definitions/cacheable_assets.py`

 * *Files 3% similar despite different names*

```diff
@@ -28,14 +28,18 @@
             ("internal_asset_deps", Optional[Mapping[str, AbstractSet[AssetKey]]]),
             ("group_name", Optional[str]),
             ("metadata_by_output_name", Optional[Mapping[str, MetadataUserInput]]),
             ("key_prefix", Optional[CoercibleToAssetKeyPrefix]),
             ("can_subset", bool),
             ("extra_metadata", Optional[Mapping[Any, Any]]),
             ("freshness_policies_by_output_name", Optional[Mapping[str, FreshnessPolicy]]),
+            (
+                "auto_materialize_policies_by_output_name",
+                Optional[Mapping[str, AutoMaterializePolicy]],
+            ),
         ],
     )
 ):
     """Data representing cacheable metadata about assets, which can be used to generate
     AssetsDefinition objects in other processes.
     """
 
@@ -46,14 +50,17 @@
         internal_asset_deps: Optional[Mapping[str, AbstractSet[AssetKey]]] = None,
         group_name: Optional[str] = None,
         metadata_by_output_name: Optional[Mapping[str, MetadataUserInput]] = None,
         key_prefix: Optional[Sequence[str]] = None,
         can_subset: bool = False,
         extra_metadata: Optional[Mapping[Any, Any]] = None,
         freshness_policies_by_output_name: Optional[Mapping[str, FreshnessPolicy]] = None,
+        auto_materialize_policies_by_output_name: Optional[
+            Mapping[str, AutoMaterializePolicy]
+        ] = None,
     ):
         extra_metadata = check.opt_nullable_mapping_param(extra_metadata, "extra_metadata")
         try:
             # check that the value is JSON serializable
             seven.dumps(extra_metadata)
         except TypeError:
             check.failed("Value for `extra_metadata` is not JSON serializable.")
@@ -83,19 +90,25 @@
             extra_metadata=extra_metadata,
             freshness_policies_by_output_name=check.opt_nullable_mapping_param(
                 freshness_policies_by_output_name,
                 "freshness_policies_by_output_name",
                 key_type=str,
                 value_type=FreshnessPolicy,
             ),
+            auto_materialize_policies_by_output_name=check.opt_nullable_mapping_param(
+                auto_materialize_policies_by_output_name,
+                "auto_materialize_policies_by_output_name",
+                key_type=str,
+                value_type=AutoMaterializePolicy,
+            ),
         )
 
     # Allow this to be hashed for use in `lru_cache`. This is needed because:
-    # - `ReconstructablePipeline` uses `lru_cache`
-    # - `ReconstructablePipeline` has a `ReconstructableRepository` attribute
+    # - `ReconstructableJob` uses `lru_cache`
+    # - `ReconstructableJob` has a `ReconstructableRepository` attribute
     # - `ReconstructableRepository` has a `RepositoryLoadData` attribute
     # - `RepositoryLoadData` has a `Mapping` attribute containing `AssetsDefinitionCacheableData`
     # - `AssetsDefinitionCacheableData` has collection attributes that are unhashable by default
     def __hash__(self) -> int:
         if not hasattr(self, "_hash"):
             self._hash = hash_collection(self)
         return self._hash
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/composition.py` & `dagster-1.3.3/dagster/_core/definitions/composition.py`

 * *Files 0% similar despite different names*

```diff
@@ -721,15 +721,15 @@
         op_retry_policy: Optional[RetryPolicy] = None,
         version_strategy: Optional[VersionStrategy] = None,
         partitions_def: Optional["PartitionsDefinition"] = None,
         input_values: Optional[Mapping[str, object]] = None,
     ) -> "JobDefinition":
         if not isinstance(self.node_def, GraphDefinition):
             raise DagsterInvalidInvocationError(
-                "Attemped to call `execute_in_process` on a composite solid.  Only graphs "
+                "Attemped to call `to_job` on a non-graph.  Only graphs "
                 "constructed using the `@graph` decorator support this method."
             )
 
         tags = check.opt_mapping_param(tags, "tags", key_type=str)
         hooks = check.opt_set_param(hooks, "hooks", HookDefinition)
         input_values = check.opt_mapping_param(input_values, "input_values")
         op_retry_policy = check.opt_inst_param(op_retry_policy, "op_retry_policy", RetryPolicy)
@@ -759,15 +759,15 @@
         resources: Optional[Mapping[str, Any]] = None,
         raise_on_error: bool = True,
         run_id: Optional[str] = None,
         input_values: Optional[Mapping[str, object]] = None,
     ) -> "ExecuteInProcessResult":
         if not isinstance(self.node_def, GraphDefinition):
             raise DagsterInvalidInvocationError(
-                "Attemped to call `execute_in_process` on a composite solid.  Only graphs "
+                "Attemped to call `execute_in_process` on a non-graph.  Only graphs "
                 "constructed using the `@graph` decorator support this method."
             )
 
         from dagster._core.execution.build_resources import wrap_resources_for_execution
 
         from .executor_definition import execute_in_process_executor
         from .job_definition import JobDefinition
@@ -1018,24 +1018,24 @@
         graph_name (str): User-defined name of the definition being constructed
         fn (Callable): The composition function to be called.
         provided_input_defs(List[InputDefinition]): List of input definitions
             explicitly provided to the decorator by the user.
         provided_output_defs(List[OutputDefinition]): List of output definitions
             explicitly provided to the decorator by the user.
         config_mapping (Any): Config mapping provided to decorator by user. In
-            pipeline/composite_solid case, this would have been constructed from a user-provided
+            job/graph case, this would have been constructed from a user-provided
             config_schema and config_fn.
         ignore_output_from_composite_fn(Bool): Because of backwards compatibility
-            issues, pipelines ignore the return value out of the mapping if
+            issues, jobs ignore the return value out of the mapping if
             the user has not explicitly provided the output definitions.
             This should be removed in 0.11.0.
     """
     from .decorators.op_decorator import (
         NoContextDecoratedOpFunction,
-        resolve_checked_solid_fn_inputs,
+        resolve_checked_op_fn_inputs,
     )
 
     actual_output_defs: Sequence[OutputDefinition]
     if provided_output_defs is None:
         outputs_are_explicit = False
         actual_output_defs = [OutputDefinition.create_from_inferred(infer_output_props(fn))]
     elif len(provided_output_defs) == 1:
@@ -1043,15 +1043,15 @@
         actual_output_defs = [provided_output_defs[0].combine_with_inferred(infer_output_props(fn))]
     else:
         outputs_are_explicit = True
         actual_output_defs = provided_output_defs
 
     compute_fn = NoContextDecoratedOpFunction(fn)
 
-    actual_input_defs = resolve_checked_solid_fn_inputs(
+    actual_input_defs = resolve_checked_op_fn_inputs(
         decorator_name=decorator_name,
         fn_name=graph_name,
         compute_fn=compute_fn,
         explicit_input_defs=provided_input_defs,
         exclude_nothing=False,
     )
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/config.py` & `dagster-1.3.3/dagster/_core/definitions/config.py`

 * *Files 2% similar despite different names*

```diff
@@ -36,15 +36,15 @@
     """Defines a config mapping for a graph (or job).
 
     By specifying a config mapping function, you can override the configuration for the child
     ops and graphs contained within a graph.
 
     Config mappings require the configuration schema to be specified as ``config_schema``, which will
     be exposed as the configuration schema for the graph, as well as a configuration mapping
-    function, ``config_fn``, which maps the config provided to the composite solid to the config
+    function, ``config_fn``, which maps the config provided to the graph to the config
     that will be provided to the child nodes.
 
     Args:
         config_fn (Callable[[dict], dict]): The function that will be called
             to map the graph config to a config appropriate for the child nodes.
         config_schema (ConfigSchema): The schema of the graph config.
         receive_processed_config_values (Optional[bool]): If true, config values provided to the config_fn
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/configurable.py` & `dagster-1.3.3/dagster/_core/definitions/configurable.py`

 * *Files 2% similar despite different names*

```diff
@@ -41,15 +41,15 @@
 
     def apply_config_mapping(self, config: Any) -> EvaluateValueResult:
         """Applies user-provided config mapping functions to the given configuration and validates the
         results against the respective config schema.
 
         Expects incoming config to be validated and have fully-resolved values (StringSource values
         resolved, Enum types hydrated, etc.) via process_config() during ResolvedRunConfig
-        construction and CompositeSolid config mapping.
+        construction and Graph config mapping.
 
         Args:
             config (Any): A validated and resolved configuration dictionary matching this object's
             config_schema
 
         Returns (EvaluateValueResult):
             If successful, the value is a validated and resolved configuration dictionary for the
@@ -163,28 +163,28 @@
     from dagster._core.definitions.composition import PendingNodeInvocation
 
     check.param_invariant(
         not isinstance(configurable, PendingNodeInvocation),
         "configurable",
         (
             "You have invoked `configured` on a PendingNodeInvocation (an intermediate type), which"
-            " is produced by aliasing or tagging a solid definition. To configure a solid, you must"
-            " call `configured` on either a SolidDefinition and CompositeSolidDefinition. To fix"
+            " is produced by aliasing or tagging a node definition. To configure a node, you must"
+            " call `configured` on either an OpDefinition and GraphDefinition. To fix"
             " this error, make sure to call `configured` on the definition object *before* using"
             " the `tag` or `alias` methods. For usage examples, see"
             " https://docs.dagster.io/concepts/configuration/configured"
         ),
     )
     check.inst_param(
         configurable,
         "configurable",
         ConfigurableDefinition,
         (
             "Only the following types can be used with the `configured` method: ResourceDefinition,"
-            " ExecutorDefinition, CompositeSolidDefinition, SolidDefinition, and LoggerDefinition."
+            " ExecutorDefinition, GraphDefinition, NodeDefinition, and LoggerDefinition."
             " For usage examples of `configured`, see"
             " https://docs.dagster.io/concepts/configuration/configured"
         ),
     )
 
 
 T_Configurable = TypeVar(
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/data_time.py` & `dagster-1.3.3/dagster/_core/definitions/data_time.py`

 * *Files 0% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 from dagster._core.definitions.events import AssetKey
 from dagster._core.definitions.time_window_partitions import (
     TimeWindowPartitionsDefinition,
     TimeWindowPartitionsSubset,
 )
 from dagster._core.errors import DagsterInvariantViolationError
 from dagster._core.event_api import EventLogRecord
-from dagster._core.storage.pipeline_run import FINISHED_STATUSES, DagsterRunStatus, RunsFilter
+from dagster._core.storage.dagster_run import FINISHED_STATUSES, DagsterRunStatus, RunsFilter
 from dagster._utils import make_hashable
 from dagster._utils.cached_method import cached_method
 from dagster._utils.caching_instance_queryer import CachingInstanceQueryer
 
 
 class CachingDataTimeResolver:
     _instance_queryer: CachingInstanceQueryer
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/data_version.py` & `dagster-1.3.3/dagster/_core/definitions/data_version.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/decorators/__init__.py` & `dagster-1.3.3/dagster/_core/definitions/decorators/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/decorators/asset_decorator.py` & `dagster-1.3.3/dagster/_core/definitions/decorators/asset_decorator.py`

 * *Files 2% similar despite different names*

```diff
@@ -66,15 +66,15 @@
     config_schema: Optional[UserConfigSchema] = None,
     required_resource_keys: Optional[Set[str]] = ...,
     resource_defs: Optional[Mapping[str, object]] = ...,
     io_manager_def: Optional[IOManagerDefinition] = ...,
     io_manager_key: Optional[str] = ...,
     compute_kind: Optional[str] = ...,
     dagster_type: Optional[DagsterType] = ...,
-    partitions_def: Optional[PartitionsDefinition[Any]] = ...,
+    partitions_def: Optional[PartitionsDefinition] = ...,
     op_tags: Optional[Mapping[str, Any]] = ...,
     group_name: Optional[str] = ...,
     output_required: bool = ...,
     freshness_policy: Optional[FreshnessPolicy] = ...,
     auto_materialize_policy: Optional[AutoMaterializePolicy] = ...,
     retry_policy: Optional[RetryPolicy] = ...,
     code_version: Optional[str] = ...,
@@ -94,15 +94,15 @@
     config_schema: Optional[UserConfigSchema] = None,
     required_resource_keys: Optional[Set[str]] = None,
     resource_defs: Optional[Mapping[str, object]] = None,
     io_manager_def: Optional[IOManagerDefinition] = None,
     io_manager_key: Optional[str] = None,
     compute_kind: Optional[str] = None,
     dagster_type: Optional[DagsterType] = None,
-    partitions_def: Optional[PartitionsDefinition[Any]] = None,
+    partitions_def: Optional[PartitionsDefinition] = None,
     op_tags: Optional[Mapping[str, Any]] = None,
     group_name: Optional[str] = None,
     output_required: bool = True,
     freshness_policy: Optional[FreshnessPolicy] = None,
     auto_materialize_policy: Optional[AutoMaterializePolicy] = None,
     retry_policy: Optional[RetryPolicy] = None,
     code_version: Optional[str] = None,
@@ -351,43 +351,48 @@
         }
         partition_mappings = {
             keys_by_input_name[input_name]: asset_in.partition_mapping
             for input_name, asset_in in self.ins.items()
             if asset_in.partition_mapping is not None
         }
 
-        return AssetsDefinition(
+        return AssetsDefinition.dagster_internal_init(
             keys_by_input_name=keys_by_input_name,
             keys_by_output_name={"result": out_asset_key},
             node_def=op,
             partitions_def=self.partitions_def,
             partition_mappings=partition_mappings if partition_mappings else None,
             resource_defs=self.resource_defs,
             group_names_by_key={out_asset_key: self.group_name} if self.group_name else None,
             freshness_policies_by_key={out_asset_key: self.freshness_policy}
             if self.freshness_policy
             else None,
             auto_materialize_policies_by_key={out_asset_key: self.auto_materialize_policy}
             if self.auto_materialize_policy
             else None,
+            asset_deps=None,  # no asset deps in single-asset decorator
+            selected_asset_keys=None,  # no subselection in decorator
+            can_subset=False,
+            metadata_by_key=None,  # not supported for now
+            descriptions_by_key=None,  # not supported for now
         )
 
 
 def multi_asset(
     *,
     outs: Mapping[str, AssetOut],
     name: Optional[str] = None,
     ins: Optional[Mapping[str, AssetIn]] = None,
     non_argument_deps: Optional[Union[Set[AssetKey], Set[str]]] = None,
     description: Optional[str] = None,
     config_schema: Optional[UserConfigSchema] = None,
     required_resource_keys: Optional[Set[str]] = None,
     compute_kind: Optional[str] = None,
     internal_asset_deps: Optional[Mapping[str, Set[AssetKey]]] = None,
-    partitions_def: Optional[PartitionsDefinition[object]] = None,
+    partitions_def: Optional[PartitionsDefinition] = None,
     op_tags: Optional[Mapping[str, Any]] = None,
     can_subset: bool = False,
     resource_defs: Optional[Mapping[str, object]] = None,
     group_name: Optional[str] = None,
     retry_policy: Optional[RetryPolicy] = None,
     code_version: Optional[str] = None,
 ) -> Callable[[Callable[..., Any]], AssetsDefinition]:
@@ -562,26 +567,29 @@
         }
         partition_mappings = {
             keys_by_input_name[input_name]: asset_in.partition_mapping
             for input_name, asset_in in (ins or {}).items()
             if asset_in.partition_mapping is not None
         }
 
-        return AssetsDefinition(
+        return AssetsDefinition.dagster_internal_init(
             keys_by_input_name=keys_by_input_name,
             keys_by_output_name=keys_by_output_name,
             node_def=op,
             asset_deps={keys_by_output_name[name]: asset_deps[name] for name in asset_deps},
             partitions_def=partitions_def,
             partition_mappings=partition_mappings if partition_mappings else None,
             can_subset=can_subset,
             resource_defs=resource_defs,
             group_names_by_key=group_names_by_key,
             freshness_policies_by_key=freshness_policies_by_key,
             auto_materialize_policies_by_key=auto_materialize_policies_by_key,
+            selected_asset_keys=None,  # no subselection in decorator
+            descriptions_by_key=None,  # not supported for now
+            metadata_by_key=None,  # not supported for now
         )
 
     return inner
 
 
 def build_asset_ins(
     fn: Callable,
@@ -816,15 +824,15 @@
 
 
 def graph_multi_asset(
     *,
     outs: Mapping[str, AssetOut],
     name: Optional[str] = None,
     ins: Optional[Mapping[str, AssetIn]] = None,
-    partitions_def: Optional[PartitionsDefinition[object]] = None,
+    partitions_def: Optional[PartitionsDefinition] = None,
     group_name: Optional[str] = None,
     can_subset: bool = False,
     resource_defs: Optional[Mapping[str, ResourceDefinition]] = None,
 ) -> Callable[[Callable[..., Any]], AssetsDefinition]:
     """Create a combined definition of multiple assets that are computed using the same graph of
     ops, and the same upstream assets.
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/decorators/config_mapping_decorator.py` & `dagster-1.3.3/dagster/_core/definitions/decorators/config_mapping_decorator.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/decorators/graph_decorator.py` & `dagster-1.3.3/dagster/_core/definitions/decorators/graph_decorator.py`

 * *Files 1% similar despite different names*

```diff
@@ -68,15 +68,15 @@
 
         from dagster._core.definitions.composition import do_composition
 
         (
             input_mappings,
             output_mappings,
             dependencies,
-            solid_defs,
+            node_defs,
             config_mapping,
             positional_inputs,
             node_input_source_assets,
         ) = do_composition(
             decorator_name="@graph",
             graph_name=self.name,
             fn=fn,
@@ -85,15 +85,15 @@
             ignore_output_from_composition_fn=False,
             config_mapping=self.config_mapping,
         )
 
         graph_def = GraphDefinition(
             name=self.name,
             dependencies=dependencies,
-            node_defs=solid_defs,
+            node_defs=node_defs,
             description=self.description or format_docstring_for_description(fn),
             input_mappings=input_mappings,
             output_mappings=output_mappings,
             config=config_mapping,
             positional_inputs=positional_inputs,
             tags=self.tags,
             node_input_source_assets=node_input_source_assets,
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/decorators/hook_decorator.py` & `dagster-1.3.3/dagster/_core/definitions/decorators/hook_decorator.py`

 * *Files 6% similar despite different names*

```diff
@@ -98,16 +98,16 @@
 
     This decorator is currently used internally by Dagster machinery to support success_hook and
     failure_hook.
 
     The user-defined hook function requires two parameters:
     - A `context` object is passed as the first parameter. The context is an instance of
         :py:class:`context <HookContext>`, and provides access to system
-        information, such as loggers (context.log), resources (context.resources), the solid
-        (context.solid) and its execution step (context.step) which triggers this hook.
+        information, such as loggers (context.log), resources (context.resources), the op
+        (context.op) and its execution step (context.step) which triggers this hook.
     - An `event_list` object is passed as the second paramter. It provides the full event list of the
         associated execution step.
 
     Args:
         name (Optional[str]): The name of this hook.
         required_resource_keys (Optional[AbstractSet[str]]): Keys for the resources required by the
             hook.
@@ -115,18 +115,15 @@
     Examples:
         .. code-block:: python
 
             @event_list_hook(required_resource_keys={'slack'})
             def slack_on_materializations(context, event_list):
                 for event in event_list:
                     if event.event_type == DagsterEventType.ASSET_MATERIALIZATION:
-                        message = '{solid} has materialized an asset {key}.'.format(
-                            solid=context.solid.name,
-                            key=event.asset_key
-                        )
+                        message = f'{context.op_name} has materialized an asset {event.asset_key}.'
                         # send a slack message every time a materialization event occurs
                         context.resources.slack.send_message(message)
 
 
     """
     # This case is for when decorator is used bare, without arguments.
     # e.g. @event_list_hook versus @event_list_hook()
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/decorators/job_decorator.py` & `dagster-1.3.3/dagster/_core/definitions/decorators/job_decorator.py`

 * *Files 2% similar despite different names*

```diff
@@ -25,22 +25,22 @@
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
         tags: Optional[Mapping[str, Any]] = None,
         metadata: Optional[Mapping[str, RawMetadataValue]] = None,
         resource_defs: Optional[Mapping[str, ResourceDefinition]] = None,
         config: Optional[
-            Union[ConfigMapping, Mapping[str, Any], "RunConfig", "PartitionedConfig[object]"]
+            Union[ConfigMapping, Mapping[str, Any], "RunConfig", "PartitionedConfig"]
         ] = None,
         logger_defs: Optional[Mapping[str, LoggerDefinition]] = None,
         executor_def: Optional["ExecutorDefinition"] = None,
         hooks: Optional[AbstractSet[HookDefinition]] = None,
         op_retry_policy: Optional[RetryPolicy] = None,
         version_strategy: Optional[VersionStrategy] = None,
-        partitions_def: Optional["PartitionsDefinition[object]"] = None,
+        partitions_def: Optional["PartitionsDefinition"] = None,
         input_values: Optional[Mapping[str, object]] = None,
     ):
         from dagster._core.definitions.run_config import convert_config_input
 
         self.name = name
         self.description = description
         self.tags = tags
@@ -63,15 +63,15 @@
 
         from dagster._core.definitions.composition import do_composition
 
         (
             input_mappings,
             output_mappings,
             dependencies,
-            solid_defs,
+            node_defs,
             config_mapping,
             positional_inputs,
             node_input_source_assets,
         ) = do_composition(
             decorator_name="@job",
             graph_name=self.name,
             fn=fn,
@@ -80,15 +80,15 @@
             ignore_output_from_composition_fn=False,
             config_mapping=None,
         )
 
         graph_def = GraphDefinition(
             name=self.name,
             dependencies=dependencies,
-            node_defs=solid_defs,
+            node_defs=node_defs,
             description=self.description or format_docstring_for_description(fn),
             input_mappings=input_mappings,
             output_mappings=output_mappings,
             config=config_mapping,
             positional_inputs=positional_inputs,
             tags=self.tags,
             node_input_source_assets=node_input_source_assets,
@@ -119,45 +119,45 @@
 
 @overload
 def job(
     *,
     name: Optional[str] = ...,
     description: Optional[str] = ...,
     resource_defs: Optional[Mapping[str, object]] = ...,
-    config: Union[ConfigMapping, Mapping[str, Any], "RunConfig", "PartitionedConfig[object]"] = ...,
+    config: Union[ConfigMapping, Mapping[str, Any], "RunConfig", "PartitionedConfig"] = ...,
     tags: Optional[Mapping[str, Any]] = ...,
     metadata: Optional[Mapping[str, RawMetadataValue]] = ...,
     logger_defs: Optional[Mapping[str, LoggerDefinition]] = ...,
     executor_def: Optional["ExecutorDefinition"] = ...,
     hooks: Optional[AbstractSet[HookDefinition]] = ...,
     op_retry_policy: Optional[RetryPolicy] = ...,
     version_strategy: Optional[VersionStrategy] = ...,
-    partitions_def: Optional["PartitionsDefinition[object]"] = ...,
+    partitions_def: Optional["PartitionsDefinition"] = ...,
     input_values: Optional[Mapping[str, object]] = ...,
 ) -> _Job:
     ...
 
 
 def job(
     compose_fn: Optional[Callable[..., Any]] = None,
     *,
     name: Optional[str] = None,
     description: Optional[str] = None,
     resource_defs: Optional[Mapping[str, object]] = None,
     config: Optional[
-        Union[ConfigMapping, Mapping[str, Any], "RunConfig", "PartitionedConfig[object]"]
+        Union[ConfigMapping, Mapping[str, Any], "RunConfig", "PartitionedConfig"]
     ] = None,
     tags: Optional[Mapping[str, Any]] = None,
     metadata: Optional[Mapping[str, RawMetadataValue]] = None,
     logger_defs: Optional[Mapping[str, LoggerDefinition]] = None,
     executor_def: Optional["ExecutorDefinition"] = None,
     hooks: Optional[AbstractSet[HookDefinition]] = None,
     op_retry_policy: Optional[RetryPolicy] = None,
     version_strategy: Optional[VersionStrategy] = None,
-    partitions_def: Optional["PartitionsDefinition[object]"] = None,
+    partitions_def: Optional["PartitionsDefinition"] = None,
     input_values: Optional[Mapping[str, object]] = None,
 ) -> Union[JobDefinition, _Job]:
     """Creates a job with the specified parameters from the decorated graph/op invocation function.
 
     Using this decorator allows you to build an executable job by writing a function that invokes
     ops (or graphs).
 
@@ -185,15 +185,15 @@
             for the job whenever the job is executed, similar to providing a dictionary.
 
             If a :py:class:`ConfigMapping` object is provided, then the schema for the job's run config is
             determined by the config mapping, and the ConfigMapping, which should return
             configuration in the standard format to configure the job.
 
             If a :py:class:`PartitionedConfig` object is provided, then it defines a discrete set of config
-            values that can parameterize the pipeline, as well as a function for mapping those
+            values that can parameterize the job, as well as a function for mapping those
             values to the base config. The values provided will be viewable and editable in the
             Dagit playground, so be careful with secrets.
         tags (Optional[Dict[str, Any]]):
             Arbitrary information that will be attached to the execution of the Job.
             Values that are not strings will be json encoded and must meet the criteria that
             `json.loads(json.dumps(value)) == value`.  These tag values may be overwritten by tag
             values provided at invocation time.
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/decorators/op_decorator.py` & `dagster-1.3.3/dagster/_core/definitions/decorators/op_decorator.py`

 * *Files 2% similar despite different names*

```diff
@@ -58,21 +58,21 @@
         self.name = check.opt_str_param(name, "name")
         self.decorator_takes_context = check.bool_param(
             decorator_takes_context, "decorator_takes_context"
         )
 
         self.description = check.opt_str_param(description, "description")
 
-        # these will be checked within SolidDefinition
+        # these will be checked within OpDefinition
         self.required_resource_keys = required_resource_keys
         self.tags = tags
         self.code_version = code_version
         self.retry_policy = retry_policy
 
-        # config will be checked within SolidDefinition
+        # config will be checked within OpDefinition
         self.config_schema = config_schema
 
         self.ins = check.opt_nullable_mapping_param(ins, "ins", key_type=str, value_type=In)
         self.out = out
 
     def __call__(self, fn: Callable[..., Any]) -> "OpDefinition":
         from dagster._config.pythonic_config import validate_resource_annotated_function
@@ -119,25 +119,26 @@
             (
                 "Cannot specify resource requirements in both @op decorator and as arguments to the"
                 " decorated function"
             ),
         )
         resolved_resource_keys = decorator_resource_keys.union(arg_resource_keys)
 
-        op_def = OpDefinition(
+        op_def = OpDefinition.dagster_internal_init(
             name=self.name,
             ins=self.ins,
             outs=outs,
             compute_fn=compute_fn,
             config_schema=self.config_schema,
             description=self.description or format_docstring_for_description(fn),
             required_resource_keys=resolved_resource_keys,
             tags=self.tags,
             code_version=self.code_version,
             retry_policy=self.retry_policy,
+            version=None,  # code_version has replaced version
         )
         update_wrapper(op_def, compute_fn.decorated_fn)
         return op_def
 
 
 @overload
 def op(compute_fn: Callable[..., Any]) -> "OpDefinition":
@@ -264,15 +265,15 @@
         retry_policy=retry_policy,
         ins=ins,
         out=out,
     )
 
 
 class DecoratedOpFunction(NamedTuple):
-    """Wrapper around the decorated solid function to provide commonly used util methods."""
+    """Wrapper around the decorated op function to provide commonly used util methods."""
 
     decorated_fn: Callable[..., Any]
 
     @lru_cache(maxsize=1)
     def has_context_arg(self) -> bool:
         return is_context_provided(get_function_params(self.decorated_fn))
 
@@ -316,44 +317,44 @@
     def get_output_annotation(self) -> Any:
         from ..inference import infer_output_props
 
         return infer_output_props(self.decorated_fn).annotation
 
 
 class NoContextDecoratedOpFunction(DecoratedOpFunction):
-    """Wrapper around a decorated solid function, when the decorator does not permit a context
-    parameter (such as lambda_solid).
+    """Wrapper around a decorated op function, when the decorator does not permit a context
+    parameter.
     """
 
     @lru_cache(maxsize=1)
     def has_context_arg(self) -> bool:
         return False
 
 
 def is_context_provided(params: Sequence[Parameter]) -> bool:
     if len(params) == 0:
         return False
     return params[0].name in get_valid_name_permutations("context")
 
 
-def resolve_checked_solid_fn_inputs(
+def resolve_checked_op_fn_inputs(
     decorator_name: str,
     fn_name: str,
     compute_fn: DecoratedOpFunction,
     explicit_input_defs: Sequence[InputDefinition],
     exclude_nothing: bool,
 ) -> Sequence[InputDefinition]:
     """Validate provided input definitions and infer the remaining from the type signature of the compute_fn.
     Returns the resolved set of InputDefinitions.
 
     Args:
-        decorator_name (str): Name of the decorator that is wrapping the op/solid function.
+        decorator_name (str): Name of the decorator that is wrapping the op function.
         fn_name (str): Name of the decorated function.
-        compute_fn (DecoratedSolidFunction): The decorated function, wrapped in the
-            DecoratedSolidFunction wrapper.
+        compute_fn (DecoratedOpFunction): The decorated function, wrapped in the
+            DecoratedOpFunction wrapper.
         explicit_input_defs (List[InputDefinition]): The input definitions that were explicitly
             provided in the decorator.
         exclude_nothing (bool): True if Nothing type inputs should be excluded from compute_fn
             arguments.
     """
     explicit_names = set()
     if exclude_nothing:
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/decorators/repository_decorator.py` & `dagster-1.3.3/dagster/_core/definitions/decorators/repository_decorator.py`

 * *Files 0% similar despite different names*

```diff
@@ -96,15 +96,15 @@
     def __call__(
         self,
         fn: Union[
             Callable[[], Sequence[PendingRepositoryListDefinition]],
             Callable[[], RepositoryDictSpec],
         ],
     ) -> Union[RepositoryDefinition, PendingRepositoryDefinition]:
-        from dagster._core.definitions import AssetGroup, AssetsDefinition, SourceAsset
+        from dagster._core.definitions import AssetsDefinition, SourceAsset
         from dagster._core.definitions.cacheable_assets import CacheableAssetsDefinition
 
         check.callable_param(fn, "fn")
 
         if not self.name:
             self.name = fn.__name__
 
@@ -122,15 +122,14 @@
                     definition,
                     (
                         JobDefinition,
                         ScheduleDefinition,
                         UnresolvedPartitionedAssetScheduleDefinition,
                         SensorDefinition,
                         GraphDefinition,
-                        AssetGroup,
                         AssetsDefinition,
                         SourceAsset,
                         UnresolvedAssetJobDefinition,
                     ),
                 ):
                     bad_defns.append((i, type(definition)))
                 else:
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/decorators/schedule_decorator.py` & `dagster-1.3.3/dagster/_core/definitions/decorators/schedule_decorator.py`

 * *Files 2% similar despite different names*

```diff
@@ -167,25 +167,30 @@
         has_context_arg = has_at_least_one_parameter(fn)
         evaluation_fn = DecoratedScheduleFunction(
             decorated_fn=fn,
             wrapped_fn=_wrapped_fn,
             has_context_arg=has_context_arg,
         )
 
-        schedule_def = ScheduleDefinition(
+        schedule_def = ScheduleDefinition.dagster_internal_init(
             name=schedule_name,
             cron_schedule=cron_schedule,
             job_name=job_name,
             environment_vars=environment_vars,
             execution_timezone=execution_timezone,
             description=description,
             execution_fn=evaluation_fn,
             job=job,
             default_status=default_status,
             required_resource_keys=required_resource_keys,
+            run_config=None,  # cannot supply run_config or run_config_fn to decorator
+            run_config_fn=None,
+            tags=None,  # cannot supply tags or tags_fn to decorator
+            tags_fn=None,
+            should_execute=None,  # already encompassed in evaluation_fn
         )
 
         update_wrapper(schedule_def, wrapped=fn)
 
         return schedule_def
 
     return inner
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/decorators/sensor_decorator.py` & `dagster-1.3.3/dagster/_core/definitions/decorators/sensor_decorator.py`

 * *Files 0% similar despite different names*

```diff
@@ -66,15 +66,15 @@
             the sensor condition is met. This can be provided instead of specifying a job.
     """
     check.opt_str_param(name, "name")
 
     def inner(fn: RawSensorEvaluationFunction) -> SensorDefinition:
         check.callable_param(fn, "fn")
 
-        sensor_def = SensorDefinition(
+        sensor_def = SensorDefinition.dagster_internal_init(
             name=name,
             job_name=job_name,
             evaluation_fn=fn,
             minimum_interval_seconds=minimum_interval_seconds,
             description=description,
             job=job,
             jobs=jobs,
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/decorators/source_asset_decorator.py` & `dagster-1.3.3/dagster/_core/definitions/decorators/source_asset_decorator.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/definition_config_schema.py` & `dagster-1.3.3/dagster/_core/definitions/definition_config_schema.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/definitions_class.py` & `dagster-1.3.3/dagster/_core/definitions/definitions_class.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/dependency.py` & `dagster-1.3.3/dagster/_core/definitions/dependency.py`

 * *Files 0% similar despite different names*

```diff
@@ -685,15 +685,15 @@
 ):
     """Represents a fan-in edge in the DAG of op instances forming a job.
 
     This object is used only when an input of type ``List[T]`` is assembled by fanning-in multiple
     upstream outputs of type ``T``.
 
     This object is used at the leaves of a dictionary structure that represents the complete
-    dependency structure of a job or pipeline whose keys represent the dependent ops or graphs and dependent
+    dependency structure of a job whose keys represent the dependent ops or graphs and dependent
     input, so this object only contains information about the dependee.
 
     Concretely, if the input named 'input' of op_c depends on the outputs named 'result' of
     op_a and op_b, this structure will look as follows:
 
     .. code-block:: python
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/events.py` & `dagster-1.3.3/dagster/_core/definitions/events.py`

 * *Files 0% similar despite different names*

```diff
@@ -628,15 +628,15 @@
     """Event corresponding to a successful typecheck.
 
     Events of this type should be returned by user-defined type checks when they need to encapsulate
     additional metadata about a type check's success or failure. (i.e., when using
     :py:func:`as_dagster_type`, :py:func:`@usable_as_dagster_type <dagster_type>`, or the underlying
     :py:func:`PythonObjectDagsterType` API.)
 
-    Solid compute functions should generally avoid yielding events of this type to avoid confusion.
+    Op compute functions should generally avoid yielding events of this type to avoid confusion.
 
     Args:
         success (bool): ``True`` if the type check succeeded, ``False`` otherwise.
         description (Optional[str]): A human-readable description of the type check.
         metadata (Optional[Dict[str, RawMetadataValue]]):
             Arbitrary metadata about the failure.  Keys are displayed string labels, and values are
             one of the following: string, float, int, JSON-serializable dict, JSON-serializable
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/executor_definition.py` & `dagster-1.3.3/dagster/_core/definitions/executor_definition.py`

 * *Files 4% similar despite different names*

```diff
@@ -8,16 +8,16 @@
 from dagster._annotations import public
 from dagster._builtins import Int
 from dagster._config import Field, Selector, UserConfigSchema
 from dagster._core.definitions.configurable import (
     ConfiguredDefinitionConfigSchema,
     NamedConfigurableDefinition,
 )
-from dagster._core.definitions.pipeline_base import IPipeline
-from dagster._core.definitions.reconstruct import ReconstructablePipeline
+from dagster._core.definitions.job_base import IJob
+from dagster._core.definitions.reconstruct import ReconstructableJob
 from dagster._core.errors import DagsterUnmetExecutorRequirementsError
 from dagster._core.execution.retries import RetryMode, get_retries_config
 from dagster._core.execution.tags import get_tag_concurrency_limits_config
 
 from .definition_config_schema import (
     IDefinitionConfigSchema,
     convert_user_facing_definition_config_schema,
@@ -29,27 +29,27 @@
     from dagster._core.executor.init import InitExecutorContext
     from dagster._core.executor.multiprocess import MultiprocessExecutor
     from dagster._core.instance import DagsterInstance
 
 
 class ExecutorRequirement(PyEnum):
     """An ExecutorDefinition can include a list of requirements that the system uses to
-    check whether the executor will be able to work for a particular job/pipeline execution.
+    check whether the executor will be able to work for a particular job execution.
     """
 
-    # The passed in IPipeline must be reconstructable across process boundaries
+    # The passed in IJob must be reconstructable across process boundaries
     RECONSTRUCTABLE_PIPELINE = (  # This needs to still exist for folks who may have written their own executor
         "RECONSTRUCTABLE_PIPELINE"
     )
     RECONSTRUCTABLE_JOB = "RECONSTRUCTABLE_PIPELINE"
 
     # The DagsterInstance must be loadable in a different process
     NON_EPHEMERAL_INSTANCE = "NON_EPHEMERAL_INSTANCE"
 
-    # Any solid outputs on the pipeline must be persisted
+    # Any op outputs on the job must be persisted
     PERSISTENT_OUTPUTS = "PERSISTENT_OUTPUTS"
 
 
 def multiple_process_executor_requirements() -> Sequence[ExecutorRequirement]:
     return [
         ExecutorRequirement.RECONSTRUCTABLE_JOB,
         ExecutorRequirement.NON_EPHEMERAL_INSTANCE,
@@ -67,15 +67,15 @@
 
     Args:
         name (str): The name of the executor.
         config_schema (Optional[ConfigSchema]): The schema for the config. Configuration data
             available in `init_context.executor_config`. If not set, Dagster will accept any config
             provided.
         requirements (Optional[List[ExecutorRequirement]]): Any requirements that must
-            be met in order for the executor to be usable for a particular pipeline execution.
+            be met in order for the executor to be usable for a particular job execution.
         executor_creation_fn(Optional[Callable]): Should accept an :py:class:`InitExecutorContext`
             and return an instance of :py:class:`Executor`
         required_resource_keys (Optional[Set[str]]): Keys for the resources required by the
             executor.
         description (Optional[str]): A description of the executor.
     """
 
@@ -220,15 +220,15 @@
     of :py:class:`Executor`.
 
     Args:
         name (Optional[str]): The name of the executor.
         config_schema (Optional[ConfigSchema]): The schema for the config. Configuration data available in
             `init_context.executor_config`. If not set, Dagster will accept any config provided for.
         requirements (Optional[List[ExecutorRequirement]]): Any requirements that must
-            be met in order for the executor to be usable for a particular pipeline execution.
+            be met in order for the executor to be usable for a particular job execution.
     """
     if callable(name):
         check.invariant(config_schema is None)
         check.invariant(requirements is None)
         return _ExecutorDecoratorCallable()(name)
 
     return _ExecutorDecoratorCallable(
@@ -287,23 +287,22 @@
 @executor(
     name="in_process",
     config_schema=IN_PROC_CONFIG,
 )
 def in_process_executor(init_context):
     """The in-process executor executes all steps in a single process.
 
-    For legacy pipelines, this will be the default executor. To select it explicitly,
-    include the following top-level fragment in config:
+    To select it, include the following top-level fragment in config:
 
     .. code-block:: yaml
 
         execution:
           in_process:
 
-    Execution priority can be configured using the ``dagster/priority`` tag via solid/op metadata,
+    Execution priority can be configured using the ``dagster/priority`` tag via op metadata,
     where the higher the number the higher the priority. 0 is the default and both positive
     and negative numbers can be used.
     """
     return _core_in_process_executor_creation(init_context.executor_config)
 
 
 @executor(name="execute_in_process_executor")
@@ -401,61 +400,57 @@
     config_schema=MULTI_PROC_CONFIG,
     requirements=multiple_process_executor_requirements(),
 )
 def multiprocess_executor(init_context):
     """The multiprocess executor executes each step in an individual process.
 
     Any job that does not specify custom executors will use the multiprocess_executor by default.
-    For jobs or legacy pipelines, to configure the multiprocess executor, include a fragment such
-    as the following in your run config:
+    To configure the multiprocess executor, include a fragment such as the following in your run
+    config:
 
     .. code-block:: yaml
 
         execution:
           config:
             multiprocess:
               max_concurrent: 4
 
     The ``max_concurrent`` arg is optional and tells the execution engine how many processes may run
     concurrently. By default, or if you set ``max_concurrent`` to be 0, this is the return value of
     :py:func:`python:multiprocessing.cpu_count`.
 
-    Execution priority can be configured using the ``dagster/priority`` tag via solid/op metadata,
+    Execution priority can be configured using the ``dagster/priority`` tag via op metadata,
     where the higher the number the higher the priority. 0 is the default and both positive
     and negative numbers can be used.
     """
     return _core_multiprocess_executor_creation(init_context.executor_config)
 
 
 def check_cross_process_constraints(init_context: "InitExecutorContext") -> None:
     from dagster._core.executor.init import InitExecutorContext
 
     check.inst_param(init_context, "init_context", InitExecutorContext)
     requirements_lst = init_context.executor_def.get_requirements(init_context.executor_config)
 
     if ExecutorRequirement.RECONSTRUCTABLE_JOB in requirements_lst:
-        _check_intra_process_pipeline(init_context.pipeline)
+        _check_intra_process_job(init_context.job)
 
     if ExecutorRequirement.NON_EPHEMERAL_INSTANCE in requirements_lst:
         _check_non_ephemeral_instance(init_context.instance)
 
 
-def _check_intra_process_pipeline(pipeline: IPipeline) -> None:
-    from dagster._core.definitions import JobDefinition
-
-    if not isinstance(pipeline, ReconstructablePipeline):
-        target = "job" if isinstance(pipeline.get_definition(), JobDefinition) else "pipeline"
+def _check_intra_process_job(job: IJob) -> None:
+    if not isinstance(job, ReconstructableJob):
         raise DagsterUnmetExecutorRequirementsError(
-            "You have attempted to use an executor that uses multiple processes with the {target}"
-            ' "{name}" that is not reconstructable. {target_cap} must be loaded in a way that'
-            " allows dagster to reconstruct them in a new process. This means: \n  * using the"
-            " file, module, or repository.yaml arguments of dagit/dagster-graphql/dagster\n  *"
-            " loading the {target} through the reconstructable() function\n".format(
-                target=target, name=pipeline.get_definition().name, target_cap=target.capitalize()
-            )
+            "You have attempted to use an executor that uses multiple processes with the job"
+            f' "{job.get_definition().name}" that is not reconstructable. Job must be loaded in a'
+            " way that allows dagster to reconstruct them in a new process. This means: \n  *"
+            " using the file, module, or repository.yaml arguments of"
+            " dagit/dagster-graphql/dagster\n  * loading the job through the reconstructable()"
+            " function\n"
         )
 
 
 def _check_non_ephemeral_instance(instance: "DagsterInstance") -> None:
     if instance.is_ephemeral:
         raise DagsterUnmetExecutorRequirementsError(
             "You have attempted to use an executor that uses multiple processes with an ephemeral"
@@ -507,23 +502,23 @@
     .. code-block:: yaml
 
         execution:
           config:
             multiprocess:
               max_concurrent: 4
               retries:
-              enabled:
+                enabled:
 
     The ``max_concurrent`` arg is optional and tells the execution engine how many processes may run
     concurrently. By default, or if you set ``max_concurrent`` to be 0, this is the return value of
     :py:func:`python:multiprocessing.cpu_count`.
 
     When using the in_process mode, then only retries can be configured.
 
-    Execution priority can be configured using the ``dagster/priority`` tag via solid metadata,
+    Execution priority can be configured using the ``dagster/priority`` tag via op metadata,
     where the higher the number the higher the priority. 0 is the default and both positive
     and negative numbers can be used.
     """
     if "multiprocess" in init_context.executor_config:
         return _core_multiprocess_executor_creation(
             check.dict_elem(init_context.executor_config, "multiprocess")
         )
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/external_asset_graph.py` & `dagster-1.3.3/dagster/_core/definitions/external_asset_graph.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/freshness_policy.py` & `dagster-1.3.3/dagster/_core/definitions/freshness_policy.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/freshness_policy_sensor_definition.py` & `dagster-1.3.3/dagster/_core/definitions/freshness_policy_sensor_definition.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/graph_definition.py` & `dagster-1.3.3/dagster/_core/definitions/graph_definition.py`

 * *Files 0% similar despite different names*

```diff
@@ -133,15 +133,15 @@
 
     End users should prefer the :func:`@graph <graph>` decorator. GraphDefinition is generally
     intended to be used by framework authors or for programatically generated graphs.
 
     Args:
         name (str): The name of the graph. Must be unique within any :py:class:`GraphDefinition`
             or :py:class:`JobDefinition` containing the graph.
-        description (Optional[str]): A human-readable description of the pipeline.
+        description (Optional[str]): A human-readable description of the job.
         node_defs (Optional[Sequence[NodeDefinition]]): The set of ops / graphs used in this graph.
         dependencies (Optional[Dict[Union[str, NodeInvocation], Dict[str, DependencyDefinition]]]):
             A structure that declares the dependencies of each op's inputs on the outputs of other
             ops in the graph. Keys of the top level dict are either the string names of ops in the
             graph or, in the case of aliased ops, :py:class:`NodeInvocations <NodeInvocation>`.
             Values of the top level dict are themselves dicts, which map input names belonging to
             the op or aliased op to :py:class:`DependencyDefinitions <DependencyDefinition>`.
@@ -545,25 +545,25 @@
     @public
     def to_job(
         self,
         name: Optional[str] = None,
         description: Optional[str] = None,
         resource_defs: Optional[Mapping[str, object]] = None,
         config: Optional[
-            Union["RunConfig", ConfigMapping, Mapping[str, object], "PartitionedConfig[T]"]
+            Union["RunConfig", ConfigMapping, Mapping[str, object], "PartitionedConfig"]
         ] = None,
         tags: Optional[Mapping[str, str]] = None,
         metadata: Optional[Mapping[str, RawMetadataValue]] = None,
         logger_defs: Optional[Mapping[str, LoggerDefinition]] = None,
         executor_def: Optional["ExecutorDefinition"] = None,
         hooks: Optional[AbstractSet[HookDefinition]] = None,
         op_retry_policy: Optional[RetryPolicy] = None,
         version_strategy: Optional[VersionStrategy] = None,
         op_selection: Optional[Sequence[str]] = None,
-        partitions_def: Optional["PartitionsDefinition[T]"] = None,
+        partitions_def: Optional["PartitionsDefinition"] = None,
         asset_layer: Optional["AssetLayer"] = None,
         input_values: Optional[Mapping[str, object]] = None,
         _asset_selection_data: Optional[AssetSelectionData] = None,
     ) -> "JobDefinition":
         """Make this graph in to an executable Job by providing remaining components required for execution.
 
         Args:
@@ -624,15 +624,15 @@
         """
         from dagster._core.execution.build_resources import wrap_resources_for_execution
 
         from .job_definition import JobDefinition
 
         wrapped_resource_defs = wrap_resources_for_execution(resource_defs)
 
-        return JobDefinition(
+        return JobDefinition.dagster_internal_init(
             name=name,
             description=description or self.description,
             graph_def=self,
             resource_defs=wrapped_resource_defs,
             logger_defs=logger_defs,
             executor_def=executor_def,
             config=config,
@@ -641,14 +641,15 @@
             metadata=metadata,
             hook_defs=hooks,
             version_strategy=version_strategy,
             op_retry_policy=op_retry_policy,
             asset_layer=asset_layer,
             input_values=input_values,
             _subset_selection_data=_asset_selection_data,
+            _was_explicitly_provided_resources=None,  # None means this is determined by whether resource_defs contains any explicitly provided resources
         ).get_job_def_for_subset_selection(op_selection)
 
     def coerce_to_job(self) -> "JobDefinition":
         # attempt to coerce a Graph in to a Job, raising a useful error if it doesn't work
         try:
             return self.to_job()
         except DagsterInvalidDefinitionError as err:
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/hook_definition.py` & `dagster-1.3.3/dagster/_core/definitions/hook_definition.py`

 * *Files 8% similar despite different names*

```diff
@@ -50,15 +50,15 @@
         )
 
     def __call__(self, *args, **kwargs):
         """This is invoked when the hook is used as a decorator.
 
         We currently support hooks to decorate the following:
 
-        - PipelineDefinition: when the hook decorates a job definition, it will be added to
+        - JobDefinition: when the hook decorates a job definition, it will be added to
             all the op invocations within the job.
 
         Example:
             .. code-block:: python
 
                 @success_hook
                 def slack_message_on_success(_):
@@ -72,16 +72,16 @@
         """
         from ..execution.context.hook import HookContext
         from .graph_definition import GraphDefinition
         from .hook_invocation import hook_invocation_result
         from .job_definition import JobDefinition
 
         if len(args) > 0 and isinstance(args[0], (JobDefinition, GraphDefinition)):
-            # when it decorates a pipeline, we apply this hook to all the solid invocations within
-            # the pipeline.
+            # when it decorates a job, we apply this hook to all the op invocations within
+            # the job.
             return args[0].with_hooks({self})
         else:
             if not self.decorated_fn:
                 raise DagsterInvalidInvocationError(
                     "Only hook definitions created using one of the hook decorators can be invoked."
                 )
             fxn_args = get_function_params(self.decorated_fn)
@@ -138,13 +138,13 @@
                         kwargs[context_arg_name], context_arg_name, HookContext
                     )
                 return hook_invocation_result(self, context)
 
     def get_resource_requirements(
         self, outer_context: Optional[object] = None
     ) -> Iterator[ResourceRequirement]:
-        # outer_context in this case is a string of (pipeline/job, pipeline/job name) or (node, node name)
+        # outer_context in this case is a string of (job, job name) or (node, node name)
         attached_to = cast(Optional[str], outer_context)
         for resource_key in sorted(list(self.required_resource_keys)):
             yield HookResourceRequirement(
                 key=resource_key, attached_to=attached_to, hook_name=self.name
             )
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/hook_invocation.py` & `dagster-1.3.3/dagster/_core/definitions/hook_invocation.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/inference.py` & `dagster-1.3.3/dagster/_core/definitions/inference.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/input.py` & `dagster-1.3.3/dagster/_core/definitions/input.py`

 * *Files 1% similar despite different names*

```diff
@@ -65,17 +65,17 @@
                     ),
                 )
 
     return default_value
 
 
 class InputDefinition:
-    """Defines an argument to a solid's compute function.
+    """Defines an argument to an op's compute function.
 
-    Inputs may flow from previous solids' outputs, or be stubbed using config. They may optionally
+    Inputs may flow from previous op outputs, or be stubbed using config. They may optionally
     be typed using the Dagster type system.
 
     Args:
         name (str): Name of the input.
         dagster_type (Optional[Union[Type, DagsterType]]]): The type of this input.
             Users should provide the Python type of the objects that they expect to be passed for
             this input, or a :py:class:`DagsterType` that defines a runtime check that they want
@@ -225,53 +225,53 @@
         """
         if callable(self._asset_key):
             return self._asset_key(context)
         else:
             return self.hardcoded_asset_key
 
     def get_asset_partitions(self, context: "InputContext") -> Optional[Set[str]]:
-        """Get the set of partitions that this solid will read from this InputDefinition for the given
+        """Get the set of partitions that this op will read from this InputDefinition for the given
         :py:class:`InputContext` (if any).
 
         Args:
             context (InputContext): The InputContext that this InputDefinition is being evaluated
                 in
         """
         if self._asset_partitions_fn is None:
             return None
 
         return self._asset_partitions_fn(context)
 
     def mapping_to(
-        self, solid_name: str, input_name: str, fan_in_index: Optional[int] = None
+        self, node_name: str, input_name: str, fan_in_index: Optional[int] = None
     ) -> "InputMapping":
-        """Create an input mapping to an input of a child solid.
+        """Create an input mapping to an input of a child node.
 
-        In a CompositeSolidDefinition, you can use this helper function to construct
-        an :py:class:`InputMapping` to the input of a child solid.
+        In a GraphDefinition, you can use this helper function to construct
+        an :py:class:`InputMapping` to the input of a child node.
 
         Args:
-            solid_name (str): The name of the child solid to which to map this input.
-            input_name (str): The name of the child solid' input to which to map this input.
+            node_name (str): The name of the child node to which to map this input.
+            input_name (str): The name of the child node' input to which to map this input.
             fan_in_index (Optional[int]): The index in to a fanned in input, else None
 
         Examples:
             .. code-block:: python
 
                 input_mapping = InputDefinition('composite_input', Int).mapping_to(
-                    'child_solid', 'int_input'
+                    'child_node', 'int_input'
                 )
         """
-        check.str_param(solid_name, "solid_name")
+        check.str_param(node_name, "node_name")
         check.str_param(input_name, "input_name")
         check.opt_int_param(fan_in_index, "fan_in_index")
 
         return InputMapping(
             graph_input_name=self.name,
-            mapped_node_name=solid_name,
+            mapped_node_name=node_name,
             mapped_node_input_name=input_name,
             fan_in_index=fan_in_index,
             graph_input_description=self.description,
             dagster_type=self.dagster_type,
         )
 
     @staticmethod
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/instigation_logger.py` & `dagster-1.3.3/dagster/_core/definitions/instigation_logger.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/job_definition.py` & `dagster-1.3.3/dagster/_core/definitions/job_definition.py`

 * *Files 2% similar despite different names*

```diff
@@ -62,14 +62,15 @@
     SelectionTreeLeaf,
     parse_op_selection,
 )
 from dagster._core.storage.io_manager import IOManagerDefinition, io_manager
 from dagster._core.storage.tags import MEMOIZED_RUN_TAG
 from dagster._core.types.dagster_type import DagsterType
 from dagster._core.utils import str_format_set
+from dagster._utils import IHasInternalInit
 from dagster._utils.backcompat import deprecation_warning, experimental_class_warning
 from dagster._utils.merger import merge_dicts
 
 from .asset_layer import AssetLayer, build_asset_selection_job
 from .config import ConfigMapping
 from .dependency import (
     DependencyDefinition,
@@ -90,39 +91,38 @@
 from .version_strategy import VersionStrategy
 
 if TYPE_CHECKING:
     from dagster._config.snap import ConfigSchemaSnapshot
     from dagster._core.definitions.run_config import RunConfig
     from dagster._core.execution.execute_in_process_result import ExecuteInProcessResult
     from dagster._core.execution.resources_init import InitResourceContext
-    from dagster._core.host_representation.pipeline_index import PipelineIndex
+    from dagster._core.host_representation.job_index import JobIndex
     from dagster._core.instance import DagsterInstance
-    from dagster._core.snap import PipelineSnapshot
+    from dagster._core.snap import JobSnapshot
 
     from .run_config_schema import RunConfigSchema
 
 DEFAULT_EXECUTOR_DEF = multi_or_in_process_executor
 
 
-class JobDefinition:
+class JobDefinition(IHasInternalInit):
     """Defines a Dagster job."""
 
     _name: str
     _graph_def: GraphDefinition
     _description: Optional[str]
     _tags: Mapping[str, str]
     _metadata: Mapping[str, MetadataValue]
     _current_level_node_defs: Sequence[NodeDefinition]
     _hook_defs: AbstractSet[HookDefinition]
     _op_retry_policy: Optional[RetryPolicy]
     _asset_layer: AssetLayer
     _resource_requirements: Mapping[str, AbstractSet[str]]
     _all_node_defs: Mapping[str, NodeDefinition]
     _cached_run_config_schemas: Dict[str, "RunConfigSchema"]
-    _cached_external_pipeline: Any
     _version_strategy: VersionStrategy
     _subset_selection_data: Optional[Union[OpSelectionData, AssetSelectionData]]
     input_values: Mapping[str, object]
 
     def __init__(
         self,
         *,
@@ -146,15 +146,15 @@
         input_values: Optional[Mapping[str, object]] = None,
         _was_explicitly_provided_resources: Optional[bool] = None,
     ):
         from dagster._core.definitions.run_config import RunConfig, convert_config_input
 
         self._graph_def = graph_def
         self._current_level_node_defs = self._graph_def.node_defs
-        # Recursively explore all nodes in the this pipeline
+        # Recursively explore all nodes in the this job
         self._all_node_defs = _build_all_node_defs(self._current_level_node_defs)
         self._asset_layer = check.opt_inst_param(
             asset_layer, "asset_layer", AssetLayer
         ) or _infer_asset_layer_from_source_asset_deps(graph_def)
 
         # validates
         self._graph_def.get_inputs_must_be_resolved_top_level(self._asset_layer)
@@ -173,15 +173,15 @@
         )
         config = convert_config_input(config)
 
         partitions_def = check.opt_inst_param(
             partitions_def, "partitions_def", PartitionsDefinition
         )
         # tags and description can exist on graph as well, but since
-        # same graph may be in multiple pipelines/jobs, keep separate layer
+        # same graph may be in multiple jobs, keep separate layer
         self._description = check.opt_str_param(description, "description")
         self._tags = validate_tags(tags)
         self._metadata = normalize_metadata(
             check.opt_mapping_param(metadata, "metadata", key_type=str)
         )
         self._hook_defs = check.opt_set_param(hook_defs, "hook_defs")
         self._op_retry_policy = check.opt_inst_param(
@@ -256,14 +256,56 @@
         for input_name in sorted(list(self.input_values.keys())):
             if not graph_def.has_input(input_name):
                 raise DagsterInvalidDefinitionError(
                     f"Error when constructing JobDefinition '{self.name}': Input value provided for"
                     f" key '{input_name}', but job has no top-level input with that name."
                 )
 
+    def dagster_internal_init(
+        *,
+        graph_def: GraphDefinition,
+        resource_defs: Optional[Mapping[str, ResourceDefinition]],
+        executor_def: Optional[ExecutorDefinition],
+        logger_defs: Optional[Mapping[str, LoggerDefinition]],
+        name: Optional[str],
+        config: Optional[
+            Union[ConfigMapping, Mapping[str, object], PartitionedConfig, "RunConfig"]
+        ],
+        description: Optional[str],
+        partitions_def: Optional[PartitionsDefinition],
+        tags: Optional[Mapping[str, Any]],
+        metadata: Optional[Mapping[str, RawMetadataValue]],
+        hook_defs: Optional[AbstractSet[HookDefinition]],
+        op_retry_policy: Optional[RetryPolicy],
+        version_strategy: Optional[VersionStrategy],
+        _subset_selection_data: Optional[Union[OpSelectionData, AssetSelectionData]],
+        asset_layer: Optional[AssetLayer],
+        input_values: Optional[Mapping[str, object]],
+        _was_explicitly_provided_resources: Optional[bool],
+    ) -> "JobDefinition":
+        return JobDefinition(
+            graph_def=graph_def,
+            resource_defs=resource_defs,
+            executor_def=executor_def,
+            logger_defs=logger_defs,
+            name=name,
+            config=config,
+            description=description,
+            partitions_def=partitions_def,
+            tags=tags,
+            metadata=metadata,
+            hook_defs=hook_defs,
+            op_retry_policy=op_retry_policy,
+            version_strategy=version_strategy,
+            _subset_selection_data=_subset_selection_data,
+            asset_layer=asset_layer,
+            input_values=input_values,
+            _was_explicitly_provided_resources=_was_explicitly_provided_resources,
+        )
+
     @property
     def name(self) -> str:
         return self._name
 
     @property
     def tags(self) -> Mapping[str, str]:
         return merge_dicts(self._graph_def.tags, self._tags)
@@ -489,15 +531,15 @@
         while lineage:
             name = lineage.pop()
             # While lineage is non-empty, definition is guaranteed to be a graph
             definition = cast(GraphDefinition, node.definition)
             node = definition.node_named(name)
             hook_defs = hook_defs.union(node.hook_defs)
 
-        # hooks applied to a pipeline definition will run on every node
+        # hooks applied to a job definition will run on every node
         hook_defs = hook_defs.union(self.hook_defs)
 
         return frozenset(hook_defs)
 
     def get_retry_policy_for_handle(self, handle: NodeHandle) -> Optional[RetryPolicy]:
         node = self.get_node(handle)
         definition = node.definition
@@ -591,53 +633,59 @@
 
         # Combine provided input values at execute_in_process with input values
         # provided to the definition. Input values provided at
         # execute_in_process will override those provided on the definition.
         input_values = merge_dicts(self.input_values, input_values)
 
         bound_resource_defs = dict(self.resource_defs)
-        ephemeral_job = JobDefinition(
+        ephemeral_job = JobDefinition.dagster_internal_init(
             name=self._name,
             graph_def=self._graph_def,
             resource_defs={**_swap_default_io_man(bound_resource_defs, self), **resource_defs},
             executor_def=execute_in_process_executor,
             logger_defs=self._loggers,
             hook_defs=self.hook_defs,
             config=self.config_mapping or self.partitioned_config or self.run_config,
             tags=self.tags,
             op_retry_policy=self._op_retry_policy,
             version_strategy=self.version_strategy,
             asset_layer=self.asset_layer,
             input_values=input_values,
+            description=self.description,
+            partitions_def=self.partitions_def,
+            metadata=self.metadata,
+            _subset_selection_data=None,  # this is added below
+            _was_explicitly_provided_resources=True,
         )
 
         ephemeral_job = ephemeral_job.get_job_def_for_subset_selection(
             op_selection, frozenset(asset_selection) if asset_selection else None
         )
 
         merged_tags = merge_dicts(self.tags, tags or {})
         if partition_key:
             if not (self.partitions_def and self.partitioned_config):
                 check.failed("Attempted to execute a partitioned run for a non-partitioned job")
+            self.partitions_def.validate_partition_key(
+                partition_key, dynamic_partitions_store=instance
+            )
 
             run_config = (
                 run_config
                 if run_config
-                else self.partitioned_config.get_run_config_for_partition_key(
-                    partition_key, instance
-                )
+                else self.partitioned_config.get_run_config_for_partition_key(partition_key)
             )
             merged_tags.update(
                 self.partitioned_config.get_tags_for_partition_key(
-                    partition_key, instance, job_name=self.name
+                    partition_key, job_name=self.name
                 )
             )
 
         return core_execute_in_process(
-            ephemeral_pipeline=ephemeral_job,
+            ephemeral_job=ephemeral_job,
             run_config=run_config,
             instance=instance,
             output_capturing_enabled=True,
             raise_on_error=raise_on_error,
             run_tags=merged_tags,
             run_id=run_id,
             asset_selection=frozenset(asset_selection),
@@ -656,15 +704,15 @@
         return (
             self._subset_selection_data
             if isinstance(self._subset_selection_data, AssetSelectionData)
             else None
         )
 
     @property
-    def is_subset_pipeline(self) -> bool:
+    def is_subset_job(self) -> bool:
         return bool(self._subset_selection_data)
 
     def get_job_def_for_subset_selection(
         self,
         op_selection: Optional[Sequence[str]] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
     ) -> Self:
@@ -746,15 +794,15 @@
                 config=config,
                 graph_def=sub_graph,
                 _subset_selection_data=OpSelectionData(
                     op_selection=op_selection,
                     resolved_op_selection=set(
                         resolved_op_selection_dict.keys()
                     ),  # equivalent to solids_to_execute. currently only gets top level nodes.
-                    parent_job_def=self,  # used by pipeline snapshot lineage
+                    parent_job_def=self,  # used by job snapshot lineage
                 ),
                 # TODO: subset this structure.
                 # https://github.com/dagster-io/dagster/issues/7541
                 asset_layer=self.asset_layer,
             )
         except DagsterInvalidDefinitionError as exc:
             # This handles the case when you construct a subset such that an unsatisfied
@@ -811,65 +859,58 @@
             # since this requires querying the instance once per run request for the
             # existent dynamic partitions
             check.failed(
                 "run_request_for_partition is not supported for dynamic partitions. Instead, use"
                 " RunRequest(partition_key=...)"
             )
 
-        partition = self.partitions_def.get_partition(
-            partition_key, dynamic_partitions_store=None, current_time=current_time
-        )
+        self.partitions_def.validate_partition_key(partition_key, current_time=current_time)
+
         run_config = (
             run_config
             if run_config is not None
-            else self.partitioned_config.get_run_config_for_partition_key(
-                partition.name, dynamic_partitions_store=None, current_time=current_time
-            )
+            else self.partitioned_config.get_run_config_for_partition_key(partition_key)
         )
         run_request_tags = {
             **(tags or {}),
             **self.partitioned_config.get_tags_for_partition_key(
                 partition_key,
-                dynamic_partitions_store=None,
-                current_time=current_time,
                 job_name=self.name,
             ),
         }
 
         return RunRequest(
             run_key=run_key,
             run_config=run_config,
             tags=run_request_tags,
             job_name=self.name,
             asset_selection=asset_selection,
             partition_key=partition_key,
         )
 
     def get_config_schema_snapshot(self) -> "ConfigSchemaSnapshot":
-        return self.get_pipeline_snapshot().config_schema_snapshot
+        return self.get_job_snapshot().config_schema_snapshot
 
-    def get_pipeline_snapshot(self) -> "PipelineSnapshot":
-        return self.get_pipeline_index().pipeline_snapshot
+    def get_job_snapshot(self) -> "JobSnapshot":
+        return self.get_job_index().job_snapshot
 
-    def get_pipeline_index(self) -> "PipelineIndex":
-        from dagster._core.host_representation import PipelineIndex
-        from dagster._core.snap import PipelineSnapshot
+    def get_job_index(self) -> "JobIndex":
+        from dagster._core.host_representation import JobIndex
+        from dagster._core.snap import JobSnapshot
 
-        return PipelineIndex(
-            PipelineSnapshot.from_pipeline_def(self), self.get_parent_pipeline_snapshot()
-        )
+        return JobIndex(JobSnapshot.from_job_def(self), self.get_parent_job_snapshot())
 
-    def get_pipeline_snapshot_id(self) -> str:
-        return self.get_pipeline_index().pipeline_snapshot_id
+    def get_job_snapshot_id(self) -> str:
+        return self.get_job_index().job_snapshot_id
 
-    def get_parent_pipeline_snapshot(self) -> Optional["PipelineSnapshot"]:
+    def get_parent_job_snapshot(self) -> Optional["JobSnapshot"]:
         if self.op_selection_data:
-            return self.op_selection_data.parent_job_def.get_pipeline_snapshot()
+            return self.op_selection_data.parent_job_def.get_job_snapshot()
         elif self.asset_selection_data:
-            return self.asset_selection_data.parent_job_def.get_pipeline_snapshot()
+            return self.asset_selection_data.parent_job_def.get_job_snapshot()
         else:
             return None
 
     def has_direct_input_value(self, input_name: str) -> bool:
         return input_name in self.input_values
 
     def get_direct_input_value(self, input_name: str) -> object:
@@ -895,17 +936,19 @@
             metadata=self._metadata,
             hook_defs=self.hook_defs,
             op_retry_policy=self._op_retry_policy,
             version_strategy=self.version_strategy,
             _subset_selection_data=self._subset_selection_data,
             asset_layer=self.asset_layer,
             input_values=self.input_values,
+            partitions_def=self.partitions_def,
+            _was_explicitly_provided_resources=None,
         )
         resolved_kwargs = {**base_kwargs, **kwargs}  # base kwargs overwritten for conflicts
-        job_def = JobDefinition(**resolved_kwargs)
+        job_def = JobDefinition.dagster_internal_init(**resolved_kwargs)
         update_wrapper(job_def, self, updated=())
         return job_def
 
     @public
     def with_top_level_resources(
         self, resource_defs: Mapping[str, ResourceDefinition]
     ) -> "JobDefinition":
@@ -1275,19 +1318,19 @@
     from .run_config import (
         RunConfigSchemaCreationData,
         construct_config_type_dictionary,
         define_run_config_schema_type,
     )
     from .run_config_schema import RunConfigSchema
 
-    # When executing with a subset pipeline, include the missing nodes
-    # from the original pipeline as ignored to allow execution with
+    # When executing with a subset job, include the missing nodes
+    # from the original job as ignored to allow execution with
     # run config that is valid for the original
     ignored_nodes: Sequence[Node] = []
-    if job_def.is_subset_pipeline:
+    if job_def.is_subset_job:
         if isinstance(job_def.graph, SubselectedGraphDefinition):  # op selection provided
             ignored_nodes = job_def.graph.get_top_level_omitted_nodes()
         elif job_def.asset_selection_data:
             parent_job = job_def
             while parent_job.asset_selection_data:
                 parent_job = parent_job.asset_selection_data.parent_job_def
 
@@ -1295,15 +1338,15 @@
                 node for node in parent_job.graph.nodes if not job_def.has_node_named(node.name)
             ]
     else:
         ignored_nodes = []
 
     run_config_schema_type = define_run_config_schema_type(
         RunConfigSchemaCreationData(
-            pipeline_name=job_def.name,
+            job_name=job_def.name,
             nodes=job_def.graph.nodes,
             graph_def=job_def.graph,
             dependency_structure=job_def.graph.dependency_structure,
             executor_def=job_def.executor_def,
             resource_defs=job_def.resource_defs,
             logger_defs=job_def.loggers,
             ignored_nodes=ignored_nodes,
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/load_assets_from_modules.py` & `dagster-1.3.3/dagster/_core/definitions/load_assets_from_modules.py`

 * *Files 10% similar despite different names*

```diff
@@ -98,14 +98,15 @@
 def load_assets_from_modules(
     modules: Iterable[ModuleType],
     group_name: Optional[str] = None,
     key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
     *,
     freshness_policy: Optional[FreshnessPolicy] = None,
     auto_materialize_policy: Optional[AutoMaterializePolicy] = None,
+    source_key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
 ) -> Sequence[Union[AssetsDefinition, SourceAsset, CacheableAssetsDefinition]]:
     """Constructs a list of assets and source assets from the given modules.
 
     Args:
         modules (Iterable[ModuleType]): The Python modules to look for assets inside.
         group_name (Optional[str]):
             Group name to apply to the loaded assets. The returned assets will be copies of the
@@ -113,14 +114,16 @@
         key_prefix (Optional[Union[str, Sequence[str]]]):
             Prefix to prepend to the keys of the loaded assets. The returned assets will be copies
             of the loaded objects, with the prefix prepended.
         freshness_policy (Optional[FreshnessPolicy]): FreshnessPolicy to apply to all the loaded
             assets.
         auto_materialize_policy (Optional[AutoMaterializePolicy]): AutoMaterializePolicy to apply
             to all the loaded assets.
+        source_key_prefix (bool): Prefix to prepend to the keys of loaded SourceAssets. The returned
+            assets will be copies of the loaded objects, with the prefix prepended.
 
     Returns:
         Sequence[Union[AssetsDefinition, SourceAsset]]:
             A list containing assets and source assets defined in the given modules.
     """
     group_name = check.opt_str_param(group_name, "group_name")
     key_prefix = check_opt_coercible_to_asset_key_prefix_param(key_prefix, "key_prefix")
@@ -139,23 +142,25 @@
         assets,
         source_assets,
         cacheable_assets,
         key_prefix=key_prefix,
         group_name=group_name,
         freshness_policy=freshness_policy,
         auto_materialize_policy=auto_materialize_policy,
+        source_key_prefix=source_key_prefix,
     )
 
 
 def load_assets_from_current_module(
     group_name: Optional[str] = None,
     key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
     *,
     freshness_policy: Optional[FreshnessPolicy] = None,
     auto_materialize_policy: Optional[AutoMaterializePolicy] = None,
+    source_key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
 ) -> Sequence[Union[AssetsDefinition, SourceAsset, CacheableAssetsDefinition]]:
     """Constructs a list of assets, source assets, and cacheable assets from the module where
     this function is called.
 
     Args:
         group_name (Optional[str]):
             Group name to apply to the loaded assets. The returned assets will be copies of the
@@ -163,14 +168,16 @@
         key_prefix (Optional[Union[str, Sequence[str]]]):
             Prefix to prepend to the keys of the loaded assets. The returned assets will be copies
             of the loaded objects, with the prefix prepended.
         freshness_policy (Optional[FreshnessPolicy]): FreshnessPolicy to apply to all the loaded
             assets.
         auto_materialize_policy (Optional[AutoMaterializePolicy]): AutoMaterializePolicy to apply
             to all the loaded assets.
+        source_key_prefix (bool): Prefix to prepend to the keys of loaded SourceAssets. The returned
+            assets will be copies of the loaded objects, with the prefix prepended.
 
     Returns:
         Sequence[Union[AssetsDefinition, SourceAsset, CachableAssetsDefinition]]:
             A list containing assets, source assets, and cacheable assets defined in the module.
     """
     caller = inspect.stack()[1]
     module = inspect.getmodule(caller[0])
@@ -211,14 +218,15 @@
 def load_assets_from_package_module(
     package_module: ModuleType,
     group_name: Optional[str] = None,
     key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
     *,
     freshness_policy: Optional[FreshnessPolicy] = None,
     auto_materialize_policy: Optional[AutoMaterializePolicy] = None,
+    source_key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
 ) -> Sequence[Union[AssetsDefinition, SourceAsset, CacheableAssetsDefinition]]:
     """Constructs a list of assets and source assets that includes all asset
     definitions, source assets, and cacheable assets in all sub-modules of the given package module.
 
     A package module is the result of importing a package.
 
     Args:
@@ -229,14 +237,16 @@
         key_prefix (Optional[Union[str, Sequence[str]]]):
             Prefix to prepend to the keys of the loaded assets. The returned assets will be copies
             of the loaded objects, with the prefix prepended.
         freshness_policy (Optional[FreshnessPolicy]): FreshnessPolicy to apply to all the loaded
             assets.
         auto_materialize_policy (Optional[AutoMaterializePolicy]): AutoMaterializePolicy to apply
             to all the loaded assets.
+        source_key_prefix (bool): Prefix to prepend to the keys of loaded SourceAssets. The returned
+            assets will be copies of the loaded objects, with the prefix prepended.
 
     Returns:
         Sequence[Union[AssetsDefinition, SourceAsset, CacheableAssetsDefinition]]:
             A list containing assets, source assets, and cacheable assets defined in the module.
     """
     group_name = check.opt_str_param(group_name, "group_name")
     key_prefix = check_opt_coercible_to_asset_key_prefix_param(key_prefix, "key_prefix")
@@ -254,24 +264,26 @@
         assets,
         source_assets,
         cacheable_assets,
         key_prefix=key_prefix,
         group_name=group_name,
         freshness_policy=freshness_policy,
         auto_materialize_policy=auto_materialize_policy,
+        source_key_prefix=source_key_prefix,
     )
 
 
 def load_assets_from_package_name(
     package_name: str,
     group_name: Optional[str] = None,
     key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
     *,
     freshness_policy: Optional[FreshnessPolicy] = None,
     auto_materialize_policy: Optional[AutoMaterializePolicy] = None,
+    source_key_prefix: Optional[CoercibleToAssetKeyPrefix] = None,
 ) -> Sequence[Union[AssetsDefinition, SourceAsset, CacheableAssetsDefinition]]:
     """Constructs a list of assets, source assets, and cacheable assets that includes all asset
     definitions and source assets in all sub-modules of the given package.
 
     Args:
         package_name (str): The name of a Python package to look for assets inside.
         group_name (Optional[str]):
@@ -280,14 +292,16 @@
         key_prefix (Optional[Union[str, Sequence[str]]]):
             Prefix to prepend to the keys of the loaded assets. The returned assets will be copies
             of the loaded objects, with the prefix prepended.
         freshness_policy (Optional[FreshnessPolicy]): FreshnessPolicy to apply to all the loaded
             assets.
         auto_materialize_policy (Optional[AutoMaterializePolicy]): AutoMaterializePolicy to apply
             to all the loaded assets.
+        source_key_prefix (bool): Prefix to prepend to the keys of loaded SourceAssets. The returned
+            assets will be copies of the loaded objects, with the prefix prepended.
 
     Returns:
         Sequence[Union[AssetsDefinition, SourceAsset, CacheableAssetsDefinition]]:
             A list containing assets, source assets, and cacheable assets defined in the module.
     """
     package_module = import_module(package_name)
     return load_assets_from_package_module(
@@ -312,16 +326,19 @@
     else:
         raise ValueError(
             f"Tried to find modules in package {package_module}, but its __file__ is None"
         )
 
 
 def prefix_assets(
-    assets_defs: Sequence[AssetsDefinition], key_prefix: CoercibleToAssetKeyPrefix
-) -> Sequence[AssetsDefinition]:
+    assets_defs: Sequence[AssetsDefinition],
+    key_prefix: CoercibleToAssetKeyPrefix,
+    source_assets: Sequence[SourceAsset],
+    source_key_prefix: Optional[CoercibleToAssetKeyPrefix],
+) -> Tuple[Sequence[AssetsDefinition], Sequence[SourceAsset]]:
     """Given a list of assets, prefix the input and output asset keys with key_prefix.
     The prefix is not added to source assets.
 
     Input asset keys that reference other assets within assets_defs are "brought along" -
     i.e. prefixed as well.
 
     Example with a single asset:
@@ -350,14 +367,15 @@
             result = prefixed_asset_key_replacements([asset1, asset2], "my_prefix")
             assert result.assets[0].asset_key == AssetKey(["my_prefix", "asset1"])
             assert result.assets[1].asset_key == AssetKey(["my_prefix", "asset2"])
             assert result.assets[1].dependency_keys == {AssetKey(["my_prefix", "asset1"])}
 
     """
     asset_keys = {asset_key for assets_def in assets_defs for asset_key in assets_def.keys}
+    source_asset_keys = {source_asset.key for source_asset in source_assets}
 
     if isinstance(key_prefix, str):
         key_prefix = [key_prefix]
     key_prefix = check.is_list(key_prefix, of_type=str)
 
     result_assets: List[AssetsDefinition] = []
     for assets_def in assets_defs:
@@ -366,39 +384,55 @@
         }
         input_asset_key_replacements = {}
         for dep_asset_key in assets_def.dependency_keys:
             if dep_asset_key in asset_keys:
                 input_asset_key_replacements[dep_asset_key] = AssetKey(
                     [*key_prefix, *dep_asset_key.path]
                 )
+            elif source_key_prefix and dep_asset_key in source_asset_keys:
+                input_asset_key_replacements[dep_asset_key] = AssetKey(
+                    [*source_key_prefix, *dep_asset_key.path]
+                )
 
         result_assets.append(
             assets_def.with_attributes(
                 output_asset_key_replacements=output_asset_key_replacements,
                 input_asset_key_replacements=input_asset_key_replacements,
             )
         )
-    return result_assets
+
+    if source_key_prefix:
+        result_source_assets = [
+            source_asset.with_attributes(key=AssetKey([*source_key_prefix, *source_asset.key.path]))
+            for source_asset in source_assets
+        ]
+    else:
+        result_source_assets = source_assets
+
+    return result_assets, result_source_assets
 
 
 def assets_with_attributes(
     assets_defs: Sequence[AssetsDefinition],
     source_assets: Sequence[SourceAsset],
     cacheable_assets: Sequence[CacheableAssetsDefinition],
     key_prefix: Optional[Sequence[str]],
     group_name: Optional[str],
     freshness_policy: Optional[FreshnessPolicy],
-    auto_materialize_policy: Optional[AutoMaterializePolicy] = None,
+    auto_materialize_policy: Optional[AutoMaterializePolicy],
+    source_key_prefix: Optional[Sequence[str]],
 ) -> Sequence[Union[AssetsDefinition, SourceAsset, CacheableAssetsDefinition]]:
     # There is a tricky edge case here where if a non-cacheable asset depends on a cacheable asset,
     # and the assets are prefixed, the non-cacheable asset's dependency will not be prefixed since
     # at prefix-time it is not known that its dependency is one of the cacheable assets.
     # https://github.com/dagster-io/dagster/pull/10389#pullrequestreview-1170913271
     if key_prefix:
-        assets_defs = prefix_assets(assets_defs, key_prefix)
+        assets_defs, source_assets = prefix_assets(
+            assets_defs, key_prefix, source_assets, source_key_prefix
+        )
         cacheable_assets = [
             cached_asset.with_prefix_for_all(key_prefix) for cached_asset in cacheable_assets
         ]
 
     if group_name or freshness_policy or auto_materialize_policy:
         assets_defs = [
             asset.with_attributes(
@@ -408,15 +442,16 @@
                 freshness_policy=freshness_policy,
                 auto_materialize_policy=auto_materialize_policy,
             )
             for asset in assets_defs
         ]
         if group_name:
             source_assets = [
-                source_asset.with_group_name(group_name) for source_asset in source_assets
+                source_asset.with_attributes(group_name=group_name)
+                for source_asset in source_assets
             ]
         cacheable_assets = [
             cached_asset.with_attributes_for_all(
                 group_name,
                 freshness_policy=freshness_policy,
                 auto_materialize_policy=auto_materialize_policy,
             )
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/logger_definition.py` & `dagster-1.3.3/dagster/_core/definitions/logger_definition.py`

 * *Files 5% similar despite different names*

```diff
@@ -25,15 +25,15 @@
 
     Loggers are job-scoped logging handlers, which will be automatically invoked whenever
     dagster messages are logged from within a job.
 
     Args:
         logger_fn (Callable[[InitLoggerContext], logging.Logger]): User-provided function to
             instantiate the logger. This logger will be automatically invoked whenever the methods
-            on ``context.log`` are called from within job/pipeline compute logic.
+            on ``context.log`` are called from within job compute logic.
         config_schema (Optional[ConfigSchema]): The schema for the config. Configuration data available in
             `init_context.logger_config`. If not set, Dagster will accept any config provided.
         description (Optional[str]): A human-readable description of this logger.
     """
 
     def __init__(
         self,
@@ -64,27 +64,27 @@
         context_param_name = get_function_params(self.logger_fn)[0].name
 
         if args:
             context = check.opt_inst_param(
                 args[0],
                 context_param_name,
                 UnboundInitLoggerContext,
-                default=UnboundInitLoggerContext(logger_config=None, pipeline_def=None),
+                default=UnboundInitLoggerContext(logger_config=None, job_def=None),
             )
             return logger_invocation_result(self, context)
         else:
             if context_param_name not in kwargs:
                 raise DagsterInvalidInvocationError(
                     f"Logger initialization expected argument '{context_param_name}'."
                 )
             context = check.opt_inst_param(
                 kwargs[context_param_name],
                 context_param_name,
                 UnboundInitLoggerContext,
-                default=UnboundInitLoggerContext(logger_config=None, pipeline_def=None),
+                default=UnboundInitLoggerContext(logger_config=None, job_def=None),
             )
 
             return logger_invocation_result(self, context)
 
     @public
     @property
     def logger_fn(self) -> "InitLoggerFunction":
@@ -154,46 +154,32 @@
         )
 
     return _wrap
 
 
 def build_init_logger_context(
     logger_config: Any = None,
-    pipeline_def: Optional["JobDefinition"] = None,
     job_def: Optional["JobDefinition"] = None,
 ) -> "UnboundInitLoggerContext":
     """Builds logger initialization context from provided parameters.
 
     This function can be used to provide the context argument to the invocation of a logger
     definition.
 
     Note that you may only specify one of pipeline_def and job_def.
 
     Args:
         logger_config (Any): The config to provide during initialization of logger.
-        pipeline_def (Optional[PipelineDefinition]): The pipeline definition that the logger will be
-            used with.
         job_def (Optional[JobDefinition]): The job definition that the logger will be used with.
 
     Examples:
         .. code-block:: python
 
             context = build_init_logger_context()
             logger_to_init(context)
     """
     from dagster._core.definitions import JobDefinition
     from dagster._core.execution.context.logger import UnboundInitLoggerContext
 
-    check.opt_inst_param(pipeline_def, "pipeline_def", JobDefinition)
     check.opt_inst_param(job_def, "job_def", JobDefinition)
 
-    check.invariant(
-        not (pipeline_def and job_def),
-        (
-            "In build_init_logger_context, you may only specify one of the pipeline_def and job_def"
-            " parameters, not both."
-        ),
-    )
-
-    return UnboundInitLoggerContext(
-        logger_config=logger_config, pipeline_def=pipeline_def or job_def
-    )
+    return UnboundInitLoggerContext(logger_config=logger_config, job_def=job_def)
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/logger_invocation.py` & `dagster-1.3.3/dagster/_core/definitions/logger_invocation.py`

 * *Files 18% similar despite different names*

```diff
@@ -4,11 +4,11 @@
 
 
 def logger_invocation_result(logger_def: LoggerDefinition, init_context: UnboundInitLoggerContext):
     """Using the provided context, call the underlying `logger_fn` and return created logger."""
     logger_config = resolve_bound_config(init_context.logger_config, logger_def)
 
     bound_context = InitLoggerContext(
-        logger_config, logger_def, init_context.pipeline_def, init_context.run_id
+        logger_config, logger_def, init_context.job_def, init_context.run_id
     )
 
     return logger_def.logger_fn(bound_context)
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/materialize.py` & `dagster-1.3.3/dagster/_core/definitions/materialize.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/metadata/__init__.py` & `dagster-1.3.3/dagster/_core/definitions/metadata/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -808,15 +808,15 @@
         return super(DagsterAssetMetadataValue, cls).__new__(
             cls, check.inst_param(asset_key, "asset_key", AssetKey)
         )
 
     @public
     @property
     def value(self) -> "AssetKey":
-        return self.value
+        return self.asset_key
 
 
 # This should be deprecated or fixed so that `value` does not return itself.
 @experimental
 @whitelist_for_serdes(storage_name="TableMetadataEntryData")
 class TableMetadataValue(
     NamedTuple(
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/metadata/table.py` & `dagster-1.3.3/dagster/_core/definitions/metadata/table.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/multi_asset_sensor_definition.py` & `dagster-1.3.3/dagster/_core/definitions/multi_asset_sensor_definition.py`

 * *Files 0% similar despite different names*

```diff
@@ -243,23 +243,27 @@
             self._monitored_asset_keys = list(
                 monitored_assets.resolve([*repo_assets, *repo_source_assets])
             )
         else:
             self._monitored_asset_keys = monitored_assets
 
         self._assets_by_key: Dict[AssetKey, Optional[AssetsDefinition]] = {}
+        self._partitions_def_by_asset_key: Dict[AssetKey, Optional[PartitionsDefinition]] = {}
         for asset_key in self._monitored_asset_keys:
             assets_def = self._repository_def.assets_defs_by_key.get(asset_key)
             self._assets_by_key[asset_key] = assets_def
 
-        self._partitions_def_by_asset_key = {
-            asset_key: asset_def.partitions_def
-            for asset_key, asset_def in self._assets_by_key.items()
-            if asset_def is not None
-        }
+            source_asset_def = self._repository_def.source_assets_by_key.get(asset_key)
+            self._partitions_def_by_asset_key[asset_key] = (
+                assets_def.partitions_def
+                if assets_def
+                else source_asset_def.partitions_def
+                if source_asset_def
+                else None
+            )
 
         # Cursor object with utility methods for updating and retrieving cursor information.
         # At the end of each tick, must call update_cursor_after_evaluation to update the serialized
         # cursor.
         self._unpacked_cursor = MultiAssetSensorContextCursor(cursor, self)
         self._cursor_advance_state_mutation = MultiAssetSensorCursorAdvances()
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/multi_dimensional_partitions.py` & `dagster-1.3.3/dagster/_core/definitions/multi_dimensional_partitions.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,33 +9,34 @@
     Mapping,
     NamedTuple,
     Optional,
     Sequence,
     Set,
     Tuple,
     Type,
+    Union,
     cast,
 )
 
 import dagster._check as check
+from dagster._annotations import public
 from dagster._core.errors import (
     DagsterInvalidDefinitionError,
     DagsterInvalidInvocationError,
     DagsterUnknownPartitionError,
 )
 from dagster._core.instance import DynamicPartitionsStore
 from dagster._core.storage.tags import (
     MULTIDIMENSIONAL_PARTITION_PREFIX,
     get_multidimensional_partition_tag,
 )
 
 from .partition import (
     DefaultPartitionsSubset,
     DynamicPartitionsDefinition,
-    Partition,
     PartitionsDefinition,
     PartitionsSubset,
     StaticPartitionsDefinition,
 )
 from .time_window_partitions import TimeWindow, TimeWindowPartitionsDefinition
 
 INVALID_STATIC_PARTITIONS_KEY_CHARACTERS = set(["|", ",", "[", "]"])
@@ -159,15 +160,15 @@
                 raise DagsterInvalidDefinitionError(
                     f"Invalid character in partition key for dimension {dim_name}. "
                     "A multi-partitions definition cannot contain partition keys with "
                     "the following characters: |, [, ], ,"
                 )
 
 
-class MultiPartitionsDefinition(PartitionsDefinition):
+class MultiPartitionsDefinition(PartitionsDefinition[MultiPartitionKey]):
     """Takes the cross-product of partitions from two partitions definitions.
 
     For example, with a static partitions definition where the partitions are ["a", "b", "c"]
     and a daily partitions definition, this partitions definition will have the following
     partitions:
 
     2020-01-01|a
@@ -239,79 +240,59 @@
 
     def get_partitions_def_for_dimension(self, dimension_name: str) -> PartitionsDefinition:
         for dim_def in self._partitions_defs:
             if dim_def.name == dimension_name:
                 return dim_def.partitions_def
         check.failed(f"Invalid dimension name {dimension_name}")
 
-    def get_partition(
+    # We override the default implementation of `has_partition_key` for performance.
+    def has_partition_key(
         self,
-        partition_key: str,
+        partition_key: Union[MultiPartitionKey, str],
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> Partition:
-        if not isinstance(partition_key, MultiPartitionKey):
-            partition_key = self.get_partition_key_from_str(partition_key)
-        partition_key = cast(MultiPartitionKey, partition_key)
-
+    ) -> bool:
+        partition_key = (
+            partition_key
+            if isinstance(partition_key, MultiPartitionKey)
+            else self.get_partition_key_from_str(partition_key)
+        )
         if partition_key.keys_by_dimension.keys() != set(self.partition_dimension_names):
             raise DagsterUnknownPartitionError(
                 f"Invalid partition key {partition_key}. The dimensions of the partition key are"
                 " not the dimensions of the partitions definition."
             )
 
-        partitions_by_dimension: Dict[str, Partition] = {}
         for dimension in self.partitions_defs:
-            partition = dimension.partitions_def.get_partition(
+            if not dimension.partitions_def.has_partition_key(
                 partition_key.keys_by_dimension[dimension.name],
                 current_time=current_time,
                 dynamic_partitions_store=dynamic_partitions_store,
-            )
-            if not partition:
-                check.failed(
-                    f"Invalid partition key {partition_key}. The partition key does not exist in"
-                    " the partitions definition."
-                )
-            partitions_by_dimension[dimension.name] = partition
-
-        return Partition(value=partitions_by_dimension, name=partition_key)
+            ):
+                return False
+        return True
 
-    def get_partitions(
+    @public
+    def get_partition_keys(
         self,
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> Sequence[Partition]:
-        partition_sequences = [
-            partition_dim.partitions_def.get_partitions(
+    ) -> Sequence[MultiPartitionKey]:
+        partition_key_sequences = [
+            partition_dim.partitions_def.get_partition_keys(
                 current_time=current_time, dynamic_partitions_store=dynamic_partitions_store
             )
             for partition_dim in self._partitions_defs
         ]
 
-        def get_multi_dimensional_partition(partitions_tuple: Tuple[Partition]) -> Partition:
-            check.invariant(len(partitions_tuple) == len(self._partitions_defs))
-
-            partitions_by_dimension: Dict[str, Partition] = {
-                self._partitions_defs[i].name: partitions_tuple[i]
-                for i in range(len(partitions_tuple))
-            }
-
-            return Partition(
-                value=partitions_by_dimension,
-                name=MultiPartitionKey(
-                    {
-                        dimension_key: partition.name
-                        for dimension_key, partition in partitions_by_dimension.items()
-                    }
-                ),
-            )
-
         return [
-            get_multi_dimensional_partition(partitions_tuple)
-            for partitions_tuple in itertools.product(*partition_sequences)
+            MultiPartitionKey(
+                {self._partitions_defs[i].name: key for i, key in enumerate(partition_key_tuple)}
+            )
+            for partition_key_tuple in itertools.product(*partition_key_sequences)
         ]
 
     def filter_valid_partition_keys(
         self, partition_keys: Set[str], dynamic_partitions_store: DynamicPartitionsStore
     ) -> Set[MultiPartitionKey]:
         partition_keys_by_dimension = {
             dim.name: dim.partitions_def.get_partition_keys(
@@ -362,15 +343,15 @@
             f"{dimension_2.name.capitalize()}: {str(dimension_2.partitions_def)}"
         )
         return partition_str
 
     def __repr__(self) -> str:
         return f"{type(self).__name__}(dimensions={[str(dim) for dim in self.partitions_defs]}"
 
-    def get_partition_key_from_str(self, partition_key_str: str) -> str:
+    def get_partition_key_from_str(self, partition_key_str: str) -> MultiPartitionKey:
         """Given a string representation of a partition key, returns a MultiPartitionKey object."""
         check.str_param(partition_key_str, "partition_key_str")
 
         partition_key_strs = partition_key_str.split(MULTIPARTITION_KEY_DELIMITER)
         check.invariant(
             len(partition_key_strs) == len(self.partitions_defs),
             (
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/node_container.py` & `dagster-1.3.3/dagster/_core/definitions/node_container.py`

 * *Files 2% similar despite different names*

```diff
@@ -97,15 +97,15 @@
 
 def create_execution_structure(
     node_defs: Sequence["NodeDefinition"],
     dependencies_dict: DependencyMapping[NodeInvocation],
     graph_definition: "GraphDefinition",
 ) -> Tuple[DependencyStructure, Mapping[str, Node]]:
     """This builder takes the dependencies dictionary specified during creation of the
-    PipelineDefinition object and builds (1) the execution structure and (2) a node dependency
+    JobDefinition object and builds (1) the execution structure and (2) a node dependency
     dictionary.
 
     For example, for the following dependencies:
 
     dep_dict = {
             NodeInvocation('giver'): {},
             NodeInvocation('sleeper', alias='sleeper_1'): {
@@ -127,20 +127,20 @@
                 'in_4': DependencyDefinition('sleeper_4', 'total'),
             },
         },
 
     This will create:
 
     node_dict = {
-        'giver': <dagster._core.definitions.dependency.Solid object>,
-        'sleeper_1': <dagster._core.definitions.dependency.Solid object>,
-        'sleeper_2': <dagster._core.definitions.dependency.Solid object>,
-        'sleeper_3': <dagster._core.definitions.dependency.Solid object>,
-        'sleeper_4': <dagster._core.definitions.dependency.Solid object>,
-        'total': <dagster._core.definitions.dependency.Solid object>
+        'giver': <dagster._core.definitions.dependency.Node object>,
+        'sleeper_1': <dagster._core.definitions.dependency.Node object>,
+        'sleeper_2': <dagster._core.definitions.dependency.Node object>,
+        'sleeper_3': <dagster._core.definitions.dependency.Node object>,
+        'sleeper_4': <dagster._core.definitions.dependency.Node object>,
+        'total': <dagster._core.definitions.dependency.Node object>
     }
 
     as well as a dagster._core.definitions.dependency.DependencyStructure object.
     """
     from .graph_definition import GraphDefinition
     from .node_definition import NodeDefinition
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/node_definition.py` & `dagster-1.3.3/dagster/_core/definitions/node_definition.py`

 * *Files 0% similar despite different names*

```diff
@@ -25,15 +25,15 @@
     from .composition import PendingNodeInvocation
     from .dependency import NodeHandle, NodeInputHandle
     from .input import InputDefinition
     from .op_definition import OpDefinition
     from .output import OutputDefinition
 
 
-# base class for SolidDefinition and GraphDefinition
+# base class for OpDefinition and GraphDefinition
 # represents that this is embedable within a graph
 class NodeDefinition(NamedConfigurableDefinition):
     _name: str
     _description: Optional[str]
     _tags: Mapping[str, str]
     _input_defs: Sequence["InputDefinition"]
     _input_dict: Mapping[str, "InputDefinition"]
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/observe.py` & `dagster-1.3.3/dagster/_core/definitions/observe.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/op_definition.py` & `dagster-1.3.3/dagster/_core/definitions/op_definition.py`

 * *Files 3% similar despite different names*

```diff
@@ -29,14 +29,15 @@
     InputManagerRequirement,
     OpDefinitionResourceRequirement,
     OutputManagerRequirement,
     ResourceRequirement,
 )
 from dagster._core.errors import DagsterInvalidInvocationError, DagsterInvariantViolationError
 from dagster._core.types.dagster_type import DagsterType, DagsterTypeKind
+from dagster._utils import IHasInternalInit
 from dagster._utils.backcompat import canonicalize_backcompat_args, deprecation_warning
 
 from .definition_config_schema import (
     IDefinitionConfigSchema,
     convert_user_facing_definition_config_schema,
 )
 from .hook_definition import HookDefinition
@@ -49,15 +50,15 @@
 
     from .composition import PendingNodeInvocation
     from .decorators.op_decorator import DecoratedOpFunction
 
 OpComputeFunction: TypeAlias = Callable[..., Any]
 
 
-class OpDefinition(NodeDefinition):
+class OpDefinition(NodeDefinition, IHasInternalInit):
     """Defines an op, the functional unit of user-defined computation.
 
     For more details on what a op is, refer to the
     `Ops Overview <../../concepts/ops-jobs-graphs/ops>`_ .
 
     End users should prefer the :func:`@op <op>` decorator. OpDefinition is generally intended to be
     used by framework authors or for programatically generated ops.
@@ -120,23 +121,23 @@
         config_schema: Optional[Union[UserConfigSchema, IDefinitionConfigSchema]] = None,
         required_resource_keys: Optional[AbstractSet[str]] = None,
         tags: Optional[Mapping[str, Any]] = None,
         version: Optional[str] = None,
         retry_policy: Optional[RetryPolicy] = None,
         code_version: Optional[str] = None,
     ):
-        from .decorators.op_decorator import DecoratedOpFunction, resolve_checked_solid_fn_inputs
+        from .decorators.op_decorator import DecoratedOpFunction, resolve_checked_op_fn_inputs
 
         ins = check.opt_mapping_param(ins, "ins")
         input_defs = [
             inp.to_definition(name) for name, inp in sorted(ins.items(), key=lambda inp: inp[0])
         ]  # sort so that input definition order is deterministic
 
         if isinstance(compute_fn, DecoratedOpFunction):
-            resolved_input_defs: Sequence[InputDefinition] = resolve_checked_solid_fn_inputs(
+            resolved_input_defs: Sequence[InputDefinition] = resolve_checked_op_fn_inputs(
                 decorator_name="@op",
                 fn_name=name,
                 compute_fn=cast(DecoratedOpFunction, compute_fn),
                 explicit_input_defs=input_defs,
                 exclude_nothing=True,
             )
             self._compute_fn = compute_fn
@@ -171,14 +172,42 @@
             input_defs=check.sequence_param(resolved_input_defs, "input_defs", InputDefinition),
             output_defs=check.sequence_param(output_defs, "output_defs", OutputDefinition),
             description=description,
             tags=check.opt_mapping_param(tags, "tags", key_type=str),
             positional_inputs=positional_inputs,
         )
 
+    def dagster_internal_init(
+        *,
+        compute_fn: Union[Callable[..., Any], "DecoratedOpFunction"],
+        name: str,
+        ins: Optional[Mapping[str, In]],
+        outs: Optional[Mapping[str, Out]],
+        description: Optional[str],
+        config_schema: Optional[Union[UserConfigSchema, IDefinitionConfigSchema]],
+        required_resource_keys: Optional[AbstractSet[str]],
+        tags: Optional[Mapping[str, Any]],
+        version: Optional[str],
+        retry_policy: Optional[RetryPolicy],
+        code_version: Optional[str],
+    ) -> "OpDefinition":
+        return OpDefinition(
+            compute_fn=compute_fn,
+            name=name,
+            ins=ins,
+            outs=outs,
+            description=description,
+            config_schema=config_schema,
+            required_resource_keys=required_resource_keys,
+            tags=tags,
+            version=version,
+            retry_policy=retry_policy,
+            code_version=code_version,
+        )
+
     @property
     def node_type_str(self) -> str:
         return "op"
 
     @property
     def is_graph_job_op_node(self) -> bool:
         return True
@@ -303,40 +332,58 @@
 
     def default_value_for_input(self, input_name: str) -> InputDefinition:
         return self.input_def_named(input_name).default_value
 
     def input_supports_dynamic_output_dep(self, input_name: str) -> bool:
         return True
 
-    def copy_for_configured(
+    def with_replaced_properties(
         self,
         name: str,
-        description: Optional[str],
-        config_schema: IDefinitionConfigSchema,
+        ins: Optional[Mapping[str, In]] = None,
+        outs: Optional[Mapping[str, Out]] = None,
+        config_schema: Optional[IDefinitionConfigSchema] = None,
+        description: Optional[str] = None,
     ) -> "OpDefinition":
-        return OpDefinition(
+        return OpDefinition.dagster_internal_init(
             name=name,
-            ins={input_def.name: In.from_definition(input_def) for input_def in self.input_defs},
-            outs={
+            ins=ins
+            or {input_def.name: In.from_definition(input_def) for input_def in self.input_defs},
+            outs=outs
+            or {
                 output_def.name: Out.from_definition(output_def) for output_def in self.output_defs
             },
             compute_fn=self.compute_fn,
-            config_schema=config_schema,
+            config_schema=config_schema or self.config_schema,
             description=description or self.description,
             tags=self.tags,
             required_resource_keys=self.required_resource_keys,
-            code_version=self.version,
+            code_version=self._version,
             retry_policy=self.retry_policy,
+            version=None,  # code_version replaces version
+        )
+
+    def copy_for_configured(
+        self,
+        name: str,
+        description: Optional[str],
+        config_schema: IDefinitionConfigSchema,
+    ) -> "OpDefinition":
+        return self.with_replaced_properties(
+            name=name,
+            description=description,
+            config_schema=config_schema,
         )
 
     def get_resource_requirements(
         self,
         outer_context: Optional[object] = None,
     ) -> Iterator[ResourceRequirement]:
-        # Outer requiree in this context is the outer-calling node handle. If not provided, then just use the solid name.
+        # Outer requiree in this context is the outer-calling node handle. If not provided, then
+        # just use the op name.
         outer_context = cast(Optional[Tuple[NodeHandle, Optional["AssetLayer"]]], outer_context)
         if not outer_context:
             handle = None
             asset_layer = None
         else:
             handle, asset_layer = outer_context
         node_description = f"{self.node_type_str} '{handle or self.name}'"
@@ -386,42 +433,40 @@
         from ..execution.context.invocation import UnboundOpExecutionContext
         from .composition import is_in_composition
         from .decorators.op_decorator import DecoratedOpFunction
 
         if is_in_composition():
             return super(OpDefinition, self).__call__(*args, **kwargs)
         else:
-            node_label = self.node_type_str  # string "solid" for solids, "op" for ops
-
             if not isinstance(self.compute_fn, DecoratedOpFunction):
                 raise DagsterInvalidInvocationError(
-                    f"Attemped to invoke {node_label} that was not constructed using the"
-                    f" `@{node_label}` decorator. Only {node_label}s constructed using the"
-                    f" `@{node_label}` decorator can be directly invoked."
+                    "Attemped to invoke op that was not constructed using the"
+                    " `@op` decorator. Only ops constructed using the"
+                    " `@op` decorator can be directly invoked."
                 )
             if self.compute_fn.has_context_arg():
                 if len(args) + len(kwargs) == 0:
                     raise DagsterInvalidInvocationError(
-                        f"Compute function of {node_label} '{self.name}' has context argument, but"
+                        f"Compute function of op '{self.name}' has context argument, but"
                         " no context was provided when invoking."
                     )
                 if len(args) > 0:
                     if args[0] is not None and not isinstance(args[0], UnboundOpExecutionContext):
                         raise DagsterInvalidInvocationError(
-                            f"Compute function of {node_label} '{self.name}' has context argument, "
+                            f"Compute function of op '{self.name}' has context argument, "
                             "but no context was provided when invoking."
                         )
                     context = args[0]
                     return op_invocation_result(self, context, *args[1:], **kwargs)
                 # Context argument is provided under kwargs
                 else:
                     context_param_name = get_function_params(self.compute_fn.decorated_fn)[0].name
                     if context_param_name not in kwargs:
                         raise DagsterInvalidInvocationError(
-                            f"Compute function of {node_label} '{self.name}' has context argument "
+                            f"Compute function of op '{self.name}' has context argument "
                             f"'{context_param_name}', but no value for '{context_param_name}' was "
                             f"found when invoking. Provided kwargs: {kwargs}"
                         )
                     context = cast(UnboundOpExecutionContext, kwargs[context_param_name])
                     kwargs_sans_context = {
                         kwarg: val
                         for kwarg, val in kwargs.items()
@@ -432,14 +477,27 @@
             else:
                 context = None
                 if len(args) > 0 and isinstance(args[0], UnboundOpExecutionContext):
                     context = cast(UnboundOpExecutionContext, args[0])
                     args = args[1:]
                 return op_invocation_result(self, context, *args, **kwargs)
 
+    def __eq__(self, other) -> bool:
+        if not isinstance(other, OpDefinition):
+            return False
+        return (
+            self.compute_fn == other.compute_fn
+            and self.name == other.name
+            and self.description == other.description
+            and self.config_schema == other.config_schema
+            and self.required_resource_keys == other.required_resource_keys
+            and self.tags == other.tags
+            and self.retry_policy == other.retry_policy
+        )
+
 
 def _resolve_output_defs_from_outs(
     compute_fn: Union[Callable[..., Any], "DecoratedOpFunction"],
     outs: Optional[Mapping[str, Out]],
     default_code_version: Optional[str],
 ) -> Sequence[OutputDefinition]:
     from .decorators.op_decorator import DecoratedOpFunction
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/op_invocation.py` & `dagster-1.3.3/dagster/_core/definitions/op_invocation.py`

 * *Files 1% similar despite different names*

```diff
@@ -154,15 +154,15 @@
     config_provided_in_multiple_places = config_input and context and context.op_config
     if config_provided_in_multiple_places:
         raise DagsterInvalidInvocationError("Cannot provide config in both context and kwargs")
     if config_input:
         from dagster._config.pythonic_config import Config
 
         context = (context or build_op_context()).replace_config(
-            config_input._as_config_dict()  # noqa: SLF001
+            config_input._convert_to_config_dictionary()  # noqa: SLF001
             if isinstance(config_input, Config)
             else config_input
         )
 
     _check_invocation_requirements(op_def, context)
 
     bound_context = (context or build_op_context()).bind(op_def_or_invocation)
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/output.py` & `dagster-1.3.3/dagster/_core/definitions/output.py`

 * *Files 1% similar despite different names*

```diff
@@ -122,15 +122,15 @@
         return False
 
     def mapping_from(
         self, node_name: str, output_name: Optional[str] = None, from_dynamic_mapping: bool = False
     ) -> "OutputMapping":
         """Create an output mapping from an output of a child node.
 
-        In a CompositeSolidDefinition, you can use this helper function to construct
+        In a GraphDefinition, you can use this helper function to construct
         an :py:class:`OutputMapping` from the output of a child node.
 
         Args:
             node_name (str): The name of the child node from which to map this output.
             output_name (str): The name of the child node's output from which to map this output.
 
         Examples:
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/partition.py` & `dagster-1.3.3/dagster/_core/definitions/partition.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,84 +1,90 @@
 import copy
 import hashlib
 import json
 from abc import ABC, abstractmethod
 from datetime import (
     datetime,
-    time,
     timedelta,
 )
 from enum import Enum
 from typing import (
     Any,
     Callable,
     Generic,
     Iterable,
-    List,
     Mapping,
     NamedTuple,
     Optional,
     Sequence,
     Set,
     Type,
-    TypeVar,
     Union,
     cast,
 )
 
-import pendulum
 from dateutil.relativedelta import relativedelta
+from typing_extensions import TypeVar
 
 import dagster._check as check
-from dagster._annotations import PublicAttr, public
+from dagster._annotations import PublicAttr, deprecated, public
 from dagster._core.definitions.partition_key_range import PartitionKeyRange
 from dagster._core.definitions.run_request import (
     AddDynamicPartitionsRequest,
     DeleteDynamicPartitionsRequest,
 )
 from dagster._core.instance import DagsterInstance, DynamicPartitionsStore
 from dagster._core.storage.tags import PARTITION_NAME_TAG, PARTITION_SET_TAG
 from dagster._serdes import whitelist_for_serdes
-from dagster._seven.compat.pendulum import PendulumDateTime, to_timezone
-from dagster._utils.backcompat import deprecation_warning, experimental_arg_warning
+from dagster._utils import xor
+from dagster._utils.backcompat import (
+    canonicalize_backcompat_args,
+    deprecation_warning,
+    experimental_arg_warning,
+)
 from dagster._utils.cached_method import cached_method
-from dagster._utils.schedules import schedule_execution_time_iterator
 
 from ..errors import (
     DagsterInvalidDefinitionError,
     DagsterInvalidDeserializationVersionError,
     DagsterInvalidInvocationError,
-    DagsterInvariantViolationError,
     DagsterUnknownPartitionError,
 )
 from .config import ConfigMapping
 from .utils import validate_tags
 
 DEFAULT_DATE_FORMAT = "%Y-%m-%d"
 
-T_cov = TypeVar("T_cov", covariant=True)
-
+T_cov = TypeVar("T_cov", default=Any, covariant=True)
+T_str = TypeVar("T_str", bound=str, default=str, covariant=True)
+T_PartitionsDefinition = TypeVar(
+    "T_PartitionsDefinition",
+    bound="PartitionsDefinition",
+    default="PartitionsDefinition",
+    covariant=True,
+)
 
 # Dagit selects partition ranges following the format '2022-01-13...2022-01-14'
 # "..." is an invalid substring in partition keys
 # The other escape characters are characters that may not display in Dagit
 INVALID_PARTITION_SUBSTRINGS = ["...", "\a", "\b", "\f", "\n", "\r", "\t", "\v", "\0"]
 
 
+@deprecated
 class Partition(Generic[T_cov]):
     """A Partition represents a single slice of the entire set of a job's possible work. It consists
     of a value, which is an object that represents that partition, and an optional name, which is
     used to label the partition in a human-readable way.
 
     Args:
         value (Any): The object for this partition
         name (str): Name for this partition
     """
 
-    def __init__(self, value: T_cov, name: Optional[str] = None):
+    def __init__(self, value: Any, name: Optional[str] = None):
         self._value = value
         self._name = check.str_param(name or str(value), "name")
 
     @property
     def value(self) -> T_cov:
         return self._value
 
@@ -86,84 +92,17 @@
     def name(self) -> str:
         return self._name
 
     def __eq__(self, other: object) -> bool:
         if not isinstance(other, Partition):
             return False
         else:
-            other = cast(Partition[object], other)
             return self.value == other.value and self.name == other.name
 
 
-def schedule_partition_range(
-    start: datetime,
-    end: Optional[datetime],
-    cron_schedule: str,
-    fmt: str,
-    timezone: Optional[str],
-    execution_time_to_partition_fn: Callable[[datetime], datetime],
-    current_time: Optional[datetime],
-) -> Sequence[Partition[datetime]]:
-    if end and start > end:
-        raise DagsterInvariantViolationError(
-            'Selected date range start "{start}" is after date range end "{end}'.format(
-                start=start.strftime(fmt),
-                end=end.strftime(fmt),
-            )
-        )
-
-    tz = timezone if timezone else "UTC"
-
-    _current_time = current_time if current_time else pendulum.now(tz)
-
-    # Coerce to the definition timezone
-    _start = (
-        to_timezone(start, tz)
-        if isinstance(start, PendulumDateTime)
-        else pendulum.instance(start, tz=tz)
-    )
-    _current_time = (
-        to_timezone(_current_time, tz)
-        if isinstance(_current_time, PendulumDateTime)
-        else pendulum.instance(_current_time, tz=tz)
-    )
-
-    # The end partition time should be before the last partition that
-    # executes before the current time
-    end_partition_time = execution_time_to_partition_fn(_current_time)
-
-    # The partition set has an explicit end time that represents the end of the partition range
-    if end:
-        _end = (
-            to_timezone(end, tz)
-            if isinstance(end, PendulumDateTime)
-            else pendulum.instance(end, tz=tz)
-        )
-
-        # If the explicit end time is before the last partition time,
-        # update the end partition time
-        end_partition_time = min(_end, end_partition_time)
-
-    end_timestamp = end_partition_time.timestamp()
-
-    partitions: List[Partition[datetime]] = []
-    for next_time in schedule_execution_time_iterator(_start.timestamp(), cron_schedule, tz):
-        partition_time = execution_time_to_partition_fn(next_time)
-
-        if partition_time.timestamp() > end_timestamp:
-            break
-
-        if partition_time.timestamp() < _start.timestamp():
-            continue
-
-        partitions.append(Partition(value=partition_time, name=partition_time.strftime(fmt)))
-
-    return partitions
-
-
 @whitelist_for_serdes
 class ScheduleType(Enum):
     HOURLY = "HOURLY"
     DAILY = "DAILY"
     WEEKLY = "WEEKLY"
     MONTHLY = "MONTHLY"
 
@@ -189,88 +128,58 @@
         return self.ordinal > other.ordinal
 
     def __lt__(self, other: "ScheduleType") -> bool:
         check.inst(other, ScheduleType, "Cannot compare ScheduleType with non-ScheduleType")
         return self.ordinal < other.ordinal
 
 
-class PartitionsDefinition(ABC, Generic[T_cov]):
+class PartitionsDefinition(ABC, Generic[T_str]):
     """Defines a set of partitions, which can be attached to a software-defined asset or job.
 
     Abstract class with implementations for different kinds of partitions.
     """
 
     @property
-    def partitions_subset_class(self) -> Type["PartitionsSubset"]:
-        return DefaultPartitionsSubset
+    def partitions_subset_class(self) -> Type["PartitionsSubset[T_str]"]:
+        return DefaultPartitionsSubset[T_str]
 
     @abstractmethod
-    def get_partitions(
+    @public
+    def get_partition_keys(
         self,
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> Sequence[Partition[T_cov]]:
+    ) -> Sequence[T_str]:
         ...
 
-    def get_partition(
-        self,
-        partition_key: str,
-        current_time: Optional[datetime] = None,
-        dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> Partition[T_cov]:
-        for partition in self.get_partitions(
-            current_time=current_time, dynamic_partitions_store=dynamic_partitions_store
-        ):
-            if partition.name == partition_key:
-                return partition
-
-        raise DagsterUnknownPartitionError(f"Could not find a partition with key `{partition_key}`")
-
     def __str__(self) -> str:
         joined_keys = ", ".join([f"'{key}'" for key in self.get_partition_keys()])
         return joined_keys
 
-    @public
-    def get_partition_keys(
-        self,
-        current_time: Optional[datetime] = None,
-        dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> Sequence[str]:
-        return [
-            partition.name
-            for partition in self.get_partitions(current_time, dynamic_partitions_store)
-        ]
-
     def get_last_partition_key(
         self,
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> Optional[str]:
-        partitions = self.get_partitions(current_time, dynamic_partitions_store)
-        if partitions:
-            return partitions[-1].name
-        else:
-            return None
+    ) -> Optional[T_str]:
+        partition_keys = self.get_partition_keys(current_time, dynamic_partitions_store)
+        return partition_keys[-1] if partition_keys else None
 
     def get_first_partition_key(
         self,
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> Optional[str]:
-        partitions = self.get_partitions(current_time, dynamic_partitions_store)
-        if partitions:
-            return partitions[0].name
-        else:
-            return None
+    ) -> Optional[T_str]:
+        partition_keys = self.get_partition_keys(current_time, dynamic_partitions_store)
+        return partition_keys[0] if partition_keys else None
 
     def get_partition_keys_in_range(
         self,
         partition_key_range: PartitionKeyRange,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> Sequence[str]:
+    ) -> Sequence[T_str]:
         partition_keys = self.get_partition_keys(dynamic_partitions_store=dynamic_partitions_store)
 
         keys_exist = {
             partition_key_range.start: partition_key_range.start in partition_keys,
             partition_key_range.end: partition_key_range.end in partition_keys,
         }
         if not all(keys_exist.values()):
@@ -283,31 +192,31 @@
         return partition_keys[
             partition_keys.index(partition_key_range.start) : partition_keys.index(
                 partition_key_range.end
             )
             + 1
         ]
 
-    def empty_subset(self) -> "PartitionsSubset[T_cov]":
+    def empty_subset(self) -> "PartitionsSubset[T_str]":
         return self.partitions_subset_class.empty_subset(self)
 
     def subset_with_partition_keys(
         self, partition_keys: Iterable[str]
-    ) -> "PartitionsSubset[T_cov]":
+    ) -> "PartitionsSubset[T_str]":
         return self.empty_subset().with_partition_keys(partition_keys)
 
     def subset_with_all_partitions(
         self,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> "PartitionsSubset[T_cov]":
+    ) -> "PartitionsSubset[T_str]":
         return self.subset_with_partition_keys(
             self.get_partition_keys(dynamic_partitions_store=dynamic_partitions_store)
         )
 
-    def deserialize_subset(self, serialized: str) -> "PartitionsSubset[T_cov]":
+    def deserialize_subset(self, serialized: str) -> "PartitionsSubset[T_str]":
         return self.partitions_subset_class.from_serialized(self, serialized)
 
     def can_deserialize_subset(
         self,
         serialized: str,
         serialized_partitions_def_unique_id: Optional[str],
         serialized_partitions_def_class_name: Optional[str],
@@ -346,14 +255,25 @@
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
     ) -> bool:
         return partition_key in self.get_partition_keys(
             current_time=current_time,
             dynamic_partitions_store=dynamic_partitions_store,
         )
 
+    def validate_partition_key(
+        self,
+        partition_key: str,
+        current_time: Optional[datetime] = None,
+        dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
+    ) -> None:
+        if not self.has_partition_key(partition_key, current_time, dynamic_partitions_store):
+            raise DagsterUnknownPartitionError(
+                f"Could not find a partition with key `{partition_key}`."
+            )
+
 
 def raise_error_on_invalid_partition_key_substring(partition_keys: Sequence[str]) -> None:
     for partition_key in partition_keys:
         found_invalid_substrs = [
             invalid_substr
             for invalid_substr in INVALID_PARTITION_SUBSTRINGS
             if invalid_substr in partition_key
@@ -383,183 +303,46 @@
 
     def __init__(self, partition_keys: Sequence[str]):
         check.sequence_param(partition_keys, "partition_keys", of_type=str)
 
         # TODO 1.3.0 enforce that partition keys are unique
         raise_error_on_invalid_partition_key_substring(partition_keys)
 
-        self._partitions = [Partition(key) for key in partition_keys]
+        self._partition_keys = partition_keys
 
-    def get_partitions(
+    @public
+    def get_partition_keys(
         self,
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> Sequence[Partition[str]]:
-        return self._partitions
+    ) -> Sequence[str]:
+        return self._partition_keys
 
     def __hash__(self):
         return hash(self.__repr__())
 
     def __eq__(self, other) -> bool:
         return isinstance(other, StaticPartitionsDefinition) and (
-            self is other or self._partitions == other.get_partitions()
+            self is other or self._partition_keys == other.get_partition_keys()
         )
 
     def __repr__(self) -> str:
-        return f"{type(self).__name__}(partition_keys={[p.name for p in self._partitions]})"
+        return f"{type(self).__name__}(partition_keys={self._partition_keys})"
 
     def get_num_partitions(
         self,
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
     ) -> int:
         # We don't currently throw an error when a duplicate partition key is defined
         # in a static partitions definition, though we will at 1.3.0.
         # This ensures that partition counts are correct in Dagit.
         return len(set(self.get_partition_keys(current_time, dynamic_partitions_store)))
 
 
-class ScheduleTimeBasedPartitionsDefinition(
-    PartitionsDefinition[datetime],
-    NamedTuple(
-        "_ScheduleTimeBasedPartitionsDefinition",
-        [
-            ("schedule_type", ScheduleType),
-            ("start", datetime),
-            ("execution_time", time),
-            ("execution_day", Optional[int]),
-            ("end", Optional[datetime]),
-            ("fmt", str),
-            ("timezone", str),
-            ("offset", int),
-        ],
-    ),
-):
-    """Computes the partitions backwards from the scheduled execution times."""
-
-    def __new__(
-        cls,
-        schedule_type: ScheduleType,
-        start: datetime,
-        execution_time: Optional[time] = None,
-        execution_day: Optional[int] = None,
-        end: Optional[datetime] = None,
-        fmt: Optional[str] = None,
-        timezone: Optional[str] = None,
-        offset: Optional[int] = None,
-    ):
-        if end is not None:
-            check.invariant(
-                start <= end,
-                f'Selected date range start "{start}" is after date range end "{end}"'.format(
-                    start=start.strftime(fmt) if fmt is not None else start,
-                    end=cast(datetime, end).strftime(fmt) if fmt is not None else end,
-                ),
-            )
-        if schedule_type in [ScheduleType.HOURLY, ScheduleType.DAILY]:
-            check.invariant(
-                not execution_day,
-                f'Execution day should not be provided for schedule type "{schedule_type}"',
-            )
-        elif schedule_type is ScheduleType.WEEKLY:
-            execution_day = execution_day if execution_day is not None else 0
-            check.invariant(
-                execution_day is not None and 0 <= execution_day <= 6,
-                (
-                    f'Execution day "{execution_day}" must be between 0 and 6 for '
-                    f'schedule type "{schedule_type}"'
-                ),
-            )
-        elif schedule_type is ScheduleType.MONTHLY:
-            execution_day = execution_day if execution_day is not None else 1
-            check.invariant(
-                execution_day is not None and 1 <= execution_day <= 31,
-                (
-                    f'Execution day "{execution_day}" must be between 1 and 31 for '
-                    f'schedule type "{schedule_type}"'
-                ),
-            )
-
-        return super(ScheduleTimeBasedPartitionsDefinition, cls).__new__(
-            cls,
-            check.inst_param(schedule_type, "schedule_type", ScheduleType),
-            check.inst_param(start, "start", datetime),
-            check.opt_inst_param(execution_time, "execution_time", time, time(0, 0)),
-            check.opt_int_param(
-                execution_day,
-                "execution_day",
-            ),
-            check.opt_inst_param(end, "end", datetime),
-            check.opt_str_param(fmt, "fmt", default=DEFAULT_DATE_FORMAT),
-            check.opt_str_param(timezone, "timezone", default="UTC"),
-            check.opt_int_param(offset, "offset", default=1),
-        )
-
-    def get_partitions(
-        self,
-        current_time: Optional[datetime] = None,
-        dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> Sequence[Partition[datetime]]:
-        check.opt_inst_param(current_time, "current_time", datetime)
-
-        return schedule_partition_range(
-            start=self.start,
-            end=self.end,
-            cron_schedule=self.get_cron_schedule(),
-            fmt=self.fmt,
-            timezone=self.timezone,
-            execution_time_to_partition_fn=self.get_execution_time_to_partition_fn(),
-            current_time=current_time,
-        )
-
-    def get_cron_schedule(self) -> str:
-        return cron_schedule_from_schedule_type_and_offsets(
-            schedule_type=self.schedule_type,
-            minute_offset=self.execution_time.minute,
-            hour_offset=self.execution_time.hour,
-            day_offset=self.execution_day,
-        )
-
-    def get_execution_time_to_partition_fn(self) -> Callable[[datetime], datetime]:
-        if self.schedule_type is ScheduleType.HOURLY:
-            # Using subtract(minutes=d.minute) here instead of .replace(minute=0) because on
-            # pendulum 1, replace(minute=0) sometimes changes the timezone:
-            # >>> a = create_pendulum_time(2021, 11, 7, 0, 0, tz="US/Central")
-            #
-            # >>> a.add(hours=1)
-            # <Pendulum [2021-11-07T01:00:00-05:00]>
-            # >>> a.add(hours=1).replace(minute=0)
-            # <Pendulum [2021-11-07T01:00:00-06:00]>
-            return lambda d: pendulum.instance(d).subtract(hours=self.offset, minutes=d.minute)
-        elif self.schedule_type is ScheduleType.DAILY:
-            return (
-                lambda d: pendulum.instance(d).replace(hour=0, minute=0).subtract(days=self.offset)
-            )
-        elif self.schedule_type is ScheduleType.WEEKLY:
-            execution_day = cast(int, self.execution_day)
-            day_difference = (execution_day - (self.start.weekday() + 1)) % 7
-            return (
-                lambda d: pendulum.instance(d)
-                .replace(hour=0, minute=0)
-                .subtract(
-                    weeks=self.offset,
-                    days=day_difference,
-                )
-            )
-        elif self.schedule_type is ScheduleType.MONTHLY:
-            execution_day = cast(int, self.execution_day)
-            return (
-                lambda d: pendulum.instance(d)
-                .replace(hour=0, minute=0)
-                .subtract(months=self.offset, days=execution_day - 1)
-            )
-        else:
-            check.assert_never(self.schedule_type)
-
-
 class CachingDynamicPartitionsLoader(DynamicPartitionsStore):
     """A batch loader that caches the partition keys for a given dynamic partitions definition,
     to avoid repeated calls to the database for the same partitions definition.
     """
 
     def __init__(self, instance: DagsterInstance):
         self._instance = instance
@@ -666,188 +449,215 @@
 
     def __str__(self) -> str:
         if self.name:
             return f'Dynamic partitions: "{self._validated_name()}"'
         else:
             return super().__str__()
 
-    def get_partitions(
+    @public
+    def get_partition_keys(
         self,
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> Sequence[Partition]:
+    ) -> Sequence[str]:
         if self.partition_fn:
             partitions = self.partition_fn(current_time)
             if all(isinstance(partition, Partition) for partition in partitions):
-                return cast(Sequence[Partition], partitions)
+                return [partition.name for partition in partitions]  # type: ignore  # (illegible conditional)
             else:
-                return [Partition(p) for p in partitions]
+                return partitions  # type: ignore  # (illegible conditional)
         else:
             check.opt_inst_param(
                 dynamic_partitions_store, "dynamic_partitions_store", DynamicPartitionsStore
             )
 
             if dynamic_partitions_store is None:
                 check.failed(
                     "The instance is not available to load partitions. You may be seeing this error"
                     " when using dynamic partitions with a version of dagit or dagster-cloud that"
                     " is older than 1.1.18."
                 )
 
-            partitions = dynamic_partitions_store.get_dynamic_partitions(
+            return dynamic_partitions_store.get_dynamic_partitions(
                 partitions_def_name=self._validated_name()
             )
-            return [Partition(key) for key in partitions]
 
     def has_partition_key(
         self,
         partition_key: str,
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
     ) -> bool:
-        if dynamic_partitions_store is None:
-            check.failed(
-                "The instance is not available to load partitions. You may be seeing this error"
-                " when using dynamic partitions with a version of dagit or dagster-cloud that"
-                " is older than 1.1.18."
-            )
+        if self.partition_fn:
+            return partition_key in self.get_partition_keys(current_time)
+        else:
+            if dynamic_partitions_store is None:
+                check.failed(
+                    "The instance is not available to load partitions. You may be seeing this error"
+                    " when using dynamic partitions with a version of dagit or dagster-cloud that"
+                    " is older than 1.1.18."
+                )
 
-        return dynamic_partitions_store.has_dynamic_partition(
-            partitions_def_name=self._validated_name(), partition_key=partition_key
-        )
+            return dynamic_partitions_store.has_dynamic_partition(
+                partitions_def_name=self._validated_name(), partition_key=partition_key
+            )
 
     def build_add_request(self, partition_keys: Sequence[str]) -> AddDynamicPartitionsRequest:
         check.sequence_param(partition_keys, "partition_keys", of_type=str)
         validated_name = self._validated_name()
         return AddDynamicPartitionsRequest(validated_name, partition_keys)
 
     def build_delete_request(self, partition_keys: Sequence[str]) -> DeleteDynamicPartitionsRequest:
         check.sequence_param(partition_keys, "partition_keys", of_type=str)
         validated_name = self._validated_name()
         return DeleteDynamicPartitionsRequest(validated_name, partition_keys)
 
 
-class PartitionedConfig(Generic[T_cov]):
+class PartitionedConfig(Generic[T_PartitionsDefinition]):
     """Defines a way of configuring a job where the job can be run on one of a discrete set of
     partitions, and each partition corresponds to run configuration for the job.
 
     Setting PartitionedConfig as the config for a job allows you to launch backfills for that job
     and view the run history across partitions.
     """
 
     def __init__(
         self,
-        partitions_def: PartitionsDefinition[T_cov],
-        run_config_for_partition_fn: Callable[[Partition[T_cov]], Mapping[str, Any]],
+        partitions_def: T_PartitionsDefinition,
+        run_config_for_partition_fn: Optional[Callable[[Partition], Mapping[str, Any]]] = None,
         decorated_fn: Optional[Callable[..., Mapping[str, Any]]] = None,
-        tags_for_partition_fn: Optional[Callable[[Partition[T_cov]], Mapping[str, str]]] = None,
+        tags_for_partition_fn: Optional[Callable[[Partition[Any]], Mapping[str, str]]] = None,
+        run_config_for_partition_key_fn: Optional[Callable[[str], Mapping[str, Any]]] = None,
+        tags_for_partition_key_fn: Optional[Callable[[str], Mapping[str, str]]] = None,
     ):
         self._partitions = check.inst_param(partitions_def, "partitions_def", PartitionsDefinition)
-        self._run_config_for_partition_fn = check.callable_param(
+        self._decorated_fn = decorated_fn
+
+        check.invariant(
+            xor(run_config_for_partition_fn, run_config_for_partition_key_fn),
+            (
+                "Must provide exactly one of run_config_for_partition_fn or"
+                " run_config_for_partition_key_fn"
+            ),
+        )
+        check.invariant(
+            not (tags_for_partition_fn and tags_for_partition_key_fn),
+            "Cannot provide both of tags_for_partition_fn or tags_for_partition_key_fn",
+        )
+        if run_config_for_partition_fn:
+            deprecation_warning(
+                "run_config_for_partition_fn", "2.0", "Use run_config_for_partition_key_fn instead"
+            )
+        if tags_for_partition_fn:
+            deprecation_warning(
+                "tags_for_partition_fn", "2.0", "Use tags_for_partition_key_fn instead"
+            )
+
+        self._run_config_for_partition_fn = check.opt_callable_param(
             run_config_for_partition_fn, "run_config_for_partition_fn"
         )
-        self._decorated_fn = decorated_fn
+        self._run_config_for_partition_key_fn = check.opt_callable_param(
+            run_config_for_partition_key_fn, "run_config_for_partition_key_fn"
+        )
         self._tags_for_partition_fn = check.opt_callable_param(
             tags_for_partition_fn, "tags_for_partition_fn"
         )
+        self._tags_for_partition_key_fn = check.opt_callable_param(
+            tags_for_partition_key_fn, "tags_for_partition_key_fn"
+        )
 
     @public
     @property
     def partitions_def(
         self,
-    ) -> PartitionsDefinition[T_cov]:
+    ) -> T_PartitionsDefinition:
         return self._partitions
 
+    @deprecated
     @public
     @property
-    def run_config_for_partition_fn(self) -> Callable[[Partition[T_cov]], Mapping[str, Any]]:
+    def run_config_for_partition_fn(
+        self,
+    ) -> Optional[Callable[[Partition], Mapping[str, Any]]]:
         return self._run_config_for_partition_fn
 
     @public
     @property
-    def tags_for_partition_fn(self) -> Optional[Callable[[Partition[T_cov]], Mapping[str, str]]]:
+    def run_config_for_partition_key_fn(
+        self,
+    ) -> Optional[Callable[[str], Mapping[str, Any]]]:
+        return self._run_config_for_partition_key_fn
+
+    @deprecated
+    @public
+    @property
+    def tags_for_partition_fn(self) -> Optional[Callable[[Partition], Mapping[str, str]]]:
         return self._tags_for_partition_fn
 
+    @public
+    @property
+    def tags_for_partition_key_fn(
+        self,
+    ) -> Optional[Callable[[str], Mapping[str, str]]]:
+        return self._tags_for_partition_key_fn
+
+    @public
     def get_partition_keys(self, current_time: Optional[datetime] = None) -> Sequence[str]:
-        return [partition.name for partition in self.partitions_def.get_partitions(current_time)]
+        return self.partitions_def.get_partition_keys(current_time)
 
+    # Assumes partition key already validated
     def get_run_config_for_partition_key(
         self,
         partition_key: str,
-        dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-        current_time: Optional[datetime] = None,
     ) -> Mapping[str, Any]:
         """Generates the run config corresponding to a partition key.
 
         Args:
             partition_key (str): the key for a partition that should be used to generate a run config.
         """
-        partition = self._key_to_partition(partition_key, current_time, dynamic_partitions_store)
-        return self.get_run_config_for_partition(partition)
-
-    def get_run_config_for_partition(
-        self,
-        partition: Partition,
-    ) -> Mapping[str, Any]:
-        """Generates the run config corresponding to a partition.
-
-        Args:
-            partition: the partition that should be used to generate a run config.
-        """
-        return copy.deepcopy(self.run_config_for_partition_fn(partition))
+        # _run_config_for_partition_fn is deprecated, we can remove this branching logic in 2.0
+        if self._run_config_for_partition_fn:
+            run_config = self._run_config_for_partition_fn(Partition(partition_key))
+        elif self._run_config_for_partition_key_fn:
+            run_config = self._run_config_for_partition_key_fn(partition_key)
+        else:
+            check.failed("Unreachable.")  # one of the above funcs always defined
+        return copy.deepcopy(run_config)
 
-    def get_tags_for_partition(
+    # Assumes partition key already validated
+    def get_tags_for_partition_key(
         self,
-        partition: Partition,
+        partition_key: str,
         job_name: Optional[str] = None,
     ) -> Mapping[str, str]:
         from dagster._core.host_representation.external_data import (
             external_partition_set_name_for_job_name,
         )
 
-        user_tags = (
-            validate_tags(self._tags_for_partition_fn(partition), allow_reserved_tags=False)
-            if self._tags_for_partition_fn
-            else {}
-        )
+        # _tags_for_partition_fn is deprecated, we can remove this branching logic in 2.0
+        if self._tags_for_partition_fn:
+            user_tags = self._tags_for_partition_fn(Partition(partition_key))
+        elif self._tags_for_partition_key_fn:
+            user_tags = self._tags_for_partition_key_fn(partition_key)
+        else:
+            user_tags = {}
+        user_tags = validate_tags(user_tags, allow_reserved_tags=False)
+
         system_tags = {
-            **self.partitions_def.get_tags_for_partition_key(partition.name),
+            **self.partitions_def.get_tags_for_partition_key(partition_key),
             **(
+                # `PartitionSetDefinition` has been deleted but we still need to attach this special tag in
+                # order for reexecution against partitions to work properly.
                 {PARTITION_SET_TAG: external_partition_set_name_for_job_name(job_name)}
                 if job_name
                 else {}
             ),
         }
-        # `PartitionSetDefinition` has been deleted but we still need to attach this special tag in
-        # order for reexecution against partitions to work properly.
-        return {**user_tags, **system_tags}
-
-    def get_tags_for_partition_key(
-        self,
-        partition_key: str,
-        dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-        current_time: Optional[datetime] = None,
-        job_name: Optional[str] = None,
-    ) -> Mapping[str, str]:
-        partition = self._key_to_partition(partition_key, current_time, dynamic_partitions_store)
-        return self.get_tags_for_partition(partition, job_name)
-
-    def _key_to_partition(
-        self,
-        partition_key: str,
-        current_time: Optional[datetime],
-        dynamic_partitions_store: Optional[DynamicPartitionsStore],
-    ) -> Partition[T_cov]:
-        partition = self.partitions_def.get_partition(
-            partition_key,
-            current_time=current_time,
-            dynamic_partitions_store=dynamic_partitions_store,
-        )
 
-        return partition
+        return {**user_tags, **system_tags}
 
     @classmethod
     def from_flexible_config(
         cls,
         config: Optional[Union[ConfigMapping, Mapping[str, object], "PartitionedConfig"]],
         partitions_def: PartitionsDefinition,
     ) -> "PartitionedConfig":
@@ -863,30 +673,34 @@
                     "Can't supply a PartitionedConfig for 'config' with a different "
                     "PartitionsDefinition than supplied for 'partitions_def'."
                 ),
             )
             return config
         else:
             hardcoded_config = config if config else {}
-            return cls(partitions_def, lambda _: cast(Mapping, hardcoded_config))
+            return cls(
+                partitions_def,
+                run_config_for_partition_key_fn=lambda _: cast(Mapping, hardcoded_config),
+            )
 
     def __call__(self, *args, **kwargs):
         if self._decorated_fn is None:
             raise DagsterInvalidInvocationError(
                 "Only PartitionedConfig objects created using one of the partitioned config "
                 "decorators can be directly invoked."
             )
         else:
             return self._decorated_fn(*args, **kwargs)
 
 
 def static_partitioned_config(
     partition_keys: Sequence[str],
     tags_for_partition_fn: Optional[Callable[[str], Mapping[str, str]]] = None,
-) -> Callable[[Callable[[str], Mapping[str, Any]]], PartitionedConfig]:
+    tags_for_partition_key_fn: Optional[Callable[[str], Mapping[str, str]]] = None,
+) -> Callable[[Callable[[str], Mapping[str, Any]]], PartitionedConfig[StaticPartitionsDefinition]]:
     """Creates a static partitioned config for a job.
 
     The provided partition_keys is a static list of strings identifying the set of partitions. The
     list of partitions is static, so while the run config returned by the decorated function may
     change over time, the list of valid partition keys does not.
 
     This has performance advantages over `dynamic_partitioned_config` in terms of loading different
@@ -894,45 +708,51 @@
 
     The decorated function takes in a partition key and returns a valid run config for a particular
     target job.
 
     Args:
         partition_keys (Sequence[str]): A list of valid partition keys, which serve as the range of
             values that can be provided to the decorated run config function.
-        tags_for_partition_fn (Optional[Callable[[str], Mapping[str, str]]]): A function that
+        tags_for_partition_fn (Optional[Callable[[str], Mapping[str, str]]]): (deprecated) A function that
+            accepts a partition key and returns a dictionary of tags to attach to runs for that
+            partition.
+        tags_for_partition_key_fn (Optional[Callable[[str], Mapping[str, str]]]): A function that
             accepts a partition key and returns a dictionary of tags to attach to runs for that
             partition.
 
     Returns:
         PartitionedConfig
     """
     check.sequence_param(partition_keys, "partition_keys", str)
 
-    def inner(fn: Callable[[str], Mapping[str, Any]]) -> PartitionedConfig:
-        check.callable_param(fn, "fn")
-
-        def _run_config_wrapper(partition: Partition) -> Mapping[str, Any]:
-            return fn(partition.name)
-
-        def _tag_wrapper(partition: Partition) -> Mapping[str, str]:
-            return tags_for_partition_fn(partition.name) if tags_for_partition_fn else {}
+    tags_for_partition_key_fn = canonicalize_backcompat_args(
+        tags_for_partition_key_fn,
+        "tags_for_partition_key_fn",
+        tags_for_partition_fn,
+        "tags_for_partition_fn",
+        "2.0",
+    )
 
+    def inner(
+        fn: Callable[[str], Mapping[str, Any]]
+    ) -> PartitionedConfig[StaticPartitionsDefinition]:
         return PartitionedConfig(
             partitions_def=StaticPartitionsDefinition(partition_keys),
-            run_config_for_partition_fn=_run_config_wrapper,
+            run_config_for_partition_key_fn=fn,
             decorated_fn=fn,
-            tags_for_partition_fn=_tag_wrapper,
+            tags_for_partition_key_fn=tags_for_partition_key_fn,
         )
 
     return inner
 
 
 def dynamic_partitioned_config(
     partition_fn: Callable[[Optional[datetime]], Sequence[str]],
     tags_for_partition_fn: Optional[Callable[[str], Mapping[str, str]]] = None,
+    tags_for_partition_key_fn: Optional[Callable[[str], Mapping[str, str]]] = None,
 ) -> Callable[[Callable[[str], Mapping[str, Any]]], PartitionedConfig]:
     """Creates a dynamic partitioned config for a job.
 
     The provided partition_fn returns a list of strings identifying the set of partitions, given
     an optional datetime argument (representing the current time).  The list of partitions returned
     may change over time.
 
@@ -948,26 +768,28 @@
             partition.
 
     Returns:
         PartitionedConfig
     """
     check.callable_param(partition_fn, "partition_fn")
 
-    def inner(fn: Callable[[str], Mapping[str, Any]]) -> PartitionedConfig:
-        def _run_config_wrapper(partition: Partition) -> Mapping[str, Any]:
-            return fn(partition.name)
-
-        def _tag_wrapper(partition: Partition) -> Mapping[str, str]:
-            return tags_for_partition_fn(partition.name) if tags_for_partition_fn else {}
+    tags_for_partition_key_fn = canonicalize_backcompat_args(
+        tags_for_partition_key_fn,
+        "tags_for_partition_key_fn",
+        tags_for_partition_fn,
+        "tags_for_partition_fn",
+        "2.0",
+    )
 
+    def inner(fn: Callable[[str], Mapping[str, Any]]) -> PartitionedConfig:
         return PartitionedConfig(
             partitions_def=DynamicPartitionsDefinition(partition_fn),
-            run_config_for_partition_fn=_run_config_wrapper,
+            run_config_for_partition_key_fn=fn,
             decorated_fn=fn,
-            tags_for_partition_fn=_tag_wrapper,
+            tags_for_partition_key_fn=tags_for_partition_key_fn,
         )
 
     return inner
 
 
 def cron_schedule_from_schedule_type_and_offsets(
     schedule_type: ScheduleType,
@@ -983,66 +805,67 @@
         return f"{minute_offset} {hour_offset} * * {day_offset if day_offset is not None else 0}"
     elif schedule_type is ScheduleType.MONTHLY:
         return f"{minute_offset} {hour_offset} {day_offset if day_offset is not None else 1} * *"
     else:
         check.assert_never(schedule_type)
 
 
-class PartitionsSubset(ABC, Generic[T_cov]):
+class PartitionsSubset(ABC, Generic[T_str]):
     """Represents a subset of the partitions within a PartitionsDefinition."""
 
     @abstractmethod
     def get_partition_keys_not_in_subset(
         self,
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> Iterable[str]:
+    ) -> Iterable[T_str]:
         ...
 
     @abstractmethod
-    def get_partition_keys(self, current_time: Optional[datetime] = None) -> Iterable[str]:
+    @public
+    def get_partition_keys(self, current_time: Optional[datetime] = None) -> Iterable[T_str]:
         ...
 
     @abstractmethod
     def get_partition_key_ranges(
         self,
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
     ) -> Sequence[PartitionKeyRange]:
         ...
 
     @abstractmethod
-    def with_partition_keys(self, partition_keys: Iterable[str]) -> "PartitionsSubset[T_cov]":
+    def with_partition_keys(self, partition_keys: Iterable[str]) -> "PartitionsSubset[T_str]":
         ...
 
     def with_partition_key_range(
         self,
         partition_key_range: PartitionKeyRange,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> "PartitionsSubset[T_cov]":
+    ) -> "PartitionsSubset[T_str]":
         return self.with_partition_keys(
             self.partitions_def.get_partition_keys_in_range(
                 partition_key_range, dynamic_partitions_store=dynamic_partitions_store
             )
         )
 
-    def __or__(self, other: "PartitionsSubset") -> "PartitionsSubset[T_cov]":
+    def __or__(self, other: "PartitionsSubset") -> "PartitionsSubset[T_str]":
         if self is other:
             return self
         return self.with_partition_keys(other.get_partition_keys())
 
     @abstractmethod
     def serialize(self) -> str:
         ...
 
     @classmethod
     @abstractmethod
     def from_serialized(
-        cls, partitions_def: PartitionsDefinition, serialized: str
-    ) -> "PartitionsSubset":
+        cls, partitions_def: PartitionsDefinition[T_str], serialized: str
+    ) -> "PartitionsSubset[T_str]":
         ...
 
     @classmethod
     @abstractmethod
     def can_deserialize(
         cls,
         partitions_def: PartitionsDefinition,
@@ -1050,38 +873,38 @@
         serialized_partitions_def_unique_id: Optional[str],
         serialized_partitions_def_class_name: Optional[str],
     ) -> bool:
         ...
 
     @property
     @abstractmethod
-    def partitions_def(self) -> PartitionsDefinition[T_cov]:
+    def partitions_def(self) -> PartitionsDefinition[T_str]:
         ...
 
     @abstractmethod
     def __len__(self) -> int:
         ...
 
     @abstractmethod
     def __contains__(self, value) -> bool:
         ...
 
     @classmethod
     @abstractmethod
-    def empty_subset(cls, partitions_def: PartitionsDefinition) -> "PartitionsSubset[T_cov]":
+    def empty_subset(cls, partitions_def: PartitionsDefinition[T_str]) -> "PartitionsSubset[T_str]":
         ...
 
 
-class DefaultPartitionsSubset(PartitionsSubset[T_cov]):
+class DefaultPartitionsSubset(PartitionsSubset[T_str]):
     # Every time we change the serialization format, we should increment the version number.
     # This will ensure that we can gracefully degrade when deserializing old data.
     SERIALIZATION_VERSION = 1
 
     def __init__(
-        self, partitions_def: PartitionsDefinition[T_cov], subset: Optional[Set[str]] = None
+        self, partitions_def: PartitionsDefinition[T_str], subset: Optional[Set[T_str]] = None
     ):
         check.opt_set_param(subset, "subset")
         self._partitions_def = partitions_def
         self._subset = subset or set()
 
     def get_partition_keys_not_in_subset(
         self,
@@ -1124,29 +947,29 @@
         if cur_range_start is not None and cur_range_end is not None:
             result.append(PartitionKeyRange(cur_range_start, cur_range_end))
 
         return result
 
     def with_partition_keys(
         self, partition_keys: Iterable[str]
-    ) -> "DefaultPartitionsSubset[T_cov]":
+    ) -> "DefaultPartitionsSubset[T_str]":
         return DefaultPartitionsSubset(
             self._partitions_def,
             self._subset | set(partition_keys),
         )
 
     def serialize(self) -> str:
         # Serialize version number, so attempting to deserialize old versions can be handled gracefully.
         # Any time the serialization format changes, we should increment the version number.
         return json.dumps({"version": self.SERIALIZATION_VERSION, "subset": list(self._subset)})
 
     @classmethod
     def from_serialized(
-        cls, partitions_def: PartitionsDefinition[T_cov], serialized: str
-    ) -> "PartitionsSubset[T_cov]":
+        cls, partitions_def: PartitionsDefinition[T_str], serialized: str
+    ) -> "PartitionsSubset[T_str]":
         # Check the version number, so only valid versions can be deserialized.
         data = json.loads(serialized)
 
         if isinstance(data, list):
             # backwards compatibility
             return cls(subset=set(data), partitions_def=partitions_def)
         else:
@@ -1156,29 +979,29 @@
                     f" but only version {cls.SERIALIZATION_VERSION} is supported."
                 )
             return cls(subset=set(data.get("subset")), partitions_def=partitions_def)
 
     @classmethod
     def can_deserialize(
         cls,
-        partitions_def: PartitionsDefinition[T_cov],
+        partitions_def: PartitionsDefinition[T_str],
         serialized: str,
         serialized_partitions_def_unique_id: Optional[str],
         serialized_partitions_def_class_name: Optional[str],
     ) -> bool:
         if serialized_partitions_def_class_name is not None:
             return serialized_partitions_def_class_name == partitions_def.__class__.__name__
 
         data = json.loads(serialized)
         return isinstance(data, list) or (
             data.get("subset") is not None and data.get("version") == cls.SERIALIZATION_VERSION
         )
 
     @property
-    def partitions_def(self) -> PartitionsDefinition[T_cov]:
+    def partitions_def(self) -> PartitionsDefinition[T_str]:
         return self._partitions_def
 
     def __eq__(self, other: object) -> bool:
         return (
             isinstance(other, DefaultPartitionsSubset)
             and self._partitions_def == other._partitions_def  # noqa: SLF001
             and self._subset == other._subset  # noqa: SLF001
@@ -1192,9 +1015,9 @@
 
     def __repr__(self) -> str:
         return (
             f"DefaultPartitionsSubset(subset={self._subset}, partitions_def={self._partitions_def})"
         )
 
     @classmethod
-    def empty_subset(cls, partitions_def: PartitionsDefinition[T_cov]) -> "PartitionsSubset[T_cov]":
+    def empty_subset(cls, partitions_def: PartitionsDefinition[T_str]) -> "PartitionsSubset[T_str]":
         return cls(partitions_def=partitions_def)
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/partition_mapping.py` & `dagster-1.3.3/dagster/_core/definitions/partition_mapping.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/partitioned_schedule.py` & `dagster-1.3.3/dagster/_core/definitions/partitioned_schedule.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/pipeline_base.py` & `dagster-1.3.3/dagster/_core/definitions/job_base.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,67 +8,67 @@
 from dagster._core.errors import DagsterInvalidSubsetError
 from dagster._core.selector import parse_solid_selection
 
 if TYPE_CHECKING:
     from .job_definition import JobDefinition
 
 
-class IPipeline(ABC):
-    """IPipeline is a wrapper interface for PipelineDefinitions to be used as parameters to Dagster's
-    core execution APIs.  This enables these execution APIs to operate on both in memory pipeline
-    definitions to be executed in the current process (InMemoryPipeline) as well as definitions that
-    can be reconstructed and executed in a different process (ReconstructablePipeline).
+class IJob(ABC):
+    """IJob is a wrapper interface for JobDefinitions to be used as parameters to Dagster's
+    core execution APIs.  This enables these execution APIs to operate on both in memory job
+    definitions to be executed in the current process (InMemoryJob) as well as definitions that
+    can be reconstructed and executed in a different process (ReconstructableJob).
     """
 
     @abstractmethod
     def get_definition(self) -> "JobDefinition":
         pass
 
     @abstractmethod
     def subset_for_execution(
         self,
         solid_selection: Optional[Sequence[str]] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
-    ) -> "IPipeline":
+    ) -> "IJob":
         pass
 
     @property
     @abstractmethod
     def solids_to_execute(self) -> Optional[AbstractSet[str]]:
         pass
 
     @property
     @abstractmethod
     def asset_selection(self) -> Optional[AbstractSet[AssetKey]]:
         pass
 
     @abstractmethod
-    def subset_for_execution_from_existing_pipeline(
+    def subset_for_execution_from_existing_job(
         self,
         solids_to_execute: Optional[AbstractSet[str]] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
-    ) -> "IPipeline":
+    ) -> "IJob":
         pass
 
 
-class InMemoryPipeline(IPipeline, object):
+class InMemoryJob(IJob, object):
     def __init__(
         self,
-        pipeline_def: "JobDefinition",
+        job_def: "JobDefinition",
         solid_selection: Optional[Sequence[str]] = None,
         solids_to_execute: Optional[AbstractSet[str]] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
     ):
-        self._pipeline_def = pipeline_def
+        self._job_def = job_def
         self._solid_selection = solid_selection
         self._solids_to_execute = solids_to_execute
         self._asset_selection = asset_selection
 
     def get_definition(self) -> "JobDefinition":
-        return self._pipeline_def
+        return self._job_def
 
     def _resolve_op_selection(self, op_selection: Sequence[str]) -> AbstractSet[str]:
         # resolve a list of op selection queries to a frozenset of qualified op names
         # e.g. ['foo_op+'] to {'foo_op', 'bar_op'}
         check.list_param(op_selection, "op_selection", of_type=str)
         solids_to_execute = parse_solid_selection(self.get_definition(), op_selection)
         if len(solids_to_execute) == 0:
@@ -80,29 +80,27 @@
     def _subset_for_execution(
         self,
         solids_to_execute: Optional[AbstractSet[str]],
         solid_selection: Optional[Sequence[str]] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
     ) -> Self:
         if asset_selection:
-            return InMemoryPipeline(
-                self._pipeline_def.get_job_def_for_subset_selection(
-                    asset_selection=asset_selection
-                ),
+            return InMemoryJob(
+                self._job_def.get_job_def_for_subset_selection(asset_selection=asset_selection),
                 asset_selection=asset_selection,
             )
-        if self._pipeline_def.is_subset_pipeline:
-            return InMemoryPipeline(
-                self._pipeline_def.parent_pipeline_def.get_pipeline_subset_def(solids_to_execute),  # type: ignore  # (possible none)
+        if self._job_def.is_subset_job:
+            return InMemoryJob(
+                self._job_def.parent_job_def.get_pipeline_subset_def(solids_to_execute),  # type: ignore  # (possible none)
                 solid_selection=solid_selection,
                 solids_to_execute=solids_to_execute,
             )
 
-        return InMemoryPipeline(
-            self._pipeline_def.get_pipeline_subset_def(solids_to_execute),  # type: ignore  # (possible none)
+        return InMemoryJob(
+            self._job_def.get_pipeline_subset_def(solids_to_execute),  # type: ignore  # (possible none)
             solid_selection=solid_selection,
             solids_to_execute=solids_to_execute,
         )
 
     def subset_for_execution(
         self,
         solid_selection: Optional[Sequence[str]] = None,
@@ -116,20 +114,20 @@
             not (solid_selection and asset_selection),
             "solid_selection and asset_selection cannot both be provided as arguments",
         )
 
         solids_to_execute = self._resolve_op_selection(solid_selection) if solid_selection else None
         return self._subset_for_execution(solids_to_execute, solid_selection, asset_selection)
 
-    def subset_for_execution_from_existing_pipeline(
+    def subset_for_execution_from_existing_job(
         self,
         solids_to_execute: Optional[AbstractSet[str]] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
     ) -> Self:
-        # take a frozenset of resolved solid names from an existing pipeline run
+        # take a frozenset of resolved solid names from an existing run
         # so there's no need to parse the selection
         check.opt_set_param(solids_to_execute, "solids_to_execute", of_type=str)
         check.opt_set_param(asset_selection, "asset_selection", of_type=AssetKey)
 
         check.invariant(
             not (solids_to_execute and asset_selection),
             "solids_to_execute and asset_selection cannot both be provided as arguments",
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/policy.py` & `dagster-1.3.3/dagster/_core/definitions/policy.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/reconstruct.py` & `dagster-1.3.3/dagster/_core/definitions/reconstruct.py`

 * *Files 9% similar despite different names*

```diff
@@ -31,39 +31,40 @@
     FileCodePointer,
     ModuleCodePointer,
     get_python_file_from_target,
 )
 from dagster._core.errors import DagsterInvariantViolationError
 from dagster._core.origin import (
     DEFAULT_DAGSTER_ENTRY_POINT,
-    PipelinePythonOrigin,
+    JobPythonOrigin,
     RepositoryPythonOrigin,
 )
 from dagster._core.selector import parse_solid_selection
 from dagster._serdes import pack_value, unpack_value, whitelist_for_serdes
 from dagster._utils import hash_collection
 
 from .events import AssetKey
-from .pipeline_base import IPipeline
+from .job_base import IJob
 
 if TYPE_CHECKING:
+    from dagster._core.definitions.assets import AssetsDefinition
     from dagster._core.definitions.job_definition import JobDefinition
     from dagster._core.definitions.repository_definition import (
         PendingRepositoryDefinition,
         RepositoryLoadData,
     )
+    from dagster._core.definitions.source_asset import SourceAsset
 
-    from .asset_group import AssetGroup
     from .graph_definition import GraphDefinition
     from .repository_definition import RepositoryDefinition
 
 
-def get_ephemeral_repository_name(pipeline_name: str) -> str:
-    check.str_param(pipeline_name, "pipeline_name")
-    return f"__repository__{pipeline_name}"
+def get_ephemeral_repository_name(job_name: str) -> str:
+    check.str_param(job_name, "job_name")
+    return f"__repository__{job_name}"
 
 
 @whitelist_for_serdes
 class ReconstructableRepository(
     NamedTuple(
         "_ReconstructableRepository",
         [
@@ -111,16 +112,16 @@
         self, metadata: Optional["RepositoryLoadData"]
     ) -> "ReconstructableRepository":
         return self._replace(repository_load_data=metadata)
 
     def get_definition(self) -> "RepositoryDefinition":
         return repository_def_from_pointer(self.pointer, self.repository_load_data)
 
-    def get_reconstructable_pipeline(self, name: str) -> ReconstructablePipeline:
-        return ReconstructablePipeline(self, name)
+    def get_reconstructable_job(self, name: str) -> ReconstructableJob:
+        return ReconstructableJob(self, name)
 
     @classmethod
     def for_file(
         cls,
         file: str,
         fn_name: str,
         working_directory: Optional[str] = None,
@@ -159,168 +160,173 @@
             container_context=self.container_context,
         )
 
     def get_python_origin_id(self) -> str:
         return self.get_python_origin().get_id()
 
     # Allow this to be hashed for use in `lru_cache`. This is needed because:
-    # - `ReconstructablePipeline` uses `lru_cache`
-    # - `ReconstructablePipeline` has a `ReconstructableRepository` attribute
+    # - `ReconstructableJob` uses `lru_cache`
+    # - `ReconstructableJob` has a `ReconstructableRepository` attribute
     # - `ReconstructableRepository` has `Sequence` attributes that are unhashable by default
     def __hash__(self) -> int:
         if not hasattr(self, "_hash"):
             self._hash = hash_collection(self)
         return self._hash
 
 
-@whitelist_for_serdes
-class ReconstructablePipeline(
+@whitelist_for_serdes(
+    storage_name="ReconstructablePipeline",
+    storage_field_names={
+        "job_name": "pipeline_name",
+    },
+)
+class ReconstructableJob(
     NamedTuple(
-        "_ReconstructablePipeline",
+        "_ReconstructableJob",
         [
             ("repository", ReconstructableRepository),
-            ("pipeline_name", str),
+            ("job_name", str),
             ("solid_selection_str", Optional[str]),
             ("solids_to_execute", Optional[AbstractSet[str]]),
             ("asset_selection", Optional[AbstractSet[AssetKey]]),
         ],
     ),
-    IPipeline,
+    IJob,
 ):
-    """Defines a reconstructable pipeline. When your pipeline/job must cross process boundaries,
-    Dagster must know how to reconstruct the pipeline/job on the other side of the process boundary.
+    """Defines a reconstructable job. When your job must cross process boundaries, Dagster must know
+    how to reconstruct the job on the other side of the process boundary.
 
     Args:
         repository (ReconstructableRepository): The reconstructable representation of the repository
-            the pipeline/job belongs to.
-        pipeline_name (str): The name of the pipeline/job.
+            the job belongs to.
+        job_name (str): The name of the job.
         solid_selection_str (Optional[str]): The string value of a comma separated list of user-input
-            solid/op selection. None if no selection is specified, i.e. the entire pipeline/job will
+            op selection. None if no selection is specified, i.e. the entire job will
             be run.
-        solids_to_execute (Optional[FrozenSet[str]]): A set of solid/op names to execute. None if no selection
-            is specified, i.e. the entire pipeline/job will be run.
+        solids_to_execute (Optional[FrozenSet[str]]): A set of op names to execute. None if no selection
+            is specified, i.e. the entire job will be run.
         asset_selection (Optional[FrozenSet[AssetKey]]) A set of assets to execute. None if no selection
             is specified, i.e. the entire job will be run.
     """
 
     def __new__(
         cls,
         repository: ReconstructableRepository,
-        pipeline_name: str,
+        job_name: str,
         solid_selection_str: Optional[str] = None,
         solids_to_execute: Optional[AbstractSet[str]] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
     ):
         check.opt_set_param(solids_to_execute, "solids_to_execute", of_type=str)
         check.opt_set_param(asset_selection, "asset_selection", AssetKey)
-        return super(ReconstructablePipeline, cls).__new__(
+        return super(ReconstructableJob, cls).__new__(
             cls,
             repository=check.inst_param(repository, "repository", ReconstructableRepository),
-            pipeline_name=check.str_param(pipeline_name, "pipeline_name"),
+            job_name=check.str_param(job_name, "job_name"),
             solid_selection_str=check.opt_str_param(solid_selection_str, "solid_selection_str"),
             solids_to_execute=solids_to_execute,
             asset_selection=asset_selection,
         )
 
     def with_repository_load_data(
         self, metadata: Optional["RepositoryLoadData"]
-    ) -> ReconstructablePipeline:
+    ) -> ReconstructableJob:
         return self._replace(repository=self.repository.with_repository_load_data(metadata))
 
     @property
     def solid_selection(self) -> Optional[Sequence[str]]:
         return seven.json.loads(self.solid_selection_str) if self.solid_selection_str else None
 
     # Keep the most recent 1 definition (globally since this is a NamedTuple method)
     # This allows repeated calls to get_definition in execution paths to not reload the job
     @lru_cache(maxsize=1)
     def get_definition(self) -> Union[JobDefinition, "JobDefinition"]:
         return self.repository.get_definition().get_maybe_subset_job_def(
-            self.pipeline_name,
+            self.job_name,
             self.solid_selection,
             self.asset_selection,
             self.solids_to_execute,
         )
 
     def get_reconstructable_repository(self) -> ReconstructableRepository:
         return self.repository
 
     def _subset_for_execution(
         self,
         solids_to_execute: Optional[AbstractSet[str]],
         solid_selection: Optional[Sequence[str]],
         asset_selection: Optional[AbstractSet[AssetKey]],
-    ) -> "ReconstructablePipeline":
+    ) -> "ReconstructableJob":
         # no selection
         if solid_selection is None and solids_to_execute is None and asset_selection is None:
-            return ReconstructablePipeline(
+            return ReconstructableJob(
                 repository=self.repository,
-                pipeline_name=self.pipeline_name,
+                job_name=self.job_name,
             )
 
         from dagster._core.definitions import JobDefinition
 
-        pipeline_def = self.get_definition()
-        if isinstance(pipeline_def, JobDefinition):
+        job_def = self.get_definition()
+        if isinstance(job_def, JobDefinition):
             # jobs use pre-resolved selection
             # when subselecting a job
             # * job subselection depend on solid_selection rather than solids_to_execute
             # * we'll resolve the op selection later in the stack
             if solid_selection is None:
                 # when the pre-resolution info is unavailable (e.g. subset from existing run),
                 # we need to fill the solid_selection in order to pass the value down to deeper stack.
                 solid_selection = list(solids_to_execute) if solids_to_execute else None
-            return ReconstructablePipeline(
+            return ReconstructableJob(
                 repository=self.repository,
-                pipeline_name=self.pipeline_name,
+                job_name=self.job_name,
                 solid_selection_str=seven.json.dumps(solid_selection) if solid_selection else None,
                 solids_to_execute=None,
                 asset_selection=asset_selection,
             )
-        elif isinstance(pipeline_def, JobDefinition):
-            # when subselecting a pipeline
-            # * pipeline subselection depend on solids_to_excute rather than solid_selection
+        elif isinstance(job_def, JobDefinition):
+            # when subselecting a job
+            # * job subselection depend on solids_to_excute rather than solid_selection
             # * we resolve a list of solid selection queries to a frozenset of qualified solid names
             #   e.g. ['foo_solid+'] to {'foo_solid', 'bar_solid'}
             if solid_selection and solids_to_execute is None:
                 # when post-resolution query is unavailable, resolve the query
-                solids_to_execute = parse_solid_selection(pipeline_def, solid_selection)
-            return ReconstructablePipeline(
+                solids_to_execute = parse_solid_selection(job_def, solid_selection)
+            return ReconstructableJob(
                 repository=self.repository,
-                pipeline_name=self.pipeline_name,
+                job_name=self.job_name,
                 solid_selection_str=seven.json.dumps(solid_selection) if solid_selection else None,
                 solids_to_execute=frozenset(solids_to_execute) if solids_to_execute else None,
             )
         else:
-            raise Exception(f"Unexpected pipeline/job type {pipeline_def.__class__.__name__}")
+            raise Exception(f"Unexpected job type {job_def.__class__.__name__}")
 
     def subset_for_execution(
         self,
         solid_selection: Optional[Sequence[str]] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
-    ) -> "ReconstructablePipeline":
+    ) -> "ReconstructableJob":
         # take a list of unresolved selection queries
         check.opt_sequence_param(solid_selection, "solid_selection", of_type=str)
         check.opt_set_param(asset_selection, "asset_selection", of_type=AssetKey)
 
         check.invariant(
             not (solid_selection and asset_selection),
             "solid_selection and asset_selection cannot both be provided as arguments",
         )
 
         return self._subset_for_execution(
             solids_to_execute=None, solid_selection=solid_selection, asset_selection=asset_selection
         )
 
-    def subset_for_execution_from_existing_pipeline(
+    def subset_for_execution_from_existing_job(
         self,
         solids_to_execute: Optional[AbstractSet[str]] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
-    ) -> ReconstructablePipeline:
-        # take a frozenset of resolved solid names from an existing pipeline
+    ) -> ReconstructableJob:
+        # take a frozenset of resolved solid names from an existing job
         # so there's no need to parse the selection
 
         check.invariant(
             not (solids_to_execute and asset_selection),
             "solids_to_execute and asset_selection cannot both be provided as arguments",
         )
 
@@ -331,68 +337,63 @@
             solids_to_execute=solids_to_execute,
             solid_selection=None,
             asset_selection=asset_selection,
         )
 
     def describe(self) -> str:
         return '"{name}" in repository ({repo})'.format(
-            repo=self.repository.pointer.describe, name=self.pipeline_name
+            repo=self.repository.pointer.describe, name=self.job_name
         )
 
     @staticmethod
-    def for_file(python_file: str, fn_name: str) -> ReconstructablePipeline:
-        return bootstrap_standalone_recon_pipeline(
-            FileCodePointer(python_file, fn_name, os.getcwd())
-        )
+    def for_file(python_file: str, fn_name: str) -> ReconstructableJob:
+        return bootstrap_standalone_recon_job(FileCodePointer(python_file, fn_name, os.getcwd()))
 
     @staticmethod
-    def for_module(module: str, fn_name: str) -> ReconstructablePipeline:
-        return bootstrap_standalone_recon_pipeline(ModuleCodePointer(module, fn_name, os.getcwd()))
+    def for_module(module: str, fn_name: str) -> ReconstructableJob:
+        return bootstrap_standalone_recon_job(ModuleCodePointer(module, fn_name, os.getcwd()))
 
     def to_dict(self) -> Mapping[str, object]:
         return pack_value(self)
 
     @staticmethod
-    def from_dict(val: Mapping[str, Any]) -> ReconstructablePipeline:
+    def from_dict(val: Mapping[str, Any]) -> ReconstructableJob:
         check.mapping_param(val, "val")
 
         inst = unpack_value(val)
         check.invariant(
-            isinstance(inst, ReconstructablePipeline),
-            "Deserialized object is not instance of ReconstructablePipeline, got {type}".format(
+            isinstance(inst, ReconstructableJob),
+            "Deserialized object is not instance of ReconstructableJob, got {type}".format(
                 type=type(inst)
             ),
         )
         return inst  # type: ignore  # (illegible runtime check)
 
-    def get_python_origin(self) -> PipelinePythonOrigin:
-        return PipelinePythonOrigin(self.pipeline_name, self.repository.get_python_origin())
+    def get_python_origin(self) -> JobPythonOrigin:
+        return JobPythonOrigin(self.job_name, self.repository.get_python_origin())
 
     def get_python_origin_id(self) -> str:
         return self.get_python_origin().get_id()
 
     def get_module(self) -> Optional[str]:
-        """Return the module the pipeline is found in, the origin is a module code pointer."""
+        """Return the module the job is found in, the origin is a module code pointer."""
         pointer = self.get_python_origin().get_repo_pointer()
         if isinstance(pointer, ModuleCodePointer):
             return pointer.module
 
         return None
 
 
-ReconstructableJob = ReconstructablePipeline
-
-
-def reconstructable(target: Callable[..., "JobDefinition"]) -> ReconstructablePipeline:
-    """Create a :py:class:`~dagster._core.definitions.reconstructable.ReconstructablePipeline` from a
-    function that returns a :py:class:`~dagster.PipelineDefinition`/:py:class:`~dagster.JobDefinition`,
+def reconstructable(target: Callable[..., "JobDefinition"]) -> ReconstructableJob:
+    """Create a :py:class:`~dagster._core.definitions.reconstructable.ReconstructableJob` from a
+    function that returns a :py:class:`~dagster.JobDefinition`/:py:class:`~dagster.JobDefinition`,
     or a function decorated with :py:func:`@job <dagster.job>`.
 
-    When your pipeline/job must cross process boundaries, e.g., for execution on multiple nodes or
-    in different systems (like ``dagstermill``), Dagster must know how to reconstruct the pipeline/job
+    When your job must cross process boundaries, e.g., for execution on multiple nodes or
+    in different systems (like ``dagstermill``), Dagster must know how to reconstruct the job
     on the other side of the process boundary.
 
     Passing a job created with ``~dagster.GraphDefinition.to_job`` to ``reconstructable()``,
     requires you to wrap that job's definition in a module-scoped function, and pass that function
     instead:
 
     .. code-block:: python
@@ -405,15 +406,15 @@
 
         def define_my_job():
             return my_graph.to_job()
 
         reconstructable(define_my_job)
 
     This function implements a very conservative strategy for reconstruction, so that its behavior
-    is easy to predict, but as a consequence it is not able to reconstruct certain kinds of pipelines
+    is easy to predict, but as a consequence it is not able to reconstruct certain kinds of jobs
     or jobs, such as those defined by lambdas, in nested scopes (e.g., dynamically within a method
     call), or in interactive environments such as the Python REPL or Jupyter notebooks.
 
     If you need to reconstruct objects constructed in these ways, you should use
     :py:func:`~dagster.reconstructable.build_reconstructable_job` instead, which allows you to
     specify your own reconstruction strategy.
 
@@ -474,42 +475,42 @@
 
     try:
         if (
             hasattr(target, "__module__")
             and hasattr(target, "__name__")
             and getattr(inspect.getmodule(target), "__name__", None) != "__main__"
         ):
-            return ReconstructablePipeline.for_module(target.__module__, target.__name__)
+            return ReconstructableJob.for_module(target.__module__, target.__name__)
     except:
         pass
 
     python_file = get_python_file_from_target(target)
     if not python_file:
         raise DagsterInvariantViolationError(
-            "reconstructable() can not reconstruct jobs or pipelines defined in interactive "
+            "reconstructable() can not reconstruct jobs defined in interactive "
             "environments like <stdin>, IPython, or Jupyter notebooks. "
-            "Use a pipeline defined in a module or file instead, or use build_reconstructable_job."
+            "Use a job defined in a module or file instead, or use build_reconstructable_job."
         )
 
     pointer = FileCodePointer(
         python_file=python_file, fn_name=target.__name__, working_directory=os.getcwd()
     )
 
-    return bootstrap_standalone_recon_pipeline(pointer)
+    return bootstrap_standalone_recon_job(pointer)
 
 
 @experimental
 def build_reconstructable_job(
     reconstructor_module_name: str,
     reconstructor_function_name: str,
     reconstructable_args: Optional[Tuple[object]] = None,
     reconstructable_kwargs: Optional[Mapping[str, object]] = None,
     reconstructor_working_directory: Optional[str] = None,
-) -> ReconstructablePipeline:
-    """Create a :py:class:`dagster._core.definitions.reconstructable.ReconstructablePipeline`.
+) -> ReconstructableJob:
+    """Create a :py:class:`dagster._core.definitions.reconstructable.ReconstructableJob`.
 
     When your job must cross process boundaries, e.g., for execution on multiple nodes or in
     different systems (like ``dagstermill``), Dagster must know how to reconstruct the job
     on the other side of the process boundary.
 
     This function allows you to use the strategy of your choice for reconstructing jobs, so
     that you can reconstruct certain kinds of jobs that are not supported by
@@ -587,71 +588,77 @@
         reconstructor_module_name,
         reconstructor_function_name,
         working_directory=reconstructor_working_directory,
     )
 
     pointer = CustomPointer(reconstructor_pointer, _reconstructable_args, _reconstructable_kwargs)
 
-    pipeline_def = pipeline_def_from_pointer(pointer)
+    job_def = job_def_from_pointer(pointer)
 
-    return ReconstructablePipeline(
+    return ReconstructableJob(
         repository=ReconstructableRepository(pointer),  # creates ephemeral repo
-        pipeline_name=pipeline_def.name,
+        job_name=job_def.name,
     )
 
 
-# back compat, in case users have imported these directly
-build_reconstructable_pipeline = build_reconstructable_job
-build_reconstructable_target = build_reconstructable_job
-
-
-def bootstrap_standalone_recon_pipeline(pointer: CodePointer) -> ReconstructablePipeline:
-    # So this actually straps the the pipeline for the sole
-    # purpose of getting the pipeline name. If we changed ReconstructablePipeline
-    # to get the pipeline on demand in order to get name, we could avoid this.
-    pipeline_def = pipeline_def_from_pointer(pointer)
-    return ReconstructablePipeline(
+def bootstrap_standalone_recon_job(pointer: CodePointer) -> ReconstructableJob:
+    # So this actually straps the the job for the sole
+    # purpose of getting the job name. If we changed ReconstructableJob
+    # to get the job on demand in order to get name, we could avoid this.
+    job_def = job_def_from_pointer(pointer)
+    return ReconstructableJob(
         repository=ReconstructableRepository(pointer),  # creates ephemeral repo
-        pipeline_name=pipeline_def.name,
+        job_name=job_def.name,
     )
 
 
 LoadableDefinition: TypeAlias = Union[
     "JobDefinition",
     "RepositoryDefinition",
     "PendingRepositoryDefinition",
     "GraphDefinition",
-    "AssetGroup",
+    "Sequence[Union[AssetsDefinition, SourceAsset]]",
 ]
 
 T_LoadableDefinition = TypeVar("T_LoadableDefinition", bound=LoadableDefinition)
 
 
-def _check_is_loadable(definition: T_LoadableDefinition) -> T_LoadableDefinition:
-    from dagster._core.definitions import AssetGroup
+def _is_list_of_assets(
+    definition: LoadableDefinition,
+) -> bool:
+    from dagster._core.definitions.assets import AssetsDefinition
+    from dagster._core.definitions.source_asset import SourceAsset
+
+    return isinstance(definition, list) and all(
+        isinstance(item, (AssetsDefinition, SourceAsset)) for item in definition
+    )
+
 
+def _check_is_loadable(definition: T_LoadableDefinition) -> T_LoadableDefinition:
     from .definitions_class import Definitions
     from .graph_definition import GraphDefinition
     from .job_definition import JobDefinition
     from .repository_definition import PendingRepositoryDefinition, RepositoryDefinition
 
-    if not isinstance(
-        definition,
-        (
-            JobDefinition,
-            RepositoryDefinition,
-            PendingRepositoryDefinition,
-            GraphDefinition,
-            AssetGroup,
-            Definitions,
-        ),
+    if not (
+        isinstance(
+            definition,
+            (
+                JobDefinition,
+                RepositoryDefinition,
+                PendingRepositoryDefinition,
+                GraphDefinition,
+                Definitions,
+            ),
+        )
+        or _is_list_of_assets(definition)
     ):
         raise DagsterInvariantViolationError(
             "Loadable attributes must be either a JobDefinition, GraphDefinition, "
-            f"PipelineDefinition, AssetGroup, or RepositoryDefinition. Got {repr(definition)}."
+            f"or RepositoryDefinition. Got {repr(definition)}."
         )
     return definition
 
 
 def load_def_in_module(
     module_name: str, attribute: str, working_directory: Optional[str]
 ) -> LoadableDefinition:
@@ -673,24 +680,21 @@
 
 
 def def_from_pointer(
     pointer: CodePointer,
 ) -> LoadableDefinition:
     target = pointer.load_target()
 
-    from dagster._core.definitions import AssetGroup
-
     from .graph_definition import GraphDefinition
     from .job_definition import JobDefinition
     from .repository_definition import PendingRepositoryDefinition, RepositoryDefinition
 
     if isinstance(
         target,
         (
-            AssetGroup,
             GraphDefinition,
             JobDefinition,
             PendingRepositoryDefinition,
             RepositoryDefinition,
         ),
     ) or not callable(target):
         return _check_is_loadable(target)  # type: ignore
@@ -705,32 +709,31 @@
                 target=pointer.describe()
             )
         )
 
     return _check_is_loadable(target())
 
 
-def pipeline_def_from_pointer(pointer: CodePointer) -> "JobDefinition":
+def job_def_from_pointer(pointer: CodePointer) -> "JobDefinition":
     from .job_definition import JobDefinition
 
     target = def_from_pointer(pointer)
 
     if isinstance(target, JobDefinition):
         return target
 
     raise DagsterInvariantViolationError(
-        "CodePointer ({str}) must resolve to a JobDefinition (or PipelineDefinition for legacy"
+        "CodePointer ({str}) must resolve to a JobDefinition (or JobDefinition for legacy"
         " code). Received a {type}".format(str=pointer.describe(), type=type(target))
     )
 
 
 @overload
-# NOTE: mypy can't handle these overloads but pyright can
 def repository_def_from_target_def(
-    target: Union["RepositoryDefinition", "JobDefinition", "GraphDefinition", "AssetGroup"],
+    target: Union["RepositoryDefinition", "JobDefinition", "GraphDefinition"],
     repository_load_data: Optional["RepositoryLoadData"] = None,
 ) -> "RepositoryDefinition":
     ...
 
 
 @overload
 def repository_def_from_target_def(
@@ -738,41 +741,43 @@
 ) -> None:
     ...
 
 
 def repository_def_from_target_def(
     target: object, repository_load_data: Optional["RepositoryLoadData"] = None
 ) -> Optional["RepositoryDefinition"]:
-    from dagster._core.definitions import AssetGroup
-
+    from .assets import AssetsDefinition
     from .definitions_class import Definitions
     from .graph_definition import GraphDefinition
     from .job_definition import JobDefinition
     from .repository_definition import (
         SINGLETON_REPOSITORY_NAME,
         CachingRepositoryData,
         PendingRepositoryDefinition,
         RepositoryDefinition,
     )
+    from .source_asset import SourceAsset
 
     if isinstance(target, Definitions):
         # reassign to handle both repository and pending repo case
         target = target.get_inner_repository_for_loading_process()
 
-    # special case - we can wrap a single pipeline in a repository
+    # special case - we can wrap a single job in a repository
     if isinstance(target, (JobDefinition, GraphDefinition)):
-        # consider including pipeline name in generated repo name
+        # consider including job name in generated repo name
         return RepositoryDefinition(
             name=get_ephemeral_repository_name(target.name),
             repository_data=CachingRepositoryData.from_list([target]),
         )
-    elif isinstance(target, AssetGroup):
+    elif isinstance(target, list) and all(
+        isinstance(item, (AssetsDefinition, SourceAsset)) for item in target
+    ):
         return RepositoryDefinition(
             name=SINGLETON_REPOSITORY_NAME,
-            repository_data=CachingRepositoryData.from_list([target]),
+            repository_data=CachingRepositoryData.from_list(target),
         )
     elif isinstance(target, RepositoryDefinition):
         return target
     elif isinstance(target, PendingRepositoryDefinition):
         # must load repository from scratch
         if repository_load_data is None:
             return target.compute_repository_definition()
@@ -786,11 +791,11 @@
     pointer: CodePointer, repository_load_data: Optional["RepositoryLoadData"] = None
 ) -> "RepositoryDefinition":
     target = def_from_pointer(pointer)
     repo_def = repository_def_from_target_def(target, repository_load_data)
     if not repo_def:
         raise DagsterInvariantViolationError(
             "CodePointer ({str}) must resolve to a "
-            "RepositoryDefinition, JobDefinition, or PipelineDefinition. "
+            "RepositoryDefinition, JobDefinition, or JobDefinition. "
             "Received a {type}".format(str=pointer.describe(), type=type(target))
         )
     return repo_def
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/repository_definition/__init__.py` & `dagster-1.3.3/dagster/_core/definitions/repository_definition/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/repository_definition/caching_index.py` & `dagster-1.3.3/dagster/_core/definitions/repository_definition/caching_index.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/repository_definition/repository_data.py` & `dagster-1.3.3/dagster/_core/definitions/repository_definition/repository_data.py`

 * *Files 0% similar despite different names*

```diff
@@ -116,15 +116,15 @@
         return [schedule.name for schedule in self.get_all_schedules()]
 
     @public
     def get_all_schedules(self) -> Sequence[ScheduleDefinition]:
         """Return all schedules in the repository as a list.
 
         Returns:
-            List[ScheduleDefinition]: All pipelines in the repository.
+            List[ScheduleDefinition]: All jobs in the repository.
         """
         return []
 
     @public
     def get_schedule(self, schedule_name: str) -> ScheduleDefinition:
         """Get a schedule by name.
 
@@ -318,17 +318,16 @@
         default_logger_defs: Optional[Mapping[str, LoggerDefinition]] = None,
         top_level_resources: Optional[Mapping[str, ResourceDefinition]] = None,
         resource_key_mapping: Optional[Mapping[int, str]] = None,
     ) -> "CachingRepositoryData":
         """Static constructor.
 
         Args:
-            repository_definitions (List[Union[PipelineDefinition, ScheduleDefinition, SensorDefinition, AssetGroup, GraphDefinition]]):
-                Use this constructor when you have no need to lazy load jobs or other
-                definitions.
+            repository_definitions (List[Union[JobDefinition, ScheduleDefinition, SensorDefinition, GraphDefinition]]):
+                Use this constructor when you have no need to lazy load jobs or other definitions.
             top_level_resources (Optional[Mapping[str, ResourceDefinition]]): A dict of top-level
                 resource keys to defintions, for resources which should be displayed in the UI.
         """
         from .repository_data_builder import build_caching_repository_data_from_list
 
         return build_caching_repository_data_from_list(
             repository_definitions=repository_definitions,
@@ -369,15 +368,15 @@
 
     def get_all_jobs(self) -> Sequence[JobDefinition]:
         """Return all jobs in the repository as a list.
 
         Note that this will construct any job that has not yet been constructed.
 
         Returns:
-            List[PipelineDefinition]: All jobs in the repository.
+            List[JobDefinition]: All jobs in the repository.
         """
         if self._all_jobs is not None:
             return self._all_jobs
 
         self._all_jobs = self._jobs.get_all_definitions()
         self._check_node_defs(self._all_jobs)
         return self._all_jobs
@@ -463,15 +462,15 @@
                 if isinstance(node_def, SubselectedGraphDefinition):
                     break
 
                 if node_def.name not in node_defs:
                     node_defs[node_def.name] = node_def
                     node_to_job[node_def.name] = job_def.name
 
-                if node_defs[node_def.name] is not node_def:
+                if node_defs[node_def.name] != node_def:
                     first_name, second_name = sorted([node_to_job[node_def.name], job_def.name])
                     raise DagsterInvalidDefinitionError(
                         f"Conflicting definitions found in repository with name '{node_def.name}'."
                         " Op/Graph definition names must be unique within a repository."
                         f" {node_def.__class__.__name__} is defined in"
                         f" job '{first_name}' and in"
                         f" job '{second_name}'."
@@ -494,14 +493,14 @@
     def _validate_sensor(self, sensor: SensorDefinition) -> SensorDefinition:
         job_names = self.get_job_names()
         if len(sensor.targets) == 0:
             # skip validation when the sensor does not target a job
             return sensor
 
         for target in sensor.targets:
-            if target.pipeline_name not in job_names:
+            if target.job_name not in job_names:
                 raise DagsterInvalidDefinitionError(
                     f'SensorDefinition "{sensor.name}" targets job "{sensor.job_name}" '
                     "which was not found in this repository."
                 )
 
         return sensor
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/repository_definition/repository_data_builder.py` & `dagster-1.3.3/dagster/_core/definitions/repository_definition/repository_data_builder.py`

 * *Files 4% similar despite different names*

```diff
@@ -95,15 +95,15 @@
 def build_caching_repository_data_from_list(
     repository_definitions: Sequence[RepositoryListDefinition],
     default_executor_def: Optional[ExecutorDefinition] = None,
     default_logger_defs: Optional[Mapping[str, LoggerDefinition]] = None,
     top_level_resources: Optional[Mapping[str, ResourceDefinition]] = None,
     resource_key_mapping: Optional[Mapping[int, str]] = None,
 ) -> CachingRepositoryData:
-    from dagster._core.definitions import AssetGroup, AssetsDefinition
+    from dagster._core.definitions import AssetsDefinition
     from dagster._core.definitions.partitioned_schedule import (
         UnresolvedPartitionedAssetScheduleDefinition,
     )
 
     schedule_and_sensor_names: Set[str] = set()
     jobs: Dict[str, JobDefinition] = {}
     coerced_graphs: Dict[str, JobDefinition] = {}
@@ -112,15 +112,14 @@
     unresolved_partitioned_asset_schedules: Dict[
         str, UnresolvedPartitionedAssetScheduleDefinition
     ] = {}
     sensors: Dict[str, SensorDefinition] = {}
     assets_defs: List[AssetsDefinition] = []
     asset_keys: Set[AssetKey] = set()
     source_assets: List[SourceAsset] = []
-    combined_asset_group = None
     for definition in repository_definitions:
         if isinstance(definition, JobDefinition):
             if (
                 definition.name in jobs and jobs[definition.name] != definition
             ) or definition.name in unresolved_jobs:
                 raise DagsterInvalidDefinitionError(
                     f"Duplicate job definition found for {definition.describe_target()}"
@@ -166,57 +165,37 @@
         elif isinstance(definition, UnresolvedAssetJobDefinition):
             if definition.name in jobs or definition.name in unresolved_jobs:
                 raise DagsterInvalidDefinitionError(
                     f"Duplicate definition found for unresolved job '{definition.name}'"
                 )
             # we can only resolve these once we have all assets
             unresolved_jobs[definition.name] = definition
-        elif isinstance(definition, AssetGroup):
-            if combined_asset_group:
-                combined_asset_group += definition
-            else:
-                combined_asset_group = definition
         elif isinstance(definition, AssetsDefinition):
             for key in definition.keys:
                 if key in asset_keys:
                     raise DagsterInvalidDefinitionError(f"Duplicate asset key: {key}")
 
             asset_keys.update(definition.keys)
             assets_defs.append(definition)
         elif isinstance(definition, SourceAsset):
             source_assets.append(definition)
         else:
             check.failed(f"Unexpected repository entry {definition}")
 
     if assets_defs or source_assets:
-        if combined_asset_group is not None:
-            raise DagsterInvalidDefinitionError(
-                "A repository can't have both an AssetGroup and direct asset defs"
-            )
-        combined_asset_group = AssetGroup(
+        for job_def in get_base_asset_jobs(
             assets=assets_defs,
             source_assets=source_assets,
             executor_def=default_executor_def,
-        )
-
-    if combined_asset_group:
-        for job_def in get_base_asset_jobs(
-            assets=combined_asset_group.assets,
-            source_assets=combined_asset_group.source_assets,
-            executor_def=combined_asset_group.executor_def,
-            resource_defs=combined_asset_group.resource_defs,
+            resource_defs={},  # ????
         ):
             jobs[job_def.name] = job_def
 
-        source_assets_by_key = {
-            source_asset.key: source_asset for source_asset in combined_asset_group.source_assets
-        }
-        assets_defs_by_key = {
-            key: asset for asset in combined_asset_group.assets for key in asset.keys
-        }
+        source_assets_by_key = {source_asset.key: source_asset for source_asset in source_assets}
+        assets_defs_by_key = {key: asset for asset in assets_defs for key in asset.keys}
     else:
         source_assets_by_key = {}
         assets_defs_by_key = {}
 
     for name, sensor_def in sensors.items():
         if sensor_def.has_loadable_targets():
             targets = sensor_def.load_targets()
@@ -228,19 +207,15 @@
     for name, schedule_def in schedules.items():
         if schedule_def.has_loadable_target():
             target = schedule_def.load_target()
             _process_and_validate_target(
                 schedule_def, coerced_graphs, unresolved_jobs, jobs, target
             )
 
-    asset_graph = AssetGraph.from_assets(
-        [*combined_asset_group.assets, *combined_asset_group.source_assets]
-        if combined_asset_group
-        else []
-    )
+    asset_graph = AssetGraph.from_assets([*assets_defs, *source_assets])
 
     if unresolved_partitioned_asset_schedules:
         for (
             name,
             unresolved_partitioned_asset_schedule,
         ) in unresolved_partitioned_asset_schedules.items():
             _process_and_validate_target(
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/repository_definition/repository_definition.py` & `dagster-1.3.3/dagster/_core/definitions/repository_definition/repository_definition.py`

 * *Files 6% similar despite different names*

```diff
@@ -66,16 +66,16 @@
                     key_type=str,
                     value_type=list,
                 )
             ),
         )
 
     # Allow this to be hashed for use in `lru_cache`. This is needed because:
-    # - `ReconstructablePipeline` uses `lru_cache`
-    # - `ReconstructablePipeline` has a `ReconstructableRepository` attribute
+    # - `ReconstructableJob` uses `lru_cache`
+    # - `ReconstructableJob` has a `ReconstructableRepository` attribute
     # - `ReconstructableRepository` has a `RepositoryLoadData` attribute
     # - `RepositoryLoadData` has collection attributes that are unhashable by default
     def __hash__(self) -> int:
         if not hasattr(self, "_hash"):
             self._hash = hash_collection(self)
         return self._hash
 
@@ -123,40 +123,20 @@
     def description(self) -> Optional[str]:
         return self._description
 
     def load_all_definitions(self):
         # force load of all lazy constructed code artifacts
         self._repository_data.load_all_definitions()
 
-    @property
-    def pipeline_names(self) -> Sequence[str]:
-        """List[str]: Names of all pipelines/jobs in the repository."""
-        return self._repository_data.get_job_names()
-
     @public
     @property
     def job_names(self) -> Sequence[str]:
         """List[str]: Names of all jobs in the repository."""
         return self._repository_data.get_job_names()
 
-    def get_pipeline(self, name: str) -> JobDefinition:
-        """Get a pipeline/job by name.
-
-        If this pipeline/job is present in the lazily evaluated dictionary passed to the
-        constructor, but has not yet been constructed, only this pipeline/job is constructed, and will
-        be cached for future calls.
-
-        Args:
-            name (str): Name of the pipeline/job to retrieve.
-
-        Returns:
-            PipelineDefinition: The pipeline/job definition corresponding to the given name.
-        """
-        return self._repository_data.get_job(name)
-
     def get_top_level_resources(self) -> Mapping[str, ResourceDefinition]:
         return self._repository_data.get_top_level_resources()
 
     def get_env_vars_by_top_level_resource(self) -> Mapping[str, AbstractSet[str]]:
         return self._repository_data.get_env_vars_by_top_level_resource()
 
     def get_resource_key_mapping(self) -> Mapping[int, str]:
@@ -290,15 +270,14 @@
     def get_maybe_subset_job_def(
         self,
         job_name: str,
         op_selection: Optional[Sequence[str]] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
         solids_to_execute: Optional[AbstractSet[str]] = None,
     ):
-        # named job forward expecting pipeline distinction to be removed soon
         defn = self.get_job(job_name)
         return defn.get_job_def_for_subset_selection(op_selection, asset_selection)
 
     @public
     def load_asset_value(
         self,
         asset_key: CoercibleToAssetKey,
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/repository_definition/valid_definitions.py` & `dagster-1.3.3/dagster/_core/definitions/repository_definition/valid_definitions.py`

 * *Files 8% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 from dagster._core.definitions.job_definition import JobDefinition
 from dagster._core.definitions.schedule_definition import ScheduleDefinition
 from dagster._core.definitions.sensor_definition import SensorDefinition
 from dagster._core.definitions.source_asset import SourceAsset
 from dagster._core.definitions.unresolved_asset_job_definition import UnresolvedAssetJobDefinition
 
 if TYPE_CHECKING:
-    from dagster._core.definitions import AssetGroup, AssetsDefinition
+    from dagster._core.definitions import AssetsDefinition
     from dagster._core.definitions.cacheable_assets import CacheableAssetsDefinition
     from dagster._core.definitions.partitioned_schedule import (
         UnresolvedPartitionedAssetScheduleDefinition,
     )
 
 SINGLETON_REPOSITORY_NAME = "__repository__"
 
@@ -29,15 +29,14 @@
     JobDefinition,
     ScheduleDefinition,
     SensorDefinition,
 )
 
 RepositoryListDefinition: TypeAlias = Union[
     "AssetsDefinition",
-    "AssetGroup",
     GraphDefinition,
     JobDefinition,
     ScheduleDefinition,
     SensorDefinition,
     SourceAsset,
     UnresolvedAssetJobDefinition,
     "UnresolvedPartitionedAssetScheduleDefinition",
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/resolved_asset_deps.py` & `dagster-1.3.3/dagster/_core/definitions/resolved_asset_deps.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/resource_annotation.py` & `dagster-1.3.3/dagster/_core/definitions/resource_annotation.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/resource_definition.py` & `dagster-1.3.3/dagster/_core/definitions/resource_definition.py`

 * *Files 3% similar despite different names*

```diff
@@ -17,14 +17,15 @@
 
 import dagster._check as check
 from dagster._annotations import public
 from dagster._core.decorator_utils import format_docstring_for_description
 from dagster._core.definitions.config import is_callable_valid_config_arg
 from dagster._core.definitions.configurable import AnonymousConfigurableDefinition
 from dagster._core.errors import DagsterInvalidDefinitionError, DagsterInvalidInvocationError
+from dagster._utils import IHasInternalInit
 from dagster._utils.backcompat import experimental_arg_warning
 
 from ..decorator_utils import (
     get_function_params,
     has_at_least_one_parameter,
     is_required_param,
     positional_arg_name_list,
@@ -54,15 +55,15 @@
 ResourceFunctionWithoutContext: TypeAlias = Callable[[], Any]
 ResourceFunction: TypeAlias = Union[
     ResourceFunctionWithContext,
     ResourceFunctionWithoutContext,
 ]
 
 
-class ResourceDefinition(AnonymousConfigurableDefinition, RequiresResources):
+class ResourceDefinition(AnonymousConfigurableDefinition, RequiresResources, IHasInternalInit):
     """Core class for defining resources.
 
     Resources are scoped ways to make external resources (like database connections) available to
     ops and assets during job execution and to clean up after execution resolves.
 
     If resource_fn yields once rather than returning (in the manner of functions decorable with
     :py:func:`@contextlib.contextmanager <python:contextlib.contextmanager>`) then the body of the
@@ -102,14 +103,31 @@
         self._required_resource_keys = check.opt_set_param(
             required_resource_keys, "required_resource_keys"
         )
         self._version = check.opt_str_param(version, "version")
         if version:
             experimental_arg_warning("version", "ResourceDefinition.__init__")
 
+    @staticmethod
+    def dagster_internal_init(
+        *,
+        resource_fn: ResourceFunction,
+        config_schema: CoercableToConfigSchema,
+        description: Optional[str],
+        required_resource_keys: Optional[AbstractSet[str]],
+        version: Optional[str],
+    ) -> "ResourceDefinition":
+        return ResourceDefinition(
+            resource_fn=resource_fn,
+            config_schema=config_schema,
+            description=description,
+            required_resource_keys=required_resource_keys,
+            version=version,
+        )
+
     @property
     def resource_fn(self) -> ResourceFunction:
         return self._resource_fn
 
     @property
     def config_schema(self) -> IDefinitionConfigSchema:
         return self._config_schema
@@ -184,15 +202,15 @@
         )
 
     def copy_for_configured(
         self,
         description: Optional[str],
         config_schema: CoercableToConfigSchema,
     ) -> "ResourceDefinition":
-        return ResourceDefinition(
+        return ResourceDefinition.dagster_internal_init(
             config_schema=config_schema,
             description=description or self.description,
             resource_fn=self.resource_fn,
             required_resource_keys=self.required_resource_keys,
             version=self.version,
         )
 
@@ -282,15 +300,15 @@
         if required_extras:
             raise DagsterInvalidDefinitionError(
                 f"@resource decorated function '{resource_fn.__name__}' expects only a single"
                 " positional required argument. Got required extra params"
                 f" {', '.join(positional_arg_name_list(required_extras))}"
             )
 
-        resource_def = ResourceDefinition(
+        resource_def = ResourceDefinition.dagster_internal_init(
             resource_fn=resource_fn,
             config_schema=self.config_schema,
             description=self.description or format_docstring_for_description(resource_fn),
             version=self.version,
             required_resource_keys=self.required_resource_keys,
         )
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/resource_invocation.py` & `dagster-1.3.3/dagster/_core/definitions/resource_invocation.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/resource_requirement.py` & `dagster-1.3.3/dagster/_core/definitions/resource_requirement.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/run_config.py` & `dagster-1.3.3/dagster/_core/definitions/run_config.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,15 @@
     ALL_CONFIG_BUILTINS,
     ConfigType,
     Field,
     Permissive,
     Selector,
     Shape,
 )
-from dagster._config.pythonic_config import Config, config_dictionary_from_values
+from dagster._config.pythonic_config import Config
 from dagster._core.definitions.asset_layer import AssetLayer
 from dagster._core.definitions.executor_definition import (
     ExecutorDefinition,
     execute_in_process_executor,
     in_process_executor,
 )
 from dagster._core.definitions.input import InputDefinition
@@ -88,15 +88,15 @@
         ),
         is_required=is_required,
         description=description,
     )
 
 
 class RunConfigSchemaCreationData(NamedTuple):
-    pipeline_name: str
+    job_name: str
     nodes: Sequence[Node]
     graph_def: GraphDefinition
     dependency_structure: DependencyStructure
     executor_def: ExecutorDefinition
     resource_defs: Mapping[str, ResourceDefinition]
     logger_defs: Mapping[str, LoggerDefinition]
     ignored_nodes: Sequence[Node]
@@ -609,29 +609,32 @@
             type_dict_by_name[name] = config_type
 
         type_dict_by_key[config_type.key] = config_type
 
     return type_dict_by_name, type_dict_by_key
 
 
-def _convert_config_classes(configs: Dict[str, Any]) -> Dict[str, Any]:
+def _convert_config_classes_inner(configs: Any) -> Any:
+    if not isinstance(configs, dict):
+        return configs
+
     return {
-        k: {
-            "config": config_dictionary_from_values(
-                v._as_config_dict(), v.to_config_schema().as_field()  # noqa: SLF001
-            )
-            if isinstance(v, Config)
-            else v
-        }
+        k: {"config": v._convert_to_config_dictionary()}  # noqa: SLF001
+        if isinstance(v, Config)
+        else _convert_config_classes_inner(v)
         for k, v in configs.items()
     }
 
 
+def _convert_config_classes(configs: Dict[str, Any]) -> Dict[str, Any]:
+    return _convert_config_classes_inner(configs)
+
+
 class RunConfig:
-    """Container for all the configuration that can be passed to a pipeline run. Accepts Pythonic definitions
+    """Container for all the configuration that can be passed to a run. Accepts Pythonic definitions
     for op and asset config and resources and converts them under the hood to the appropriate config dictionaries.
 
     Example usage:
 
     .. code-block:: python
 
         class MyAssetConfig(Config):
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/run_config_schema.py` & `dagster-1.3.3/dagster/_core/definitions/run_config_schema.py`

 * *Files 9% similar despite different names*

```diff
@@ -36,10 +36,10 @@
                 check.failed("ConfigMapping config type unexpectedly None")
             return mapped_type
 
         return self.run_config_schema_type
 
 
 def create_run_config_schema(
-    pipeline_def: JobDefinition,
+    job_def: JobDefinition,
 ) -> RunConfigSchema:
-    return pipeline_def.run_config_schema
+    return job_def.run_config_schema
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/run_request.py` & `dagster-1.3.3/dagster/_core/definitions/run_request.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 from enum import Enum
 from typing import TYPE_CHECKING, Any, Mapping, NamedTuple, Optional, Sequence, Set, Union, cast
 
 import dagster._check as check
 from dagster._annotations import PublicAttr, experimental
 from dagster._core.definitions.events import AssetKey
 from dagster._core.instance import DynamicPartitionsStore
-from dagster._core.storage.pipeline_run import DagsterRun, DagsterRunStatus
+from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus
 from dagster._core.storage.tags import PARTITION_NAME_TAG
 from dagster._serdes.serdes import whitelist_for_serdes
 from dagster._utils.error import SerializableErrorInfo
 
 if TYPE_CHECKING:
     from dagster._core.definitions.job_definition import JobDefinition
     from dagster._core.definitions.run_config import RunConfig
@@ -172,15 +172,14 @@
         ],
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
     ) -> "RunRequest":
         from dagster._core.definitions.job_definition import JobDefinition
         from dagster._core.definitions.partition import (
             DynamicPartitionsDefinition,
-            Partition,
             PartitionedConfig,
             PartitionsDefinition,
         )
 
         if self.partition_key is None:
             check.failed(
                 "Cannot resolve partition for run request without partition key",
@@ -235,83 +234,76 @@
             if self.partition_key not in partition_keys_after_requests_resolved:
                 check.failed(
                     f"Dynamic partition key {self.partition_key} for partitions def"
                     f" '{partitions_def.name}' is invalid. After dynamic partitions requests are"
                     " applied, it does not exist in the set of valid partition keys."
                 )
 
-            partition = Partition(self.partition_key, self.partition_key)
-
         else:
-            # Relies on the partitions def to throw an error if the partition does not exist
-            partition = partitions_def.get_partition(
+            partitions_def.validate_partition_key(
                 self.partition_key,
-                current_time=current_time,
                 dynamic_partitions_store=dynamic_partitions_store,
+                current_time=current_time,
             )
 
-        get_run_request_tags = lambda partition: (
-            {
-                **self.tags,
-                **partitioned_config.get_tags_for_partition(
-                    partition,
-                    job_name=target_definition.name,
-                ),
-            }
-            if self.tags
-            else partitioned_config.get_tags_for_partition(
-                partition,
+        tags = {
+            **(self.tags or {}),
+            **partitioned_config.get_tags_for_partition_key(
+                self.partition_key,
                 job_name=target_definition.name,
-            )
-        )
+            ),
+        }
 
         return self.with_replaced_attrs(
             run_config=self.run_config
             if self.run_config
-            else partitioned_config.get_run_config_for_partition(
-                partition,
-            ),
-            tags=get_run_request_tags(partition),
+            else partitioned_config.get_run_config_for_partition_key(self.partition_key),
+            tags=tags,
         )
 
     def has_resolved_partition(self) -> bool:
         # Backcompat run requests yielded via `run_request_for_partition` already have resolved
         # partitioning
         return self.tags.get(PARTITION_NAME_TAG) is not None if self.partition_key else True
 
 
-@whitelist_for_serdes
-class PipelineRunReaction(
+@whitelist_for_serdes(
+    storage_name="PipelineRunReaction",
+    storage_field_names={
+        "dagster_run": "pipeline_run",
+    },
+)
+class DagsterRunReaction(
     NamedTuple(
-        "_PipelineRunReaction",
+        "_DagsterRunReaction",
         [
-            ("pipeline_run", Optional[DagsterRun]),
+            ("dagster_run", Optional[DagsterRun]),
             ("error", Optional[SerializableErrorInfo]),
             ("run_status", Optional[DagsterRunStatus]),
         ],
     )
 ):
-    """Represents a request that reacts to an existing pipeline run. If success, it will report logs
+    """Represents a request that reacts to an existing dagster run. If success, it will report logs
     back to the run.
 
     Attributes:
-        pipeline_run (Optional[PipelineRun]): The pipeline run that originates this reaction.
+        dagster_run (Optional[DagsterRun]): The dagster run that originates this reaction.
         error (Optional[SerializableErrorInfo]): user code execution error.
-        run_status: (Optional[PipelineRunStatus]): The run status that triggered the reaction.
+        run_status: (Optional[DagsterRunStatus]): The run status that triggered the reaction.
     """
 
     def __new__(
         cls,
-        pipeline_run: Optional[DagsterRun],
+        dagster_run: Optional[DagsterRun],
         error: Optional[SerializableErrorInfo] = None,
         run_status: Optional[DagsterRunStatus] = None,
     ):
-        return super(PipelineRunReaction, cls).__new__(
+        return super(DagsterRunReaction, cls).__new__(
             cls,
-            pipeline_run=check.opt_inst_param(pipeline_run, "pipeline_run", DagsterRun),
+            dagster_run=check.opt_inst_param(dagster_run, "dagster_run", DagsterRun),
             error=check.opt_inst_param(error, "error", SerializableErrorInfo),
             run_status=check.opt_inst_param(run_status, "run_status", DagsterRunStatus),
         )
 
 
 @experimental
 class SensorResult(
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/run_status_sensor_definition.py` & `dagster-1.3.3/dagster/_core/definitions/run_status_sensor_definition.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 import logging
-import warnings
 from contextlib import ExitStack
 from datetime import datetime
 from typing import (
     TYPE_CHECKING,
     Callable,
     Iterator,
     Mapping,
@@ -26,33 +25,33 @@
 from dagster._core.definitions.scoped_resources_builder import Resources, ScopedResourcesBuilder
 from dagster._core.errors import (
     DagsterInvalidDefinitionError,
     DagsterInvariantViolationError,
     RunStatusSensorExecutionError,
     user_code_error_boundary,
 )
-from dagster._core.events import PIPELINE_RUN_STATUS_TO_EVENT_TYPE, DagsterEvent
+from dagster._core.events import PIPELINE_RUN_STATUS_TO_EVENT_TYPE, DagsterEvent, DagsterEventType
 from dagster._core.instance import DagsterInstance
-from dagster._core.storage.pipeline_run import DagsterRun, DagsterRunStatus, RunsFilter
+from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus, RunsFilter
 from dagster._serdes import (
     serialize_value,
     whitelist_for_serdes,
 )
 from dagster._serdes.errors import DeserializationError
 from dagster._serdes.serdes import deserialize_value
 from dagster._seven import JSONDecodeError
 from dagster._utils import utc_datetime_from_timestamp
 from dagster._utils.backcompat import deprecation_warning
 from dagster._utils.error import serializable_error_info_from_exc_info
 
 from .graph_definition import GraphDefinition
 from .job_definition import JobDefinition
 from .sensor_definition import (
+    DagsterRunReaction,
     DefaultSensorStatus,
-    PipelineRunReaction,
     RawSensorEvaluationFunctionReturn,
     RunRequest,
     SensorDefinition,
     SensorEvaluationContext,
     SensorResult,
     SensorType,
     SkipReason,
@@ -108,23 +107,15 @@
 
     @staticmethod
     def from_json(json_str: str) -> "RunStatusSensorCursor":
         return deserialize_value(json_str, RunStatusSensorCursor)
 
 
 class RunStatusSensorContext:
-    """The ``context`` object available to a decorated function of ``run_status_sensor``.
-
-    Attributes:
-        sensor_name (str): the name of the sensor.
-        dagster_run (DagsterRun): the run of the job or pipeline.
-        dagster_event (DagsterEvent): the event associated with the job or pipeline run status.
-        instance (DagsterInstance): the current instance.
-        log (logging.Logger): the logger for the given sensor evaluation
-    """
+    """The ``context`` object available to a decorated function of ``run_status_sensor``."""
 
     def __init__(
         self,
         sensor_name,
         dagster_run,
         dagster_event,
         instance,
@@ -201,74 +192,94 @@
                 )
 
         return self._resources
 
     @public
     @property
     def sensor_name(self) -> str:
+        """The name of the sensor."""
         return self._sensor_name
 
     @public
     @property
     def dagster_run(self) -> DagsterRun:
+        """The run of the job."""
         return self._dagster_run
 
     @public
     @property
     def dagster_event(self) -> DagsterEvent:
+        """The event associated with the job run status."""
         return self._dagster_event
 
     @public
     @property
     def instance(self) -> DagsterInstance:
+        """The current instance."""
         return self._instance
 
     @public
     @property
     def log(self) -> logging.Logger:
+        """The logger for the current sensor evaluation."""
         if not self._logger:
             self._logger = InstigationLogger()
 
         return self._logger
 
     @public
     @property
     def partition_key(self) -> Optional[str]:
         return self._partition_key
 
-    @property
-    def pipeline_run(self) -> DagsterRun:
-        warnings.warn(
-            "`RunStatusSensorContext.pipeline_run` is deprecated as of 0.13.0; use "
-            "`RunStatusSensorContext.dagster_run` instead."
-        )
-        return self.dagster_run
-
     def __enter__(self) -> "RunStatusSensorContext":
         self._cm_scope_entered = True
         return self
 
     def __exit__(self, *exc) -> None:
         self._exit_stack.close()
         self._logger = None
 
 
 class RunFailureSensorContext(RunStatusSensorContext):
     """The ``context`` object available to a decorated function of ``run_failure_sensor``.
 
     Attributes:
         sensor_name (str): the name of the sensor.
-        dagster_run (DagsterRun): the failed pipeline run.
-        failure_event (DagsterEvent): the pipeline failure event.
+        dagster_run (DagsterRun): the failed run.
     """
 
+    @public
     @property
-    def failure_event(self):
+    def failure_event(self) -> DagsterEvent:
+        """The run failure event.
+
+        If the run failed because of an error inside a step, get_step_failure_events will have more
+        details on the step failure.
+        """
         return self.dagster_event
 
+    @public
+    def get_step_failure_events(self) -> Sequence[DagsterEvent]:
+        """The step failure event for each step in the run that failed.
+
+        Examples:
+            .. code-block:: python
+
+                error_strings_by_step_key = {
+                    # includes the stack trace
+                    event.step_key: event.event_specific_data.error.to_string()
+                    for event in context.get_step_failure_events()
+                }
+        """
+        records = self.instance.get_records_for_run(
+            run_id=self.dagster_run.run_id, of_type=DagsterEventType.STEP_FAILURE
+        ).records
+        return [cast(DagsterEvent, record.event_log_entry.dagster_event) for record in records]
+
 
 def build_run_status_sensor_context(
     sensor_name: str,
     dagster_event: DagsterEvent,
     dagster_instance: DagsterInstance,
     dagster_run: DagsterRun,
     context: Optional[SensorEvaluationContext] = None,
@@ -459,22 +470,22 @@
     if callable(name):
         return inner(name)
 
     return inner
 
 
 class RunStatusSensorDefinition(SensorDefinition):
-    """Define a sensor that reacts to a given status of pipeline execution, where the decorated
+    """Define a sensor that reacts to a given status of job execution, where the decorated
     function will be evaluated when a run is at the given status.
 
     Args:
         name (str): The name of the sensor. Defaults to the name of the decorated function.
         run_status (DagsterRunStatus): The status of a run which will be
             monitored by the sensor.
-        run_status_sensor_fn (Callable[[RunStatusSensorContext], Union[SkipReason, PipelineRunReaction]]): The core
+        run_status_sensor_fn (Callable[[RunStatusSensorContext], Union[SkipReason, DagsterRunReaction]]): The core
             evaluation function for the sensor. Takes a :py:class:`~dagster.RunStatusSensorContext`.
         minimum_interval_seconds (Optional[int]): The minimum number of seconds that will elapse
             between sensor evaluations.
         description (Optional[str]): A human-readable description of the sensor.
         monitored_jobs (Optional[List[Union[JobDefinition, GraphDefinition, UnresolvedAssetJobDefinition, JobSelector, RepositorySelector, CodeLocationSelector]]]):
             The jobs in the current repository that will be monitored by this sensor. Defaults to
             None, which means the alert will be sent when any job in the repository fails.
@@ -574,15 +585,15 @@
             [x for x in monitored_jobs if not isinstance(x, (JobSelector, RepositorySelector))]
             if monitored_jobs
             else []
         )
 
         def _wrapped_fn(
             context: SensorEvaluationContext,
-        ) -> Iterator[Union[RunRequest, SkipReason, PipelineRunReaction, SensorResult]]:
+        ) -> Iterator[Union[RunRequest, SkipReason, DagsterRunReaction, SensorResult]]:
             # initiate the cursor to (most recent event id, current timestamp) when:
             # * it's the first time starting the sensor
             # * or, the cursor isn't in valid format (backcompt)
             if context.cursor is None or not RunStatusSensorCursor.is_valid(context.cursor):
                 most_recent_event_records = list(
                     context.instance.get_event_records(
                         EventRecordsFilter(event_type=event_type), ascending=False, limit=1
@@ -641,50 +652,50 @@
                         RunStatusSensorCursor(
                             record_id=storage_id,
                             update_timestamp=approximate_update_timestamp.isoformat(),
                         ).to_json()
                     )
                     continue
 
-                pipeline_run = run_records[0].dagster_run
+                dagster_run = run_records[0].dagster_run
                 update_timestamp = run_records[0].update_timestamp
 
                 job_match = False
 
                 # if monitor_all_repositories is provided, then we want to run the sensor for all jobs in all repositories
                 if monitor_all_repositories:
                     job_match = True
 
                 # check if the run is in the current repository and (if provided) one of jobs specified in monitored_jobs
                 if (
                     not job_match
                     and
-                    # the pipeline has a repository (not manually executed)
-                    pipeline_run.external_pipeline_origin
+                    # the job has a repository (not manually executed)
+                    dagster_run.external_job_origin
                     and
-                    # the pipeline belongs to the current repository
-                    pipeline_run.external_pipeline_origin.external_repository_origin.repository_name
+                    # the job belongs to the current repository
+                    dagster_run.external_job_origin.external_repository_origin.repository_name
                     == context.repository_name
                 ):
                     if monitored_jobs:
-                        if pipeline_run.pipeline_name in map(lambda x: x.name, current_repo_jobs):
+                        if dagster_run.job_name in map(lambda x: x.name, current_repo_jobs):
                             job_match = True
                     else:
                         job_match = True
 
                 if not job_match:
                     # check if the run is one of the jobs specified by JobSelector or RepositorySelector (ie in another repo)
                     # make a JobSelector for the run in question
                     external_repository_origin = check.not_none(
-                        pipeline_run.external_pipeline_origin
+                        dagster_run.external_job_origin
                     ).external_repository_origin
                     run_job_selector = JobSelector(
                         location_name=external_repository_origin.code_location_origin.location_name,
                         repository_name=external_repository_origin.repository_name,
-                        job_name=pipeline_run.pipeline_name,
+                        job_name=dagster_run.job_name,
                     )
                     if run_job_selector in other_repo_jobs:
                         job_match = True
 
                     # make a RepositorySelector for the run in question
                     run_repo_selector = RepositorySelector(
                         location_name=external_repository_origin.code_location_origin.location_name,
@@ -707,20 +718,20 @@
                 resource_args_populated = validate_and_get_resource_dict(
                     context.resources, name, resource_arg_names
                 )
 
                 try:
                     with RunStatusSensorContext(
                         sensor_name=name,
-                        dagster_run=pipeline_run,
+                        dagster_run=dagster_run,
                         dagster_event=event_log_entry.dagster_event,
                         instance=context.instance,
                         resource_defs=context.resource_defs,
                         logger=context.log,
-                        partition_key=pipeline_run.tags.get("dagster/partition"),
+                        partition_key=dagster_run.tags.get("dagster/partition"),
                     ) as sensor_context, user_code_error_boundary(
                         RunStatusSensorExecutionError,
                         lambda: f'Error occurred during the execution sensor "{name}".',
                     ):
                         context_param_name = get_context_param_name(run_status_sensor_fn)
                         context_param = (
                             {context_param_name: sensor_context} if context_param_name else {}
@@ -745,15 +756,15 @@
                                         f"Error in run status sensor {name}: Sensor returned a"
                                         " SensorResult with a cursor value. The cursor is managed"
                                         " by the sensor and should not be modified by a user."
                                     )
                                 yield sensor_return
                             elif isinstance(
                                 sensor_return,
-                                (RunRequest, SkipReason, PipelineRunReaction),
+                                (RunRequest, SkipReason, DagsterRunReaction),
                             ):
                                 yield sensor_return
                             else:
                                 yield from sensor_return
                             return
                 except RunStatusSensorExecutionError as run_status_sensor_execution_error:
                     # When the user code errors, we report error to the sensor tick not the original run.
@@ -763,20 +774,20 @@
 
                 context.update_cursor(
                     RunStatusSensorCursor(
                         record_id=storage_id, update_timestamp=update_timestamp.isoformat()
                     ).to_json()
                 )
 
-                # Yield PipelineRunReaction to indicate the execution success/failure.
+                # Yield DagsterRunReaction to indicate the execution success/failure.
                 # The sensor machinery would
                 # * report back to the original run if success
                 # * update cursor and job state
-                yield PipelineRunReaction(
-                    pipeline_run=pipeline_run,
+                yield DagsterRunReaction(
+                    dagster_run=dagster_run,
                     run_status=run_status,
                     error=serializable_error,
                 )
 
         super(RunStatusSensorDefinition, self).__init__(
             name=name,
             evaluation_fn=_wrapped_fn,
@@ -840,34 +851,34 @@
         ]
     ] = None,
     monitor_all_repositories: bool = False,
     default_status: DefaultSensorStatus = DefaultSensorStatus.STOPPED,
     request_job: Optional[ExecutableDefinition] = None,
     request_jobs: Optional[Sequence[ExecutableDefinition]] = None,
 ) -> Callable[[RunStatusSensorEvaluationFunction], RunStatusSensorDefinition,]:
-    """Creates a sensor that reacts to a given status of pipeline execution, where the decorated
-    function will be run when a pipeline is at the given status.
+    """Creates a sensor that reacts to a given status of job execution, where the decorated
+    function will be run when a job is at the given status.
 
     Takes a :py:class:`~dagster.RunStatusSensorContext`.
 
     Args:
         run_status (DagsterRunStatus): The status of run execution which will be
             monitored by the sensor.
         name (Optional[str]): The name of the sensor. Defaults to the name of the decorated function.
         minimum_interval_seconds (Optional[int]): The minimum number of seconds that will elapse
             between sensor evaluations.
         description (Optional[str]): A human-readable description of the sensor.
-        monitored_jobs (Optional[List[Union[PipelineDefinition, GraphDefinition, UnresolvedAssetJobDefinition, RepositorySelector, JobSelector, CodeLocationSelector]]]):
+        monitored_jobs (Optional[List[Union[JobDefinition, GraphDefinition, UnresolvedAssetJobDefinition, RepositorySelector, JobSelector, CodeLocationSelector]]]):
             Jobs in the current repository that will be monitored by this sensor. Defaults to None, which means the alert will
             be sent when any job in the repository matches the requested run_status. Jobs in external repositories can be monitored by using
             RepositorySelector or JobSelector.
         monitor_all_repositories (bool): If set to True, the sensor will monitor all runs in the Dagster instance.
             If set to True, an error will be raised if you also specify monitored_jobs or job_selection.
             Defaults to False.
-        job_selection (Optional[List[Union[PipelineDefinition, GraphDefinition, RepositorySelector, JobSelector, CodeLocationSelector]]]):
+        job_selection (Optional[List[Union[JobDefinition, GraphDefinition, RepositorySelector, JobSelector, CodeLocationSelector]]]):
             (deprecated in favor of monitored_jobs) Jobs in the current repository that will be
             monitored by this sensor. Defaults to None, which means the alert will be sent when
             any job in the repository matches the requested run_status.
         default_status (DefaultSensorStatus): Whether the sensor starts as running or not. The default
             status can be overridden from Dagit or via the GraphQL API.
         request_job (Optional[Union[GraphDefinition, JobDefinition, UnresolvedAssetJobDefinition]]): The job that should be
             executed if a RunRequest is yielded from the sensor.
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/schedule_definition.py` & `dagster-1.3.3/dagster/_core/definitions/schedule_definition.py`

 * *Files 8% similar despite different names*

```diff
@@ -25,30 +25,30 @@
 
 import dagster._check as check
 from dagster._annotations import deprecated, public
 from dagster._core.definitions.instigation_logger import InstigationLogger
 from dagster._core.definitions.resource_annotation import get_resource_args
 from dagster._core.definitions.scoped_resources_builder import Resources
 from dagster._serdes import whitelist_for_serdes
-from dagster._utils import ensure_gen
+from dagster._utils import IHasInternalInit, ensure_gen
 from dagster._utils.backcompat import deprecation_warning
 from dagster._utils.merger import merge_dicts
 from dagster._utils.schedules import is_valid_cron_schedule
 
 from ..decorator_utils import has_at_least_one_parameter
 from ..errors import (
     DagsterInvalidDefinitionError,
     DagsterInvalidInvocationError,
     DagsterInvariantViolationError,
     ScheduleExecutionError,
     user_code_error_boundary,
 )
 from ..instance import DagsterInstance
 from ..instance.ref import InstanceRef
-from ..storage.pipeline_run import DagsterRun
+from ..storage.dagster_run import DagsterRun
 from .graph_definition import GraphDefinition
 from .job_definition import JobDefinition
 from .run_request import RunRequest, SkipReason
 from .target import DirectTarget, ExecutableDefinition, RepoRelativeTarget
 from .unresolved_asset_job_definition import UnresolvedAssetJobDefinition
 from .utils import check_valid_name, validate_tags
 
@@ -148,22 +148,14 @@
     """The context object available as the first argument various functions defined on a :py:class:`dagster.ScheduleDefinition`.
 
     A `ScheduleEvaluationContext` object is passed as the first argument to ``run_config_fn``, ``tags_fn``,
     and ``should_execute``.
 
     Users should not instantiate this object directly. To construct a `ScheduleEvaluationContext` for testing purposes, use :py:func:`dagster.build_schedule_context`.
 
-    Attributes:
-        instance_ref (Optional[InstanceRef]): The serialized instance configured to run the schedule
-        scheduled_execution_time (datetime):
-            The time in which the execution was scheduled to happen. May differ slightly
-            from both the actual execution time and the time at which the run config is computed.
-            Not available in all schedulers - currently only set in deployments using
-            DagsterDaemonScheduler.
-
     Example:
         .. code-block:: python
 
             from dagster import schedule, ScheduleEvaluationContext
 
             @schedule
             def the_schedule(context: ScheduleEvaluationContext):
@@ -234,16 +226,20 @@
         self._exit_stack.close()
         self._logger = None
 
     @property
     def resource_defs(self) -> Optional[Mapping[str, "ResourceDefinition"]]:
         return self._resource_defs
 
+    @public
     @property
     def resources(self) -> Resources:
+        """Mapping of resource key to resource definition to be made available
+        during schedule execution.
+        """
         from dagster._core.definitions.scoped_resources_builder import (
             IContainsGenerator,
         )
         from dagster._core.execution.build_resources import build_resources
 
         if not self._resources:
             instance = self.instance if self._instance or self._instance_ref else None
@@ -298,19 +294,23 @@
             self._instance = self._exit_stack.enter_context(
                 DagsterInstance.from_ref(self._instance_ref)
             )
         return cast(DagsterInstance, self._instance)
 
     @property
     def instance_ref(self) -> Optional[InstanceRef]:
+        """The serialized instance configured to run the schedule."""
         return self._instance_ref
 
     @public
     @property
     def scheduled_execution_time(self) -> datetime:
+        """The time in which the execution was scheduled to happen. May differ slightly
+        from both the actual execution time and the time at which the run config is computed.
+        """
         if self._scheduled_execution_time is None:
             check.failed(
                 "Attempting to access scheduled_execution_time, but no scheduled_execution_time was"
                 " set on this context"
             )
 
         return self._scheduled_execution_time
@@ -444,15 +444,15 @@
             raise DagsterInvalidDefinitionError(
                 f"Resource with key '{k}' required by schedule '{schedule_name}' was not provided."
             )
 
     return {k: getattr(resources, k) for k in required_resource_keys}
 
 
-class ScheduleDefinition:
+class ScheduleDefinition(IHasInternalInit):
     """Define a schedule that targets a job.
 
     Args:
         name (Optional[str]): The name of the schedule to create. Defaults to the job name plus
             "_schedule".
         cron_schedule (Union[str, Sequence[str]]): A valid cron string or sequence of cron strings
             specifying when the schedule will run, e.g., ``'45 23 * * 6'`` for a schedule that runs
@@ -496,23 +496,30 @@
     def with_updated_job(self, new_job: ExecutableDefinition) -> "ScheduleDefinition":
         """Returns a copy of this schedule with the job replaced.
 
         Args:
             job (ExecutableDefinition): The job that should execute when this
                 schedule runs.
         """
-        return ScheduleDefinition(
+        return ScheduleDefinition.dagster_internal_init(
             name=self.name,
             cron_schedule=self._cron_schedule,
             job_name=self.job_name,
             execution_timezone=self.execution_timezone,
             execution_fn=self._execution_fn,
             description=self.description,
             job=new_job,
             default_status=self.default_status,
+            environment_vars=self._environment_vars,
+            required_resource_keys=self.required_resource_keys,
+            run_config=None,  # run_config, tags, should_execute encapsulated in execution_fn
+            run_config_fn=None,
+            tags=None,
+            tags_fn=None,
+            should_execute=None,
         )
 
     def __init__(
         self,
         name: Optional[str] = None,
         *,
         cron_schedule: Optional[Union[str, Sequence[str]]] = None,
@@ -540,15 +547,15 @@
                 "Dagster recognizes standard cron expressions consisting of 5 fields."
             )
 
         if job is not None:
             self._target: Union[DirectTarget, RepoRelativeTarget] = DirectTarget(job)
         else:
             self._target = RepoRelativeTarget(
-                pipeline_name=check.str_param(job_name, "job_name"),
+                job_name=check.str_param(job_name, "job_name"),
                 solid_selection=None,
             )
 
         if name:
             self._name = check_valid_name(name)
         elif job_name:
             self._name = job_name + "_schedule"
@@ -611,26 +618,26 @@
             else:
                 tags_fn = check.opt_callable_param(
                     tags_fn, "tags_fn", default=lambda _context: cast(Mapping[str, str], {})
                 )
             self._tags_fn = tags_fn
             self._tags = tags
 
-            _should_execute: ScheduleShouldExecuteFunction = check.opt_callable_param(
+            self._should_execute: ScheduleShouldExecuteFunction = check.opt_callable_param(
                 should_execute, "should_execute", default=lambda _context: True
             )
 
             # Several type-ignores are present in this function to work around bugs in mypy
             # inference.
             def _execution_fn(context: ScheduleEvaluationContext) -> RunRequestIterator:
                 with user_code_error_boundary(
                     ScheduleExecutionError,
                     lambda: f"Error occurred during the execution of should_execute for schedule {name}",
                 ):
-                    if not _should_execute(context):
+                    if not self._should_execute(context):
                         yield SkipReason(
                             "should_execute function for {schedule_name} returned false.".format(
                                 schedule_name=name
                             )
                         )
                         return
 
@@ -687,14 +694,51 @@
         )
 
         self._required_resource_keys = (
             check.opt_set_param(required_resource_keys, "required_resource_keys", of_type=str)
             or resource_arg_names
         )
 
+    @staticmethod
+    def dagster_internal_init(
+        *,
+        name: Optional[str],
+        cron_schedule: Optional[Union[str, Sequence[str]]],
+        job_name: Optional[str],
+        run_config: Optional[Any],
+        run_config_fn: Optional[ScheduleRunConfigFunction],
+        tags: Optional[Mapping[str, str]],
+        tags_fn: Optional[ScheduleTagsFunction],
+        should_execute: Optional[ScheduleShouldExecuteFunction],
+        environment_vars: Optional[Mapping[str, str]],
+        execution_timezone: Optional[str],
+        execution_fn: Optional[ScheduleExecutionFunction],
+        description: Optional[str],
+        job: Optional[ExecutableDefinition],
+        default_status: DefaultScheduleStatus,
+        required_resource_keys: Optional[Set[str]],
+    ) -> "ScheduleDefinition":
+        return ScheduleDefinition(
+            name=name,
+            cron_schedule=cron_schedule,
+            job_name=job_name,
+            run_config=run_config,
+            run_config_fn=run_config_fn,
+            tags=tags,
+            tags_fn=tags_fn,
+            should_execute=should_execute,
+            environment_vars=environment_vars,
+            execution_timezone=execution_timezone,
+            execution_fn=execution_fn,
+            description=description,
+            job=job,
+            default_status=default_status,
+            required_resource_keys=required_resource_keys,
+        )
+
     def __call__(self, *args, **kwargs) -> ScheduleEvaluationFunctionReturn:
         from dagster._core.definitions.sensor_definition import get_context_param_name
 
         from .decorators.schedule_decorator import DecoratedScheduleFunction
 
         if not isinstance(self._execution_fn, DecoratedScheduleFunction):
             raise DagsterInvalidInvocationError(
@@ -720,15 +764,15 @@
     @property
     def name(self) -> str:
         return self._name
 
     @public
     @property
     def job_name(self) -> str:
-        return self._target.pipeline_name
+        return self._target.job_name
 
     @public
     @property
     def description(self) -> Optional[str]:
         return self._description
 
     @public
@@ -821,15 +865,15 @@
             if run_request.partition_key and not run_request.has_resolved_partition():
                 if context.repository_def is None:
                     raise DagsterInvariantViolationError(
                         "Must provide repository def to build_schedule_context when yielding"
                         " partitioned run requests"
                     )
 
-                scheduled_target = context.repository_def.get_job(self._target.pipeline_name)
+                scheduled_target = context.repository_def.get_job(self._target.job_name)
                 resolved_request = run_request.with_resolved_tags_and_config(
                     target_definition=scheduled_target,
                     dynamic_partitions_requests=[],
                     current_time=context.scheduled_execution_time,
                     dynamic_partitions_store=dynamic_partitions_store,
                 )
             else:
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/scoped_resources_builder.py` & `dagster-1.3.3/dagster/_core/definitions/scoped_resources_builder.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/selector.py` & `dagster-1.3.3/dagster/_core/definitions/selector.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,66 +2,66 @@
 
 import dagster._check as check
 from dagster._core.definitions.events import AssetKey
 from dagster._core.definitions.repository_definition import SINGLETON_REPOSITORY_NAME
 from dagster._serdes import create_snapshot_id, whitelist_for_serdes
 
 
-class PipelineSelector(
+class JobSubsetSelector(
     NamedTuple(
-        "_PipelineSelector",
+        "_JobSubsetSelector",
         [
             ("location_name", str),
             ("repository_name", str),
-            ("pipeline_name", str),
+            ("job_name", str),
             ("solid_selection", Optional[Sequence[str]]),
             ("asset_selection", Optional[Sequence[AssetKey]]),
         ],
     )
 ):
     """The information needed to resolve a job within a host process."""
 
     def __new__(
         cls,
         location_name: str,
         repository_name: str,
-        pipeline_name: str,
+        job_name: str,
         solid_selection: Optional[Sequence[str]],
         asset_selection: Optional[Sequence[AssetKey]] = None,
     ):
-        return super(PipelineSelector, cls).__new__(
+        return super(JobSubsetSelector, cls).__new__(
             cls,
             location_name=check.str_param(location_name, "location_name"),
             repository_name=check.str_param(repository_name, "repository_name"),
-            pipeline_name=check.str_param(pipeline_name, "pipeline_name"),
+            job_name=check.str_param(job_name, "job_name"),
             solid_selection=check.opt_nullable_sequence_param(
                 solid_selection, "solid_selection", str
             ),
             asset_selection=check.opt_nullable_sequence_param(
                 asset_selection, "asset_selection", AssetKey
             ),
         )
 
     def to_graphql_input(self):
         return {
             "repositoryLocationName": self.location_name,
             "repositoryName": self.repository_name,
-            "pipelineName": self.pipeline_name,
+            "pipelineName": self.job_name,
             "solidSelection": self.solid_selection,
         }
 
     def with_solid_selection(self, solid_selection):
         check.invariant(
             self.solid_selection is None,
             "Can not invoke with_solid_selection when solid_selection={} is already set".format(
                 solid_selection
             ),
         )
-        return PipelineSelector(
-            self.location_name, self.repository_name, self.pipeline_name, solid_selection
+        return JobSubsetSelector(
+            self.location_name, self.repository_name, self.job_name, solid_selection
         )
 
 
 @whitelist_for_serdes
 class JobSelector(
     NamedTuple(
         "_JobSelector", [("location_name", str), ("repository_name", str), ("job_name", str)]
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/sensor_definition.py` & `dagster-1.3.3/dagster/_core/definitions/sensor_definition.py`

 * *Files 6% similar despite different names*

```diff
@@ -43,26 +43,26 @@
     DagsterInvalidInvocationError,
     DagsterInvalidSubsetError,
     DagsterInvariantViolationError,
 )
 from dagster._core.instance import DagsterInstance
 from dagster._core.instance.ref import InstanceRef
 from dagster._serdes import whitelist_for_serdes
-from dagster._utils import normalize_to_repository
+from dagster._utils import IHasInternalInit, normalize_to_repository
 
 from ..decorator_utils import (
     get_function_params,
 )
 from .asset_selection import AssetSelection
 from .graph_definition import GraphDefinition
 from .job_definition import JobDefinition
 from .run_request import (
     AddDynamicPartitionsRequest,
+    DagsterRunReaction,
     DeleteDynamicPartitionsRequest,
-    PipelineRunReaction,
     RunRequest,
     SensorResult,
     SkipReason,
 )
 from .target import DirectTarget, ExecutableDefinition, RepoRelativeTarget
 from .unresolved_asset_job_definition import UnresolvedAssetJobDefinition
 from .utils import check_valid_name
@@ -111,14 +111,16 @@
             the sensor belongs to. If needed by the sensor top-level resource definitions will be
             pulled from this repository. You can provide either this or `definitions`.
         instance (Optional[DagsterInstance]): The deserialized instance can also be passed in
             directly (primarily useful in testing contexts).
         definitions (Optional[Definitions]): `Definitions` object that the sensor is defined in.
             If needed by the sensor, top-level resource definitions will be pulled from these
             definitions. You can provide either this or `repository_def`.
+        resources (Optional[Dict[str, Any]]): A dict of resource keys to resource
+            definitions to be made available during sensor execution.
 
     Example:
         .. code-block:: python
 
             from dagster import sensor, SensorEvaluationContext
 
             @sensor
@@ -212,14 +214,15 @@
             sensor_name=self._sensor_name,
             resources={
                 **(self._resource_defs or {}),
                 **wrap_resources_for_execution(resources_dict),
             },
         )
 
+    @public
     @property
     def resources(self) -> Resources:
         from dagster._core.definitions.scoped_resources_builder import (
             IContainsGenerator,
         )
         from dagster._core.execution.build_resources import build_resources
 
@@ -349,19 +352,19 @@
 
     @property
     def log_key(self) -> Optional[List[str]]:
         return self._log_key
 
 
 RawSensorEvaluationFunctionReturn = Union[
-    Iterator[Union[SkipReason, RunRequest, PipelineRunReaction, SensorResult]],
+    Iterator[Union[SkipReason, RunRequest, DagsterRunReaction, SensorResult]],
     Sequence[RunRequest],
     SkipReason,
     RunRequest,
-    PipelineRunReaction,
+    DagsterRunReaction,
     SensorResult,
 ]
 RawSensorEvaluationFunction: TypeAlias = Callable[..., RawSensorEvaluationFunctionReturn]
 
 SensorEvaluationFunction: TypeAlias = Callable[..., Iterator[Union[SkipReason, RunRequest]]]
 
 
@@ -435,15 +438,15 @@
             req_keys_to_delete_by_partitions_def_name[req.partitions_def_name].update(
                 req.partition_keys
             )
         else:
             check.failed(f"Unexpected dynamic partition request type: {req}")
 
 
-class SensorDefinition:
+class SensorDefinition(IHasInternalInit):
     """Define a sensor that initiates a set of runs based on some external state.
 
     Args:
         evaluation_fn (Callable[[SensorEvaluationContext]]): The core evaluation function for the
             sensor, which is run at an interval to determine whether a run should be launched or
             not. Takes a :py:class:`~dagster.SensorEvaluationContext`.
 
@@ -464,23 +467,25 @@
     def with_updated_jobs(self, new_jobs: Sequence[ExecutableDefinition]) -> "SensorDefinition":
         """Returns a copy of this sensor with the jobs replaced.
 
         Args:
             job (ExecutableDefinition): The job that should execute when this
                 schedule runs.
         """
-        return SensorDefinition(
+        return SensorDefinition.dagster_internal_init(
             name=self.name,
             evaluation_fn=self._evaluation_fn,
             minimum_interval_seconds=self.minimum_interval_seconds,
             description=self.description,
+            job_name=None,  # if original init was passed job name, was resolved to a job
             jobs=new_jobs if len(new_jobs) > 1 else None,
             job=new_jobs[0] if len(new_jobs) == 1 else None,
             default_status=self.default_status,
             asset_selection=self.asset_selection,
+            required_resource_keys=self.required_resource_keys,
         )
 
     def with_updated_job(self, new_job: ExecutableDefinition) -> "SensorDefinition":
         """Returns a copy of this sensor with the job replaced.
 
         Args:
             job (ExecutableDefinition): The job that should execute when this
@@ -525,15 +530,15 @@
 
         jobs = jobs if jobs else [job] if job else None
 
         targets: Optional[List[Union[RepoRelativeTarget, DirectTarget]]] = None
         if job_name:
             targets = [
                 RepoRelativeTarget(
-                    pipeline_name=check.str_param(job_name, "job_name"),
+                    job_name=check.str_param(job_name, "job_name"),
                     solid_selection=None,
                 )
             ]
         elif job:
             targets = [DirectTarget(job)]
         elif jobs:
             targets = [DirectTarget(job) for job in jobs]
@@ -548,22 +553,24 @@
         self._raw_fn: RawSensorEvaluationFunction = check.callable_param(
             evaluation_fn, "evaluation_fn"
         )
         self._evaluation_fn: Union[
             SensorEvaluationFunction,
             Callable[
                 [SensorEvaluationContext],
-                Iterator[Union[SkipReason, RunRequest, PipelineRunReaction]],
+                Iterator[Union[SkipReason, RunRequest, DagsterRunReaction]],
             ],
         ] = wrap_sensor_evaluation(self._name, evaluation_fn)
         self._min_interval = check.opt_int_param(
             minimum_interval_seconds, "minimum_interval_seconds", DEFAULT_SENSOR_DAEMON_INTERVAL
         )
         self._description = check.opt_str_param(description, "description")
-        self._targets = check.opt_list_param(targets, "targets", (DirectTarget, RepoRelativeTarget))
+        self._targets: Sequence[Union[RepoRelativeTarget, DirectTarget]] = check.opt_list_param(
+            targets, "targets", (DirectTarget, RepoRelativeTarget)
+        )
         self._default_status = check.inst_param(
             default_status, "default_status", DefaultSensorStatus
         )
         self._asset_selection = check.opt_inst_param(
             asset_selection, "asset_selection", AssetSelection
         )
         validate_resource_annotated_function(self._raw_fn)
@@ -577,14 +584,41 @@
             ),
         )
         self._required_resource_keys = (
             check.opt_set_param(required_resource_keys, "required_resource_keys", of_type=str)
             or resource_arg_names
         )
 
+    @staticmethod
+    def dagster_internal_init(
+        *,
+        name: Optional[str],
+        evaluation_fn: Optional[RawSensorEvaluationFunction],
+        job_name: Optional[str],
+        minimum_interval_seconds: Optional[int],
+        description: Optional[str],
+        job: Optional[ExecutableDefinition],
+        jobs: Optional[Sequence[ExecutableDefinition]],
+        default_status: DefaultSensorStatus = DefaultSensorStatus.STOPPED,
+        asset_selection: Optional[AssetSelection],
+        required_resource_keys: Optional[Set[str]],
+    ) -> "SensorDefinition":
+        return SensorDefinition(
+            name=name,
+            evaluation_fn=evaluation_fn,
+            job_name=job_name,
+            minimum_interval_seconds=minimum_interval_seconds,
+            description=description,
+            job=job,
+            jobs=jobs,
+            default_status=default_status,
+            asset_selection=asset_selection,
+            required_resource_keys=required_resource_keys,
+        )
+
     def __call__(self, *args, **kwargs) -> RawSensorEvaluationFunctionReturn:
         context_param_name_if_present = get_context_param_name(self._raw_fn)
         context = get_or_create_sensor_context(self._raw_fn, *args, **kwargs)
 
         context_param = (
             {context_param_name_if_present: context} if context_param_name_if_present else {}
         )
@@ -630,15 +664,15 @@
                 )
         raise DagsterInvalidDefinitionError("No job was provided to SensorDefinition.")
 
     @public
     @property
     def jobs(self) -> List[Union[JobDefinition, GraphDefinition, UnresolvedAssetJobDefinition]]:
         if self._targets and all(isinstance(target, DirectTarget) for target in self._targets):
-            return [target.target for target in self._targets]
+            return [target.target for target in self._targets]  # type: ignore  # (illegible conditional)
         raise DagsterInvalidDefinitionError("No job was provided to SensorDefinition.")
 
     @property
     def sensor_type(self) -> SensorType:
         return SensorType.STANDARD
 
     def evaluate_tick(self, context: "SensorEvaluationContext") -> "SensorExecutionData":
@@ -653,25 +687,25 @@
         """
         context = check.inst_param(context, "context", SensorEvaluationContext)
 
         result = list(self._evaluation_fn(context))
 
         skip_message: Optional[str] = None
         run_requests: List[RunRequest] = []
-        pipeline_run_reactions: List[PipelineRunReaction] = []
+        dagster_run_reactions: List[DagsterRunReaction] = []
         dynamic_partitions_requests: Optional[
             Sequence[Union[AddDynamicPartitionsRequest, DeleteDynamicPartitionsRequest]]
         ] = []
         updated_cursor = context.cursor
 
         if not result or result == [None]:
             skip_message = "Sensor function returned an empty result"
         elif len(result) == 1:
             item = result[0]
-            check.inst(item, (SkipReason, RunRequest, PipelineRunReaction, SensorResult))
+            check.inst(item, (SkipReason, RunRequest, DagsterRunReaction, SensorResult))
 
             if isinstance(item, SensorResult):
                 run_requests = list(item.run_requests) if item.run_requests else []
                 skip_message = (
                     item.skip_reason.skip_message
                     if item.skip_reason
                     else (None if run_requests else "Sensor function returned an empty result")
@@ -688,60 +722,58 @@
                     )
                 updated_cursor = item.cursor
 
             elif isinstance(item, RunRequest):
                 run_requests = [item]
             elif isinstance(item, SkipReason):
                 skip_message = item.skip_message if isinstance(item, SkipReason) else None
-            elif isinstance(item, PipelineRunReaction):
-                pipeline_run_reactions = (
-                    [cast(PipelineRunReaction, item)]
-                    if isinstance(item, PipelineRunReaction)
-                    else []
+            elif isinstance(item, DagsterRunReaction):
+                dagster_run_reactions = (
+                    [cast(DagsterRunReaction, item)] if isinstance(item, DagsterRunReaction) else []
                 )
             else:
                 check.failed(f"Unexpected type {type(item)} in sensor result")
         else:
             if any(isinstance(item, SensorResult) for item in result):
                 check.failed(
                     "When a SensorResult is returned from a sensor, it must be the only object"
                     " returned."
                 )
 
-            check.is_list(result, (SkipReason, RunRequest, PipelineRunReaction))
+            check.is_list(result, (SkipReason, RunRequest, DagsterRunReaction))
             has_skip = any(map(lambda x: isinstance(x, SkipReason), result))
             run_requests = [item for item in result if isinstance(item, RunRequest)]
-            pipeline_run_reactions = [
-                item for item in result if isinstance(item, PipelineRunReaction)
+            dagster_run_reactions = [
+                item for item in result if isinstance(item, DagsterRunReaction)
             ]
 
             if has_skip:
                 if len(run_requests) > 0:
                     check.failed(
                         "Expected a single SkipReason or one or more RunRequests: received both "
                         "RunRequest and SkipReason"
                     )
-                elif len(pipeline_run_reactions) > 0:
+                elif len(dagster_run_reactions) > 0:
                     check.failed(
-                        "Expected a single SkipReason or one or more PipelineRunReaction: "
-                        "received both PipelineRunReaction and SkipReason"
+                        "Expected a single SkipReason or one or more DagsterRunReaction: "
+                        "received both DagsterRunReaction and SkipReason"
                     )
                 else:
                     check.failed("Expected a single SkipReason: received multiple SkipReasons")
 
         _check_dynamic_partitions_requests(dynamic_partitions_requests)
         resolved_run_requests = self.resolve_run_requests(
             run_requests, context, self._asset_selection, dynamic_partitions_requests
         )
 
         return SensorExecutionData(
             resolved_run_requests,
             skip_message,
             updated_cursor,
-            pipeline_run_reactions,
+            dagster_run_reactions,
             captured_log_key=context.log_key if context.has_captured_logs() else None,
             dynamic_partitions_requests=dynamic_partitions_requests,
         )
 
     def has_loadable_targets(self) -> bool:
         for target in self._targets:
             if isinstance(target, DirectTarget):
@@ -774,15 +806,15 @@
                 raise DagsterInvariantViolationError(
                     "Must provide repository def to build_sensor_context when yielding partitioned"
                     " run requests"
                 )
             return context.repository_def.get_job(job_name)
 
         has_multiple_targets = len(self._targets) > 1
-        target_names = [target.pipeline_name for target in self._targets]
+        target_names = [target.job_name for target in self._targets]
 
         if run_requests and len(self._targets) == 0 and not self._asset_selection:
             raise Exception(
                 f"Error in sensor {self._name}: Sensor evaluation function returned a RunRequest "
                 "for a sensor lacking a specified target (job_name, job, or jobs). Targets "
                 "can be specified by providing job, jobs, or job_name to the @sensor "
                 "decorator."
@@ -842,77 +874,79 @@
     @property
     def job_name(self) -> Optional[str]:
         if len(self._targets) > 1:
             raise DagsterInvalidInvocationError(
                 f"Cannot use `job_name` property for sensor {self.name}, which targets multiple"
                 " jobs."
             )
-        return self._targets[0].pipeline_name
+        return self._targets[0].job_name
 
     @public
     @property
     def default_status(self) -> DefaultSensorStatus:
         return self._default_status
 
     @property
     def asset_selection(self) -> Optional[AssetSelection]:
         return self._asset_selection
 
 
-@whitelist_for_serdes
+@whitelist_for_serdes(
+    storage_field_names={"dagster_run_reactions": "pipeline_run_reactions"},
+)
 class SensorExecutionData(
     NamedTuple(
         "_SensorExecutionData",
         [
             ("run_requests", Optional[Sequence[RunRequest]]),
             ("skip_message", Optional[str]),
             ("cursor", Optional[str]),
-            ("pipeline_run_reactions", Optional[Sequence[PipelineRunReaction]]),
+            ("dagster_run_reactions", Optional[Sequence[DagsterRunReaction]]),
             ("captured_log_key", Optional[Sequence[str]]),
             (
                 "dynamic_partitions_requests",
                 Optional[
                     Sequence[Union[AddDynamicPartitionsRequest, DeleteDynamicPartitionsRequest]]
                 ],
             ),
         ],
     )
 ):
+    dagster_run_reactions: Optional[Sequence[DagsterRunReaction]]
+
     def __new__(
         cls,
         run_requests: Optional[Sequence[RunRequest]] = None,
         skip_message: Optional[str] = None,
         cursor: Optional[str] = None,
-        pipeline_run_reactions: Optional[Sequence[PipelineRunReaction]] = None,
+        dagster_run_reactions: Optional[Sequence[DagsterRunReaction]] = None,
         captured_log_key: Optional[Sequence[str]] = None,
         dynamic_partitions_requests: Optional[
             Sequence[Union[AddDynamicPartitionsRequest, DeleteDynamicPartitionsRequest]]
         ] = None,
     ):
         check.opt_sequence_param(run_requests, "run_requests", RunRequest)
         check.opt_str_param(skip_message, "skip_message")
         check.opt_str_param(cursor, "cursor")
-        check.opt_sequence_param(
-            pipeline_run_reactions, "pipeline_run_reactions", PipelineRunReaction
-        )
+        check.opt_sequence_param(dagster_run_reactions, "dagster_run_reactions", DagsterRunReaction)
         check.opt_list_param(captured_log_key, "captured_log_key", str)
         check.opt_sequence_param(
             dynamic_partitions_requests,
             "dynamic_partitions_requests",
             (AddDynamicPartitionsRequest, DeleteDynamicPartitionsRequest),
         )
         check.invariant(
             not (run_requests and skip_message), "Found both skip data and run request data"
         )
         return super(SensorExecutionData, cls).__new__(
             cls,
             run_requests=run_requests,
             skip_message=skip_message,
             cursor=cursor,
-            pipeline_run_reactions=pipeline_run_reactions,
+            dagster_run_reactions=dagster_run_reactions,
             captured_log_key=captured_log_key,
             dynamic_partitions_requests=dynamic_partitions_requests,
         )
 
 
 def wrap_sensor_evaluation(
     sensor_name: str,
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/source_asset.py` & `dagster-1.3.3/dagster/_core/definitions/source_asset.py`

 * *Files 1% similar despite different names*

```diff
@@ -281,26 +281,28 @@
                 metadata=self.raw_metadata,
                 resource_defs=relevant_resource_defs,
                 group_name=self.group_name,
                 observe_fn=self.observe_fn,
                 _required_resource_keys=self._required_resource_keys,
             )
 
-    def with_group_name(self, group_name: str) -> "SourceAsset":
-        if self.group_name != DEFAULT_GROUP_NAME:
+    def with_attributes(
+        self, group_name: Optional[str] = None, key: Optional[AssetKey] = None
+    ) -> "SourceAsset":
+        if group_name is not None and self.group_name != DEFAULT_GROUP_NAME:
             raise DagsterInvalidDefinitionError(
                 "A group name has already been provided to source asset"
                 f" {self.key.to_user_string()}"
             )
 
         with warnings.catch_warnings():
             warnings.simplefilter("ignore", category=ExperimentalWarning)
 
             return SourceAsset(
-                key=self.key,
+                key=key or self.key,
                 metadata=self.raw_metadata,
                 io_manager_key=self.io_manager_key,
                 io_manager_def=self.io_manager_def,
                 description=self.description,
                 partitions_def=self.partitions_def,
                 group_name=group_name,
                 resource_defs=self.resource_defs,
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/step_launcher.py` & `dagster-1.3.3/dagster/_core/definitions/step_launcher.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,29 +1,29 @@
 from abc import ABC, abstractmethod
 from typing import TYPE_CHECKING, Mapping, NamedTuple, Optional
 
 import dagster._check as check
-from dagster._core.definitions.reconstruct import ReconstructablePipeline
+from dagster._core.definitions.reconstruct import ReconstructableJob
 from dagster._core.execution.retries import RetryMode
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 
 if TYPE_CHECKING:
     from dagster._core.execution.plan.state import KnownExecutionState
 
 
 class StepRunRef(
     NamedTuple(
         "_StepRunRef",
         [
             ("run_config", Mapping[str, object]),
             ("dagster_run", DagsterRun),
             ("run_id", str),
             ("retry_mode", RetryMode),
             ("step_key", str),
-            ("recon_pipeline", ReconstructablePipeline),
+            ("recon_job", ReconstructableJob),
             ("known_state", Optional["KnownExecutionState"]),
         ],
     )
 ):
     """A serializable object that specifies what's needed to hydrate a step so
     that it can be executed in a process outside the plan process.
 
@@ -33,27 +33,27 @@
     def __new__(
         cls,
         run_config: Mapping[str, object],
         dagster_run: DagsterRun,
         run_id: str,
         retry_mode: RetryMode,
         step_key: str,
-        recon_pipeline: ReconstructablePipeline,
+        recon_job: ReconstructableJob,
         known_state: Optional["KnownExecutionState"],
     ):
         from dagster._core.execution.plan.state import KnownExecutionState
 
         return super(StepRunRef, cls).__new__(
             cls,
             check.mapping_param(run_config, "run_config", key_type=str),
             check.inst_param(dagster_run, "dagster_run", DagsterRun),
             check.str_param(run_id, "run_id"),
             check.inst_param(retry_mode, "retry_mode", RetryMode),
             check.str_param(step_key, "step_key"),
-            check.inst_param(recon_pipeline, "recon_pipeline", ReconstructablePipeline),
+            check.inst_param(recon_job, "recon_job", ReconstructableJob),
             check.opt_inst_param(known_state, "known_state", KnownExecutionState),
         )
 
 
 class StepLauncher(ABC):
     """A StepLauncher is responsible for executing steps, either in-process or in an external process.
     """
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/target.py` & `dagster-1.3.3/dagster/_core/definitions/target.py`

 * *Files 6% similar despite different names*

```diff
@@ -12,18 +12,18 @@
 
 ExecutableDefinition: TypeAlias = Union[
     JobDefinition, "GraphDefinition", UnresolvedAssetJobDefinition
 ]
 
 
 class RepoRelativeTarget(NamedTuple):
-    """The thing to be executed by a schedule or sensor, selecting by name a pipeline in the same repository.
+    """The thing to be executed by a schedule or sensor, selecting by name a job in the same repository.
     """
 
-    pipeline_name: str
+    job_name: str
     solid_selection: Optional[Sequence[str]]
 
 
 class DirectTarget(
     NamedTuple(
         "_DirectTarget",
         [("target", ExecutableDefinition)],
@@ -45,17 +45,17 @@
 
         return super().__new__(
             cls,
             target,
         )
 
     @property
-    def pipeline_name(self) -> str:
+    def job_name(self) -> str:
         return self.target.name
 
     @property
     def solid_selection(self):
-        # open question on how to direct target subset pipeline
+        # open question on how to direct target subset job
         return None
 
     def load(self) -> ExecutableDefinition:
         return self.target
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/time_window_partition_mapping.py` & `dagster-1.3.3/dagster/_core/definitions/time_window_partition_mapping.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/time_window_partitions.py` & `dagster-1.3.3/dagster/_core/definitions/time_window_partitions.py`

 * *Files 2% similar despite different names*

```diff
@@ -31,19 +31,17 @@
     is_valid_cron_schedule,
     reverse_cron_string_iterator,
 )
 
 from ..errors import (
     DagsterInvalidDefinitionError,
     DagsterInvalidDeserializationVersionError,
-    DagsterUnknownPartitionError,
 )
 from .partition import (
     DEFAULT_DATE_FORMAT,
-    Partition,
     PartitionedConfig,
     PartitionsDefinition,
     PartitionsSubset,
     ScheduleType,
     cron_schedule_from_schedule_type_and_offsets,
 )
 from .partition_key_range import PartitionKeyRange
@@ -58,15 +56,15 @@
     """
 
     start: PublicAttr[datetime]
     end: PublicAttr[datetime]
 
 
 class TimeWindowPartitionsDefinition(
-    PartitionsDefinition[TimeWindow],
+    PartitionsDefinition,
     NamedTuple(
         "_TimeWindowPartitionsDefinition",
         [
             ("start", PublicAttr[datetime]),
             ("timezone", PublicAttr[str]),
             ("fmt", PublicAttr[str]),
             ("end_offset", PublicAttr[int]),
@@ -125,30 +123,31 @@
             check.invariant(
                 schedule_type is None and not minute_offset and not hour_offset and not day_offset,
                 (
                     "If cron_schedule argument is provided, then schedule_type, minute_offset, "
                     "hour_offset, and day_offset can't also be provided"
                 ),
             )
-            if not is_valid_cron_schedule(cron_schedule):
-                raise DagsterInvalidDefinitionError(
-                    f"Found invalid cron schedule '{cron_schedule}' for a"
-                    " TimeWindowPartitionsDefinition."
-                )
         else:
             if schedule_type is None:
                 check.failed("One of schedule_type and cron_schedule must be provided")
 
             cron_schedule = cron_schedule_from_schedule_type_and_offsets(
                 schedule_type=schedule_type,
                 minute_offset=minute_offset or 0,
                 hour_offset=hour_offset or 0,
                 day_offset=day_offset or 0,
             )
 
+        if not is_valid_cron_schedule(cron_schedule):
+            raise DagsterInvalidDefinitionError(
+                f"Found invalid cron schedule '{cron_schedule}' for a"
+                " TimeWindowPartitionsDefinition."
+            )
+
         return super(TimeWindowPartitionsDefinition, cls).__new__(
             cls, start_dt, timezone, fmt, end_offset, cron_schedule
         )
 
     def get_current_timestamp(self, current_time: Optional[datetime] = None) -> float:
         return (
             pendulum.instance(current_time, tz=self.timezone)
@@ -216,41 +215,39 @@
                 break
 
         if reached_end and self.end_offset < 0:
             partition_keys = partition_keys[: self.end_offset]
 
         return partition_keys
 
-    def get_partitions(
+    def get_partition_keys(
         self,
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> Sequence[Partition[TimeWindow]]:
+    ) -> Sequence[str]:
         current_timestamp = self.get_current_timestamp(current_time=current_time)
 
         partitions_past_current_time = 0
-        partitions: List[Partition[TimeWindow]] = []
+        partition_keys: List[str] = []
         for time_window in self._iterate_time_windows(self.start):
             if (
                 time_window.end.timestamp() <= current_timestamp
                 or partitions_past_current_time < self.end_offset
             ):
-                partitions.append(
-                    Partition(value=time_window, name=time_window.start.strftime(self.fmt))
-                )
+                partition_keys.append(time_window.start.strftime(self.fmt))
 
                 if time_window.end.timestamp() > current_timestamp:
                     partitions_past_current_time += 1
             else:
                 break
 
         if self.end_offset < 0:
-            partitions = partitions[: self.end_offset]
+            partition_keys = partition_keys[: self.end_offset]
 
-        return partitions
+        return partition_keys
 
     def _get_validated_time_window_for_partition_key(
         self, partition_key: str, current_time: Optional[datetime] = None
     ) -> Optional[TimeWindow]:
         """Returns a TimeWindow for the given partition key if it is valid, otherwise returns None.
         """
         try:
@@ -267,31 +264,14 @@
             or time_window.start > last_partition_window.start
             or time_window.start.strftime(self.fmt) != partition_key
         ):
             return None
 
         return time_window
 
-    def get_partition(
-        self,
-        partition_key: str,
-        current_time: Optional[datetime] = None,
-        dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
-    ) -> Partition[TimeWindow]:
-        time_window = self._get_validated_time_window_for_partition_key(
-            partition_key, current_time=current_time
-        )
-
-        if time_window is None:
-            raise DagsterUnknownPartitionError(
-                f"Could not find a partition with key `{partition_key}`"
-            )
-
-        return Partition(value=time_window, name=partition_key)
-
     def __str__(self) -> str:
         schedule_str = (
             self.schedule_type.value.capitalize() if self.schedule_type else self.cron_schedule
         )
         partition_def_str = (
             f"{schedule_str}, starting {self.start.strftime(self.fmt)} {self.timezone}."
         )
@@ -753,16 +733,15 @@
 
     def has_partition_key(
         self,
         partition_key: str,
         current_time: Optional[datetime] = None,
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
     ) -> bool:
-        time_window = self._get_validated_time_window_for_partition_key(partition_key, current_time)
-        return True if time_window else False
+        return bool(self._get_validated_time_window_for_partition_key(partition_key, current_time))
 
 
 class DailyPartitionsDefinition(TimeWindowPartitionsDefinition):
     """A set of daily partitions.
 
     The first partition in the set will start at the start_date at midnight. The last partition
     in the set will end before the current time, unless the end_offset argument is set to a
@@ -812,34 +791,52 @@
             hour_offset=hour_offset,
             timezone=timezone,
             fmt=_fmt,
             end_offset=end_offset,
         )
 
 
+def wrap_time_window_run_config_fn(
+    run_config_fn: Optional[Callable[[datetime, datetime], Mapping[str, Any]]],
+    partitions_def: TimeWindowPartitionsDefinition,
+) -> Callable[[str], Mapping[str, Any]]:
+    def _run_config_wrapper(key: str) -> Mapping[str, Any]:
+        if not run_config_fn:
+            return {}
+        time_window = partitions_def.time_window_for_partition_key(key)
+        return run_config_fn(time_window.start, time_window.end)
+
+    return _run_config_wrapper
+
+
 def wrap_time_window_tags_fn(
-    tags_fn: Optional[Callable[[datetime, datetime], Mapping[str, str]]]
-) -> Callable[[Partition], Mapping[str, str]]:
-    def _tag_wrapper(partition: Partition) -> Mapping[str, str]:
+    tags_fn: Optional[Callable[[datetime, datetime], Mapping[str, str]]],
+    partitions_def: TimeWindowPartitionsDefinition,
+) -> Callable[[str], Mapping[str, str]]:
+    def _tag_wrapper(key: str) -> Mapping[str, str]:
         if not tags_fn:
             return {}
-        return tags_fn(cast(datetime, partition.value[0]), cast(datetime, partition.value[1]))
+        time_window = partitions_def.time_window_for_partition_key(key)
+        return tags_fn(time_window.start, time_window.end)
 
     return _tag_wrapper
 
 
 def daily_partitioned_config(
     start_date: Union[datetime, str],
     minute_offset: int = 0,
     hour_offset: int = 0,
     timezone: Optional[str] = None,
     fmt: Optional[str] = None,
     end_offset: int = 0,
     tags_for_partition_fn: Optional[Callable[[datetime, datetime], Mapping[str, str]]] = None,
-) -> Callable[[Callable[[datetime, datetime], Mapping[str, Any]]], PartitionedConfig]:
+) -> Callable[
+    [Callable[[datetime, datetime], Mapping[str, Any]]],
+    PartitionedConfig[DailyPartitionsDefinition],
+]:
     """Defines run config over a set of daily partitions.
 
     The decorated function should accept a start datetime and end datetime, which represent the bounds
     of the date partition the config should delineate.
 
     The decorated function should return a run config dictionary.
 
@@ -872,31 +869,35 @@
         @daily_partitioned_config(start_date="2022-03-12")
         # creates partitions (2022-03-12-00:00, 2022-03-13-00:00), (2022-03-13-00:00, 2022-03-14-00:00), ...
 
         @daily_partitioned_config(start_date="2022-03-12", minute_offset=15, hour_offset=16)
         # creates partitions (2022-03-12-16:15, 2022-03-13-16:15), (2022-03-13-16:15, 2022-03-14-16:15), ...
     """
 
-    def inner(fn: Callable[[datetime, datetime], Mapping[str, Any]]) -> PartitionedConfig:
+    def inner(
+        fn: Callable[[datetime, datetime], Mapping[str, Any]]
+    ) -> PartitionedConfig[DailyPartitionsDefinition]:
         check.callable_param(fn, "fn")
 
+        partitions_def = DailyPartitionsDefinition(
+            start_date=start_date,
+            minute_offset=minute_offset,
+            hour_offset=hour_offset,
+            timezone=timezone,
+            fmt=fmt,
+            end_offset=end_offset,
+        )
+
         return PartitionedConfig(
-            run_config_for_partition_fn=lambda partition: fn(
-                partition.value[0], partition.value[1]
-            ),
-            partitions_def=DailyPartitionsDefinition(
-                start_date=start_date,
-                minute_offset=minute_offset,
-                hour_offset=hour_offset,
-                timezone=timezone,
-                fmt=fmt,
-                end_offset=end_offset,
-            ),
+            run_config_for_partition_key_fn=wrap_time_window_run_config_fn(fn, partitions_def),
+            partitions_def=partitions_def,
             decorated_fn=fn,
-            tags_for_partition_fn=wrap_time_window_tags_fn(tags_for_partition_fn),
+            tags_for_partition_key_fn=wrap_time_window_tags_fn(
+                tags_for_partition_fn, partitions_def
+            ),
         )
 
     return inner
 
 
 class HourlyPartitionsDefinition(TimeWindowPartitionsDefinition):
     """A set of hourly partitions.
@@ -953,15 +954,18 @@
 def hourly_partitioned_config(
     start_date: Union[datetime, str],
     minute_offset: int = 0,
     timezone: Optional[str] = None,
     fmt: Optional[str] = None,
     end_offset: int = 0,
     tags_for_partition_fn: Optional[Callable[[datetime, datetime], Mapping[str, str]]] = None,
-) -> Callable[[Callable[[datetime, datetime], Mapping[str, Any]]], PartitionedConfig]:
+) -> Callable[
+    [Callable[[datetime, datetime], Mapping[str, Any]]],
+    PartitionedConfig[HourlyPartitionsDefinition],
+]:
     """Defines run config over a set of hourly partitions.
 
     The decorated function should accept a start datetime and end datetime, which represent the date
     partition the config should delineate.
 
     The decorated function should return a run config dictionary.
 
@@ -993,30 +997,33 @@
         @hourly_partitioned_config(start_date=datetime(2022, 03, 12))
         # creates partitions (2022-03-12-00:00, 2022-03-12-01:00), (2022-03-12-01:00, 2022-03-12-02:00), ...
 
         @hourly_partitioned_config(start_date=datetime(2022, 03, 12), minute_offset=15)
         # creates partitions (2022-03-12-00:15, 2022-03-12-01:15), (2022-03-12-01:15, 2022-03-12-02:15), ...
     """
 
-    def inner(fn: Callable[[datetime, datetime], Mapping[str, Any]]) -> PartitionedConfig:
+    def inner(
+        fn: Callable[[datetime, datetime], Mapping[str, Any]]
+    ) -> PartitionedConfig[HourlyPartitionsDefinition]:
         check.callable_param(fn, "fn")
 
+        partitions_def = HourlyPartitionsDefinition(
+            start_date=start_date,
+            minute_offset=minute_offset,
+            timezone=timezone,
+            fmt=fmt,
+            end_offset=end_offset,
+        )
         return PartitionedConfig(
-            run_config_for_partition_fn=lambda partition: fn(
-                partition.value[0], partition.value[1]
-            ),
-            partitions_def=HourlyPartitionsDefinition(
-                start_date=start_date,
-                minute_offset=minute_offset,
-                timezone=timezone,
-                fmt=fmt,
-                end_offset=end_offset,
-            ),
+            run_config_for_partition_key_fn=wrap_time_window_run_config_fn(fn, partitions_def),
+            partitions_def=partitions_def,
             decorated_fn=fn,
-            tags_for_partition_fn=wrap_time_window_tags_fn(tags_for_partition_fn),
+            tags_for_partition_key_fn=wrap_time_window_tags_fn(
+                tags_for_partition_fn, partitions_def
+            ),
         )
 
     return inner
 
 
 class MonthlyPartitionsDefinition(TimeWindowPartitionsDefinition):
     """A set of monthly partitions.
@@ -1083,15 +1090,18 @@
     minute_offset: int = 0,
     hour_offset: int = 0,
     day_offset: int = 1,
     timezone: Optional[str] = None,
     fmt: Optional[str] = None,
     end_offset: int = 0,
     tags_for_partition_fn: Optional[Callable[[datetime, datetime], Mapping[str, str]]] = None,
-) -> Callable[[Callable[[datetime, datetime], Mapping[str, Any]]], PartitionedConfig]:
+) -> Callable[
+    [Callable[[datetime, datetime], Mapping[str, Any]]],
+    PartitionedConfig[MonthlyPartitionsDefinition],
+]:
     """Defines run config over a set of monthly partitions.
 
     The decorated function should accept a start datetime and end datetime, which represent the date
     partition the config should delineate.
 
     The decorated function should return a run config dictionary.
 
@@ -1127,32 +1137,36 @@
         @monthly_partitioned_config(start_date="2022-03-12")
         # creates partitions (2022-04-01-00:00, 2022-05-01-00:00), (2022-05-01-00:00, 2022-06-01-00:00), ...
 
         @monthly_partitioned_config(start_date="2022-03-12", minute_offset=15, hour_offset=3, day_offset=5)
         # creates partitions (2022-04-05-03:15, 2022-05-05-03:15), (2022-05-05-03:15, 2022-06-05-03:15), ...
     """
 
-    def inner(fn: Callable[[datetime, datetime], Mapping[str, Any]]) -> PartitionedConfig:
+    def inner(
+        fn: Callable[[datetime, datetime], Mapping[str, Any]]
+    ) -> PartitionedConfig[MonthlyPartitionsDefinition]:
         check.callable_param(fn, "fn")
 
+        partitions_def = MonthlyPartitionsDefinition(
+            start_date=start_date,
+            minute_offset=minute_offset,
+            hour_offset=hour_offset,
+            day_offset=day_offset,
+            timezone=timezone,
+            fmt=fmt,
+            end_offset=end_offset,
+        )
+
         return PartitionedConfig(
-            run_config_for_partition_fn=lambda partition: fn(
-                partition.value[0], partition.value[1]
-            ),
-            partitions_def=MonthlyPartitionsDefinition(
-                start_date=start_date,
-                minute_offset=minute_offset,
-                hour_offset=hour_offset,
-                day_offset=day_offset,
-                timezone=timezone,
-                fmt=fmt,
-                end_offset=end_offset,
-            ),
+            run_config_for_partition_key_fn=wrap_time_window_run_config_fn(fn, partitions_def),
+            partitions_def=partitions_def,
             decorated_fn=fn,
-            tags_for_partition_fn=wrap_time_window_tags_fn(tags_for_partition_fn),
+            tags_for_partition_key_fn=wrap_time_window_tags_fn(
+                tags_for_partition_fn, partitions_def
+            ),
         )
 
     return inner
 
 
 class WeeklyPartitionsDefinition(TimeWindowPartitionsDefinition):
     """Defines a set of weekly partitions.
@@ -1220,15 +1234,18 @@
     minute_offset: int = 0,
     hour_offset: int = 0,
     day_offset: int = 0,
     timezone: Optional[str] = None,
     fmt: Optional[str] = None,
     end_offset: int = 0,
     tags_for_partition_fn: Optional[Callable[[datetime, datetime], Mapping[str, str]]] = None,
-) -> Callable[[Callable[[datetime, datetime], Mapping[str, Any]]], PartitionedConfig]:
+) -> Callable[
+    [Callable[[datetime, datetime], Mapping[str, Any]]],
+    PartitionedConfig[WeeklyPartitionsDefinition],
+]:
     """Defines run config over a set of weekly partitions.
 
     The decorated function should accept a start datetime and end datetime, which represent the date
     partition the config should delineate.
 
     The decorated function should return a run config dictionary.
 
@@ -1265,32 +1282,35 @@
         @weekly_partitioned_config(start_date="2022-03-12")
         # creates partitions (2022-03-13-00:00, 2022-03-20-00:00), (2022-03-20-00:00, 2022-03-27-00:00), ...
 
         @weekly_partitioned_config(start_date="2022-03-12", minute_offset=15, hour_offset=3, day_offset=6)
         # creates partitions (2022-03-12-03:15, 2022-03-19-03:15), (2022-03-19-03:15, 2022-03-26-03:15), ...
     """
 
-    def inner(fn: Callable[[datetime, datetime], Mapping[str, Any]]) -> PartitionedConfig:
+    def inner(
+        fn: Callable[[datetime, datetime], Mapping[str, Any]]
+    ) -> PartitionedConfig[WeeklyPartitionsDefinition]:
         check.callable_param(fn, "fn")
 
+        partitions_def = WeeklyPartitionsDefinition(
+            start_date=start_date,
+            minute_offset=minute_offset,
+            hour_offset=hour_offset,
+            day_offset=day_offset,
+            timezone=timezone,
+            fmt=fmt,
+            end_offset=end_offset,
+        )
         return PartitionedConfig(
-            run_config_for_partition_fn=lambda partition: fn(
-                partition.value[0], partition.value[1]
-            ),
-            partitions_def=WeeklyPartitionsDefinition(
-                start_date=start_date,
-                minute_offset=minute_offset,
-                hour_offset=hour_offset,
-                day_offset=day_offset,
-                timezone=timezone,
-                fmt=fmt,
-                end_offset=end_offset,
-            ),
+            run_config_for_partition_key_fn=wrap_time_window_run_config_fn(fn, partitions_def),
+            partitions_def=partitions_def,
             decorated_fn=fn,
-            tags_for_partition_fn=wrap_time_window_tags_fn(tags_for_partition_fn),
+            tags_for_partition_key_fn=wrap_time_window_tags_fn(
+                tags_for_partition_fn, partitions_def
+            ),
         )
 
     return inner
 
 
 class TimeWindowPartitionsSubset(PartitionsSubset):
     # Every time we change the serialization format, we should increment the version number.
@@ -1382,14 +1402,15 @@
         dynamic_partitions_store: Optional[DynamicPartitionsStore] = None,
     ) -> Iterable[str]:
         partition_keys: List[str] = []
         for tw in self._get_partition_time_windows_not_in_subset(current_time):
             partition_keys.extend(self._partitions_def.get_partition_keys_in_time_window(tw))
         return partition_keys
 
+    @public
     def get_partition_keys(self, current_time: Optional[datetime] = None) -> Iterable[str]:
         if self._included_partition_keys is None:
             return [
                 pk
                 for time_window in self.included_time_windows
                 for pk in self._partitions_def.get_partition_keys_in_time_window(time_window)
             ]
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/unresolved_asset_job_definition.py` & `dagster-1.3.3/dagster/_core/definitions/unresolved_asset_job_definition.py`

 * *Files 1% similar despite different names*

```diff
@@ -129,32 +129,24 @@
             # since this requires querying the instance once per run request for the
             # existent dynamic partitions
             check.failed(
                 "run_request_for_partition is not supported for dynamic partitions. Instead, use"
                 " RunRequest(partition_key=...)"
             )
 
-        partition = self.partitions_def.get_partition(
-            partition_key, dynamic_partitions_store=None, current_time=current_time
-        )
+        self.partitions_def.validate_partition_key(partition_key, current_time=current_time)
+
         run_config = (
             run_config
             if run_config is not None
-            else partitioned_config.get_run_config_for_partition_key(
-                partition.name, dynamic_partitions_store=None, current_time=current_time
-            )
+            else partitioned_config.get_run_config_for_partition_key(partition_key)
         )
         run_request_tags = {
             **(tags or {}),
-            **partitioned_config.get_tags_for_partition_key(
-                partition_key,
-                dynamic_partitions_store=None,
-                current_time=current_time,
-                job_name=self.name,
-            ),
+            **partitioned_config.get_tags_for_partition_key(partition_key),
         }
 
         return RunRequest(
             job_name=self.name,
             run_key=run_key,
             run_config=run_config,
             tags=run_request_tags,
@@ -244,19 +236,19 @@
         )
 
 
 def define_asset_job(
     name: str,
     selection: Optional["CoercibleToAssetSelection"] = None,
     config: Optional[
-        Union[ConfigMapping, Mapping[str, Any], "PartitionedConfig[object]", "RunConfig"]
+        Union[ConfigMapping, Mapping[str, Any], "PartitionedConfig", "RunConfig"]
     ] = None,
     description: Optional[str] = None,
     tags: Optional[Mapping[str, Any]] = None,
-    partitions_def: Optional["PartitionsDefinition[Any]"] = None,
+    partitions_def: Optional["PartitionsDefinition"] = None,
     executor_def: Optional["ExecutorDefinition"] = None,
 ) -> UnresolvedAssetJobDefinition:
     """Creates a definition of a job which will either materialize a selection of assets or observe
     a selection of source assets. This will only be resolved to a JobDefinition once placed in a
     code location.
 
     Args:
@@ -278,15 +270,15 @@
             materialize assets. If the selection resolves to a mixed set of source assets and
             regular assets, an error will be thrown.
 
         config:
             Describes how the Job is parameterized at runtime.
 
             If no value is provided, then the schema for the job's run config is a standard
-            format based on its solids and resources.
+            format based on its ops and resources.
 
             If a dictionary is provided, then it must conform to the standard config schema, and
             it will be used as the job's run config for the job whenever the job is executed.
             The values provided will be viewable and editable in the Dagit playground, so be
             careful with secrets.
 
             If a :py:class:`ConfigMapping` object is provided, then the schema for the job's run config is
```

### Comparing `dagster-1.3.2/dagster/_core/definitions/utils.py` & `dagster-1.3.3/dagster/_core/definitions/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/definitions/version_strategy.py` & `dagster-1.3.3/dagster/_core/definitions/version_strategy.py`

 * *Files 12% similar despite different names*

```diff
@@ -17,22 +17,14 @@
         op_def (OpDefinition): The definition of the op to compute a version for.
         op_config (Any): The parsed config to be passed to the op during execution.
     """
 
     op_def: "OpDefinition"
     op_config: Any
 
-    @property
-    def solid_def(self) -> "OpDefinition":
-        return self.op_def
-
-    @property
-    def solid_config(self) -> Any:
-        return self.op_config
-
 
 class ResourceVersionContext(NamedTuple):
     """Provides execution-time information for computing the version for a resource.
 
     Attributes:
         resource_def (ResourceDefinition): The definition of the resource whose version will be computed.
         resource_config (Any): The parsed config to be passed to the resource during execution.
@@ -47,15 +39,15 @@
 
     When subclassing, `get_op_version` must be implemented, and
     `get_resource_version` can be optionally implemented.
 
     `get_op_version` should ingest an OpVersionContext, and `get_resource_version` should ingest a
     ResourceVersionContext. From that,  each synthesize a unique string called
     a `version`, which will
-    be tagged to outputs of that solid in the pipeline. Providing a
+    be tagged to outputs of that op in the job. Providing a
     `VersionStrategy` instance to a
     job will enable memoization on that job, such that only steps whose
     outputs do not have an up-to-date version will run.
     """
 
     @public
     @abstractmethod
```

### Comparing `dagster-1.3.2/dagster/_core/errors.py` & `dagster-1.3.3/dagster/_core/errors.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/event_api.py` & `dagster-1.3.3/dagster/_core/event_api.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/events/__init__.py` & `dagster-1.3.3/dagster/_core/events/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -38,15 +38,15 @@
 from dagster._core.execution.context.system import IPlanContext, IStepContext, StepExecutionContext
 from dagster._core.execution.plan.handle import ResolvedFromDynamicStepHandle, StepHandle
 from dagster._core.execution.plan.inputs import StepInputData
 from dagster._core.execution.plan.objects import StepFailureData, StepRetryData, StepSuccessData
 from dagster._core.execution.plan.outputs import StepOutputData
 from dagster._core.log_manager import DagsterLogManager
 from dagster._core.storage.captured_log_manager import CapturedLogContext
-from dagster._core.storage.pipeline_run import DagsterRunStatus
+from dagster._core.storage.dagster_run import DagsterRunStatus
 from dagster._serdes import (
     NamedTupleSerializer,
     whitelist_for_serdes,
 )
 from dagster._serdes.serdes import UnpackContext
 from dagster._utils.error import SerializableErrorInfo, serializable_error_info_from_exc_info
 from dagster._utils.timing import format_duration
@@ -62,27 +62,27 @@
     StepSuccessData,
     "StepMaterializationData",
     "StepExpectationResultData",
     StepInputData,
     "EngineEventData",
     "HookErroredData",
     StepRetryData,
-    "PipelineFailureData",
-    "PipelineCanceledData",
+    "JobFailureData",
+    "JobCanceledData",
     "ObjectStoreOperationResultData",
     "HandledOutputData",
     "LoadedInputData",
     "ComputeLogsCaptureData",
     "AssetObservationData",
     "AssetMaterializationPlannedData",
 ]
 
 
 class DagsterEventType(str, Enum):
-    """The types of events that may be yielded by solid and pipeline execution."""
+    """The types of events that may be yielded by op and job execution."""
 
     STEP_OUTPUT = "STEP_OUTPUT"
     STEP_INPUT = "STEP_INPUT"
     STEP_FAILURE = "STEP_FAILURE"
     STEP_START = "STEP_START"
     STEP_SUCCESS = "STEP_SUCCESS"
     STEP_SKIPPED = "STEP_SKIPPED"
@@ -292,21 +292,21 @@
     step_context.log.log_dagster_event(
         level=log_level,
         msg=event.message or f"{event_type} for step {step_context.step.key}",
         dagster_event=event,
     )
 
 
-def log_pipeline_event(pipeline_context: IPlanContext, event: "DagsterEvent") -> None:
+def log_job_event(job_context: IPlanContext, event: "DagsterEvent") -> None:
     event_type = DagsterEventType(event.event_type_value)
     log_level = logging.ERROR if event_type in FAILURE_EVENTS else logging.DEBUG
 
-    pipeline_context.log.log_dagster_event(
+    job_context.log.log_dagster_event(
         level=log_level,
-        msg=event.message or f"{event_type} for pipeline {pipeline_context.pipeline_name}",
+        msg=event.message or f"{event_type} for pipeline {job_context.job_name}",
         dagster_event=event,
     )
 
 
 def log_resource_event(log_manager: DagsterLogManager, event: "DagsterEvent") -> None:
     event_specific_data = cast(EngineEventData, event.event_specific_data)
 
@@ -338,50 +338,54 @@
         new_message = (
             f"Could not deserialize event of type {event_type_value}. This event may have been"
             " written by a newer version of Dagster."
             + (f' Original message: "{orig_message}"' if orig_message else "")
         )
         return DagsterEvent(
             event_type_value=DagsterEventType.ENGINE_EVENT.value,
-            pipeline_name=storage_dict["pipeline_name"],
+            job_name=storage_dict["pipeline_name"],
             message=new_message,
             step_key=step_key,
             event_specific_data=EngineEventData(
                 error=serializable_error_info_from_exc_info(sys.exc_info())
             ),
         )
 
 
 @whitelist_for_serdes(
-    serializer=DagsterEventSerializer, storage_field_names={"node_handle": "solid_handle"}
+    serializer=DagsterEventSerializer,
+    storage_field_names={
+        "node_handle": "solid_handle",
+        "job_name": "pipeline_name",
+    },
 )
 class DagsterEvent(
     NamedTuple(
         "_DagsterEvent",
         [
             ("event_type_value", str),
-            ("pipeline_name", str),
+            ("job_name", str),
             ("step_handle", Optional[Union[StepHandle, ResolvedFromDynamicStepHandle]]),
             ("node_handle", Optional[NodeHandle]),
             ("step_kind_value", Optional[str]),
             ("logging_tags", Optional[Mapping[str, str]]),
             ("event_specific_data", Optional["EventSpecificData"]),
             ("message", Optional[str]),
             ("pid", Optional[int]),
             ("step_key", Optional[str]),
         ],
     )
 ):
-    """Events yielded by solid and pipeline execution.
+    """Events yielded by op and job execution.
 
     Users should not instantiate this class.
 
     Attributes:
         event_type_value (str): Value for a DagsterEventType.
-        pipeline_name (str)
+        job_name (str)
         node_handle (NodeHandle)
         step_kind_value (str): Value for a StepKind.
         logging_tags (Dict[str, str])
         event_specific_data (Any): Type must correspond to event_type_value.
         message (str)
         pid (int)
         step_key (Optional[str]): DEPRECATED
@@ -392,79 +396,79 @@
         event_type: "DagsterEventType",
         step_context: IStepContext,
         event_specific_data: Optional["EventSpecificData"] = None,
         message: Optional[str] = None,
     ) -> "DagsterEvent":
         event = DagsterEvent(
             event_type_value=check.inst_param(event_type, "event_type", DagsterEventType).value,
-            pipeline_name=step_context.pipeline_name,
+            job_name=step_context.job_name,
             step_handle=step_context.step.handle,
             node_handle=step_context.step.node_handle,
             step_kind_value=step_context.step.kind.value,
             logging_tags=step_context.event_tags,
             event_specific_data=_validate_event_specific_data(event_type, event_specific_data),
             message=check.opt_str_param(message, "message"),
             pid=os.getpid(),
         )
 
         log_step_event(step_context, event)
 
         return event
 
     @staticmethod
-    def from_pipeline(
+    def from_job(
         event_type: DagsterEventType,
-        pipeline_context: IPlanContext,
+        job_context: IPlanContext,
         message: Optional[str] = None,
         event_specific_data: Optional["EventSpecificData"] = None,
         step_handle: Optional[Union[StepHandle, ResolvedFromDynamicStepHandle]] = None,
     ) -> "DagsterEvent":
         check.opt_inst_param(
             step_handle, "step_handle", (StepHandle, ResolvedFromDynamicStepHandle)
         )
 
         event = DagsterEvent(
             event_type_value=check.inst_param(event_type, "event_type", DagsterEventType).value,
-            pipeline_name=pipeline_context.pipeline_name,
+            job_name=job_context.job_name,
             message=check.opt_str_param(message, "message"),
             event_specific_data=_validate_event_specific_data(event_type, event_specific_data),
             step_handle=step_handle,
             pid=os.getpid(),
         )
 
-        log_pipeline_event(pipeline_context, event)
+        log_job_event(job_context, event)
 
         return event
 
     @staticmethod
     def from_resource(
         event_type: DagsterEventType,
-        pipeline_name: str,
+        job_name: str,
         execution_plan: "ExecutionPlan",
         log_manager: DagsterLogManager,
         message: Optional[str] = None,
         event_specific_data: Optional["EngineEventData"] = None,
     ) -> "DagsterEvent":
         event = DagsterEvent(
             event_type_value=check.inst_param(event_type, "event_type", DagsterEventType).value,
-            pipeline_name=pipeline_name,
+            job_name=job_name,
             message=check.opt_str_param(message, "message"),
             event_specific_data=_validate_event_specific_data(
                 DagsterEventType.ENGINE_EVENT, event_specific_data
             ),
             step_handle=execution_plan.step_handle_for_single_step_plans(),
             pid=os.getpid(),
         )
         log_resource_event(log_manager, event)
         return event
 
     def __new__(
         cls,
         event_type_value: str,
-        pipeline_name: str,
+        job_name: str,
         step_handle: Optional[Union[StepHandle, ResolvedFromDynamicStepHandle]] = None,
         node_handle: Optional[NodeHandle] = None,
         step_kind_value: Optional[str] = None,
         logging_tags: Optional[Mapping[str, str]] = None,
         event_specific_data: Optional["EventSpecificData"] = None,
         message: Optional[str] = None,
         pid: Optional[int] = None,
@@ -479,29 +483,29 @@
         # with legacy execution plan snapshots.
         if step_handle is not None and step_key is None:
             step_key = step_handle.to_key()
 
         return super(DagsterEvent, cls).__new__(
             cls,
             check.str_param(event_type_value, "event_type_value"),
-            check.str_param(pipeline_name, "pipeline_name"),
+            check.str_param(job_name, "job_name"),
             check.opt_inst_param(
                 step_handle, "step_handle", (StepHandle, ResolvedFromDynamicStepHandle)
             ),
             check.opt_inst_param(node_handle, "node_handle", NodeHandle),
             check.opt_str_param(step_kind_value, "step_kind_value"),
             check.opt_mapping_param(logging_tags, "logging_tags"),
             _validate_event_specific_data(DagsterEventType(event_type_value), event_specific_data),
             check.opt_str_param(message, "message"),
             check.opt_int_param(pid, "pid"),
             check.opt_str_param(step_key, "step_key"),
         )
 
     @property
-    def solid_name(self) -> str:
+    def node_name(self) -> str:
         check.invariant(self.node_handle is not None)
         node_handle = cast(NodeHandle, self.node_handle)
         return node_handle.name
 
     @public
     @property
     def event_type(self) -> DagsterEventType:
@@ -566,32 +570,32 @@
 
     @public
     @property
     def is_step_restarted(self) -> bool:
         return self.event_type == DagsterEventType.STEP_RESTARTED
 
     @property
-    def is_pipeline_success(self) -> bool:
+    def is_job_success(self) -> bool:
         return self.event_type == DagsterEventType.RUN_SUCCESS
 
     @property
-    def is_pipeline_failure(self) -> bool:
+    def is_job_failure(self) -> bool:
         return self.event_type == DagsterEventType.RUN_FAILURE
 
     @property
     def is_run_failure(self) -> bool:
         return self.event_type == DagsterEventType.RUN_FAILURE
 
     @public
     @property
     def is_failure(self) -> bool:
         return self.event_type in FAILURE_EVENTS
 
     @property
-    def is_pipeline_event(self) -> bool:
+    def is_job_event(self) -> bool:
         return self.event_type in PIPELINE_EVENTS
 
     @public
     @property
     def is_engine_event(self) -> bool:
         return self.event_type == DagsterEventType.ENGINE_EVENT
 
@@ -708,17 +712,17 @@
     def materialization(self) -> AssetMaterialization:
         _assert_type(
             "step_materialization_data", DagsterEventType.ASSET_MATERIALIZATION, self.event_type
         )
         return cast(StepMaterializationData, self.event_specific_data).materialization
 
     @property
-    def pipeline_failure_data(self) -> "PipelineFailureData":
-        _assert_type("pipeline_failure_data", DagsterEventType.RUN_FAILURE, self.event_type)
-        return cast(PipelineFailureData, self.event_specific_data)
+    def job_failure_data(self) -> "JobFailureData":
+        _assert_type("job_failure_data", DagsterEventType.RUN_FAILURE, self.event_type)
+        return cast(JobFailureData, self.event_specific_data)
 
     @property
     def engine_event_data(self) -> "EngineEventData":
         _assert_type(
             "engine_event_data",
             [
                 DagsterEventType.ENGINE_EVENT,
@@ -752,15 +756,15 @@
         _assert_type("logs_captured_data", DagsterEventType.LOGS_CAPTURED, self.event_type)
         return cast(ComputeLogsCaptureData, self.event_specific_data)
 
     @staticmethod
     def step_output_event(
         step_context: StepExecutionContext, step_output_data: StepOutputData
     ) -> "DagsterEvent":
-        output_def = step_context.solid.output_def_named(
+        output_def = step_context.op.output_def_named(
             step_output_data.step_output_handle.output_name
         )
 
         return DagsterEvent.from_step(
             event_type=DagsterEventType.STEP_OUTPUT,
             step_context=step_context,
             event_specific_data=step_output_data,
@@ -926,77 +930,67 @@
             event_type=DagsterEventType.STEP_EXPECTATION_RESULT,
             step_context=step_context,
             event_specific_data=StepExpectationResultData(expectation_result),
             message=_msg(),
         )
 
     @staticmethod
-    def pipeline_start(pipeline_context: IPlanContext) -> "DagsterEvent":
-        return DagsterEvent.from_pipeline(
+    def job_start(job_context: IPlanContext) -> "DagsterEvent":
+        return DagsterEvent.from_job(
             DagsterEventType.RUN_START,
-            pipeline_context,
-            message='Started execution of run for "{pipeline_name}".'.format(
-                pipeline_name=pipeline_context.pipeline_name
-            ),
+            job_context,
+            message=f'Started execution of run for "{job_context.job_name}".',
         )
 
     @staticmethod
-    def pipeline_success(pipeline_context: IPlanContext) -> "DagsterEvent":
-        return DagsterEvent.from_pipeline(
+    def job_success(job_context: IPlanContext) -> "DagsterEvent":
+        return DagsterEvent.from_job(
             DagsterEventType.RUN_SUCCESS,
-            pipeline_context,
-            message='Finished execution of run for "{pipeline_name}".'.format(
-                pipeline_name=pipeline_context.pipeline_name
-            ),
+            job_context,
+            message=f'Finished execution of run for "{job_context.job_name}".',
         )
 
     @staticmethod
-    def pipeline_failure(
-        pipeline_context_or_name: Union[IPlanContext, str],
+    def job_failure(
+        job_context_or_name: Union[IPlanContext, str],
         context_msg: str,
         error_info: Optional[SerializableErrorInfo] = None,
     ) -> "DagsterEvent":
         check.str_param(context_msg, "context_msg")
-        if isinstance(pipeline_context_or_name, IPlanContext):
-            return DagsterEvent.from_pipeline(
+        if isinstance(job_context_or_name, IPlanContext):
+            return DagsterEvent.from_job(
                 DagsterEventType.RUN_FAILURE,
-                pipeline_context_or_name,
-                message='Execution of run for "{pipeline_name}" failed. {context_msg}'.format(
-                    pipeline_name=pipeline_context_or_name.pipeline_name,
-                    context_msg=context_msg,
+                job_context_or_name,
+                message=(
+                    f'Execution of run for "{job_context_or_name.job_name}" failed. {context_msg}'
                 ),
-                event_specific_data=PipelineFailureData(error_info),
+                event_specific_data=JobFailureData(error_info),
             )
         else:
-            # when the failure happens trying to bring up context, the pipeline_context hasn't been
+            # when the failure happens trying to bring up context, the job_context hasn't been
             # built and so can't use from_pipeline
-            check.str_param(pipeline_context_or_name, "pipeline_name")
+            check.str_param(job_context_or_name, "pipeline_name")
             event = DagsterEvent(
                 event_type_value=DagsterEventType.RUN_FAILURE.value,
-                pipeline_name=pipeline_context_or_name,
-                event_specific_data=PipelineFailureData(error_info),
-                message='Execution of run for "{pipeline_name}" failed. {context_msg}'.format(
-                    pipeline_name=pipeline_context_or_name,
-                    context_msg=context_msg,
-                ),
+                job_name=job_context_or_name,
+                event_specific_data=JobFailureData(error_info),
+                message=f'Execution of run for "{job_context_or_name}" failed. {context_msg}',
                 pid=os.getpid(),
             )
             return event
 
     @staticmethod
-    def pipeline_canceled(
-        pipeline_context: IPlanContext, error_info: Optional[SerializableErrorInfo] = None
+    def job_canceled(
+        job_context: IPlanContext, error_info: Optional[SerializableErrorInfo] = None
     ) -> "DagsterEvent":
-        return DagsterEvent.from_pipeline(
+        return DagsterEvent.from_job(
             DagsterEventType.RUN_CANCELED,
-            pipeline_context,
-            message='Execution of run for "{pipeline_name}" canceled.'.format(
-                pipeline_name=pipeline_context.pipeline_name
-            ),
-            event_specific_data=PipelineCanceledData(
+            job_context,
+            message=f'Execution of run for "{job_context.job_name}" canceled.',
+            event_specific_data=JobCanceledData(
                 check.opt_inst_param(error_info, "error_info", SerializableErrorInfo)
             ),
         )
 
     @staticmethod
     def step_worker_starting(
         step_context: IStepContext,
@@ -1011,111 +1005,111 @@
                 metadata=metadata, marker_start="step_process_start"
             ),
         )
 
     @staticmethod
     def step_worker_started(
         log_manager: DagsterLogManager,
-        pipeline_name: str,
+        job_name: str,
         message: str,
         metadata: Mapping[str, MetadataValue],
         step_key: Optional[str],
     ) -> "DagsterEvent":
         event = DagsterEvent(
             DagsterEventType.STEP_WORKER_STARTED.value,
-            pipeline_name=pipeline_name,
+            job_name=job_name,
             message=message,
             event_specific_data=EngineEventData(metadata=metadata, marker_end="step_process_start"),
             pid=os.getpid(),
             step_key=step_key,
         )
         log_manager.log_dagster_event(
             level=logging.DEBUG,
             msg=message,
             dagster_event=event,
         )
         return event
 
     @staticmethod
     def resource_init_start(
-        pipeline_name: str,
+        job_name: str,
         execution_plan: "ExecutionPlan",
         log_manager: DagsterLogManager,
         resource_keys: AbstractSet[str],
     ) -> "DagsterEvent":
         return DagsterEvent.from_resource(
             DagsterEventType.RESOURCE_INIT_STARTED,
-            pipeline_name=pipeline_name,
+            job_name=job_name,
             execution_plan=execution_plan,
             log_manager=log_manager,
             message="Starting initialization of resources [{}].".format(
                 ", ".join(sorted(resource_keys))
             ),
             event_specific_data=EngineEventData(metadata={}, marker_start="resources"),
         )
 
     @staticmethod
     def resource_init_success(
-        pipeline_name: str,
+        job_name: str,
         execution_plan: "ExecutionPlan",
         log_manager: DagsterLogManager,
         resource_instances: Mapping[str, Any],
         resource_init_times: Mapping[str, str],
     ) -> "DagsterEvent":
         metadata = {}
         for key in resource_instances.keys():
             metadata[key] = MetadataValue.python_artifact(resource_instances[key].__class__)
             metadata[f"{key}:init_time"] = resource_init_times[key]
 
         return DagsterEvent.from_resource(
             DagsterEventType.RESOURCE_INIT_SUCCESS,
-            pipeline_name=pipeline_name,
+            job_name=job_name,
             execution_plan=execution_plan,
             log_manager=log_manager,
             message="Finished initialization of resources [{}].".format(
                 ", ".join(sorted(resource_init_times.keys()))
             ),
             event_specific_data=EngineEventData(
                 metadata=metadata,
                 marker_end="resources",
             ),
         )
 
     @staticmethod
     def resource_init_failure(
-        pipeline_name: str,
+        job_name: str,
         execution_plan: "ExecutionPlan",
         log_manager: DagsterLogManager,
         resource_keys: AbstractSet[str],
         error: SerializableErrorInfo,
     ) -> "DagsterEvent":
         return DagsterEvent.from_resource(
             DagsterEventType.RESOURCE_INIT_FAILURE,
-            pipeline_name=pipeline_name,
+            job_name=job_name,
             execution_plan=execution_plan,
             log_manager=log_manager,
             message="Initialization of resources [{}] failed.".format(", ".join(resource_keys)),
             event_specific_data=EngineEventData(
                 metadata={},
                 marker_end="resources",
                 error=error,
             ),
         )
 
     @staticmethod
     def resource_teardown_failure(
-        pipeline_name: str,
+        job_name: str,
         execution_plan: "ExecutionPlan",
         log_manager: DagsterLogManager,
         resource_keys: AbstractSet[str],
         error: SerializableErrorInfo,
     ) -> "DagsterEvent":
         return DagsterEvent.from_resource(
             DagsterEventType.ENGINE_EVENT,
-            pipeline_name=pipeline_name,
+            job_name=job_name,
             execution_plan=execution_plan,
             log_manager=log_manager,
             message="Teardown of resources [{}] failed.".format(", ".join(resource_keys)),
             event_specific_data=EngineEventData(
                 metadata={},
                 marker_start=None,
                 marker_end=None,
@@ -1133,15 +1127,15 @@
             return DagsterEvent.from_step(
                 DagsterEventType.ENGINE_EVENT,
                 step_context=plan_context,
                 event_specific_data=event_specific_data,
                 message=message,
             )
         else:
-            return DagsterEvent.from_pipeline(
+            return DagsterEvent.from_job(
                 DagsterEventType.ENGINE_EVENT,
                 plan_context,
                 message,
                 event_specific_data=event_specific_data,
             )
 
     @staticmethod
@@ -1269,22 +1263,23 @@
     def hook_completed(
         step_context: StepExecutionContext, hook_def: HookDefinition
     ) -> "DagsterEvent":
         event_type = DagsterEventType.HOOK_COMPLETED
 
         event = DagsterEvent(
             event_type_value=event_type.value,
-            pipeline_name=step_context.pipeline_name,
+            job_name=step_context.job_name,
             step_handle=step_context.step.handle,
             node_handle=step_context.step.node_handle,
             step_kind_value=step_context.step.kind.value,
             logging_tags=step_context.event_tags,
             message=(
-                'Finished the execution of hook "{hook_name}" triggered for "{solid_name}".'
-            ).format(hook_name=hook_def.name, solid_name=step_context.solid.name),
+                f'Finished the execution of hook "{hook_def.name}" triggered for'
+                f' "{step_context.op.name}".'
+            ),
         )
 
         step_context.log.log_dagster_event(
             level=logging.DEBUG, msg=event.message or "", dagster_event=event
         )
 
         return event
@@ -1293,15 +1288,15 @@
     def hook_errored(
         step_context: StepExecutionContext, error: HookExecutionError
     ) -> "DagsterEvent":
         event_type = DagsterEventType.HOOK_ERRORED
 
         event = DagsterEvent(
             event_type_value=event_type.value,
-            pipeline_name=step_context.pipeline_name,
+            job_name=step_context.job_name,
             step_handle=step_context.step.handle,
             node_handle=step_context.step.node_handle,
             step_kind_value=step_context.step.kind.value,
             logging_tags=step_context.event_tags,
             event_specific_data=_validate_event_specific_data(
                 event_type,
                 HookErroredData(
@@ -1318,23 +1313,23 @@
     def hook_skipped(
         step_context: StepExecutionContext, hook_def: HookDefinition
     ) -> "DagsterEvent":
         event_type = DagsterEventType.HOOK_SKIPPED
 
         event = DagsterEvent(
             event_type_value=event_type.value,
-            pipeline_name=step_context.pipeline_name,
+            job_name=step_context.job_name,
             step_handle=step_context.step.handle,
             node_handle=step_context.step.node_handle,
             step_kind_value=step_context.step.kind.value,
             logging_tags=step_context.event_tags,
             message=(
                 'Skipped the execution of hook "{hook_name}". It did not meet its triggering '
                 'condition during the execution of "{solid_name}".'
-            ).format(hook_name=hook_def.name, solid_name=step_context.solid.name),
+            ).format(hook_name=hook_def.name, solid_name=step_context.op.name),
         )
 
         step_context.log.log_dagster_event(
             level=logging.DEBUG, msg=event.message or "", dagster_event=event
         )
 
         return event
@@ -1350,26 +1345,30 @@
                 step_keys=[step_key],
                 file_key=step_key,
             ),
         )
 
     @staticmethod
     def capture_logs(
-        pipeline_context: IPlanContext,
+        job_context: IPlanContext,
         step_keys: Sequence[str],
         log_key: Sequence[str],
         log_context: CapturedLogContext,
     ):
         file_key = log_key[-1]
-        return DagsterEvent.from_pipeline(
+        return DagsterEvent.from_job(
             DagsterEventType.LOGS_CAPTURED,
-            pipeline_context,
+            job_context,
             message=f"Started capturing logs in process (pid: {os.getpid()}).",
             event_specific_data=ComputeLogsCaptureData(
-                step_keys=step_keys, file_key=file_key, external_url=log_context.external_url
+                step_keys=step_keys,
+                file_key=file_key,
+                external_stdout_url=log_context.external_stdout_url,
+                external_stderr_url=log_context.external_stderr_url,
+                external_url=log_context.external_url,
             ),
         )
 
 
 def get_step_output_event(
     events: Sequence[DagsterEvent], step_key: str, output_name: Optional[str] = "result"
 ) -> Optional["DagsterEvent"]:
@@ -1570,40 +1569,40 @@
         )
 
     @staticmethod
     def engine_error(error: SerializableErrorInfo) -> "EngineEventData":
         return EngineEventData(metadata={}, error=error)
 
 
-@whitelist_for_serdes
-class PipelineFailureData(
+@whitelist_for_serdes(storage_name="PipelineFailureData")
+class JobFailureData(
     NamedTuple(
-        "_PipelineFailureData",
+        "_JobFailureData",
         [
             ("error", Optional[SerializableErrorInfo]),
         ],
     )
 ):
     def __new__(cls, error: Optional[SerializableErrorInfo]):
-        return super(PipelineFailureData, cls).__new__(
+        return super(JobFailureData, cls).__new__(
             cls, error=check.opt_inst_param(error, "error", SerializableErrorInfo)
         )
 
 
-@whitelist_for_serdes
-class PipelineCanceledData(
+@whitelist_for_serdes(storage_name="PipelineCanceledData")
+class JobCanceledData(
     NamedTuple(
-        "_PipelineCanceledData",
+        "_JobCanceledData",
         [
             ("error", Optional[SerializableErrorInfo]),
         ],
     )
 ):
     def __new__(cls, error: Optional[SerializableErrorInfo]):
-        return super(PipelineCanceledData, cls).__new__(
+        return super(JobCanceledData, cls).__new__(
             cls, error=check.opt_inst_param(error, "error", SerializableErrorInfo)
         )
 
 
 @whitelist_for_serdes
 class HookErroredData(
     NamedTuple(
@@ -1689,23 +1688,34 @@
 class ComputeLogsCaptureData(
     NamedTuple(
         "_ComputeLogsCaptureData",
         [
             ("file_key", str),  # renamed log_key => file_key to avoid confusion
             ("step_keys", Sequence[str]),
             ("external_url", Optional[str]),
+            ("external_stdout_url", Optional[str]),
+            ("external_stderr_url", Optional[str]),
         ],
     )
 ):
-    def __new__(cls, file_key: str, step_keys: Sequence[str], external_url: Optional[str] = None):
+    def __new__(
+        cls,
+        file_key: str,
+        step_keys: Sequence[str],
+        external_url: Optional[str] = None,
+        external_stdout_url: Optional[str] = None,
+        external_stderr_url: Optional[str] = None,
+    ):
         return super(ComputeLogsCaptureData, cls).__new__(
             cls,
             file_key=check.str_param(file_key, "file_key"),
             step_keys=check.opt_list_param(step_keys, "step_keys", of_type=str),
             external_url=check.opt_str_param(external_url, "external_url"),
+            external_stdout_url=check.opt_str_param(external_stdout_url, "external_stdout_url"),
+            external_stderr_url=check.opt_str_param(external_stderr_url, "external_stderr_url"),
         )
 
 
 ###################################################################################################
 # THE GRAVEYARD
 #
 #            -|-                  -|-                  -|-
```

### Comparing `dagster-1.3.2/dagster/_core/events/log.py` & `dagster-1.3.3/dagster/_core/events/log.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,12 @@
 from typing import Mapping, NamedTuple, Optional, Union
 
 import dagster._check as check
 from dagster._annotations import PublicAttr, public
 from dagster._core.definitions.events import AssetMaterialization, AssetObservation
-from dagster._core.errors import DagsterInvariantViolationError
 from dagster._core.events import DagsterEvent, DagsterEventType
 from dagster._core.utils import coerce_valid_log_level
 from dagster._serdes.serdes import (
     deserialize_value,
     serialize_value,
     whitelist_for_serdes,
 )
@@ -23,26 +22,27 @@
 @whitelist_for_serdes(
     # These were originally distinguished from each other but ended up being empty subclasses
     # of EventLogEntry -- instead of using the subclasses we were relying on
     # EventLogEntry.is_dagster_event to distinguish events that originate in the logging
     # machinery from events that are yielded by user code
     old_storage_names={"DagsterEventRecord", "LogMessageRecord", "EventRecord"},
     old_fields={"message": ""},
+    storage_field_names={"job_name": "pipeline_name"},
 )
 class EventLogEntry(
     NamedTuple(
         "_EventLogEntry",
         [
             ("error_info", PublicAttr[Optional[SerializableErrorInfo]]),
             ("level", PublicAttr[Union[str, int]]),
             ("user_message", PublicAttr[str]),
             ("run_id", PublicAttr[str]),
             ("timestamp", PublicAttr[float]),
             ("step_key", PublicAttr[Optional[str]]),
-            ("pipeline_name", Optional[str]),
+            ("job_name", PublicAttr[Optional[str]]),
             ("dagster_event", PublicAttr[Optional[DagsterEvent]]),
         ],
     )
 ):
     """Entries in the event log.
 
     Users should not instantiate this object directly. These entries may originate from the logging machinery (DagsterLogManager/context.log), from
@@ -70,48 +70,35 @@
         cls,
         error_info,
         level,
         user_message,
         run_id,
         timestamp,
         step_key=None,
-        pipeline_name=None,
-        dagster_event=None,
         job_name=None,
+        dagster_event=None,
     ):
-        if pipeline_name and job_name:
-            raise DagsterInvariantViolationError(
-                "Provided both `pipeline_name` and `job_name` parameters to `EventLogEntry` "
-                "initialization. Please provide only one or the other."
-            )
-
-        pipeline_name = pipeline_name or job_name
         return super(EventLogEntry, cls).__new__(
             cls,
             check.opt_inst_param(error_info, "error_info", SerializableErrorInfo),
             coerce_valid_log_level(level),
             check.str_param(user_message, "user_message"),
             check.str_param(run_id, "run_id"),
             check.float_param(timestamp, "timestamp"),
             check.opt_str_param(step_key, "step_key"),
-            check.opt_str_param(pipeline_name, "pipeline_name"),
+            check.opt_str_param(job_name, "job_name"),
             check.opt_inst_param(dagster_event, "dagster_event", DagsterEvent),
         )
 
     @public
     @property
     def is_dagster_event(self) -> bool:
         return bool(self.dagster_event)
 
     @public
-    @property
-    def job_name(self) -> Optional[str]:
-        return self.pipeline_name
-
-    @public
     def get_dagster_event(self) -> DagsterEvent:
         if not isinstance(self.dagster_event, DagsterEvent):
             check.failed(
                 "Not a dagster event, check is_dagster_event before calling get_dagster_event",
             )
 
         return self.dagster_event
@@ -182,15 +169,15 @@
 
     return EventLogEntry(
         level=logger_message.level,
         user_message=logger_message.meta["orig_message"],
         run_id=logger_message.meta["run_id"],
         timestamp=logger_message.record.created,
         step_key=logger_message.meta.get("step_key"),
-        job_name=logger_message.meta.get("pipeline_name"),
+        job_name=logger_message.meta.get("job_name"),
         dagster_event=logger_message.meta.get("dagster_event"),
         error_info=None,
     )
 
 
 def construct_event_logger(event_record_callback):
     """Callback receives a stream of event_records. Piggybacks on the logging machinery."""
```

### Comparing `dagster-1.3.2/dagster/_core/events/utils.py` & `dagster-1.3.3/dagster/_core/events/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/execution/api.py` & `dagster-1.3.3/dagster/_core/execution/api.py`

 * *Files 15% similar despite different names*

```diff
@@ -13,42 +13,42 @@
     Tuple,
     Union,
     cast,
 )
 
 import dagster._check as check
 from dagster._annotations import experimental
-from dagster._core.definitions import IPipeline, JobDefinition
+from dagster._core.definitions import IJob, JobDefinition
 from dagster._core.definitions.events import AssetKey
-from dagster._core.definitions.pipeline_base import InMemoryPipeline
-from dagster._core.definitions.reconstruct import ReconstructableJob, ReconstructablePipeline
+from dagster._core.definitions.job_base import InMemoryJob
+from dagster._core.definitions.reconstruct import ReconstructableJob
 from dagster._core.definitions.repository_definition import RepositoryLoadData
 from dagster._core.errors import DagsterExecutionInterruptedError, DagsterInvariantViolationError
 from dagster._core.events import DagsterEvent, EngineEventData
 from dagster._core.execution.context.system import PlanOrchestrationContext
 from dagster._core.execution.plan.execute_plan import inner_plan_execution_iterator
 from dagster._core.execution.plan.outputs import StepOutputHandle
 from dagster._core.execution.plan.plan import ExecutionPlan
 from dagster._core.execution.plan.state import KnownExecutionState
 from dagster._core.execution.retries import RetryMode
 from dagster._core.instance import DagsterInstance, InstanceRef
 from dagster._core.selector import parse_step_selection
-from dagster._core.storage.pipeline_run import DagsterRun, DagsterRunStatus
+from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus
 from dagster._core.system_config.objects import ResolvedRunConfig
 from dagster._core.telemetry import log_dagster_event, log_repo_stats, telemetry_wrapper
 from dagster._utils.error import serializable_error_info_from_exc_info
 from dagster._utils.interrupts import capture_interrupts
 from dagster._utils.merger import merge_dicts
 
-from .context_creation_pipeline import (
+from .context_creation_job import (
     ExecutionContextManager,
     PlanExecutionContextManager,
     PlanOrchestrationContextManager,
     orchestration_context_event_generator,
-    scoped_pipeline_context,
+    scoped_job_context,
 )
 from .execute_job_result import ExecuteJobResult
 from .results import PipelineExecutionResult
 
 ## Brief guide to the execution APIs
 # | function name               | operates over      | sync  | supports    | creates new DagsterRun  |
 # |                             |                    |       | reexecution | in instance             |
@@ -63,20 +63,20 @@
 # (1) The appropriate bits must be set on the DagsterRun passed to this function. Specifically,
 #     parent_run_id and root_run_id must be set and consistent, and if a solids_to_execute or
 #     step_keys_to_execute are set they must be consistent with the parent and root runs.
 # (2) As for (1), but the ExecutionPlan passed must also agree in all relevant bits.
 
 
 def execute_run_iterator(
-    pipeline: IPipeline,
+    job: IJob,
     dagster_run: DagsterRun,
     instance: DagsterInstance,
     resume_from_failure: bool = False,
 ) -> Iterator[DagsterEvent]:
-    check.inst_param(pipeline, "pipeline", IPipeline)
+    check.inst_param(job, "job", IJob)
     check.inst_param(dagster_run, "dagster_run", DagsterRun)
     check.inst_param(instance, "instance", DagsterInstance)
 
     if dagster_run.status == DagsterRunStatus.CANCELED:
         # This can happen if the run was force-terminated while it was starting
         def gen_execute_on_cancel():
             yield instance.report_engine_event(
@@ -111,15 +111,15 @@
 
                 return gen_ignore_duplicate_run_worker()
             else:
 
                 def gen_fail_restarted_run_worker():
                     yield instance.report_engine_event(
                         (
-                            f"{dagster_run.pipeline_name} ({dagster_run.run_id}) started a new"
+                            f"{dagster_run.job_name} ({dagster_run.run_id}) started a new"
                             f" run worker while the run was already in state {dagster_run.status}."
                             " This most frequently happens when the run worker unexpectedly stops"
                             " and is restarted by the cluster. Marking the run as failed."
                         ),
                         dagster_run,
                     )
                     yield instance.report_run_failed(dagster_run)
@@ -129,81 +129,81 @@
     else:
         check.invariant(
             dagster_run.status == DagsterRunStatus.STARTED
             or dagster_run.status == DagsterRunStatus.STARTING,
             desc=(
                 "Run of {} ({}) in state {}, expected STARTED or STARTING because it's "
                 "resuming from a run worker failure".format(
-                    dagster_run.pipeline_name, dagster_run.run_id, dagster_run.status
+                    dagster_run.job_name, dagster_run.run_id, dagster_run.status
                 )
             ),
         )
 
     if dagster_run.solids_to_execute or dagster_run.asset_selection:
         # when `execute_run_iterator` is directly called, the sub pipeline hasn't been created
         # note that when we receive the solids to execute via DagsterRun, it won't support
         # solid selection query syntax
-        pipeline = pipeline.subset_for_execution_from_existing_pipeline(
+        job = job.subset_for_execution_from_existing_job(
             frozenset(dagster_run.solids_to_execute) if dagster_run.solids_to_execute else None,
             asset_selection=dagster_run.asset_selection,
         )
 
-    execution_plan = _get_execution_plan_from_run(pipeline, dagster_run, instance)
-    if isinstance(pipeline, ReconstructablePipeline):
-        pipeline = pipeline.with_repository_load_data(execution_plan.repository_load_data)
+    execution_plan = _get_execution_plan_from_run(job, dagster_run, instance)
+    if isinstance(job, ReconstructableJob):
+        job = job.with_repository_load_data(execution_plan.repository_load_data)
 
     return iter(
         ExecuteRunWithPlanIterable(
             execution_plan=execution_plan,
-            iterator=pipeline_execution_iterator,
+            iterator=job_execution_iterator,
             execution_context_manager=PlanOrchestrationContextManager(
                 context_event_generator=orchestration_context_event_generator,
-                pipeline=pipeline,
+                job=job,
                 execution_plan=execution_plan,
                 dagster_run=dagster_run,
                 instance=instance,
                 run_config=dagster_run.run_config,
                 raise_on_error=False,
                 executor_defs=None,
                 output_capture=None,
                 resume_from_failure=resume_from_failure,
             ),
         )
     )
 
 
 def execute_run(
-    pipeline: IPipeline,
+    job: IJob,
     dagster_run: DagsterRun,
     instance: DagsterInstance,
     raise_on_error: bool = False,
 ) -> PipelineExecutionResult:
-    """Executes an existing pipeline run synchronously.
+    """Executes an existing job run synchronously.
 
     Synchronous version of execute_run_iterator.
 
     Args:
-        pipeline (IPipeline): The pipeline to execute.
+        job (IJob): The pipeline to execute.
         dagster_run (DagsterRun): The run to execute
         instance (DagsterInstance): The instance in which the run has been created.
         raise_on_error (Optional[bool]): Whether or not to raise exceptions when they occur.
             Defaults to ``False``.
 
     Returns:
         PipelineExecutionResult: The result of the execution.
     """
-    if isinstance(pipeline, JobDefinition):
+    if isinstance(job, JobDefinition):
         raise DagsterInvariantViolationError(
             "execute_run requires a reconstructable job but received job definition directly"
             " instead. To support hand-off to other processes please wrap your definition in a call"
             " to reconstructable(). Learn more about reconstructable here:"
             " https://docs.dagster.io/_apidocs/execution#dagster.reconstructable"
         )
 
-    check.inst_param(pipeline, "pipeline", IPipeline)
+    check.inst_param(job, "job", IJob)
     check.inst_param(dagster_run, "dagster_run", DagsterRun)
     check.inst_param(instance, "instance", DagsterInstance)
 
     if dagster_run.status == DagsterRunStatus.CANCELED:
         message = "Not starting execution since the run was canceled before execution could start"
         instance.report_engine_event(
             message,
@@ -211,56 +211,56 @@
         )
         raise DagsterInvariantViolationError(message)
 
     check.invariant(
         dagster_run.status == DagsterRunStatus.NOT_STARTED
         or dagster_run.status == DagsterRunStatus.STARTING,
         desc="Run {} ({}) in state {}, expected NOT_STARTED or STARTING".format(
-            dagster_run.pipeline_name, dagster_run.run_id, dagster_run.status
+            dagster_run.job_name, dagster_run.run_id, dagster_run.status
         ),
     )
     if dagster_run.solids_to_execute or dagster_run.asset_selection:
-        # when `execute_run` is directly called, the sub pipeline hasn't been created
+        # when `execute_run` is directly called, the sub job hasn't been created
         # note that when we receive the solids to execute via DagsterRun, it won't support
         # solid selection query syntax
-        pipeline = pipeline.subset_for_execution_from_existing_pipeline(
+        job = job.subset_for_execution_from_existing_job(
             frozenset(dagster_run.solids_to_execute) if dagster_run.solids_to_execute else None,
             dagster_run.asset_selection,
         )
 
-    execution_plan = _get_execution_plan_from_run(pipeline, dagster_run, instance)
-    if isinstance(pipeline, ReconstructablePipeline):
-        pipeline = pipeline.with_repository_load_data(execution_plan.repository_load_data)
+    execution_plan = _get_execution_plan_from_run(job, dagster_run, instance)
+    if isinstance(job, ReconstructableJob):
+        job = job.with_repository_load_data(execution_plan.repository_load_data)
 
     output_capture: Optional[Dict[StepOutputHandle, Any]] = {}
 
     _execute_run_iterable = ExecuteRunWithPlanIterable(
         execution_plan=execution_plan,
-        iterator=pipeline_execution_iterator,
+        iterator=job_execution_iterator,
         execution_context_manager=PlanOrchestrationContextManager(
             context_event_generator=orchestration_context_event_generator,
-            pipeline=pipeline,
+            job=job,
             execution_plan=execution_plan,
             dagster_run=dagster_run,
             instance=instance,
             run_config=dagster_run.run_config,
             raise_on_error=raise_on_error,
             executor_defs=None,
             output_capture=output_capture,
         ),
     )
     event_list = list(_execute_run_iterable)
 
     return PipelineExecutionResult(
-        pipeline.get_definition(),
+        job.get_definition(),
         dagster_run.run_id,
         event_list,
-        lambda: scoped_pipeline_context(  # type: ignore
+        lambda: scoped_job_context(  # type: ignore
             execution_plan,
-            pipeline,
+            job,
             dagster_run.run_config,
             dagster_run,
             instance,
         ),
         output_capture=output_capture,
     )
 
@@ -421,15 +421,15 @@
             Reexecution options to provide to the run, if this run is
             intended to be a reexecution of a previous run. Cannot be used in
             tandem with the ``op_selection`` argument.
 
     Returns:
       :py:class:`JobExecutionResult`: The result of job execution.
     """
-    check.inst_param(job, "job", ReconstructablePipeline)
+    check.inst_param(job, "job", ReconstructableJob)
     check.inst_param(instance, "instance", DagsterInstance)
     check.opt_sequence_param(asset_selection, "asset_selection", of_type=AssetKey)
 
     # get the repository load data here because we call job.get_definition() later in this fn
     job_def, _ = _job_with_repository_load_data(job)
 
     if reexecution_options is not None and op_selection is not None:
@@ -468,15 +468,15 @@
         event_list=result.event_list,
         dagster_run=instance.get_run_by_id(result.run_id),
     )
 
 
 @telemetry_wrapper
 def _logged_execute_job(
-    job_arg: Union[IPipeline, JobDefinition],
+    job_arg: Union[IJob, JobDefinition],
     instance: DagsterInstance,
     run_config: Optional[Mapping[str, object]] = None,
     tags: Optional[Mapping[str, str]] = None,
     op_selection: Optional[Sequence[str]] = None,
     raise_on_error: bool = True,
     asset_selection: Optional[Sequence[AssetKey]] = None,
 ) -> PipelineExecutionResult:
@@ -493,23 +493,23 @@
     ) = _check_execute_job_args(
         job_arg=job_arg,
         run_config=run_config,
         tags=tags,
         op_selection=op_selection,
     )
 
-    log_repo_stats(instance=instance, pipeline=job_arg, source="execute_pipeline")
+    log_repo_stats(instance=instance, job=job_arg, source="execute_pipeline")
 
-    dagster_run = instance.create_run_for_pipeline(
-        pipeline_def=job_arg.get_definition(),
+    dagster_run = instance.create_run_for_job(
+        job_def=job_arg.get_definition(),
         run_config=run_config,
         solid_selection=op_selection,
         solids_to_execute=solids_to_execute,
         tags=tags,
-        pipeline_code_origin=(
+        job_code_origin=(
             job_arg.get_python_origin() if isinstance(job_arg, ReconstructableJob) else None
         ),
         repository_load_data=repository_load_data,
         asset_selection=frozenset(asset_selection) if asset_selection else None,
     )
 
     return execute_run(
@@ -517,15 +517,15 @@
         dagster_run,
         instance,
         raise_on_error=raise_on_error,
     )
 
 
 def _reexecute_job(
-    job_arg: Union[IPipeline, JobDefinition],
+    job_arg: Union[IJob, JobDefinition],
     parent_run_id: str,
     run_config: Optional[Mapping[str, object]] = None,
     step_selection: Optional[Sequence[str]] = None,
     tags: Optional[Mapping[str, str]] = None,
     instance: Optional[DagsterInstance] = None,
     raise_on_error: bool = True,
 ) -> PipelineExecutionResult:
@@ -563,25 +563,25 @@
             )
 
         if parent_dagster_run.asset_selection:
             job_arg = job_arg.subset_for_execution(
                 solid_selection=None, asset_selection=parent_dagster_run.asset_selection
             )
 
-        dagster_run = execute_instance.create_run_for_pipeline(
-            pipeline_def=job_arg.get_definition(),
+        dagster_run = execute_instance.create_run_for_job(
+            job_def=job_arg.get_definition(),
             execution_plan=execution_plan,
             run_config=run_config,
             tags=tags,
             solid_selection=parent_dagster_run.solid_selection,
             asset_selection=parent_dagster_run.asset_selection,
             solids_to_execute=parent_dagster_run.solids_to_execute,
             root_run_id=parent_dagster_run.root_run_id or parent_dagster_run.run_id,
             parent_run_id=parent_dagster_run.run_id,
-            pipeline_code_origin=(
+            job_code_origin=(
                 job_arg.get_python_origin() if isinstance(job_arg, ReconstructableJob) else None
             ),
             repository_load_data=repository_load_data,
         )
 
         return execute_run(
             job_arg,
@@ -590,263 +590,263 @@
             raise_on_error=raise_on_error,
         )
     check.failed("Should not reach here.")
 
 
 def execute_plan_iterator(
     execution_plan: ExecutionPlan,
-    pipeline: IPipeline,
+    job: IJob,
     dagster_run: DagsterRun,
     instance: DagsterInstance,
     retry_mode: Optional[RetryMode] = None,
     run_config: Optional[Mapping[str, object]] = None,
 ) -> Iterator[DagsterEvent]:
     check.inst_param(execution_plan, "execution_plan", ExecutionPlan)
-    check.inst_param(pipeline, "pipeline", IPipeline)
+    check.inst_param(job, "job", IJob)
     check.inst_param(dagster_run, "dagster_run", DagsterRun)
     check.inst_param(instance, "instance", DagsterInstance)
     retry_mode = check.opt_inst_param(retry_mode, "retry_mode", RetryMode, RetryMode.DISABLED)
     run_config = check.opt_mapping_param(run_config, "run_config")
 
-    if isinstance(pipeline, ReconstructablePipeline):
-        pipeline = pipeline.with_repository_load_data(execution_plan.repository_load_data)
+    if isinstance(job, ReconstructableJob):
+        job = job.with_repository_load_data(execution_plan.repository_load_data)
 
     return iter(
         ExecuteRunWithPlanIterable(
             execution_plan=execution_plan,
             iterator=inner_plan_execution_iterator,
             execution_context_manager=PlanExecutionContextManager(
-                pipeline=pipeline,
+                job=job,
                 retry_mode=retry_mode,
                 execution_plan=execution_plan,
                 run_config=run_config,
                 dagster_run=dagster_run,
                 instance=instance,
             ),
         )
     )
 
 
 def execute_plan(
     execution_plan: ExecutionPlan,
-    pipeline: IPipeline,
+    job: IJob,
     instance: DagsterInstance,
     dagster_run: DagsterRun,
     run_config: Optional[Mapping[str, object]] = None,
     retry_mode: Optional[RetryMode] = None,
 ) -> Sequence[DagsterEvent]:
     """This is the entry point of dagster-graphql executions. For the dagster CLI entry point, see
-    execute_pipeline() above.
+    execute_job() above.
     """
     check.inst_param(execution_plan, "execution_plan", ExecutionPlan)
-    check.inst_param(pipeline, "pipeline", IPipeline)
+    check.inst_param(job, "job", IJob)
     check.inst_param(instance, "instance", DagsterInstance)
     check.inst_param(dagster_run, "dagster_run", DagsterRun)
     run_config = check.opt_mapping_param(run_config, "run_config")
     check.opt_inst_param(retry_mode, "retry_mode", RetryMode)
 
     return list(
         execute_plan_iterator(
             execution_plan=execution_plan,
-            pipeline=pipeline,
+            job=job,
             run_config=run_config,
             dagster_run=dagster_run,
             instance=instance,
             retry_mode=retry_mode,
         )
     )
 
 
-def _check_pipeline(job_arg: Union[JobDefinition, IPipeline]) -> IPipeline:
+def _check_job(job_arg: Union[JobDefinition, IJob]) -> IJob:
     # backcompat
     if isinstance(job_arg, JobDefinition):
-        job_arg = InMemoryPipeline(job_arg)
+        job_arg = InMemoryJob(job_arg)
 
-    check.inst_param(job_arg, "job_arg", IPipeline)
+    check.inst_param(job_arg, "job_arg", IJob)
     return job_arg
 
 
 def _get_execution_plan_from_run(
-    pipeline: IPipeline,
+    job: IJob,
     dagster_run: DagsterRun,
     instance: DagsterInstance,
 ) -> ExecutionPlan:
     execution_plan_snapshot = (
         instance.get_execution_plan_snapshot(dagster_run.execution_plan_snapshot_id)
         if dagster_run.execution_plan_snapshot_id
         else None
     )
 
     # Rebuild from snapshot if able and selection has not changed
     if (
         execution_plan_snapshot is not None
         and execution_plan_snapshot.can_reconstruct_plan
-        and pipeline.solids_to_execute == dagster_run.solids_to_execute
-        and pipeline.asset_selection == dagster_run.asset_selection
+        and job.solids_to_execute == dagster_run.solids_to_execute
+        and job.asset_selection == dagster_run.asset_selection
     ):
         return ExecutionPlan.rebuild_from_snapshot(
-            dagster_run.pipeline_name,
+            dagster_run.job_name,
             execution_plan_snapshot,
         )
 
     return create_execution_plan(
-        pipeline,
+        job,
         run_config=dagster_run.run_config,
         step_keys_to_execute=dagster_run.step_keys_to_execute,
         instance_ref=instance.get_ref() if instance.is_persistent else None,
         repository_load_data=execution_plan_snapshot.repository_load_data
         if execution_plan_snapshot
         else None,
         known_state=execution_plan_snapshot.initial_known_state
         if execution_plan_snapshot
         else None,
     )
 
 
 def create_execution_plan(
-    pipeline: Union[IPipeline, JobDefinition],
+    job: Union[IJob, JobDefinition],
     run_config: Optional[Mapping[str, object]] = None,
     step_keys_to_execute: Optional[Sequence[str]] = None,
     known_state: Optional[KnownExecutionState] = None,
     instance_ref: Optional[InstanceRef] = None,
     tags: Optional[Mapping[str, str]] = None,
     repository_load_data: Optional[RepositoryLoadData] = None,
 ) -> ExecutionPlan:
-    pipeline = _check_pipeline(pipeline)
+    job = _check_job(job)
 
     # If you have repository_load_data, make sure to use it when building plan
-    if isinstance(pipeline, ReconstructablePipeline) and repository_load_data is not None:
-        pipeline = pipeline.with_repository_load_data(repository_load_data)
+    if isinstance(job, ReconstructableJob) and repository_load_data is not None:
+        job = job.with_repository_load_data(repository_load_data)
 
-    pipeline_def = pipeline.get_definition()
-    check.inst_param(pipeline_def, "pipeline_def", JobDefinition)
+    job_def = job.get_definition()
+    check.inst_param(job_def, "job_def", JobDefinition)
     run_config = check.opt_mapping_param(run_config, "run_config", key_type=str)
     check.opt_nullable_sequence_param(step_keys_to_execute, "step_keys_to_execute", of_type=str)
     check.opt_inst_param(instance_ref, "instance_ref", InstanceRef)
     tags = check.opt_mapping_param(tags, "tags", key_type=str, value_type=str)
     known_state = check.opt_inst_param(
         known_state,
         "known_state",
         KnownExecutionState,
         default=KnownExecutionState(),
     )
     repository_load_data = check.opt_inst_param(
         repository_load_data, "repository_load_data", RepositoryLoadData
     )
 
-    resolved_run_config = ResolvedRunConfig.build(pipeline_def, run_config)
+    resolved_run_config = ResolvedRunConfig.build(job_def, run_config)
 
     return ExecutionPlan.build(
-        pipeline,
+        job,
         resolved_run_config,
         step_keys_to_execute=step_keys_to_execute,
         known_state=known_state,
         instance_ref=instance_ref,
         tags=tags,
         repository_load_data=repository_load_data,
     )
 
 
-def pipeline_execution_iterator(
-    pipeline_context: PlanOrchestrationContext, execution_plan: ExecutionPlan
+def job_execution_iterator(
+    job_context: PlanOrchestrationContext, execution_plan: ExecutionPlan
 ) -> Iterator[DagsterEvent]:
     """A complete execution of a pipeline. Yields pipeline start, success,
     and failure events.
 
     Args:
         pipeline_context (PlanOrchestrationContext):
         execution_plan (ExecutionPlan):
     """
     # TODO: restart event?
-    if not pipeline_context.resume_from_failure:
-        yield DagsterEvent.pipeline_start(pipeline_context)
+    if not job_context.resume_from_failure:
+        yield DagsterEvent.job_start(job_context)
 
-    pipeline_exception_info = None
-    pipeline_canceled_info = None
+    job_exception_info = None
+    job_canceled_info = None
     failed_steps = []
     generator_closed = False
     try:
-        for event in pipeline_context.executor.execute(pipeline_context, execution_plan):
+        for event in job_context.executor.execute(job_context, execution_plan):
             if event.is_step_failure:
                 failed_steps.append(event.step_key)
             elif event.is_resource_init_failure and event.step_key:
                 failed_steps.append(event.step_key)
 
             # Telemetry
-            log_dagster_event(event, pipeline_context)
+            log_dagster_event(event, job_context)
 
             yield event
     except GeneratorExit:
         # Shouldn't happen, but avoid runtime-exception in case this generator gets GC-ed
         # (see https://amir.rachum.com/blog/2017/03/03/generator-cleanup/).
         generator_closed = True
-        pipeline_exception_info = serializable_error_info_from_exc_info(sys.exc_info())
-        if pipeline_context.raise_on_error:
+        job_exception_info = serializable_error_info_from_exc_info(sys.exc_info())
+        if job_context.raise_on_error:
             raise
     except (KeyboardInterrupt, DagsterExecutionInterruptedError):
-        pipeline_canceled_info = serializable_error_info_from_exc_info(sys.exc_info())
-        if pipeline_context.raise_on_error:
+        job_canceled_info = serializable_error_info_from_exc_info(sys.exc_info())
+        if job_context.raise_on_error:
             raise
     except BaseException:
-        pipeline_exception_info = serializable_error_info_from_exc_info(sys.exc_info())
-        if pipeline_context.raise_on_error:
+        job_exception_info = serializable_error_info_from_exc_info(sys.exc_info())
+        if job_context.raise_on_error:
             raise  # finally block will run before this is re-raised
     finally:
-        if pipeline_canceled_info:
-            reloaded_run = pipeline_context.instance.get_run_by_id(pipeline_context.run_id)
+        if job_canceled_info:
+            reloaded_run = job_context.instance.get_run_by_id(job_context.run_id)
             if reloaded_run and reloaded_run.status == DagsterRunStatus.CANCELING:
-                event = DagsterEvent.pipeline_canceled(pipeline_context, pipeline_canceled_info)
+                event = DagsterEvent.job_canceled(job_context, job_canceled_info)
             elif reloaded_run and reloaded_run.status == DagsterRunStatus.CANCELED:
                 # This happens if the run was force-terminated but was still able to send
                 # a cancellation request
                 event = DagsterEvent.engine_event(
-                    pipeline_context,
+                    job_context,
                     (
                         "Computational resources were cleaned up after the run was forcibly marked"
                         " as canceled."
                     ),
                     EngineEventData(),
                 )
-            elif pipeline_context.instance.run_will_resume(pipeline_context.run_id):
+            elif job_context.instance.run_will_resume(job_context.run_id):
                 event = DagsterEvent.engine_event(
-                    pipeline_context,
+                    job_context,
                     (
                         "Execution was interrupted unexpectedly. No user initiated termination"
                         " request was found, not treating as failure because run will be resumed."
                     ),
                     EngineEventData(),
                 )
             elif reloaded_run and reloaded_run.status == DagsterRunStatus.FAILURE:
                 event = DagsterEvent.engine_event(
-                    pipeline_context,
+                    job_context,
                     "Execution was interrupted for a run that was already in a failure state.",
                     EngineEventData(),
                 )
             else:
-                event = DagsterEvent.pipeline_failure(
-                    pipeline_context,
+                event = DagsterEvent.job_failure(
+                    job_context,
                     (
                         "Execution was interrupted unexpectedly. "
                         "No user initiated termination request was found, treating as failure."
                     ),
-                    pipeline_canceled_info,
+                    job_canceled_info,
                 )
-        elif pipeline_exception_info:
-            event = DagsterEvent.pipeline_failure(
-                pipeline_context,
+        elif job_exception_info:
+            event = DagsterEvent.job_failure(
+                job_context,
                 "An exception was thrown during execution.",
-                pipeline_exception_info,
+                job_exception_info,
             )
         elif failed_steps:
-            event = DagsterEvent.pipeline_failure(
-                pipeline_context,
+            event = DagsterEvent.job_failure(
+                job_context,
                 f"Steps failed: {failed_steps}.",
             )
         else:
-            event = DagsterEvent.pipeline_success(pipeline_context)
+            event = DagsterEvent.job_success(job_context)
         if not generator_closed:
             yield event
 
 
 class ExecuteRunWithPlanIterable:
     """Utility class to consolidate execution logic.
 
@@ -864,112 +864,112 @@
     ):
         self.execution_plan = check.inst_param(execution_plan, "execution_plan", ExecutionPlan)
         self.iterator = check.callable_param(iterator, "iterator")
         self.execution_context_manager = check.inst_param(
             execution_context_manager, "execution_context_manager", ExecutionContextManager
         )
 
-        self.pipeline_context = None
+        self.job_context = None
 
     def __iter__(self) -> Iterator[DagsterEvent]:
         # Since interrupts can't be raised at arbitrary points safely, delay them until designated
         # checkpoints during the execution.
         # To be maximally certain that interrupts are always caught during an execution process,
         # you can safely add an additional `with capture_interrupts()` at the very beginning of the
         # process that performs the execution.
         with capture_interrupts():
             yield from self.execution_context_manager.prepare_context()
-            self.pipeline_context = self.execution_context_manager.get_context()
+            self.job_context = self.execution_context_manager.get_context()
             generator_closed = False
             try:
-                if self.pipeline_context:  # False if we had a pipeline init failure
+                if self.job_context:  # False if we had a pipeline init failure
                     yield from self.iterator(
                         execution_plan=self.execution_plan,
-                        pipeline_context=self.pipeline_context,
+                        job_context=self.job_context,
                     )
             except GeneratorExit:
                 # Shouldn't happen, but avoid runtime-exception in case this generator gets GC-ed
                 # (see https://amir.rachum.com/blog/2017/03/03/generator-cleanup/).
                 generator_closed = True
                 raise
             finally:
                 for event in self.execution_context_manager.shutdown_context():
                     if not generator_closed:
                         yield event
 
 
 def _check_execute_job_args(
-    job_arg: Union[JobDefinition, IPipeline],
+    job_arg: Union[JobDefinition, IJob],
     run_config: Optional[Mapping[str, object]],
     tags: Optional[Mapping[str, str]],
     op_selection: Optional[Sequence[str]] = None,
 ) -> Tuple[
-    IPipeline,
+    IJob,
     Optional[Mapping],
     Mapping[str, str],
     Optional[AbstractSet[str]],
     Optional[Sequence[str]],
 ]:
-    job_arg = _check_pipeline(job_arg)
+    job_arg = _check_job(job_arg)
     job_def = job_arg.get_definition()
     check.inst_param(job_def, "job_def", JobDefinition)
 
     run_config = check.opt_mapping_param(run_config, "run_config")
 
     tags = check.opt_mapping_param(tags, "tags", key_type=str)
     check.opt_sequence_param(op_selection, "solid_selection", of_type=str)
 
     tags = merge_dicts(job_def.tags, tags)
 
-    # generate pipeline subset from the given solid_selection
+    # generate job subset from the given solid_selection
     if op_selection:
         job_arg = job_arg.subset_for_execution(op_selection)
 
     return (
         job_arg,
         run_config,
         tags,
         job_arg.solids_to_execute,
         op_selection,
     )
 
 
 def _resolve_reexecute_step_selection(
     instance: DagsterInstance,
-    pipeline: IPipeline,
+    job: IJob,
     run_config: Optional[Mapping],
     parent_dagster_run: DagsterRun,
     step_selection: Sequence[str],
 ) -> ExecutionPlan:
     if parent_dagster_run.solid_selection:
-        pipeline = pipeline.subset_for_execution(parent_dagster_run.solid_selection, None)
+        job = job.subset_for_execution(parent_dagster_run.solid_selection, None)
 
     state = KnownExecutionState.build_for_reexecution(instance, parent_dagster_run)
 
     parent_plan = create_execution_plan(
-        pipeline,
+        job,
         parent_dagster_run.run_config,
         known_state=state,
     )
     step_keys_to_execute = parse_step_selection(parent_plan.get_all_step_deps(), step_selection)
     execution_plan = create_execution_plan(
-        pipeline,
+        job,
         run_config,
         step_keys_to_execute=list(step_keys_to_execute),
         known_state=state.update_for_step_selection(step_keys_to_execute),
         tags=parent_dagster_run.tags,
     )
     return execution_plan
 
 
 def _job_with_repository_load_data(
-    job_arg: Union[JobDefinition, IPipeline],
-) -> Tuple[Union[JobDefinition, IPipeline], Optional[RepositoryLoadData]]:
-    """For ReconstructablePipeline, generate and return any required RepositoryLoadData, alongside
-    a ReconstructablePipeline with this repository load data baked in.
+    job_arg: Union[JobDefinition, IJob],
+) -> Tuple[Union[JobDefinition, IJob], Optional[RepositoryLoadData]]:
+    """For ReconstructableJob, generate and return any required RepositoryLoadData, alongside
+    a ReconstructableJob with this repository load data baked in.
     """
-    if isinstance(job_arg, ReconstructablePipeline):
-        # Unless this ReconstructablePipeline alread has repository_load_data attached, this will
+    if isinstance(job_arg, ReconstructableJob):
+        # Unless this ReconstructableJob alread has repository_load_data attached, this will
         # force the repository_load_data to be computed from scratch.
         repository_load_data = job_arg.repository.get_definition().repository_load_data
         return job_arg.with_repository_load_data(repository_load_data), repository_load_data
     return job_arg, None
```

### Comparing `dagster-1.3.2/dagster/_core/execution/asset_backfill.py` & `dagster-1.3.3/dagster/_core/execution/asset_backfill.py`

 * *Files 4% similar despite different names*

```diff
@@ -8,14 +8,15 @@
     List,
     Mapping,
     NamedTuple,
     Optional,
     Sequence,
     Set,
     Tuple,
+    Union,
     cast,
 )
 
 from dagster import _check as check
 from dagster._core.definitions.asset_graph import AssetGraph
 from dagster._core.definitions.asset_graph_subset import AssetGraphSubset
 from dagster._core.definitions.asset_reconciliation_sensor import (
@@ -24,41 +25,86 @@
 )
 from dagster._core.definitions.asset_selection import AssetSelection
 from dagster._core.definitions.assets_job import is_base_asset_job_name
 from dagster._core.definitions.events import AssetKey, AssetKeyPartitionKey
 from dagster._core.definitions.external_asset_graph import ExternalAssetGraph
 from dagster._core.definitions.partition import PartitionsSubset
 from dagster._core.definitions.run_request import RunRequest
-from dagster._core.definitions.selector import PipelineSelector
+from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.errors import DagsterBackfillFailedError
 from dagster._core.events import DagsterEventType
 from dagster._core.host_representation import (
     ExternalExecutionPlan,
-    ExternalPipeline,
+    ExternalJob,
 )
 from dagster._core.instance import DagsterInstance, DynamicPartitionsStore
-from dagster._core.storage.pipeline_run import DagsterRunStatus, RunsFilter
+from dagster._core.storage.dagster_run import DagsterRunStatus, RunsFilter
 from dagster._core.storage.tags import BACKFILL_ID_TAG, PARTITION_NAME_TAG
 from dagster._core.workspace.context import (
     BaseWorkspaceRequestContext,
     IWorkspaceProcessContext,
 )
 from dagster._utils import hash_collection
 from dagster._utils.caching_instance_queryer import CachingInstanceQueryer
 
 if TYPE_CHECKING:
     from .backfill import PartitionBackfill
 
 
-class BackfillPartitionsStatus(Enum):
-    REQUESTED = "REQUESTED"
-    COMPLETED = "COMPLETED"
+class AssetBackfillStatus(Enum):
+    IN_PROGRESS = "IN_PROGRESS"
+    MATERIALIZED = "MATERIALIZED"
     FAILED = "FAILED"
 
 
+class PartitionedAssetBackfillStatus(
+    NamedTuple(
+        "_PartitionedAssetBackfillStatus",
+        [
+            ("asset_key", AssetKey),
+            ("num_targeted_partitions", int),
+            ("partitions_counts_by_status", Mapping[AssetBackfillStatus, int]),
+        ],
+    )
+):
+    def __new__(
+        cls,
+        asset_key: AssetKey,
+        num_targeted_partitions: int,
+        partitions_counts_by_status: Mapping[AssetBackfillStatus, int],
+    ):
+        return super(PartitionedAssetBackfillStatus, cls).__new__(
+            cls,
+            check.inst_param(asset_key, "asset_key", AssetKey),
+            check.int_param(num_targeted_partitions, "num_targeted_partitions"),
+            check.mapping_param(
+                partitions_counts_by_status,
+                "partitions_counts_by_status",
+                key_type=AssetBackfillStatus,
+                value_type=int,
+            ),
+        )
+
+
+class UnpartitionedAssetBackfillStatus(
+    NamedTuple(
+        "_UnpartitionedAssetBackfillStatus",
+        [("asset_key", AssetKey), ("backfill_status", Optional[AssetBackfillStatus])],
+    )
+):
+    def __new__(cls, asset_key: AssetKey, asset_backfill_status: Optional[AssetBackfillStatus]):
+        return super(UnpartitionedAssetBackfillStatus, cls).__new__(
+            cls,
+            check.inst_param(asset_key, "asset_key", AssetKey),
+            check.opt_inst_param(
+                asset_backfill_status, "asset_backfill_status", AssetBackfillStatus
+            ),
+        )
+
+
 class AssetBackfillData(NamedTuple):
     """Has custom serialization instead of standard Dagster NamedTuple serialization because the
     asset graph is required to build the AssetGraphSubset objects.
     """
 
     target_subset: AssetGraphSubset
     requested_runs_for_target_roots: bool
@@ -118,65 +164,88 @@
         if len(asset_partition_nums) == 0:
             return 0
         elif len(asset_partition_nums) == 1:
             return next(iter(asset_partition_nums))
         else:
             return None
 
-    def get_num_targeted_partitions_by_asset_key(self) -> Mapping[AssetKey, int]:
-        return {
-            asset_key: len(subset)
-            for asset_key, subset in self.target_subset.partitions_subsets_by_asset_key.items()
-        }
-
-    def get_targeted_partitioned_asset_keys_topological_order(self) -> Sequence[AssetKey]:
-        """Returns a topological ordering of partitioned asset keys targeted by the backfill.
+    def get_targeted_asset_keys_topological_order(self) -> Sequence[AssetKey]:
+        """Returns a topological ordering of asset keys targeted by the backfill
+        that exist in the asset graph.
 
         Orders keys in the same topological level alphabetically.
         """
         toposorted_keys = self.target_subset.asset_graph.toposort_asset_keys()
 
         targeted_toposorted_keys = []
         for level_keys in toposorted_keys:
             for key in sorted(level_keys):
-                if (
-                    key in self.target_subset.asset_keys
-                    and self.target_subset.asset_graph.get_partitions_def(key) is not None
-                ):
+                if key in self.target_subset.asset_keys:
                     targeted_toposorted_keys.append(key)
 
         return targeted_toposorted_keys
 
-    def get_partitions_status_counts_by_asset_key(
+    def get_backfill_status_per_asset_key(
         self,
-    ) -> Mapping[AssetKey, Mapping[BackfillPartitionsStatus, int]]:
-        """Returns a mapping from asset key to a mapping from status to count of partitions in that
-        status.
-
-        Only includes assets that are partitioned.
+    ) -> Sequence[Union[PartitionedAssetBackfillStatus, UnpartitionedAssetBackfillStatus]]:
+        """Returns a list containing each targeted asset key's backfill status.
+        This list orders assets topologically and only contains statuses for assets that are
+        currently existent in the asset graph.
         """
-        return {
-            asset_key: {
-                BackfillPartitionsStatus.COMPLETED: len(
-                    self.materialized_subset.get_partitions_subset(asset_key)
-                ),
-                BackfillPartitionsStatus.FAILED: len(
-                    self.failed_and_downstream_subset.get_partitions_subset(asset_key)
-                ),
-                BackfillPartitionsStatus.REQUESTED: len(
-                    self.requested_subset.get_partitions_subset(asset_key)
+
+        def _get_status_for_asset_key(
+            asset_key: AssetKey,
+        ) -> Union[PartitionedAssetBackfillStatus, UnpartitionedAssetBackfillStatus]:
+            if self.target_subset.asset_graph.get_partitions_def(asset_key) is not None:
+                materialized_subset = self.materialized_subset.get_partitions_subset(asset_key)
+                failed_partitions = set(
+                    self.failed_and_downstream_subset.get_partitions_subset(
+                        asset_key
+                    ).get_partition_keys()
                 )
-                - (
-                    len(self.failed_and_downstream_subset.get_partitions_subset(asset_key))
-                    + len(self.materialized_subset.get_partitions_subset(asset_key))
-                ),
-            }
-            for asset_key in self.target_subset.asset_keys
-            if self.target_subset.asset_graph.get_partitions_def(asset_key) is not None
-        }
+                requested_partitions = set(
+                    self.requested_subset.get_partitions_subset(asset_key).get_partition_keys()
+                )
+
+                return PartitionedAssetBackfillStatus(
+                    asset_key,
+                    len(self.target_subset.get_partitions_subset(asset_key)),
+                    {
+                        AssetBackfillStatus.MATERIALIZED: len(materialized_subset),
+                        AssetBackfillStatus.FAILED: len(failed_partitions),
+                        AssetBackfillStatus.IN_PROGRESS: len(requested_partitions)
+                        - (
+                            len(failed_partitions & requested_partitions) + len(materialized_subset)
+                        ),
+                    },
+                )
+            else:
+                failed = bool(
+                    asset_key in self.failed_and_downstream_subset.non_partitioned_asset_keys
+                )
+                materialized = bool(
+                    asset_key in self.materialized_subset.non_partitioned_asset_keys
+                )
+                in_progress = bool(asset_key in self.requested_subset.non_partitioned_asset_keys)
+
+                if failed:
+                    return UnpartitionedAssetBackfillStatus(asset_key, AssetBackfillStatus.FAILED)
+                if materialized:
+                    return UnpartitionedAssetBackfillStatus(
+                        asset_key, AssetBackfillStatus.MATERIALIZED
+                    )
+                if in_progress:
+                    return UnpartitionedAssetBackfillStatus(
+                        asset_key, AssetBackfillStatus.IN_PROGRESS
+                    )
+                return UnpartitionedAssetBackfillStatus(asset_key, None)
+
+        # Only return back statuses for the assets that still exist in the workspace
+        topological_order = self.get_targeted_asset_keys_topological_order()
+        return [_get_status_for_asset_key(asset_key) for asset_key in topological_order]
 
     def get_partition_names(self) -> Optional[Sequence[str]]:
         """Only valid when the same number of partitions are targeted in every asset.
 
         When not valid, returns None.
         """
         subsets = self.target_subset.partitions_subsets_by_asset_key.values()
@@ -358,17 +427,15 @@
     if result.backfill_data.is_complete():
         # The asset backfill is complete when all runs to be requested have finished (success,
         # failure, or cancellation). Since the AssetBackfillData object stores materialization states
         # per asset partition, the daemon continues to update the backfill data until all runs have
         # finished in order to display the final partition statuses in the UI.
         updated_backfill = updated_backfill.with_status(BulkActionStatus.COMPLETED)
 
-    pipeline_and_execution_plan_cache: Dict[
-        int, Tuple[ExternalPipeline, ExternalExecutionPlan]
-    ] = {}
+    pipeline_and_execution_plan_cache: Dict[int, Tuple[ExternalJob, ExternalExecutionPlan]] = {}
 
     for run_request in result.run_requests:
         yield None
         submit_run_request(
             run_request=run_request,
             asset_graph=asset_graph,
             # create a new request context for each run in case the code location server
@@ -382,15 +449,15 @@
 
 
 def submit_run_request(
     asset_graph: ExternalAssetGraph,
     run_request: RunRequest,
     instance: DagsterInstance,
     workspace: BaseWorkspaceRequestContext,
-    pipeline_and_execution_plan_cache: Dict[int, Tuple[ExternalPipeline, ExternalExecutionPlan]],
+    pipeline_and_execution_plan_cache: Dict[int, Tuple[ExternalJob, ExternalExecutionPlan]],
 ) -> None:
     """Creates and submits a run for the given run request."""
     repo_handle = asset_graph.get_repository_handle(
         cast(Sequence[AssetKey], run_request.asset_selection)[0]
     )
     location_name = repo_handle.code_location_origin.location_name
     job_name = _get_implicit_job_name_for_assets(
@@ -401,59 +468,59 @@
             "Could not find an implicit asset job for the given assets:"
             f" {run_request.asset_selection}"
         )
 
     if not run_request.asset_selection:
         check.failed("Expected RunRequest to have an asset selection")
 
-    pipeline_selector = PipelineSelector(
+    pipeline_selector = JobSubsetSelector(
         location_name=location_name,
         repository_name=repo_handle.repository_name,
-        pipeline_name=job_name,
+        job_name=job_name,
         asset_selection=run_request.asset_selection,
         solid_selection=None,
     )
 
     selector_id = hash_collection(pipeline_selector)
 
     if selector_id not in pipeline_and_execution_plan_cache:
         code_location = workspace.get_code_location(repo_handle.code_location_origin.location_name)
 
-        external_pipeline = code_location.get_external_pipeline(pipeline_selector)
+        external_job = code_location.get_external_job(pipeline_selector)
 
         external_execution_plan = code_location.get_external_execution_plan(
-            external_pipeline,
+            external_job,
             {},
             step_keys_to_execute=None,
             known_state=None,
             instance=instance,
         )
         pipeline_and_execution_plan_cache[selector_id] = (
-            external_pipeline,
+            external_job,
             external_execution_plan,
         )
 
-    external_pipeline, external_execution_plan = pipeline_and_execution_plan_cache[selector_id]
+    external_job, external_execution_plan = pipeline_and_execution_plan_cache[selector_id]
 
     run = instance.create_run(
-        pipeline_snapshot=external_pipeline.pipeline_snapshot,
+        job_snapshot=external_job.job_snapshot,
         execution_plan_snapshot=external_execution_plan.execution_plan_snapshot,
-        parent_pipeline_snapshot=external_pipeline.parent_pipeline_snapshot,
-        pipeline_name=external_pipeline.name,
+        parent_job_snapshot=external_job.parent_job_snapshot,
+        job_name=external_job.name,
         run_id=None,
         solids_to_execute=None,
         solid_selection=None,
         run_config={},
         step_keys_to_execute=None,
         tags=run_request.tags,
         root_run_id=None,
         parent_run_id=None,
         status=DagsterRunStatus.NOT_STARTED,
-        external_pipeline_origin=external_pipeline.get_external_origin(),
-        pipeline_code_origin=external_pipeline.get_python_origin(),
+        external_job_origin=external_job.get_external_origin(),
+        job_code_origin=external_job.get_python_origin(),
         asset_selection=frozenset(run_request.asset_selection),
     )
 
     instance.submit_run(run.run_id, workspace)
 
 
 def _get_implicit_job_name_for_assets(
```

### Comparing `dagster-1.3.2/dagster/_core/execution/backfill.py` & `dagster-1.3.3/dagster/_core/execution/backfill.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 from enum import Enum
-from typing import Mapping, NamedTuple, Optional, Sequence, Tuple
+from typing import Mapping, NamedTuple, Optional, Sequence, Union
 
 from dagster import _check as check
 from dagster._core.definitions import AssetKey
 from dagster._core.definitions.asset_graph import AssetGraph
 from dagster._core.definitions.external_asset_graph import ExternalAssetGraph
 from dagster._core.definitions.partition import PartitionsSubset
 from dagster._core.errors import (
@@ -13,15 +13,19 @@
 from dagster._core.host_representation.origin import ExternalPartitionSetOrigin
 from dagster._core.instance import DynamicPartitionsStore
 from dagster._core.storage.tags import USER_TAG
 from dagster._core.workspace.workspace import IWorkspace
 from dagster._serdes import whitelist_for_serdes
 from dagster._utils.error import SerializableErrorInfo
 
-from .asset_backfill import AssetBackfillData, BackfillPartitionsStatus
+from .asset_backfill import (
+    AssetBackfillData,
+    PartitionedAssetBackfillStatus,
+    UnpartitionedAssetBackfillStatus,
+)
 
 
 @whitelist_for_serdes
 class BulkActionStatus(Enum):
     REQUESTED = "REQUESTED"
     COMPLETED = "COMPLETED"
     FAILED = "FAILED"
@@ -130,60 +134,35 @@
         if self.serialized_asset_backfill_data is not None:
             return AssetBackfillData.is_valid_serialization(
                 self.serialized_asset_backfill_data, ExternalAssetGraph.from_workspace(workspace)
             )
         else:
             return True
 
-    def get_partitions_status_counts_and_totals_by_asset(
+    def get_backfill_status_per_asset_key(
         self, workspace: IWorkspace
-    ) -> Mapping[AssetKey, Tuple[Mapping[BackfillPartitionsStatus, int], int]]:
-        """Returns a list of tuples of the form (asset_key, partitions_status_counts, total_partitions)
-        in topological order of the asset graph. Includes only partitioned assets.
+    ) -> Sequence[Union[PartitionedAssetBackfillStatus, UnpartitionedAssetBackfillStatus]]:
+        """Returns a sequence of backfill statuses for each targeted asset key in the asset graph,
+        in topological order.
         """
         if not self.is_valid_serialization(workspace):
-            return {}
+            return []
 
         if self.serialized_asset_backfill_data is not None:
             try:
                 asset_backfill_data = AssetBackfillData.from_serialized(
                     self.serialized_asset_backfill_data,
                     ExternalAssetGraph.from_workspace(workspace),
                 )
             except DagsterDefinitionChangedDeserializationError:
-                return {}
-
-            partitions_status_counts_by_asset_key = (
-                asset_backfill_data.get_partitions_status_counts_by_asset_key()
-            )
-            num_targeted_partitions_by_asset_key = (
-                asset_backfill_data.get_num_targeted_partitions_by_asset_key()
-            )
-            topological_order = (
-                asset_backfill_data.get_targeted_partitioned_asset_keys_topological_order()
-            )
-
-            check.invariant(
-                partitions_status_counts_by_asset_key.keys()
-                == num_targeted_partitions_by_asset_key.keys()
-            )
-            check.invariant(
-                set(partitions_status_counts_by_asset_key.keys()) == set(topological_order)
-            )
-
-            return {
-                asset_key: (
-                    partitions_status_counts_by_asset_key[asset_key],
-                    num_targeted_partitions_by_asset_key[asset_key],
-                )
-                for asset_key in topological_order
-            }
+                return []
 
+            return asset_backfill_data.get_backfill_status_per_asset_key()
         else:
-            return {}
+            return []
 
     def get_target_root_partitions_subset(
         self, workspace: IWorkspace
     ) -> Optional[PartitionsSubset]:
         if not self.is_valid_serialization(workspace):
             return None
```

### Comparing `dagster-1.3.2/dagster/_core/execution/build_resources.py` & `dagster-1.3.3/dagster/_core/execution/build_resources.py`

 * *Files 1% similar despite different names*

```diff
@@ -9,20 +9,20 @@
     ScopedResourcesBuilder,
 )
 from dagster._core.definitions.run_config import define_resource_dictionary_cls
 from dagster._core.errors import DagsterInvalidConfigError
 from dagster._core.execution.resources_init import resource_initialization_manager
 from dagster._core.instance import DagsterInstance
 from dagster._core.log_manager import DagsterLogManager
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._core.storage.io_manager import IOManager, IOManagerDefinition
-from dagster._core.storage.pipeline_run import DagsterRun
 from dagster._core.system_config.objects import ResourceConfig, config_map_resources
 
 from .api import ephemeral_instance_if_missing
-from .context_creation_pipeline import initialize_console_manager
+from .context_creation_job import initialize_console_manager
 
 
 def get_mapped_resource_config(
     resource_defs: Mapping[str, ResourceDefinition], resource_config: Mapping[str, Any]
 ) -> Mapping[str, ResourceConfig]:
     resource_config_schema = define_resource_dictionary_cls(
         resource_defs, set(resource_defs.keys())
```

### Comparing `dagster-1.3.2/dagster/_core/execution/compute_logs.py` & `dagster-1.3.3/dagster/_core/execution/compute_logs.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/execution/context/compute.py` & `dagster-1.3.3/dagster/_core/execution/context/compute.py`

 * *Files 2% similar despite different names*

```diff
@@ -27,23 +27,23 @@
 from dagster._core.errors import (
     DagsterInvalidPropertyError,
     DagsterInvariantViolationError,
 )
 from dagster._core.events import DagsterEvent
 from dagster._core.instance import DagsterInstance
 from dagster._core.log_manager import DagsterLogManager
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._utils.backcompat import deprecation_warning
 from dagster._utils.forked_pdb import ForkedPdb
 
 from .system import StepExecutionContext
 
 
 class AbstractComputeExecutionContext(ABC):
-    """Base class for solid context implemented by SolidExecutionContext and DagstermillExecutionContext.
+    """Base class for op context implemented by OpExecutionContext and DagstermillExecutionContext.
     """
 
     @abstractmethod
     def has_tag(self, key: str) -> bool:
         """Implement this method to check if a logging tag is set."""
 
     @abstractmethod
@@ -119,22 +119,22 @@
 
     @public
     @property
     def op_config(self) -> Any:
         return self._step_execution_context.op_config
 
     @property
-    def pipeline_run(self) -> DagsterRun:
+    def dagster_run(self) -> DagsterRun:
         """PipelineRun: The current pipeline run."""
         return self._step_execution_context.dagster_run
 
     @property
     def run(self) -> DagsterRun:
         """DagsterRun: The current run."""
-        return self.pipeline_run
+        return self.dagster_run
 
     @public
     @property
     def instance(self) -> DagsterInstance:
         """DagsterInstance: The current Dagster instance."""
         return self._step_execution_context.instance
 
@@ -186,81 +186,54 @@
     @public
     @property
     def run_config(self) -> Mapping[str, object]:
         """dict: The run config for the current execution."""
         return self._step_execution_context.run_config
 
     @property
-    def pipeline_def(self) -> JobDefinition:
-        """PipelineDefinition: The currently executing pipeline."""
-        return self._step_execution_context.pipeline_def
-
-    @public
-    @property
     def job_def(self) -> JobDefinition:
-        """JobDefinition: The currently executing job."""
-        return cast(
-            JobDefinition,
-            check.inst(
-                self.pipeline_def,
-                JobDefinition,
-                "Accessing job_def inside a legacy pipeline. Use pipeline_def instead.",
-            ),
-        )
-
-    @property
-    def pipeline_name(self) -> str:
-        """str: The name of the currently executing pipeline."""
-        return self._step_execution_context.pipeline_name
+        """JobDefinition: The currently executing pipeline."""
+        return self._step_execution_context.job_def
 
     @public
     @property
     def job_name(self) -> str:
-        """str: The name of the currently executing job."""
-        return self.pipeline_name
+        """str: The name of the currently executing pipeline."""
+        return self._step_execution_context.job_name
 
     @public
     @property
     def log(self) -> DagsterLogManager:
         """DagsterLogManager: The log manager available in the execution context."""
         return self._step_execution_context.log
 
     @property
     def node_handle(self) -> NodeHandle:
-        """NodeHandle: The current solid's handle.
+        """NodeHandle: The current op's handle.
 
         :meta private:
         """
         return self._step_execution_context.node_handle
 
     @property
     def op_handle(self) -> NodeHandle:
         """NodeHandle: The current op's handle.
 
         :meta private:
         """
         return self.node_handle
 
     @property
-    def solid(self) -> Node:
-        """Solid: The current solid object.
-
-        :meta private:
-
-        """
-        return self._step_execution_context.pipeline_def.get_node(self.node_handle)
-
-    @property
     def op(self) -> Node:
         """Solid: The current op object.
 
         :meta private:
 
         """
-        return self.solid
+        return self._step_execution_context.job_def.get_node(self.node_handle)
 
     @public
     @property
     def op_def(self) -> OpDefinition:
         """OpDefinition: The current op definition."""
         return cast(OpDefinition, self.op.definition)
 
@@ -336,25 +309,25 @@
             ) or (asset_info and asset_info.key in selected_asset_keys):
                 selected_outputs.add(output_name)
 
         return selected_outputs
 
     @public
     def asset_key_for_output(self, output_name: str = "result") -> AssetKey:
-        asset_output_info = self.pipeline_def.asset_layer.asset_info_for_output(
+        asset_output_info = self.job_def.asset_layer.asset_info_for_output(
             node_handle=self.op_handle, output_name=output_name
         )
         if asset_output_info is None:
             check.failed(f"Output '{output_name}' has no asset")
         else:
             return asset_output_info.key
 
     @public
     def asset_key_for_input(self, input_name: str) -> AssetKey:
-        key = self.pipeline_def.asset_layer.asset_key_for_input(
+        key = self.job_def.asset_layer.asset_key_for_input(
             node_handle=self.op_handle, input_name=input_name
         )
         if key is None:
             check.failed(f"Input '{input_name}' has no asset")
         else:
             return key
 
@@ -411,30 +384,30 @@
         """Returns the partition key of the upstream asset corresponding to the given input."""
         return self._step_execution_context.asset_partition_key_for_input(input_name)
 
     @public
     def asset_partitions_def_for_output(self, output_name: str = "result") -> PartitionsDefinition:
         """The PartitionsDefinition on the upstream asset corresponding to this input."""
         asset_key = self.asset_key_for_output(output_name)
-        result = self._step_execution_context.pipeline_def.asset_layer.partitions_def_for_asset(
+        result = self._step_execution_context.job_def.asset_layer.partitions_def_for_asset(
             asset_key
         )
         if result is None:
             raise DagsterInvariantViolationError(
                 f"Attempting to access partitions def for asset {asset_key}, but it is not"
                 " partitioned"
             )
 
         return result
 
     @public
     def asset_partitions_def_for_input(self, input_name: str) -> PartitionsDefinition:
         """The PartitionsDefinition on the upstream asset corresponding to this input."""
         asset_key = self.asset_key_for_input(input_name)
-        result = self._step_execution_context.pipeline_def.asset_layer.partitions_def_for_asset(
+        result = self._step_execution_context.job_def.asset_layer.partitions_def_for_asset(
             asset_key
         )
         if result is None:
             raise DagsterInvariantViolationError(
                 f"Attempting to access partitions def for asset {asset_key}, but it is not"
                 " partitioned"
             )
@@ -457,14 +430,25 @@
         return list(
             self._step_execution_context.asset_partitions_subset_for_input(
                 input_name
             ).get_partition_keys()
         )
 
     @public
+    def asset_partitions_time_window_for_input(self, input_name: str = "result") -> TimeWindow:
+        """The time window for the partitions of the input asset.
+
+        Raises an error if either of the following are true:
+        - The input asset has no partitioning.
+        - The input asset is not partitioned with a TimeWindowPartitionsDefinition or a
+        MultiPartitionsDefinition with one time-partitioned dimension.
+        """
+        return self._step_execution_context.asset_partitions_time_window_for_input(input_name)
+
+    @public
     def has_tag(self, key: str) -> bool:
         """Check if a logging tag is set.
 
         Args:
             key (str): The tag to check.
 
         Returns:
```

### Comparing `dagster-1.3.2/dagster/_core/execution/context/hook.py` & `dagster-1.3.3/dagster/_core/execution/context/hook.py`

 * *Files 2% similar despite different names*

```diff
@@ -42,125 +42,117 @@
             "concepts docs: https://docs.dagster.io/concepts/ops-jobs-graphs/op-hooks#testing-hooks"
         )
     else:
         return value
 
 
 class HookContext:
-    """The ``context`` object available to a hook function on an DagsterEvent.
-
-    Attributes:
-        log (DagsterLogManager): Centralized log dispatch from user code.
-        hook_def (HookDefinition): The hook that the context object belongs to.
-        op (Op): The op instance associated with the hook.
-        step_key (str): The key for the step where this hook is being triggered.
-        required_resource_keys (Set[str]): Resources required by this hook.
-        resources (Resources): Resources available in the hook context.
-        op_config (Any): The parsed config specific to this op.
-        job_name (str): The name of the job where this hook is being triggered.
-        run_id (str): The id of the run where this hook is being triggered.
-        op_exception (Optional[BaseException]): The thrown exception in a failed op.
-        op_output_values (Dict): Computed output values in an op.
-    """
+    """The ``context`` object available to a hook function on an DagsterEvent."""
 
     def __init__(
         self,
         step_execution_context: StepExecutionContext,
         hook_def: HookDefinition,
     ):
         self._step_execution_context = step_execution_context
         self._hook_def = check.inst_param(hook_def, "hook_def", HookDefinition)
         self._required_resource_keys = hook_def.required_resource_keys
         self._resources = step_execution_context.scoped_resources_builder.build(
             self._required_resource_keys
         )
 
-    @property
-    def pipeline_name(self) -> str:
-        return self.job_name
-
     @public
     @property
     def job_name(self) -> str:
+        """The name of the job where this hook is being triggered."""
         return self._step_execution_context.job_name
 
     @public
     @property
     def run_id(self) -> str:
+        """The id of the run where this hook is being triggered."""
         return self._step_execution_context.run_id
 
     @public
     @property
     def hook_def(self) -> HookDefinition:
+        """The hook that the context object belongs to."""
         return self._hook_def
 
     @public
     @property
     def instance(self) -> "DagsterInstance":
         return self._step_execution_context.instance
 
     @property
     def op(self) -> Node:
-        return self._step_execution_context.solid
+        """The op instance associated with the hook."""
+        return self._step_execution_context.op
 
     @property
     def step(self) -> ExecutionStep:
         warnings.warn(
             "The step property of HookContext has been deprecated, and will be removed "
             "in a future release."
         )
         return self._step_execution_context.step
 
     @public
     @property
     def step_key(self) -> str:
+        """The key for the step where this hook is being triggered."""
         return self._step_execution_context.step.key
 
     @public
     @property
     def required_resource_keys(self) -> AbstractSet[str]:
+        """Resources required by this hook."""
         return self._required_resource_keys
 
     @public
     @property
     def resources(self) -> "Resources":
+        """Resources available in the hook context."""
         return self._resources
 
     @property
     def solid_config(self) -> Any:
         solid_config = self._step_execution_context.resolved_run_config.ops.get(
             str(self._step_execution_context.step.node_handle)
         )
         return solid_config.config if solid_config else None
 
     @public
     @property
     def op_config(self) -> Any:
+        """The parsed config specific to this op."""
         return self.solid_config
 
     # Because of the fact that we directly use the log manager of the step, if a user calls
     # hook_context.log.with_tags, then they will end up mutating the step's logging tags as well.
     # This is not problematic because the hook only runs after the step has been completed.
     @public
     @property
     def log(self) -> DagsterLogManager:
+        """Centralized log dispatch from user code."""
         return self._step_execution_context.log
 
     @property
     def solid_exception(self) -> Optional[BaseException]:
         """The thrown exception in a failed solid.
 
         Returns:
             Optional[BaseException]: the exception object, None if the solid execution succeeds.
         """
         return self.op_exception
 
     @public
     @property
     def op_exception(self) -> Optional[BaseException]:
+        """The thrown exception in a failed op."""
         exc = self._step_execution_context.step_exception
 
         if isinstance(exc, RetryRequestedFromPolicy):
             return exc.__cause__
 
         return exc
 
@@ -191,29 +183,30 @@
                 results[step_output_handle.output_name] = value
 
         return results
 
     @public
     @property
     def op_output_values(self):
+        """Computed output values in an op."""
         return self.solid_output_values
 
 
 class UnboundHookContext(HookContext):
     def __init__(
         self,
         resources: Mapping[str, Any],
         op: Optional[Union[OpDefinition, PendingNodeInvocation]],
         run_id: Optional[str],
         job_name: Optional[str],
         op_exception: Optional[Exception],
         instance: Optional["DagsterInstance"],
     ):
         from ..build_resources import build_resources, wrap_resources_for_execution
-        from ..context_creation_pipeline import initialize_console_manager
+        from ..context_creation_job import initialize_console_manager
 
         self._op = None
         if op is not None:
 
             @graph(name="hook_context_container")
             def temp_graph():
                 op()
@@ -244,15 +237,15 @@
 
     def __del__(self):
         if self._resources_contain_cm and not self._cm_scope_entered:
             self._resources_cm.__exit__(None, None, None)
 
     @property
     def job_name(self) -> str:
-        return self.pipeline_name
+        return self.job_name
 
     @property
     def run_id(self) -> str:
         return _check_property_on_test_context(
             self, attr_str="_run_id", user_facing_name="run_id", param_on_builder="run_id"
         )
```

### Comparing `dagster-1.3.2/dagster/_core/execution/context/init.py` & `dagster-1.3.3/dagster/_core/execution/context/init.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,36 +6,22 @@
     IContainsGenerator,
     ResourceDefinition,
     Resources,
 )
 from dagster._core.errors import DagsterInvariantViolationError
 from dagster._core.instance import DagsterInstance
 from dagster._core.log_manager import DagsterLogManager
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 
 
 class InitResourceContext:
     """The context object available as the argument to the initialization function of a :py:class:`dagster.ResourceDefinition`.
 
     Users should not instantiate this object directly. To construct an `InitResourceContext` for testing purposes, use :py:func:`dagster.build_init_resource_context`.
 
-    Attributes:
-        resource_config (Any): The configuration data provided by the run config. The schema
-            for this data is defined by the ``config_field`` argument to
-            :py:class:`ResourceDefinition`.
-        resource_def (ResourceDefinition): The definition of the resource currently being
-            constructed.
-        log_manager (DagsterLogManager): The log manager for this run of the job or pipeline
-        resources (ScopedResources): The resources that are available to the resource that we are
-            initalizing.
-        dagster_run (Optional[DagsterRun]): The dagster run to use. When initializing resources
-            outside of execution context, this will be None.
-        run_id (Optional[str]): The id for this run of the job or pipeline. When initializing resources
-            outside of execution context, this will be None.
-
     Example:
         .. code-block:: python
 
             from dagster import resource, InitResourceContext
 
             @resource
             def the_resource(init_context: InitResourceContext):
@@ -57,49 +43,60 @@
         self._instance = instance
         self._resources = resources
         self._dagster_run = dagster_run
 
     @public
     @property
     def resource_config(self) -> Any:
+        """The configuration data provided by the run config. The schema
+        for this data is defined by the ``config_field`` argument to
+        :py:class:`ResourceDefinition`.
+        """
         return self._resource_config
 
     @public
     @property
     def resource_def(self) -> Optional[ResourceDefinition]:
+        """The definition of the resource currently being constructed."""
         return self._resource_def
 
     @public
     @property
     def resources(self) -> Resources:
         return self._resources
 
     @public
     @property
     def instance(self) -> Optional[DagsterInstance]:
         return self._instance
 
     @property
     def dagster_run(self) -> Optional[DagsterRun]:
+        """The dagster run to use. When initializing resources outside of execution context, this will be None.
+        """
         return self._dagster_run
 
     @public
     @property
     def log(self) -> Optional[DagsterLogManager]:
         return self._log_manager
 
     # backcompat: keep around this property from when InitResourceContext used to be a NamedTuple
     @public
     @property
     def log_manager(self) -> Optional[DagsterLogManager]:
+        """The log manager for this run of the job."""
         return self._log_manager
 
     @public
     @property
     def run_id(self) -> Optional[str]:
+        """The id for this run of the job or pipeline. When initializing resources outside of
+        execution context, this will be None.
+        """
         return self.dagster_run.run_id if self.dagster_run else None
 
     def replace_config(self, config: Any) -> "InitResourceContext":
         return InitResourceContext(
             resource_config=config,
             resources=self.resources,
             instance=self.instance,
@@ -126,15 +123,15 @@
         instance: Optional[DagsterInstance],
     ):
         from dagster._core.execution.api import ephemeral_instance_if_missing
         from dagster._core.execution.build_resources import (
             build_resources,
             wrap_resources_for_execution,
         )
-        from dagster._core.execution.context_creation_pipeline import initialize_console_manager
+        from dagster._core.execution.context_creation_job import initialize_console_manager
 
         self._instance_provided = (
             check.opt_inst_param(instance, "instance", DagsterInstance) is not None
         )
         # Construct ephemeral instance if missing
         self._instance_cm = ephemeral_instance_if_missing(instance)
         # Pylint can't infer that the ephemeral_instance context manager has an __enter__ method,
@@ -185,14 +182,15 @@
     def resource_def(self) -> Optional[ResourceDefinition]:
         raise DagsterInvariantViolationError(
             "UnboundInitLoggerContext has not been validated against a logger definition."
         )
 
     @property
     def resources(self) -> Resources:
+        """The resources that are available to the resource that we are initalizing."""
         if self._resources_cm and self._resources_contain_cm and not self._cm_scope_entered:
             raise DagsterInvariantViolationError(
                 "At least one provided resource is a generator, but attempting to access "
                 "resources outside of context manager scope. You can use the following syntax to "
                 "open a context manager: `with build_init_resource_context(...) as context:`"
             )
         return self._resources
```

### Comparing `dagster-1.3.2/dagster/_core/execution/context/input.py` & `dagster-1.3.3/dagster/_core/execution/context/input.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,15 +9,15 @@
     Optional,
     Sequence,
     Union,
 )
 
 import dagster._check as check
 from dagster._annotations import public
-from dagster._core.definitions.events import AssetKey, AssetObservation
+from dagster._core.definitions.events import AssetKey, AssetObservation, CoercibleToAssetKey
 from dagster._core.definitions.metadata import (
     ArbitraryMetadataMapping,
     MetadataValue,
 )
 from dagster._core.definitions.partition import PartitionsSubset
 from dagster._core.definitions.partition_key_range import PartitionKeyRange
 from dagster._core.definitions.time_window_partitions import TimeWindow, TimeWindowPartitionsSubset
@@ -39,38 +39,14 @@
 class InputContext:
     """The ``context`` object available to the load_input method of :py:class:`RootInputManager`.
 
     Users should not instantiate this object directly. In order to construct
     an `InputContext` for testing an IO Manager's `load_input` method, use
     :py:func:`dagster.build_input_context`.
 
-    Attributes:
-        name (Optional[str]): The name of the input that we're loading.
-        config (Optional[Any]): The config attached to the input that we're loading.
-        metadata (Optional[Dict[str, Any]]): A dict of metadata that is assigned to the
-            InputDefinition that we're loading for.
-            This property only contains metadata passed in explicitly with :py:class:`AssetIn`
-            or :py:class:`In`. To access metadata of an upstream asset or operation definition,
-            use the metadata in :py:attr:`.InputContext.upstream_output`.
-        upstream_output (Optional[OutputContext]): Info about the output that produced the object
-            we're loading.
-        dagster_type (Optional[DagsterType]): The type of this input.
-            Dagster types do not propagate from an upstream output to downstream inputs,
-            and this property only captures type information for the input that is either
-            passed in explicitly with :py:class:`AssetIn` or :py:class:`In`, or can be
-            infered from type hints. For an asset input, the Dagster type from the upstream
-            asset definition is ignored.
-        log (Optional[DagsterLogManager]): The log manager to use for this input.
-        resource_config (Optional[Dict[str, Any]]): The config associated with the resource that
-            initializes the RootInputManager.
-        resources (Optional[Resources]): The resources required by the resource that initializes the
-            input manager. If using the :py:func:`@root_input_manager` decorator, these resources
-            correspond to those requested with the `required_resource_keys` parameter.
-        op_def (Optional[OpDefinition]): The definition of the op that's loading the input.
-
     Example:
     .. code-block:: python
 
         from dagster import IOManager, InputContext
 
         class MyIOManager(IOManager):
             def load_input(self, context: InputContext):
@@ -164,14 +140,15 @@
         then it won't have an input name.
         """
         return self._name is not None
 
     @public
     @property
     def name(self) -> str:
+        """The name of the input that we're loading."""
         if self._name is None:
             raise DagsterInvariantViolationError(
                 "Attempting to access name, "
                 "but it was not provided when constructing the InputContext"
             )
 
         return self._name
@@ -181,74 +158,91 @@
         if self._job_name is None:
             raise DagsterInvariantViolationError(
                 "Attempting to access job_name, "
                 "but it was not provided when constructing the InputContext"
             )
         return self._job_name
 
-    @property
-    def pipeline_name(self) -> str:
-        return self.job_name
-
     @public
     @property
     def op_def(self) -> "OpDefinition":
+        """The definition of the op that's loading the input."""
         if self._op_def is None:
             raise DagsterInvariantViolationError(
                 "Attempting to access op_def, "
                 "but it was not provided when constructing the InputContext"
             )
 
         return self._op_def
 
     @public
     @property
     def config(self) -> Any:
+        """The config attached to the input that we're loading."""
         return self._config
 
     @public
     @property
     def metadata(self) -> Optional[ArbitraryMetadataMapping]:
+        """A dict of metadata that is assigned to the InputDefinition that we're loading for.
+        This property only contains metadata passed in explicitly with :py:class:`AssetIn`
+        or :py:class:`In`. To access metadata of an upstream asset or operation definition,
+        use the metadata in :py:attr:`.InputContext.upstream_output`.
+        """
         return self._metadata
 
     @public
     @property
     def upstream_output(self) -> Optional["OutputContext"]:
+        """Info about the output that produced the object we're loading."""
         return self._upstream_output
 
     @public
     @property
     def dagster_type(self) -> "DagsterType":
+        """The type of this input.
+        Dagster types do not propagate from an upstream output to downstream inputs,
+        and this property only captures type information for the input that is either
+        passed in explicitly with :py:class:`AssetIn` or :py:class:`In`, or can be
+        infered from type hints. For an asset input, the Dagster type from the upstream
+        asset definition is ignored.
+        """
         if self._dagster_type is None:
             raise DagsterInvariantViolationError(
                 "Attempting to access dagster_type, "
                 "but it was not provided when constructing the InputContext"
             )
 
         return self._dagster_type
 
     @public
     @property
     def log(self) -> "DagsterLogManager":
+        """The log manager to use for this input."""
         if self._log is None:
             raise DagsterInvariantViolationError(
                 "Attempting to access log, "
                 "but it was not provided when constructing the InputContext"
             )
 
         return self._log
 
     @public
     @property
     def resource_config(self) -> Optional[Mapping[str, Any]]:
+        """The config associated with the resource that initializes the RootInputManager."""
         return self._resource_config
 
     @public
     @property
     def resources(self) -> Any:
+        """The resources required by the resource that initializes the
+        input manager. If using the :py:func:`@root_input_manager` decorator, these resources
+        correspond to those requested with the `required_resource_keys` parameter.
+        """
         if self._resources is None:
             raise DagsterInvariantViolationError(
                 "Attempting to access resources, "
                 "but it was not provided when constructing the InputContext"
             )
 
         if self._resources_cm and self._resources_contain_cm and not self._cm_scope_entered:
@@ -538,15 +532,15 @@
     metadata: Optional[ArbitraryMetadataMapping] = None,
     upstream_output: Optional["OutputContext"] = None,
     dagster_type: Optional["DagsterType"] = None,
     resource_config: Optional[Mapping[str, Any]] = None,
     resources: Optional[Mapping[str, Any]] = None,
     op_def: Optional["OpDefinition"] = None,
     step_context: Optional["StepExecutionContext"] = None,
-    asset_key: Optional["AssetKey"] = None,
+    asset_key: Optional[CoercibleToAssetKey] = None,
     partition_key: Optional[str] = None,
     asset_partition_key_range: Optional[PartitionKeyRange] = None,
     asset_partitions_def: Optional["PartitionsDefinition"] = None,
     instance: Optional[DagsterInstance] = None,
 ) -> "InputContext":
     """Builds input context from provided parameters.
 
@@ -564,15 +558,15 @@
         dagster_type (Optional[DagsterType]): The type of this input.
         resource_config (Optional[Dict[str, Any]]): The resource config to make available from the
             input context. This usually corresponds to the config provided to the resource that
             loads the input manager.
         resources (Optional[Dict[str, Any]]): The resources to make available from the context.
             For a given key, you can provide either an actual instance of an object, or a resource
             definition.
-        asset_key (Optional[AssetKey]): The asset key attached to the InputDefinition.
+        asset_key (Optional[Union[AssetKey, Sequence[str], str]]): The asset key attached to the InputDefinition.
         op_def (Optional[OpDefinition]): The definition of the op that's loading the input.
         step_context (Optional[StepExecutionContext]): For internal use.
         partition_key (Optional[str]): String value representing partition key to execute with.
         asset_partition_key_range (Optional[str]): The range of asset partition keys to load.
         asset_partitions_def: Optional[PartitionsDefinition]: The PartitionsDefinition of the asset
             being loaded.
 
@@ -583,26 +577,26 @@
 
             with build_input_context(resources={"foo": context_manager_resource}) as context:
                 do_something
     """
     from dagster._core.definitions import OpDefinition, PartitionsDefinition
     from dagster._core.execution.context.output import OutputContext
     from dagster._core.execution.context.system import StepExecutionContext
-    from dagster._core.execution.context_creation_pipeline import initialize_console_manager
+    from dagster._core.execution.context_creation_job import initialize_console_manager
     from dagster._core.types.dagster_type import DagsterType
 
     name = check.opt_str_param(name, "name")
     metadata = check.opt_mapping_param(metadata, "metadata", key_type=str)
     upstream_output = check.opt_inst_param(upstream_output, "upstream_output", OutputContext)
     dagster_type = check.opt_inst_param(dagster_type, "dagster_type", DagsterType)
     resource_config = check.opt_mapping_param(resource_config, "resource_config", key_type=str)
     resources = check.opt_mapping_param(resources, "resources", key_type=str)
     op_def = check.opt_inst_param(op_def, "op_def", OpDefinition)
     step_context = check.opt_inst_param(step_context, "step_context", StepExecutionContext)
-    asset_key = check.opt_inst_param(asset_key, "asset_key", AssetKey)
+    asset_key = AssetKey.from_coerceable(asset_key) if asset_key else None
     partition_key = check.opt_str_param(partition_key, "partition_key")
     asset_partition_key_range = check.opt_inst_param(
         asset_partition_key_range, "asset_partition_key_range", PartitionKeyRange
     )
     asset_partitions_def = check.opt_inst_param(
         asset_partitions_def, "asset_partitions_def", PartitionsDefinition
     )
```

### Comparing `dagster-1.3.2/dagster/_core/execution/context/invocation.py` & `dagster-1.3.3/dagster/_core/execution/context/invocation.py`

 * *Files 2% similar despite different names*

```diff
@@ -44,15 +44,15 @@
     DagsterInvalidInvocationError,
     DagsterInvalidPropertyError,
     DagsterInvariantViolationError,
 )
 from dagster._core.execution.build_resources import build_resources, wrap_resources_for_execution
 from dagster._core.instance import DagsterInstance
 from dagster._core.log_manager import DagsterLogManager
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._core.types.dagster_type import DagsterType
 from dagster._utils.forked_pdb import ForkedPdb
 from dagster._utils.merger import merge_dicts
 
 from .compute import OpExecutionContext
 from .system import StepExecutionContext, TypeCheckContext
 
@@ -75,15 +75,15 @@
         resources_config: Mapping[str, Any],
         instance: Optional[DagsterInstance],
         partition_key: Optional[str],
         mapping_key: Optional[str],
         assets_def: Optional[AssetsDefinition],
     ):
         from dagster._core.execution.api import ephemeral_instance_if_missing
-        from dagster._core.execution.context_creation_pipeline import initialize_console_manager
+        from dagster._core.execution.context_creation_job import initialize_console_manager
 
         self._op_config = op_config
         self._mapping_key = mapping_key
 
         self._instance_provided = (
             check.opt_inst_param(instance, "instance", DagsterInstance) is not None
         )
@@ -144,15 +144,15 @@
                 "At least one provided resource is a generator, but attempting to access "
                 "resources outside of context manager scope. You can use the following syntax to "
                 "open a context manager: `with build_solid_context(...) as context:`"
             )
         return self._resources
 
     @property
-    def pipeline_run(self) -> DagsterRun:
+    def dagster_run(self) -> DagsterRun:
         raise DagsterInvalidPropertyError(_property_msg("pipeline_run", "property"))
 
     @property
     def instance(self) -> DagsterInstance:
         return self._instance
 
     @property
@@ -182,20 +182,20 @@
         return "EPHEMERAL"
 
     @property
     def run_config(self) -> dict:
         raise DagsterInvalidPropertyError(_property_msg("run_config", "property"))
 
     @property
-    def pipeline_def(self) -> JobDefinition:
-        raise DagsterInvalidPropertyError(_property_msg("pipeline_def", "property"))
+    def job_def(self) -> JobDefinition:
+        raise DagsterInvalidPropertyError(_property_msg("job_def", "property"))
 
     @property
-    def pipeline_name(self) -> str:
-        raise DagsterInvalidPropertyError(_property_msg("pipeline_name", "property"))
+    def job_name(self) -> str:
+        raise DagsterInvalidPropertyError(_property_msg("job_name", "property"))
 
     @property
     def log(self) -> DagsterLogManager:
         """DagsterLogManager: A console manager constructed for this context."""
         return self._log
 
     @property
@@ -425,15 +425,15 @@
         return self._op_config
 
     @property
     def resources(self) -> Resources:
         return self._resources
 
     @property
-    def pipeline_run(self) -> DagsterRun:
+    def dagster_run(self) -> DagsterRun:
         raise DagsterInvalidPropertyError(_property_msg("pipeline_run", "property"))
 
     @property
     def instance(self) -> DagsterInstance:
         return self._instance
 
     @property
@@ -467,33 +467,33 @@
         run_config: Dict[str, object] = {}
         if self._op_config:
             run_config["ops"] = {self._op_def.name: {"config": self._op_config}}
         run_config["resources"] = self._resources_config
         return run_config
 
     @property
-    def pipeline_def(self) -> JobDefinition:
-        raise DagsterInvalidPropertyError(_property_msg("pipeline_def", "property"))
+    def job_def(self) -> JobDefinition:
+        raise DagsterInvalidPropertyError(_property_msg("job_def", "property"))
 
     @property
-    def pipeline_name(self) -> str:
-        raise DagsterInvalidPropertyError(_property_msg("pipeline_name", "property"))
+    def job_name(self) -> str:
+        raise DagsterInvalidPropertyError(_property_msg("job_name", "property"))
 
     @property
     def log(self) -> DagsterLogManager:
         """DagsterLogManager: A console manager constructed for this context."""
         return self._log
 
     @property
     def node_handle(self) -> NodeHandle:
-        raise DagsterInvalidPropertyError(_property_msg("solid_handle", "property"))
+        raise DagsterInvalidPropertyError(_property_msg("node_handle", "property"))
 
     @property
-    def solid(self) -> Node:
-        raise DagsterInvalidPropertyError(_property_msg("solid", "property"))
+    def op(self) -> Node:
+        raise DagsterInvalidPropertyError(_property_msg("op", "property"))
 
     @property
     def op_def(self) -> OpDefinition:
         return self._op_def
 
     @property
     def assets_def(self) -> AssetsDefinition:
```

### Comparing `dagster-1.3.2/dagster/_core/execution/context/output.py` & `dagster-1.3.3/dagster/_core/execution/context/output.py`

 * *Files 3% similar despite different names*

```diff
@@ -15,14 +15,15 @@
 import dagster._check as check
 from dagster._annotations import public
 from dagster._core.definitions.asset_layer import AssetOutputInfo
 from dagster._core.definitions.events import (
     AssetKey,
     AssetMaterialization,
     AssetObservation,
+    CoercibleToAssetKey,
 )
 from dagster._core.definitions.metadata import (
     ArbitraryMetadataMapping,
     MetadataValue,
     RawMetadataValue,
 )
 from dagster._core.definitions.partition_key_range import PartitionKeyRange
@@ -48,47 +49,28 @@
 class OutputContext:
     """The context object that is available to the `handle_output` method of an :py:class:`IOManager`.
 
     Users should not instantiate this object directly. To construct an
     `OutputContext` for testing an IO Manager's `handle_output` method, use
     :py:func:`dagster.build_output_context`.
 
-    Attributes:
-        step_key (Optional[str]): The step_key for the compute step that produced the output.
-        name (Optional[str]): The name of the output that produced the output.
-        run_id (Optional[str]): The id of the run that produced the output.
-        metadata (Optional[Mapping[str, RawMetadataValue]]): A dict of the metadata that is assigned to the
-            OutputDefinition that produced the output.
-        mapping_key (Optional[str]): The key that identifies a unique mapped output. None for regular outputs.
-        config (Optional[Any]): The configuration for the output.
-        dagster_type (Optional[DagsterType]): The type of this output.
-        log (Optional[DagsterLogManager]): The log manager to use for this output.
-        version (Optional[str]): (Experimental) The version of the output.
-        resource_config (Optional[Mapping[str, Any]]): The config associated with the resource that
-            initializes the RootInputManager.
-        resources (Optional[Resources]): The resources required by the output manager, specified by the
-            `required_resource_keys` parameter.
-        op_def (Optional[OpDefinition]): The definition of the op that produced the output.
-        asset_info: Optional[AssetOutputInfo]: (Experimental) Asset info corresponding to the
-            output.
-
     Example:
     .. code-block:: python
 
         from dagster import IOManager, OutputContext
 
         class MyIOManager(IOManager):
             def handle_output(self, context: OutputContext, obj):
                 ...
 
     """
 
     _step_key: Optional[str]
     _name: Optional[str]
-    _pipeline_name: Optional[str]
+    _job_name: Optional[str]
     _run_id: Optional[str]
     _metadata: ArbitraryMetadataMapping
     _user_generated_metadata: Mapping[str, MetadataValue]
     _mapping_key: Optional[str]
     _config: object
     _op_def: Optional["OpDefinition"]
     _dagster_type: Optional["DagsterType"]
@@ -105,15 +87,15 @@
     _events: List["DagsterEvent"]
     _user_events: List[Union[AssetMaterialization, AssetObservation]]
 
     def __init__(
         self,
         step_key: Optional[str] = None,
         name: Optional[str] = None,
-        pipeline_name: Optional[str] = None,
+        job_name: Optional[str] = None,
         run_id: Optional[str] = None,
         metadata: Optional[ArbitraryMetadataMapping] = None,
         mapping_key: Optional[str] = None,
         config: object = None,
         dagster_type: Optional["DagsterType"] = None,
         log_manager: Optional["DagsterLogManager"] = None,
         version: Optional[str] = None,
@@ -126,15 +108,15 @@
         partition_key: Optional[str] = None,
     ):
         from dagster._core.definitions.resource_definition import IContainsGenerator, Resources
         from dagster._core.execution.build_resources import build_resources
 
         self._step_key = step_key
         self._name = name
-        self._pipeline_name = pipeline_name
+        self._job_name = job_name
         self._run_id = run_id
         self._metadata = metadata or {}
         self._mapping_key = mapping_key
         self._config = config
         self._op_def = op_def
         self._dagster_type = dagster_type
         self._log = log_manager
@@ -180,117 +162,133 @@
             and not self._cm_scope_entered
         ):
             self._resources_cm.__exit__(None, None, None)
 
     @public
     @property
     def step_key(self) -> str:
+        """The step_key for the compute step that produced the output."""
         if self._step_key is None:
             raise DagsterInvariantViolationError(
                 "Attempting to access step_key, "
                 "but it was not provided when constructing the OutputContext"
             )
 
         return self._step_key
 
     @public
     @property
     def name(self) -> str:
+        """The name of the output that produced the output."""
         if self._name is None:
             raise DagsterInvariantViolationError(
                 "Attempting to access name, "
                 "but it was not provided when constructing the OutputContext"
             )
 
         return self._name
 
     @property
-    def pipeline_name(self) -> str:
-        if self._pipeline_name is None:
+    def job_name(self) -> str:
+        if self._job_name is None:
             raise DagsterInvariantViolationError(
                 "Attempting to access pipeline_name, "
                 "but it was not provided when constructing the OutputContext"
             )
 
-        return self._pipeline_name
+        return self._job_name
 
     @public
     @property
     def run_id(self) -> str:
+        """The id of the run that produced the output."""
         if self._run_id is None:
             raise DagsterInvariantViolationError(
                 "Attempting to access run_id, "
                 "but it was not provided when constructing the OutputContext"
             )
 
         return self._run_id
 
     @public
     @property
     def metadata(self) -> Optional[ArbitraryMetadataMapping]:
+        """A dict of the metadata that is assigned to the OutputDefinition that produced
+        the output.
+        """
         return self._metadata
 
     @public
     @property
     def mapping_key(self) -> Optional[str]:
+        """The key that identifies a unique mapped output. None for regular outputs."""
         return self._mapping_key
 
     @public
     @property
     def config(self) -> Any:
+        """The configuration for the output."""
         return self._config
 
     @public
     @property
     def op_def(self) -> "OpDefinition":
+        """The definition of the op that produced the output."""
         from dagster._core.definitions import OpDefinition
 
         if self._op_def is None:
             raise DagsterInvariantViolationError(
                 "Attempting to access op_def, "
                 "but it was not provided when constructing the OutputContext"
             )
 
         return cast(OpDefinition, self._op_def)
 
     @public
     @property
     def dagster_type(self) -> "DagsterType":
+        """The type of this output."""
         if self._dagster_type is None:
             raise DagsterInvariantViolationError(
                 "Attempting to access dagster_type, "
                 "but it was not provided when constructing the OutputContext"
             )
 
         return self._dagster_type
 
     @public
     @property
     def log(self) -> "DagsterLogManager":
+        """The log manager to use for this output."""
         if self._log is None:
             raise DagsterInvariantViolationError(
                 "Attempting to access log, "
                 "but it was not provided when constructing the OutputContext"
             )
 
         return self._log
 
     @public
     @property
     def version(self) -> Optional[str]:
+        """(Experimental) The version of the output."""
         return self._version
 
     @public
     @property
     def resource_config(self) -> Optional[Mapping[str, object]]:
+        """The config associated with the resource that initializes the RootInputManager."""
         return self._resource_config
 
     @public
     @property
     def resources(self) -> Any:
+        """The resources required by the output manager, specified by the `required_resource_keys`
+        parameter.
+        """
         if self._resources is None:
             raise DagsterInvariantViolationError(
                 "Attempting to access resources, "
                 "but it was not provided when constructing the OutputContext"
             )
 
         if self._resources_cm and self._resources_contain_cm and not self._cm_scope_entered:
@@ -299,14 +297,15 @@
                 "resources outside of context manager scope. You can use the following syntax to "
                 "open a context manager: `with build_output_context(...) as context:`"
             )
         return self._resources
 
     @property
     def asset_info(self) -> Optional[AssetOutputInfo]:
+        """(Experimental) Asset info corresponding to the output."""
         return self._asset_info
 
     @public
     @property
     def has_asset_key(self) -> bool:
         return self._asset_info is not None
 
@@ -322,15 +321,15 @@
         return self._asset_info.key
 
     @public
     @property
     def asset_partitions_def(self) -> "PartitionsDefinition":
         """The PartitionsDefinition on the asset corresponding to this output."""
         asset_key = self.asset_key
-        result = self.step_context.pipeline_def.asset_layer.partitions_def_for_asset(asset_key)
+        result = self.step_context.job_def.asset_layer.partitions_def_for_asset(asset_key)
         if result is None:
             raise DagsterInvariantViolationError(
                 f"Attempting to access partitions def for asset {asset_key}, but it is not"
                 " partitioned"
             )
 
         return result
@@ -706,15 +705,15 @@
         result = self._user_generated_metadata
         self._user_generated_metadata = {}
         return result or {}
 
 
 def get_output_context(
     execution_plan: "ExecutionPlan",
-    pipeline_def: "JobDefinition",
+    job_def: "JobDefinition",
     resolved_run_config: "ResolvedRunConfig",
     step_output_handle: "StepOutputHandle",
     run_id: Optional[str],
     log_manager: Optional["DagsterLogManager"],
     step_context: Optional["StepExecutionContext"],
     resources: Optional["Resources"],
     version: Optional[str],
@@ -731,21 +730,21 @@
 
     if outputs_config:
         output_config = outputs_config.get_output_manager_config(step_output_handle.output_name)
     else:
         output_config = None
 
     step_output = execution_plan.get_step_output(step_output_handle)
-    output_def = pipeline_def.get_node(step_output.node_handle).output_def_named(step_output.name)
+    output_def = job_def.get_node(step_output.node_handle).output_def_named(step_output.name)
 
     io_manager_key = output_def.io_manager_key
     resource_config = resolved_run_config.resources[io_manager_key].config
 
     node_handle = execution_plan.get_step_by_key(step.key).node_handle
-    asset_info = pipeline_def.asset_layer.asset_info_for_output(
+    asset_info = job_def.asset_layer.asset_info_for_output(
         node_handle=node_handle, output_name=step_output.name
     )
 
     if step_context:
         check.invariant(
             not resources,
             (
@@ -755,41 +754,41 @@
             ),
         )
         resources = build_resources_for_manager(io_manager_key, step_context)
 
     return OutputContext(
         step_key=step_output_handle.step_key,
         name=step_output_handle.output_name,
-        pipeline_name=pipeline_def.name,
+        job_name=job_def.name,
         run_id=run_id,
         metadata=output_def.metadata,
         mapping_key=step_output_handle.mapping_key,
         config=output_config,
-        op_def=pipeline_def.get_node(step.node_handle).definition,  # type: ignore  # (should be OpDefinition not NodeDefinition)
+        op_def=job_def.get_node(step.node_handle).definition,  # type: ignore  # (should be OpDefinition not NodeDefinition)
         dagster_type=output_def.dagster_type,
         log_manager=log_manager,
         version=version,
         step_context=step_context,
         resource_config=resource_config,
         resources=resources,
         asset_info=asset_info,
         warn_on_step_context_use=warn_on_step_context_use,
     )
 
 
 def step_output_version(
-    pipeline_def: "JobDefinition",
+    job_def: "JobDefinition",
     execution_plan: "ExecutionPlan",
     resolved_run_config: "ResolvedRunConfig",
     step_output_handle: "StepOutputHandle",
 ) -> Optional[str]:
     from dagster._core.execution.resolve_versions import resolve_step_output_versions
 
     step_output_versions = resolve_step_output_versions(
-        pipeline_def, execution_plan, resolved_run_config
+        job_def, execution_plan, resolved_run_config
     )
     return (
         step_output_versions[step_output_handle]
         if step_output_handle in step_output_versions
         else None
     )
 
@@ -802,15 +801,15 @@
     mapping_key: Optional[str] = None,
     config: Optional[Any] = None,
     dagster_type: Optional["DagsterType"] = None,
     version: Optional[str] = None,
     resource_config: Optional[Mapping[str, object]] = None,
     resources: Optional[Mapping[str, object]] = None,
     op_def: Optional["OpDefinition"] = None,
-    asset_key: Optional[Union[AssetKey, str]] = None,
+    asset_key: Optional[CoercibleToAssetKey] = None,
     partition_key: Optional[str] = None,
 ) -> "OutputContext":
     """Builds output context from provided parameters.
 
     ``build_output_context`` can be used as either a function, or a context manager. If resources
     that are also context managers are provided, then ``build_output_context`` must be used as a
     context manager.
@@ -841,15 +840,15 @@
             build_output_context()
 
             with build_output_context(resources={"foo": context_manager_resource}) as context:
                 do_something
 
     """
     from dagster._core.definitions import OpDefinition
-    from dagster._core.execution.context_creation_pipeline import initialize_console_manager
+    from dagster._core.execution.context_creation_job import initialize_console_manager
     from dagster._core.types.dagster_type import DagsterType
 
     step_key = check.opt_str_param(step_key, "step_key")
     name = check.opt_str_param(name, "name")
     metadata = check.opt_mapping_param(metadata, "metadata", key_type=str)
     run_id = check.opt_str_param(run_id, "run_id", default=RUN_ID_PLACEHOLDER)
     mapping_key = check.opt_str_param(mapping_key, "mapping_key")
@@ -860,15 +859,15 @@
     op_def = check.opt_inst_param(op_def, "op_def", OpDefinition)
     asset_key = AssetKey.from_coerceable(asset_key) if asset_key else None
     partition_key = check.opt_str_param(partition_key, "partition_key")
 
     return OutputContext(
         step_key=step_key,
         name=name,
-        pipeline_name=None,
+        job_name=None,
         run_id=run_id,
         metadata=metadata,
         mapping_key=mapping_key,
         config=config,
         dagster_type=dagster_type,
         log_manager=initialize_console_manager(None),
         version=version,
```

### Comparing `dagster-1.3.2/dagster/_core/execution/context/system.py` & `dagster-1.3.3/dagster/_core/execution/context/system.py`

 * *Files 6% similar despite different names*

```diff
@@ -20,39 +20,39 @@
 )
 
 import dagster._check as check
 from dagster._annotations import public
 from dagster._core.definitions.dependency import OpNode
 from dagster._core.definitions.events import AssetKey, AssetLineageInfo
 from dagster._core.definitions.hook_definition import HookDefinition
+from dagster._core.definitions.job_base import IJob
 from dagster._core.definitions.job_definition import JobDefinition
 from dagster._core.definitions.multi_dimensional_partitions import MultiPartitionsDefinition
 from dagster._core.definitions.op_definition import OpDefinition
 from dagster._core.definitions.partition import PartitionsDefinition, PartitionsSubset
 from dagster._core.definitions.partition_key_range import PartitionKeyRange
 from dagster._core.definitions.partition_mapping import infer_partition_mapping
-from dagster._core.definitions.pipeline_base import IPipeline
 from dagster._core.definitions.policy import RetryPolicy
-from dagster._core.definitions.reconstruct import ReconstructablePipeline
+from dagster._core.definitions.reconstruct import ReconstructableJob
 from dagster._core.definitions.resource_definition import ScopedResourcesBuilder
 from dagster._core.definitions.step_launcher import StepLauncher
 from dagster._core.definitions.time_window_partitions import (
     TimeWindow,
     TimeWindowPartitionsDefinition,
     has_one_dimension_time_window_partitioning,
 )
 from dagster._core.errors import DagsterInvariantViolationError
 from dagster._core.execution.plan.handle import ResolvedFromDynamicStepHandle, StepHandle
 from dagster._core.execution.plan.outputs import StepOutputHandle
 from dagster._core.execution.plan.step import ExecutionStep
 from dagster._core.execution.retries import RetryMode
 from dagster._core.executor.base import Executor
 from dagster._core.log_manager import DagsterLogManager
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._core.storage.io_manager import IOManager
-from dagster._core.storage.pipeline_run import DagsterRun
 from dagster._core.storage.tags import (
     ASSET_PARTITION_RANGE_END_TAG,
     ASSET_PARTITION_RANGE_START_TAG,
     MULTIDIMENSIONAL_PARTITION_PREFIX,
     PARTITION_NAME_TAG,
 )
 from dagster._core.system_config.objects import ResolvedRunConfig
@@ -91,36 +91,32 @@
 
     @property
     @abstractmethod
     def plan_data(self) -> "PlanData":
         raise NotImplementedError()
 
     @property
-    def pipeline(self) -> IPipeline:
-        return self.plan_data.pipeline
+    def job(self) -> IJob:
+        return self.plan_data.job
 
     @property
     def dagster_run(self) -> DagsterRun:
         return self.plan_data.dagster_run
 
     @property
     def run_id(self) -> str:
         return self.dagster_run.run_id
 
     @property
     def run_config(self) -> Mapping[str, object]:
         return self.dagster_run.run_config
 
     @property
-    def pipeline_name(self) -> str:
-        return self.dagster_run.pipeline_name
-
-    @property
     def job_name(self) -> str:
-        return self.pipeline_name
+        return self.dagster_run.job_name
 
     @property
     def instance(self) -> "DagsterInstance":
         return self.plan_data.instance
 
     @property
     def raise_on_error(self) -> bool:
@@ -163,15 +159,15 @@
 class PlanData(NamedTuple):
     """The data about a run that is available during both orchestration and execution.
 
     This object does not contain any information that requires access to user code, such as the
     pipeline definition and resources.
     """
 
-    pipeline: IPipeline
+    job: IJob
     dagster_run: DagsterRun
     instance: "DagsterInstance"
     execution_plan: "ExecutionPlan"
     raise_on_error: bool = False
     retry_mode: RetryMode = RetryMode.DISABLED
 
 
@@ -180,15 +176,15 @@
 
     This object contains information that requires access to user code, such as the pipeline
     definition and resources.
     """
 
     scoped_resources_builder: ScopedResourcesBuilder
     resolved_run_config: ResolvedRunConfig
-    pipeline_def: JobDefinition
+    job_def: JobDefinition
 
 
 class IStepContext(IPlanContext):
     """Interface to represent data to be available during either step orchestration or execution."""
 
     @property
     @abstractmethod
@@ -222,20 +218,20 @@
         self._resume_from_failure = resume_from_failure
 
     @property
     def plan_data(self) -> PlanData:
         return self._plan_data
 
     @property
-    def reconstructable_pipeline(self) -> ReconstructablePipeline:
-        if not isinstance(self.pipeline, ReconstructablePipeline):
+    def reconstructable_job(self) -> ReconstructableJob:
+        if not isinstance(self.job, ReconstructableJob):
             raise DagsterInvariantViolationError(
-                "reconstructable_pipeline property must be a ReconstructablePipeline"
+                "reconstructable_pipeline property must be a ReconstructableJob"
             )
-        return self.pipeline
+        return self.job
 
     @property
     def log(self) -> DagsterLogManager:
         return self._log_manager
 
     @property
     def executor(self) -> Executor:
@@ -326,16 +322,16 @@
             log_manager=self._log_manager.with_tags(**step.logging_tags),
             step=step,
             output_capture=self.output_capture,
             known_state=known_state,
         )
 
     @property
-    def pipeline_def(self) -> JobDefinition:
-        return self._execution_data.pipeline_def
+    def job_def(self) -> JobDefinition:
+        return self._execution_data.job_def
 
     @property
     def resolved_run_config(self) -> ResolvedRunConfig:
         return self._execution_data.resolved_run_config
 
     @property
     def scoped_resources_builder(self) -> ScopedResourcesBuilder:
@@ -345,20 +341,20 @@
     def log(self) -> DagsterLogManager:
         return self._log_manager
 
     @property
     def partitions_def(self) -> Optional[PartitionsDefinition]:
         from dagster._core.definitions.job_definition import JobDefinition
 
-        pipeline_def = self._execution_data.pipeline_def
-        if not isinstance(pipeline_def, JobDefinition):
+        job_def = self._execution_data.job_def
+        if not isinstance(job_def, JobDefinition):
             check.failed(
                 "Can only call 'partitions_def', when using jobs, not legacy pipelines",
             )
-        partitions_def = pipeline_def.partitions_def
+        partitions_def = job_def.partitions_def
         return partitions_def
 
     @property
     def has_partitions(self) -> bool:
         tags = self._plan_data.dagster_run.tags
         return bool(
             PARTITION_NAME_TAG in tags
@@ -483,15 +479,15 @@
             plan_data=plan_data,
             execution_data=execution_data,
             log_manager=log_manager,
             output_capture=output_capture,
         )
         self._step = step
         self._required_resource_keys = get_required_resource_keys_for_step(
-            plan_data.pipeline.get_definition(),
+            plan_data.job.get_definition(),
             step,
             plan_data.execution_plan,
         )
         self._resources = execution_data.scoped_resources_builder.build(
             self._required_resource_keys
         )
         self._known_state = known_state
@@ -516,15 +512,15 @@
 
         self._step_exception: Optional[BaseException] = None
 
         self._step_output_capture: Optional[Dict[StepOutputHandle, Any]] = None
         # Enable step output capture if there are any hooks which will receive them.
         # Expect in the future that hooks may control whether or not they get outputs,
         # but for now presence of any will cause output capture.
-        if self.pipeline_def.get_all_hooks_for_handle(self.node_handle):
+        if self.job_def.get_all_hooks_for_handle(self.node_handle):
             self._step_output_capture = {}
 
         self._output_metadata: Dict[str, Any] = {}
         self._seen_outputs: Dict[str, Union[str, Set[str]]] = {}
 
         self._input_asset_records: Dict[AssetKey, Optional["EventLogRecord"]] = {}
         self._is_external_input_asset_records_loaded = False
@@ -548,50 +544,46 @@
 
     @property
     def step_launcher(self) -> Optional[StepLauncher]:
         return self._step_launcher
 
     @property
     def op_def(self) -> OpDefinition:
-        return self.solid.definition
-
-    @property
-    def pipeline_def(self) -> JobDefinition:
-        return self._execution_data.pipeline_def
+        return self.op.definition
 
     @property
     def job_def(self) -> "JobDefinition":
-        return self._execution_data.pipeline_def
+        return self._execution_data.job_def
 
     @property
-    def solid(self) -> OpNode:
-        return self.pipeline_def.get_op(self._step.node_handle)
+    def op(self) -> OpNode:
+        return self.job_def.get_op(self._step.node_handle)
 
     @property
-    def solid_retry_policy(self) -> Optional[RetryPolicy]:
-        return self.pipeline_def.get_retry_policy_for_handle(self.node_handle)
+    def op_retry_policy(self) -> Optional[RetryPolicy]:
+        return self.job_def.get_retry_policy_for_handle(self.node_handle)
 
     def describe_op(self) -> str:
         return f'op "{str(self.node_handle)}"'
 
     def get_io_manager(self, step_output_handle: StepOutputHandle) -> IOManager:
         step_output = self.execution_plan.get_step_output(step_output_handle)
         io_manager_key = (
-            self.pipeline_def.get_node(step_output.node_handle)
+            self.job_def.get_node(step_output.node_handle)
             .output_def_named(step_output.name)
             .io_manager_key
         )
 
         output_manager = getattr(self.resources, io_manager_key)
         return check.inst(output_manager, IOManager)
 
     def get_output_context(self, step_output_handle: StepOutputHandle) -> OutputContext:
         return get_output_context(
             self.execution_plan,
-            self.pipeline_def,
+            self.job_def,
             self.resolved_run_config,
             step_output_handle,
             self._get_source_run_id(step_output_handle),
             log_manager=self.log,
             step_context=self,
             resources=None,
             version=self.execution_plan.get_version_for_step_output_handle(step_output_handle),
@@ -616,41 +608,41 @@
         if source_handle is not None:
             version = self.execution_plan.get_version_for_step_output_handle(source_handle)
 
             # NOTE: this is using downstream step_context for upstream OutputContext. step_context
             # will be set to None for 0.15 release.
             upstream_output = get_output_context(
                 self.execution_plan,
-                self.pipeline_def,
+                self.job_def,
                 self.resolved_run_config,
                 source_handle,
                 self._get_source_run_id(source_handle),
                 log_manager=self.log,
                 step_context=self,
                 resources=None,
                 version=version,
                 warn_on_step_context_use=True,
             )
         else:
             upstream_output = artificial_output_context
 
-        asset_key = self.pipeline_def.asset_layer.asset_key_for_input(
+        asset_key = self.job_def.asset_layer.asset_key_for_input(
             node_handle=self.node_handle, input_name=name
         )
         asset_partitions_subset = (
             self.asset_partitions_subset_for_input(name)
             if self.has_asset_partitions_for_input(name)
             else None
         )
 
         asset_partitions_def = (
-            self.pipeline_def.asset_layer.partitions_def_for_asset(asset_key) if asset_key else None
+            self.job_def.asset_layer.partitions_def_for_asset(asset_key) if asset_key else None
         )
         return InputContext(
-            job_name=self.pipeline_def.name,
+            job_name=self.job_def.name,
             name=name,
             op_def=self.op_def,
             config=config,
             metadata=metadata,
             upstream_output=upstream_output,
             dagster_type=dagster_type,
             log_manager=self.log,
@@ -729,29 +721,29 @@
         if self.has_seen_output(output_name, mapping_key):
             output_desc = (
                 f"output '{output_def.name}'"
                 if not mapping_key
                 else f"output '{output_def.name}' with mapping_key '{mapping_key}'"
             )
             raise DagsterInvariantViolationError(
-                f"In {self.op_def.node_type_str} '{self.solid.name}', attempted to log output"
+                f"In {self.op_def.node_type_str} '{self.op.name}', attempted to log output"
                 f" metadata for {output_desc} which has already been yielded. Metadata must be"
                 " logged before the output is yielded."
             )
         if output_def.is_dynamic and not mapping_key:
             raise DagsterInvariantViolationError(
-                f"In {self.op_def.node_type_str} '{self.solid.name}', attempted to log metadata"
+                f"In {self.op_def.node_type_str} '{self.op.name}', attempted to log metadata"
                 f" for dynamic output '{output_def.name}' without providing a mapping key. When"
                 " logging metadata for a dynamic output, it is necessary to provide a mapping key."
             )
 
         if output_name in self._output_metadata:
             if not mapping_key or mapping_key in self._output_metadata[output_name]:
                 raise DagsterInvariantViolationError(
-                    f"In {self.op_def.node_type_str} '{self.solid.name}', attempted to log"
+                    f"In {self.op_def.node_type_str} '{self.op.name}', attempted to log"
                     f" metadata for output '{output_name}' more than once."
                 )
         if mapping_key:
             if output_name not in self._output_metadata:
                 self._output_metadata[output_name] = {}
             self._output_metadata[output_name][mapping_key] = metadata
 
@@ -842,15 +834,15 @@
 
     @property
     def step_materializes_assets(self) -> bool:
         step_outputs = self.step.step_outputs
         if len(step_outputs) == 0:
             return False
         else:
-            asset_info = self.pipeline_def.asset_layer.asset_info_for_output(
+            asset_info = self.job_def.asset_layer.asset_info_for_output(
                 self.node_handle, step_outputs[0].name
             )
             return asset_info is not None
 
     def set_data_version(self, asset_key: AssetKey, data_version: "DataVersion") -> None:
         self._data_version_cache[asset_key] = data_version
 
@@ -873,26 +865,26 @@
             self._fetch_input_asset_record(key)
         return self._input_asset_records[key]
 
     # "external" refers to records for inputs generated outside of this step
     def fetch_external_input_asset_records(self) -> None:
         output_keys: List[AssetKey] = []
         for step_output in self.step.step_outputs:
-            asset_info = self.pipeline_def.asset_layer.asset_info_for_output(
+            asset_info = self.job_def.asset_layer.asset_info_for_output(
                 self.node_handle, step_output.name
             )
             if asset_info is None or not asset_info.is_required:
                 continue
             output_keys.append(asset_info.key)
 
         all_dep_keys: List[AssetKey] = []
         for output_key in output_keys:
-            if output_key not in self.pipeline_def.asset_layer._asset_deps:  # noqa: SLF001
+            if output_key not in self.job_def.asset_layer._asset_deps:  # noqa: SLF001
                 continue
-            dep_keys = self.pipeline_def.asset_layer.upstream_assets_for_asset(output_key)
+            dep_keys = self.job_def.asset_layer.upstream_assets_for_asset(output_key)
             for key in dep_keys:
                 if key not in all_dep_keys and key not in output_keys:
                     all_dep_keys.append(key)
 
         self._input_asset_records = {}
         for key in all_dep_keys:
             self._fetch_input_asset_record(key)
@@ -920,15 +912,15 @@
     # intrastep asset is not required, but then that asset is materialized during the step. If we
     # don't clear the cache for this asset, then we won't use the most up-to-date asset record.
     def wipe_input_asset_record(self, key: AssetKey) -> None:
         if key in self._input_asset_records:
             del self._input_asset_records[key]
 
     def has_asset_partitions_for_input(self, input_name: str) -> bool:
-        asset_layer = self.pipeline_def.asset_layer
+        asset_layer = self.job_def.asset_layer
         upstream_asset_key = asset_layer.asset_key_for_input(self.node_handle, input_name)
 
         return (
             upstream_asset_key is not None
             and asset_layer.partitions_def_for_asset(upstream_asset_key) is not None
         )
 
@@ -945,15 +937,15 @@
                     f"({len(partition_key_ranges)}) key ranges associated with this input."
                 ),
             )
 
         return partition_key_ranges[0]
 
     def asset_partitions_subset_for_input(self, input_name: str) -> PartitionsSubset:
-        asset_layer = self.pipeline_def.asset_layer
+        asset_layer = self.job_def.asset_layer
         assets_def = asset_layer.assets_def_for_node(self.node_handle)
         upstream_asset_key = asset_layer.asset_key_for_input(self.node_handle, input_name)
 
         if upstream_asset_key is not None:
             upstream_asset_partitions_def = asset_layer.partitions_def_for_asset(upstream_asset_key)
 
             if upstream_asset_partitions_def is not None:
@@ -987,15 +979,15 @@
         else:
             check.failed(
                 f"Tried to access partition key for input '{input_name}' of step '{self.step.key}',"
                 f" but the step input has a partition range: '{start}' to '{end}'."
             )
 
     def _partitions_def_for_output(self, output_name: str) -> Optional[PartitionsDefinition]:
-        asset_info = self.pipeline_def.asset_layer.asset_info_for_output(
+        asset_info = self.job_def.asset_layer.asset_info_for_output(
             node_handle=self.node_handle, output_name=output_name
         )
         if asset_info:
             return asset_info.partitions_def
         else:
             return None
 
@@ -1047,33 +1039,70 @@
         partition_key_range = self.asset_partition_key_range_for_output(output_name)
         return TimeWindow(
             # mypy thinks partitions_def is <nothing> here because ????
             partitions_def.time_window_for_partition_key(partition_key_range.start).start,
             partitions_def.time_window_for_partition_key(partition_key_range.end).end,
         )
 
+    def asset_partitions_time_window_for_input(self, input_name: str) -> TimeWindow:
+        """The time window for the partitions of the asset correponding to the given input.
+
+        Raises an error if either of the following are true:
+        - The input asset has no partitioning.
+        - The input asset is not partitioned with a TimeWindowPartitionsDefinition or a
+          MultiPartitionsDefinition with one time-partitioned dimension.
+        """
+        asset_layer = self.job_def.asset_layer
+        upstream_asset_key = asset_layer.asset_key_for_input(self.node_handle, input_name)
+
+        if upstream_asset_key is None:
+            raise ValueError("The input has no corresponding asset")
+
+        upstream_asset_partitions_def = asset_layer.partitions_def_for_asset(upstream_asset_key)
+
+        if not upstream_asset_partitions_def:
+            raise ValueError(
+                "Tried to get asset partitions for an input that does not correspond to a "
+                "partitioned asset."
+            )
+
+        if not has_one_dimension_time_window_partitioning(upstream_asset_partitions_def):
+            raise ValueError(
+                "Tried to get asset partitions for an input that correponds to a partitioned "
+                "asset that is not time-partitioned."
+            )
+
+        upstream_asset_partitions_def = cast(
+            Union[TimeWindowPartitionsDefinition, MultiPartitionsDefinition],
+            upstream_asset_partitions_def,
+        )
+        partition_key_range = self.asset_partition_key_range_for_input(input_name)
+
+        return TimeWindow(
+            upstream_asset_partitions_def.time_window_for_partition_key(
+                partition_key_range.start
+            ).start,
+            upstream_asset_partitions_def.time_window_for_partition_key(
+                partition_key_range.end
+            ).end,
+        )
+
     def get_type_loader_context(self) -> "DagsterTypeLoaderContext":
         return DagsterTypeLoaderContext(
             plan_data=self.plan_data,
             execution_data=self._execution_data,
             log_manager=self._log_manager,
             step=self.step,
             output_capture=self._output_capture,
             known_state=self._known_state,
         )
 
 
 class TypeCheckContext:
-    """The ``context`` object available to a type check function on a DagsterType.
-
-    Attributes:
-        log (DagsterLogManager): Centralized log dispatch from user code.
-        resources (Any): An object whose attributes contain the resources available to this op.
-        run_id (str): The id of this job run.
-    """
+    """The ``context`` object available to a type check function on a DagsterType."""
 
     def __init__(
         self,
         run_id: str,
         log_manager: DagsterLogManager,
         scoped_resources_builder: ScopedResourcesBuilder,
         dagster_type: DagsterType,
@@ -1081,24 +1110,27 @@
         self._run_id = run_id
         self._log = log_manager
         self._resources = scoped_resources_builder.build(dagster_type.required_resource_keys)
 
     @public
     @property
     def resources(self) -> "Resources":
+        """An object whose attributes contain the resources available to this op."""
         return self._resources
 
     @public
     @property
     def run_id(self) -> str:
+        """The id of this job run."""
         return self._run_id
 
     @public
     @property
     def log(self) -> DagsterLogManager:
+        """Centralized log dispatch from user code."""
         return self._log
 
 
 class DagsterTypeLoaderContext(StepExecutionContext):
     """The context object provided to a :py:class:`@dagster_type_loader <dagster_type_loader>`-decorated function during execution.
 
     Users should not construct this object directly.
```

### Comparing `dagster-1.3.2/dagster/_core/execution/context_creation_pipeline.py` & `dagster-1.3.3/dagster/_core/execution/context_creation_job.py`

 * *Files 6% similar despite different names*

```diff
@@ -21,29 +21,29 @@
     Union,
     cast,
 )
 
 import dagster._check as check
 from dagster._core.definitions import ExecutorDefinition, JobDefinition
 from dagster._core.definitions.executor_definition import check_cross_process_constraints
-from dagster._core.definitions.pipeline_base import IPipeline
+from dagster._core.definitions.job_base import IJob
 from dagster._core.definitions.resource_definition import ScopedResourcesBuilder
 from dagster._core.errors import DagsterError, DagsterUserCodeExecutionError
 from dagster._core.events import DagsterEvent
 from dagster._core.execution.memoization import validate_reexecution_memoization
 from dagster._core.execution.plan.plan import ExecutionPlan
 from dagster._core.execution.resources_init import (
     get_required_resource_keys_to_init,
     resource_initialization_manager,
 )
 from dagster._core.execution.retries import RetryMode
 from dagster._core.executor.init import InitExecutorContext
 from dagster._core.instance import DagsterInstance
 from dagster._core.log_manager import DagsterLogManager
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._core.system_config.objects import ResolvedRunConfig
 from dagster._loggers import default_loggers, default_system_loggers
 from dagster._utils import EventGenerationManager
 from dagster._utils.error import serializable_error_info_from_exc_info
 
 from .context.logger import InitLoggerContext
 from .context.system import (
@@ -78,57 +78,57 @@
 # This represents all the data that is passed *into* context creation process.
 # The remainder of the objects generated (e.g. loggers, resources) are created
 # using user-defined code that may fail at runtime and result in the emission
 # of a pipeline init failure events. The data in this object are passed all
 # over the place during the context creation process so grouping here for
 # ease of argument passing etc.
 class ContextCreationData(NamedTuple):
-    pipeline: IPipeline
+    job: IJob
     resolved_run_config: ResolvedRunConfig
     dagster_run: DagsterRun
     executor_def: ExecutorDefinition
     instance: DagsterInstance
     resource_keys_to_init: AbstractSet[str]
     execution_plan: ExecutionPlan
 
     @property
-    def pipeline_def(self) -> JobDefinition:
-        return self.pipeline.get_definition()
+    def job_def(self) -> JobDefinition:
+        return self.job.get_definition()
 
 
 def create_context_creation_data(
-    pipeline: IPipeline,
+    job: IJob,
     execution_plan: ExecutionPlan,
     run_config: Mapping[str, object],
     dagster_run: DagsterRun,
     instance: DagsterInstance,
 ) -> "ContextCreationData":
-    pipeline_def = pipeline.get_definition()
-    resolved_run_config = ResolvedRunConfig.build(pipeline_def, run_config)
+    job_def = job.get_definition()
+    resolved_run_config = ResolvedRunConfig.build(job_def, run_config)
 
-    executor_def = pipeline_def.executor_def
+    executor_def = job_def.executor_def
 
     return ContextCreationData(
-        pipeline=pipeline,
+        job=job,
         resolved_run_config=resolved_run_config,
         dagster_run=dagster_run,
         executor_def=executor_def,
         instance=instance,
         resource_keys_to_init=get_required_resource_keys_to_init(
-            execution_plan, pipeline_def, resolved_run_config
+            execution_plan, job_def, resolved_run_config
         ),
         execution_plan=execution_plan,
     )
 
 
 def create_plan_data(
     context_creation_data: "ContextCreationData", raise_on_error: bool, retry_mode: RetryMode
 ) -> PlanData:
     return PlanData(
-        pipeline=context_creation_data.pipeline,
+        job=context_creation_data.job,
         dagster_run=context_creation_data.dagster_run,
         instance=context_creation_data.instance,
         execution_plan=context_creation_data.execution_plan,
         raise_on_error=raise_on_error,
         retry_mode=retry_mode,
     )
 
@@ -136,15 +136,15 @@
 def create_execution_data(
     context_creation_data: "ContextCreationData",
     scoped_resources_builder: ScopedResourcesBuilder,
 ) -> ExecutionData:
     return ExecutionData(
         scoped_resources_builder=scoped_resources_builder,
         resolved_run_config=context_creation_data.resolved_run_config,
-        pipeline_def=context_creation_data.pipeline_def,
+        job_def=context_creation_data.job_def,
     )
 
 
 TContextType = TypeVar("TContextType", bound=IPlanContext)
 
 
 class ExecutionContextManager(Generic[TContextType], ABC):
@@ -172,15 +172,15 @@
         return self._manager.generate_teardown_events()
 
     def get_generator(self) -> Generator[Union[DagsterEvent, IPlanContext], None, None]:
         return self._manager.generator
 
 
 def execution_context_event_generator(
-    pipeline: IPipeline,
+    job: IJob,
     execution_plan: ExecutionPlan,
     run_config: Mapping[str, object],
     dagster_run: DagsterRun,
     instance: DagsterInstance,
     retry_mode: RetryMode,
     scoped_resources_builder_cm: Optional[
         Callable[..., EventGenerationManager[ScopedResourcesBuilder]]
@@ -194,32 +194,32 @@
             scoped_resources_builder_cm,
             "scoped_resources_builder_cm",
             default=resource_initialization_manager,
         ),
     )
 
     execution_plan = check.inst_param(execution_plan, "execution_plan", ExecutionPlan)
-    pipeline_def = pipeline.get_definition()
+    job_def = job.get_definition()
 
     run_config = check.mapping_param(run_config, "run_config", key_type=str)
     dagster_run = check.inst_param(dagster_run, "dagster_run", DagsterRun)
     instance = check.inst_param(instance, "instance", DagsterInstance)
 
     raise_on_error = check.bool_param(raise_on_error, "raise_on_error")
 
     context_creation_data = create_context_creation_data(
-        pipeline,
+        job,
         execution_plan,
         run_config,
         dagster_run,
         instance,
     )
 
     log_manager = create_log_manager(context_creation_data)
-    resource_defs = pipeline_def.get_required_resource_defs()
+    resource_defs = job_def.get_required_resource_defs()
 
     resources_manager = scoped_resources_builder_cm(
         resource_defs=resource_defs,
         resource_configs=context_creation_data.resolved_run_config.resources,
         log_manager=log_manager,
         execution_plan=execution_plan,
         dagster_run=context_creation_data.dagster_run,
@@ -246,26 +246,26 @@
 class PlanOrchestrationContextManager(ExecutionContextManager[PlanOrchestrationContext]):
     def __init__(
         self,
         context_event_generator: Callable[
             ...,
             Iterator[Union[DagsterEvent, PlanOrchestrationContext]],
         ],
-        pipeline: IPipeline,
+        job: IJob,
         execution_plan: ExecutionPlan,
         run_config: Mapping[str, object],
         dagster_run: DagsterRun,
         instance: DagsterInstance,
         raise_on_error: Optional[bool] = False,
         output_capture: Optional[Dict["StepOutputHandle", Any]] = None,
         executor_defs: Optional[Sequence[ExecutorDefinition]] = None,
         resume_from_failure=False,
     ):
         event_generator = context_event_generator(
-            pipeline,
+            job,
             execution_plan,
             run_config,
             dagster_run,
             instance,
             raise_on_error,
             executor_defs,
             output_capture,
@@ -275,27 +275,27 @@
 
     @property
     def context_type(self) -> Type[PlanOrchestrationContext]:
         return PlanOrchestrationContext
 
 
 def orchestration_context_event_generator(
-    pipeline: IPipeline,
+    job: IJob,
     execution_plan: ExecutionPlan,
     run_config: Mapping[str, object],
     dagster_run: DagsterRun,
     instance: DagsterInstance,
     raise_on_error: bool,
     executor_defs: Optional[Sequence[ExecutorDefinition]],
     output_capture: Optional[Dict["StepOutputHandle", Any]],
     resume_from_failure: bool = False,
 ) -> Iterator[Union[DagsterEvent, PlanOrchestrationContext]]:
     check.invariant(executor_defs is None)
     context_creation_data = create_context_creation_data(
-        pipeline,
+        job,
         execution_plan,
         run_config,
         dagster_run,
         instance,
     )
 
     log_manager = create_log_manager(context_creation_data)
@@ -320,19 +320,19 @@
             # pylint does not know original_exc_info exists is is_user_code_error is true
             dagster_error.original_exc_info
             if dagster_error.is_user_code_error
             else sys.exc_info()
         )
         error_info = serializable_error_info_from_exc_info(user_facing_exc_info)
 
-        event = DagsterEvent.pipeline_failure(
-            pipeline_context_or_name=dagster_run.pipeline_name,
+        event = DagsterEvent.job_failure(
+            job_context_or_name=dagster_run.job_name,
             context_msg=(
                 "Pipeline failure during initialization for pipeline"
-                f' "{dagster_run.pipeline_name}". This may be due to a failure in initializing the'
+                f' "{dagster_run.job_name}". This may be due to a failure in initializing the'
                 " executor or one of the loggers."
             ),
             error_info=error_info,
         )
         log_manager.log_dagster_event(
             level=logging.ERROR, msg=event.message or "", dagster_event=event
         )
@@ -341,29 +341,29 @@
         if raise_on_error:
             raise dagster_error
 
 
 class PlanExecutionContextManager(ExecutionContextManager[PlanExecutionContext]):
     def __init__(
         self,
-        pipeline: IPipeline,
+        job: IJob,
         execution_plan: ExecutionPlan,
         run_config: Mapping[str, object],
         dagster_run: DagsterRun,
         instance: DagsterInstance,
         retry_mode: RetryMode,
         scoped_resources_builder_cm: Optional[
             Callable[..., EventGenerationManager[ScopedResourcesBuilder]]
         ] = None,
         raise_on_error: Optional[bool] = False,
         output_capture: Optional[Dict["StepOutputHandle", Any]] = None,
     ):
         super(PlanExecutionContextManager, self).__init__(
             execution_context_event_generator(
-                pipeline,
+                job,
                 execution_plan,
                 run_config,
                 dagster_run,
                 instance,
                 retry_mode,
                 scoped_resources_builder_cm,
                 raise_on_error=raise_on_error,
@@ -373,37 +373,35 @@
 
     @property
     def context_type(self) -> Type[PlanExecutionContext]:
         return PlanExecutionContext
 
 
 # perform any plan validation that is dependent on access to the pipeline context
-def _validate_plan_with_context(
-    pipeline_context: IPlanContext, execution_plan: ExecutionPlan
-) -> None:
-    validate_reexecution_memoization(pipeline_context, execution_plan)
+def _validate_plan_with_context(job_context: IPlanContext, execution_plan: ExecutionPlan) -> None:
+    validate_reexecution_memoization(job_context, execution_plan)
 
 
 def create_executor(context_creation_data: ContextCreationData) -> "Executor":
     check.inst_param(context_creation_data, "context_creation_data", ContextCreationData)
     init_context = InitExecutorContext(
-        job=context_creation_data.pipeline,
+        job=context_creation_data.job,
         executor_def=context_creation_data.executor_def,
         executor_config=context_creation_data.resolved_run_config.execution.execution_engine_config,
         instance=context_creation_data.instance,
     )
     check_cross_process_constraints(init_context)
     creation_fn = check.not_none(context_creation_data.executor_def.executor_creation_fn)
     return creation_fn(init_context)
 
 
 @contextmanager
-def scoped_pipeline_context(
+def scoped_job_context(
     execution_plan: ExecutionPlan,
-    pipeline: IPipeline,
+    job: IJob,
     run_config: Mapping[str, object],
     dagster_run: DagsterRun,
     instance: DagsterInstance,
     scoped_resources_builder_cm: Callable[
         ..., EventGenerationManager[ScopedResourcesBuilder]
     ] = resource_initialization_manager,
     raise_on_error: Optional[bool] = False,
@@ -412,22 +410,22 @@
     `pipeline_initialization_manager`, iterating through all the setup/teardown events and
     discarding them.  It yields the resulting `pipeline_context`.
 
     Should only be used where we need to reconstruct the pipeline context, ignoring any yielded
     events (e.g. PipelineExecutionResult, dagstermill, unit tests, etc)
     """
     check.inst_param(execution_plan, "execution_plan", ExecutionPlan)
-    check.inst_param(pipeline, "pipeline", IPipeline)
+    check.inst_param(job, "job", IJob)
     check.mapping_param(run_config, "run_config", key_type=str)
     check.inst_param(dagster_run, "dagster_run", DagsterRun)
     check.inst_param(instance, "instance", DagsterInstance)
     check.callable_param(scoped_resources_builder_cm, "scoped_resources_builder_cm")
 
     initialization_manager = PlanExecutionContextManager(
-        pipeline,
+        job,
         execution_plan,
         run_config,
         dagster_run,
         instance,
         RetryMode.DISABLED,
         scoped_resources_builder_cm=scoped_resources_builder_cm,
         raise_on_error=raise_on_error,
@@ -444,15 +442,15 @@
 
 def create_log_manager(
     context_creation_data: ContextCreationData,
 ) -> DagsterLogManager:
     check.inst_param(context_creation_data, "context_creation_data", ContextCreationData)
 
     pipeline_def, resolved_run_config, dagster_run = (
-        context_creation_data.pipeline_def,
+        context_creation_data.job_def,
         context_creation_data.resolved_run_config,
         context_creation_data.dagster_run,
     )
 
     # The following logic is tightly coupled to the processing of logger config in
     # python_modules/dagster/dagster/_core/system_config/objects.py#config_map_loggers
     # Changes here should be accompanied checked against that function, which applies config mapping
@@ -462,28 +460,28 @@
     for logger_key, logger_def in pipeline_def.loggers.items() or default_loggers().items():
         if logger_key in resolved_run_config.loggers:
             loggers.append(
                 logger_def.logger_fn(
                     InitLoggerContext(
                         resolved_run_config.loggers.get(logger_key, {}).get("config"),
                         logger_def,
-                        pipeline_def=pipeline_def,
+                        job_def=pipeline_def,
                         run_id=dagster_run.run_id,
                     )
                 )
             )
 
     if not loggers:
         for logger_def, logger_config in default_system_loggers(context_creation_data.instance):
             loggers.append(
                 logger_def.logger_fn(
                     InitLoggerContext(
                         logger_config,
                         logger_def,
-                        pipeline_def=pipeline_def,
+                        job_def=pipeline_def,
                         run_id=dagster_run.run_id,
                     )
                 )
             )
 
     return DagsterLogManager.create(
         loggers=loggers, dagster_run=dagster_run, instance=context_creation_data.instance
@@ -494,27 +492,27 @@
     instance: DagsterInstance, dagster_run: DagsterRun
 ) -> DagsterLogManager:
     """In the event of pipeline initialization failure, we want to be able to log the failure
     without a dependency on the PlanExecutionContext to initialize DagsterLogManager.
 
     Args:
         dagster_run (PipelineRun)
-        pipeline_def (PipelineDefinition)
+        pipeline_def (JobDefinition)
     """
     check.inst_param(instance, "instance", DagsterInstance)
     check.inst_param(dagster_run, "dagster_run", DagsterRun)
 
     loggers = []
     # Use the default logger
     for logger_def, logger_config in default_system_loggers(instance):
         loggers += [
             logger_def.logger_fn(
                 InitLoggerContext(
                     logger_config,
                     logger_def,
-                    pipeline_def=None,
+                    job_def=None,
                     run_id=dagster_run.run_id,
                 )
             )
         ]
 
     return DagsterLogManager.create(loggers=loggers, instance=instance, dagster_run=dagster_run)
```

### Comparing `dagster-1.3.2/dagster/_core/execution/execute_in_process.py` & `dagster-1.3.3/dagster/_core/execution/execute_in_process.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,85 +1,85 @@
 from typing import Any, Dict, FrozenSet, Mapping, Optional, cast
 
 from dagster._core.definitions import GraphDefinition, JobDefinition, Node, NodeHandle, OpDefinition
 from dagster._core.definitions.events import AssetKey
-from dagster._core.definitions.pipeline_base import InMemoryPipeline
+from dagster._core.definitions.job_base import InMemoryJob
 from dagster._core.errors import DagsterInvalidInvocationError
 from dagster._core.execution.plan.outputs import StepOutputHandle
 from dagster._core.instance import DagsterInstance
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._core.types.dagster_type import DagsterTypeKind
 
 from .api import (
     ExecuteRunWithPlanIterable,
     create_execution_plan,
     ephemeral_instance_if_missing,
-    pipeline_execution_iterator,
+    job_execution_iterator,
 )
-from .context_creation_pipeline import (
+from .context_creation_job import (
     PlanOrchestrationContextManager,
     orchestration_context_event_generator,
 )
 from .execute_in_process_result import ExecuteInProcessResult
 
 
 def core_execute_in_process(
     run_config: Mapping[str, object],
-    ephemeral_pipeline: JobDefinition,
+    ephemeral_job: JobDefinition,
     instance: Optional[DagsterInstance],
     output_capturing_enabled: bool,
     raise_on_error: bool,
     run_tags: Optional[Mapping[str, str]] = None,
     run_id: Optional[str] = None,
     asset_selection: Optional[FrozenSet[AssetKey]] = None,
 ) -> ExecuteInProcessResult:
-    job_def = ephemeral_pipeline
-    pipeline = InMemoryPipeline(job_def)
+    job_def = ephemeral_job
+    job = InMemoryJob(job_def)
 
     _check_top_level_inputs(job_def)
 
     execution_plan = create_execution_plan(
-        pipeline,
+        job,
         run_config=run_config,
         instance_ref=instance.get_ref() if instance and instance.is_persistent else None,
     )
 
     output_capture: Dict[StepOutputHandle, Any] = {}
 
     with ephemeral_instance_if_missing(instance) as execute_instance:
-        run = execute_instance.create_run_for_pipeline(
-            pipeline_def=job_def,
+        run = execute_instance.create_run_for_job(
+            job_def=job_def,
             run_config=run_config,
             tags={**job_def.tags, **(run_tags or {})},
             run_id=run_id,
             asset_selection=asset_selection,
             execution_plan=execution_plan,
         )
         run_id = run.run_id
 
         execute_run_iterable = ExecuteRunWithPlanIterable(
             execution_plan=execution_plan,
-            iterator=pipeline_execution_iterator,
+            iterator=job_execution_iterator,
             execution_context_manager=PlanOrchestrationContextManager(
                 context_event_generator=orchestration_context_event_generator,
-                pipeline=pipeline,
+                job=job,
                 execution_plan=execution_plan,
                 dagster_run=run,
                 instance=execute_instance,
                 run_config=run_config,
                 executor_defs=None,
                 output_capture=output_capture if output_capturing_enabled else None,
                 raise_on_error=raise_on_error,
             ),
         )
         event_list = list(execute_run_iterable)
         run = execute_instance.get_run_by_id(run_id)
 
     return ExecuteInProcessResult(
-        job_def=ephemeral_pipeline,
+        job_def=ephemeral_job,
         event_list=event_list,
         dagster_run=cast(DagsterRun, run),
         output_capture=output_capture,
     )
 
 
 def _check_top_level_inputs(job_def: JobDefinition) -> None:
```

### Comparing `dagster-1.3.2/dagster/_core/execution/execute_in_process_result.py` & `dagster-1.3.3/dagster/_core/execution/execute_in_process_result.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 from dagster._annotations import public
 from dagster._core.definitions import JobDefinition, NodeHandle
 from dagster._core.definitions.events import AssetKey, CoercibleToAssetKey
 from dagster._core.definitions.utils import DEFAULT_OUTPUT
 from dagster._core.errors import DagsterInvariantViolationError
 from dagster._core.events import DagsterEvent
 from dagster._core.execution.plan.outputs import StepOutputHandle
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 
 from .execution_result import ExecutionResult
 
 
 class ExecuteInProcessResult(ExecutionResult):
     """Result object returned by in-process testing APIs.
```

### Comparing `dagster-1.3.2/dagster/_core/execution/execute_job_result.py` & `dagster-1.3.3/dagster/_core/execution/execute_job_result.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 import dagster._check as check
 from dagster._annotations import public
 from dagster._core.definitions import JobDefinition, NodeHandle
 from dagster._core.definitions.utils import DEFAULT_OUTPUT
 from dagster._core.errors import DagsterInvariantViolationError
 from dagster._core.events import DagsterEvent
 from dagster._core.execution.plan.utils import build_resources_for_manager
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 
 from .execution_result import ExecutionResult
 
 
 class ExecuteJobResult(ExecutionResult):
     """Result object returned by :py:func:`dagster.execute_job`.
```

### Comparing `dagster-1.3.2/dagster/_core/execution/execution_result.py` & `dagster-1.3.3/dagster/_core/execution/execution_result.py`

 * *Files 0% similar despite different names*

```diff
@@ -12,15 +12,15 @@
     DagsterEventType,
     ExpectationResult,
     StepExpectationResultData,
     StepMaterializationData,
 )
 from dagster._core.execution.plan.objects import StepFailureData
 from dagster._core.execution.plan.step import StepKind
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 
 
 class ExecutionResult(ABC):
     @property
     @abstractmethod
     def job_def(self) -> JobDefinition:
         ...
```

### Comparing `dagster-1.3.2/dagster/_core/execution/host_mode.py` & `dagster-1.3.3/dagster/_core/execution/host_mode.py`

 * *Files 10% similar despite different names*

```diff
@@ -5,40 +5,40 @@
 import dagster._check as check
 from dagster._config import Field, process_config
 from dagster._core.definitions.executor_definition import (
     ExecutorDefinition,
     check_cross_process_constraints,
     multi_or_in_process_executor,
 )
-from dagster._core.definitions.reconstruct import ReconstructablePipeline
+from dagster._core.definitions.reconstruct import ReconstructableJob
 from dagster._core.definitions.run_config import selector_for_named_defs
 from dagster._core.errors import (
     DagsterError,
     DagsterInvalidConfigError,
     DagsterInvariantViolationError,
 )
 from dagster._core.events import DagsterEvent
 from dagster._core.execution.plan.plan import ExecutionPlan
 from dagster._core.executor.base import Executor
 from dagster._core.executor.init import InitExecutorContext
 from dagster._core.instance import DagsterInstance
 from dagster._core.log_manager import DagsterLogManager
-from dagster._core.storage.pipeline_run import DagsterRun, DagsterRunStatus
+from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus
 from dagster._loggers import default_system_loggers
 from dagster._utils import ensure_single_item
 from dagster._utils.error import serializable_error_info_from_exc_info
 
-from .api import ExecuteRunWithPlanIterable, pipeline_execution_iterator
+from .api import ExecuteRunWithPlanIterable, job_execution_iterator
 from .context.logger import InitLoggerContext
 from .context.system import PlanData, PlanOrchestrationContext
-from .context_creation_pipeline import PlanOrchestrationContextManager
+from .context_creation_job import PlanOrchestrationContextManager
 
 
 def _get_host_mode_executor(
-    recon_pipeline: ReconstructablePipeline,
+    recon_job: ReconstructableJob,
     run_config: Mapping[str, object],
     executor_defs: Sequence[ExecutorDefinition],
     instance: DagsterInstance,
 ) -> Executor:
     execution_config = run_config.get("execution", {})
     execution_config_type = Field(
         selector_for_named_defs(executor_defs), default_value={executor_defs[0].name: {}}
@@ -56,36 +56,36 @@
 
     executor_name, executor_config = ensure_single_item(execution_config_value)
 
     executor_defs_by_name = {executor_def.name: executor_def for executor_def in executor_defs}
     executor_def = executor_defs_by_name[executor_name]
 
     init_context = InitExecutorContext(
-        job=recon_pipeline,
+        job=recon_job,
         executor_def=executor_def,
         executor_config=executor_config["config"],  # type: ignore  # (config typing)
         instance=instance,
     )
     check_cross_process_constraints(init_context)
     return executor_def.executor_creation_fn(init_context)  # type: ignore  # (possible none)
 
 
 def host_mode_execution_context_event_generator(
-    pipeline: ReconstructablePipeline,
+    pipeline: ReconstructableJob,
     execution_plan: ExecutionPlan,
     run_config: Mapping[str, object],
     pipeline_run: DagsterRun,
     instance: DagsterInstance,
     raise_on_error: bool,
     executor_defs: Sequence[ExecutorDefinition],
     output_capture: None,
     resume_from_failure: bool = False,
 ) -> Iterator[Union[PlanOrchestrationContext, DagsterEvent]]:
     check.inst_param(execution_plan, "execution_plan", ExecutionPlan)
-    check.inst_param(pipeline, "pipeline", ReconstructablePipeline)
+    check.inst_param(pipeline, "pipeline", ReconstructableJob)
 
     check.dict_param(run_config, "run_config", key_type=str)
     check.inst_param(pipeline_run, "pipeline_run", DagsterRun)
     check.inst_param(instance, "instance", DagsterInstance)
     executor_defs = check.list_param(executor_defs, "executor_defs", of_type=ExecutorDefinition)
     check.bool_param(raise_on_error, "raise_on_error")
     check.invariant(output_capture is None)
@@ -95,30 +95,30 @@
     loggers = []
 
     for logger_def, logger_config in default_system_loggers(instance):
         loggers.append(
             logger_def.logger_fn(
                 InitLoggerContext(
                     logger_config,
-                    pipeline_def=None,
+                    job_def=None,
                     logger_def=logger_def,
                     run_id=pipeline_run.run_id,
                 )
             )
         )
 
     log_manager = DagsterLogManager.create(
         loggers=loggers, dagster_run=pipeline_run, instance=instance
     )
 
     try:
         executor = _get_host_mode_executor(pipeline, run_config, executor_defs, instance)
         execution_context = PlanOrchestrationContext(
             plan_data=PlanData(
-                pipeline=pipeline,
+                job=pipeline,
                 dagster_run=pipeline_run,
                 instance=instance,
                 execution_plan=execution_plan,
                 raise_on_error=raise_on_error,
                 retry_mode=executor.retries,
             ),
             log_manager=log_manager,
@@ -135,19 +135,19 @@
                 # pylint does not know original_exc_info exists is is_user_code_error is true
                 dagster_error.original_exc_info  # type: ignore
                 if dagster_error.is_user_code_error
                 else sys.exc_info()
             )
             error_info = serializable_error_info_from_exc_info(user_facing_exc_info)
 
-            event = DagsterEvent.pipeline_failure(
-                pipeline_context_or_name=pipeline_run.pipeline_name,
+            event = DagsterEvent.job_failure(
+                job_context_or_name=pipeline_run.job_name,
                 context_msg=(
                     "Pipeline failure during initialization for pipeline"
-                    f' "{pipeline_run.pipeline_name}". This may be due to a failure in initializing'
+                    f' "{pipeline_run.job_name}". This may be due to a failure in initializing'
                     " the executor or one of the loggers."
                 ),
                 error_info=error_info,
             )
             log_manager.log_dagster_event(
                 level=logging.ERROR, msg=event.message, dagster_event=event  # type: ignore
             )
@@ -157,67 +157,67 @@
             raise dagster_error
 
         if raise_on_error:
             raise dagster_error
 
 
 def execute_run_host_mode(
-    pipeline: ReconstructablePipeline,
-    pipeline_run: DagsterRun,
+    recon_job: ReconstructableJob,
+    dagster_run: DagsterRun,
     instance: DagsterInstance,
     executor_defs: Optional[Sequence[ExecutorDefinition]] = None,
     raise_on_error: bool = False,
 ) -> Sequence[DagsterEvent]:
-    check.inst_param(pipeline, "pipeline", ReconstructablePipeline)
-    check.inst_param(pipeline_run, "pipeline_run", DagsterRun)
+    check.inst_param(recon_job, "recon_job", ReconstructableJob)
+    check.inst_param(dagster_run, "dagster_run", DagsterRun)
     check.inst_param(instance, "instance", DagsterInstance)
     check.opt_sequence_param(executor_defs, "executor_defs", of_type=ExecutorDefinition)
     executor_defs = executor_defs if executor_defs is not None else [multi_or_in_process_executor]
 
-    if pipeline_run.status == DagsterRunStatus.CANCELED:
+    if dagster_run.status == DagsterRunStatus.CANCELED:
         message = "Not starting execution since the run was canceled before execution could start"
         instance.report_engine_event(
             message,
-            pipeline_run,
+            dagster_run,
         )
         raise DagsterInvariantViolationError(message)
 
     check.invariant(
-        pipeline_run.status == DagsterRunStatus.NOT_STARTED
-        or pipeline_run.status == DagsterRunStatus.STARTING,
+        dagster_run.status == DagsterRunStatus.NOT_STARTED
+        or dagster_run.status == DagsterRunStatus.STARTING,
         desc="Pipeline run {} ({}) in state {}, expected NOT_STARTED or STARTING".format(
-            pipeline_run.pipeline_name, pipeline_run.run_id, pipeline_run.status
+            dagster_run.job_name, dagster_run.run_id, dagster_run.status
         ),
     )
 
-    pipeline = pipeline.subset_for_execution_from_existing_pipeline(
-        solids_to_execute=frozenset(pipeline_run.solids_to_execute)
-        if pipeline_run.solids_to_execute
+    recon_job = recon_job.subset_for_execution_from_existing_job(
+        solids_to_execute=frozenset(dagster_run.solids_to_execute)
+        if dagster_run.solids_to_execute
         else None,
-        asset_selection=pipeline_run.asset_selection,
+        asset_selection=dagster_run.asset_selection,
     )
 
     execution_plan_snapshot = instance.get_execution_plan_snapshot(
-        check.not_none(pipeline_run.execution_plan_snapshot_id)
+        check.not_none(dagster_run.execution_plan_snapshot_id)
     )
     execution_plan = ExecutionPlan.rebuild_from_snapshot(
-        pipeline_run.pipeline_name,
+        dagster_run.job_name,
         execution_plan_snapshot,
     )
-    pipeline = pipeline.with_repository_load_data(execution_plan.repository_load_data)
+    recon_job = recon_job.with_repository_load_data(execution_plan.repository_load_data)
 
     _execute_run_iterable = ExecuteRunWithPlanIterable(
         execution_plan=execution_plan,
-        iterator=pipeline_execution_iterator,
+        iterator=job_execution_iterator,
         execution_context_manager=PlanOrchestrationContextManager(
             context_event_generator=host_mode_execution_context_event_generator,
-            pipeline=pipeline,
+            job=recon_job,
             execution_plan=execution_plan,
-            run_config=pipeline_run.run_config,
-            dagster_run=pipeline_run,
+            run_config=dagster_run.run_config,
+            dagster_run=dagster_run,
             instance=instance,
             raise_on_error=raise_on_error,
             executor_defs=executor_defs,
             output_capture=None,
         ),
     )
     event_list = list(_execute_run_iterable)
```

### Comparing `dagster-1.3.2/dagster/_core/execution/job_backfill.py` & `dagster-1.3.3/dagster/_core/execution/job_backfill.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,29 +1,29 @@
 import logging
 import os
 import time
 from typing import Callable, Iterable, Mapping, Optional, Sequence, Tuple, cast
 
 import dagster._check as check
-from dagster._core.definitions.selector import PipelineSelector
+from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.errors import DagsterBackfillFailedError
 from dagster._core.execution.plan.resume_retry import ReexecutionStrategy
 from dagster._core.execution.plan.state import KnownExecutionState
 from dagster._core.host_representation import (
     CodeLocation,
+    ExternalJob,
     ExternalPartitionSet,
-    ExternalPipeline,
 )
 from dagster._core.host_representation.external_data import (
     ExternalPartitionExecutionParamData,
     ExternalPartitionSetExecutionParamData,
 )
 from dagster._core.host_representation.origin import ExternalPartitionSetOrigin
 from dagster._core.instance import DagsterInstance
-from dagster._core.storage.pipeline_run import DagsterRun, DagsterRunStatus, RunsFilter
+from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus, RunsFilter
 from dagster._core.storage.tags import (
     PARENT_RUN_ID_TAG,
     PARTITION_NAME_TAG,
     PARTITION_SET_TAG,
     ROOT_RUN_ID_TAG,
 )
 from dagster._core.telemetry import BACKFILL_RUN_CREATED, hash_name, log_action
@@ -198,35 +198,33 @@
         external_repo.handle, partition_set_name, partition_names, instance
     )
 
     assert isinstance(result, ExternalPartitionSetExecutionParamData)
     if backfill_job.asset_selection:
         # need to make another call to the user code location to properly subset
         # for an asset selection
-        pipeline_selector = PipelineSelector(
+        pipeline_selector = JobSubsetSelector(
             location_name=code_location.name,
             repository_name=repo_name,
-            pipeline_name=external_partition_set.pipeline_name,
+            job_name=external_partition_set.job_name,
             solid_selection=None,
             asset_selection=backfill_job.asset_selection,
         )
-        external_pipeline = code_location.get_external_pipeline(pipeline_selector)
+        external_job = code_location.get_external_job(pipeline_selector)
     else:
-        external_pipeline = external_repo.get_full_external_job(
-            external_partition_set.pipeline_name
-        )
+        external_job = external_repo.get_full_external_job(external_partition_set.job_name)
     for partition_data in result.partition_data:
         # Refresh the code location in case the workspace has reloaded mid-backfill
         workspace = create_workspace()
         code_location = workspace.get_code_location(location_name)
 
         dagster_run = create_backfill_run(
             instance,
             code_location,
-            external_pipeline,
+            external_job,
             external_partition_set,
             backfill_job,
             partition_data,
         )
         if dagster_run:
             # we skip runs in certain cases, e.g. we are running a `from_failure` backfill job
             # and the partition has had a successful run since the time the backfill was
@@ -235,15 +233,15 @@
             yield dagster_run.run_id
         yield None
 
 
 def create_backfill_run(
     instance: DagsterInstance,
     code_location: CodeLocation,
-    external_pipeline: ExternalPipeline,
+    external_pipeline: ExternalJob,
     external_partition_set: ExternalPartitionSet,
     backfill_job: PartitionBackfill,
     partition_data: ExternalPartitionExecutionParamData,
 ) -> Optional[DagsterRun]:
     from dagster._daemon.daemon import get_telemetry_daemon_session_id
 
     log_action(
@@ -277,15 +275,15 @@
     elif backfill_job.from_failure:
         last_run = _fetch_last_run(instance, external_partition_set, partition_data.name)
         if not last_run or last_run.status != DagsterRunStatus.FAILURE:
             return None
         return instance.create_reexecuted_run(
             parent_run=last_run,
             code_location=code_location,
-            external_pipeline=external_pipeline,
+            external_job=external_pipeline,
             strategy=ReexecutionStrategy.FROM_FAILURE,
             extra_tags=tags,
             run_config=partition_data.run_config,
             use_parent_run_tags=False,  # don't inherit tags from the previous run
         )
 
     else:  # backfill_job.reexecution_steps
@@ -314,43 +312,45 @@
         partition_data.run_config,
         step_keys_to_execute=step_keys_to_execute,
         known_state=known_state,
         instance=instance,
     )
 
     return instance.create_run(
-        pipeline_snapshot=external_pipeline.pipeline_snapshot,
+        job_snapshot=external_pipeline.job_snapshot,
         execution_plan_snapshot=external_execution_plan.execution_plan_snapshot,
-        parent_pipeline_snapshot=external_pipeline.parent_pipeline_snapshot,
-        pipeline_name=external_pipeline.name,
+        parent_job_snapshot=external_pipeline.parent_job_snapshot,
+        job_name=external_pipeline.name,
         run_id=make_new_run_id(),
         solids_to_execute=solids_to_execute,
         run_config=partition_data.run_config,
         step_keys_to_execute=step_keys_to_execute,
         tags=tags,
         root_run_id=root_run_id,
         parent_run_id=parent_run_id,
         status=DagsterRunStatus.NOT_STARTED,
-        external_pipeline_origin=external_pipeline.get_external_origin(),
-        pipeline_code_origin=external_pipeline.get_python_origin(),
+        external_job_origin=external_pipeline.get_external_origin(),
+        job_code_origin=external_pipeline.get_python_origin(),
         solid_selection=solid_selection,
         asset_selection=frozenset(backfill_job.asset_selection)
         if backfill_job.asset_selection
         else None,
     )
 
 
-def _fetch_last_run(instance, external_partition_set, partition_name):
+def _fetch_last_run(
+    instance: DagsterInstance, external_partition_set: ExternalPartitionSet, partition_name: str
+) -> Optional[DagsterRun]:
     check.inst_param(instance, "instance", DagsterInstance)
     check.inst_param(external_partition_set, "external_partition_set", ExternalPartitionSet)
     check.str_param(partition_name, "partition_name")
 
     runs = instance.get_runs(
         RunsFilter(
-            pipeline_name=external_partition_set.pipeline_name,
+            job_name=external_partition_set.job_name,
             tags={
                 PARTITION_SET_TAG: external_partition_set.name,
                 PARTITION_NAME_TAG: partition_name,
             },
         ),
         limit=1,
     )
```

### Comparing `dagster-1.3.2/dagster/_core/execution/memoization.py` & `dagster-1.3.3/dagster/_core/execution/memoization.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/active.py` & `dagster-1.3.3/dagster/_core/execution/plan/active.py`

 * *Files 1% similar despite different names*

```diff
@@ -348,35 +348,35 @@
             steps.append(self.get_step_by_key(key))
             self._in_flight.add(key)
             self._pending_abandon.remove(key)
 
         return sorted(steps, key=self._sort_key_fn)
 
     def plan_events_iterator(
-        self, pipeline_context: Union[PlanExecutionContext, PlanOrchestrationContext]
+        self, job_context: Union[PlanExecutionContext, PlanOrchestrationContext]
     ) -> Iterator[DagsterEvent]:
         """Process all steps that can be skipped and abandoned."""
         steps_to_skip = self.get_steps_to_skip()
         while steps_to_skip:
             for step in steps_to_skip:
-                step_context = pipeline_context.for_step(step)
+                step_context = job_context.for_step(step)
                 step_context.log.info(
                     f"Skipping step {step.key} due to skipped dependencies:"
                     f" {self._skipped_deps[step.key]}."
                 )
                 yield DagsterEvent.step_skipped_event(step_context)
 
                 self.mark_skipped(step.key)
 
             steps_to_skip = self.get_steps_to_skip()
 
         steps_to_abandon = self.get_steps_to_abandon()
         while steps_to_abandon:
             for step in steps_to_abandon:
-                step_context = pipeline_context.for_step(step)
+                step_context = job_context.for_step(step)
                 failed_inputs: List[str] = []
                 for step_input in step.step_inputs:
                     failed_inputs.extend(self._failed.intersection(step_input.dependency_keys))
 
                 abandoned_inputs: List[str] = []
                 for step_input in step.step_inputs:
                     abandoned_inputs.extend(
@@ -486,19 +486,19 @@
             if dagster_event.step_output_data.step_output_handle.mapping_key:
                 check.not_none(
                     self._gathering_dynamic_outputs[step_key][
                         dagster_event.step_output_data.step_output_handle.output_name
                     ],
                 ).append(dagster_event.step_output_data.step_output_handle.mapping_key)
 
-    def verify_complete(self, pipeline_context: IPlanContext, step_key: str) -> None:
+    def verify_complete(self, job_context: IPlanContext, step_key: str) -> None:
         """Ensure that a step has reached a terminal state, if it has not mark it as an unexpected failure.
         """
         if step_key in self._in_flight:
-            pipeline_context.log.error(
+            job_context.log.error(
                 "Step {key} finished without success or failure event. Downstream steps will not"
                 " execute.".format(key=step_key)
             )
             self.mark_unknown_state(step_key)
 
     # factored out for test
     def mark_unknown_state(self, step_key: str) -> None:
```

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/compute.py` & `dagster-1.3.3/dagster/_core/execution/plan/compute.py`

 * *Files 6% similar despite different names*

```diff
@@ -46,29 +46,29 @@
     ExpectationResult,
     AssetObservation,
     DagsterEvent,
 ]
 
 
 def create_step_outputs(
-    solid: Node, handle: NodeHandle, resolved_run_config: ResolvedRunConfig, asset_layer: AssetLayer
+    node: Node, handle: NodeHandle, resolved_run_config: ResolvedRunConfig, asset_layer: AssetLayer
 ) -> Sequence[StepOutput]:
-    check.inst_param(solid, "solid", Node)
+    check.inst_param(node, "node", Node)
     check.inst_param(handle, "handle", NodeHandle)
 
-    # the run config has the solid output name configured
+    # the run config has the node output name configured
     config_output_names: Set[str] = set()
     current_handle = handle
     while current_handle:
-        solid_config = resolved_run_config.ops[current_handle.to_string()]
+        op_config = resolved_run_config.ops[current_handle.to_string()]
         current_handle = current_handle.parent
-        config_output_names = config_output_names.union(solid_config.outputs.output_names)
+        config_output_names = config_output_names.union(op_config.outputs.output_names)
 
     step_outputs: List[StepOutput] = []
-    for name, output_def in solid.definition.output_dict.items():
+    for name, output_def in node.definition.output_dict.items():
         asset_info = asset_layer.asset_info_for_output(handle, name)
         step_outputs.append(
             StepOutput(
                 node_handle=handle,
                 name=output_def.name,
                 dagster_type_key=output_def.dagster_type.key,
                 properties=StepOutputProperties(
@@ -161,15 +161,15 @@
     for event in iterate_with_context(
         lambda: op_execution_error_boundary(
             DagsterExecutionStepExecutionError,
             msg_fn=lambda: f"Error occurred while executing {op_label}:",
             step_context=step_context,
             step_key=step_context.step.key,
             op_def_name=step_context.op_def.name,
-            op_name=step_context.solid.name,
+            op_name=step_context.op.name,
         ),
         user_event_generator,
     ):
         if context.has_events():
             yield from context.consume_events()
         yield _validate_event(event, step_context)
 
@@ -190,14 +190,14 @@
 
     emitted_result_names = set()
     for step_output in _yield_compute_results(step_context, inputs, compute_fn):
         yield step_output
         if isinstance(step_output, (DynamicOutput, Output)):
             emitted_result_names.add(step_output.output_name)
 
-    solid_output_names = {output.name for output in step.step_outputs}
-    omitted_outputs = solid_output_names.difference(emitted_result_names)
+    op_output_names = {output.name for output in step.step_outputs}
+    omitted_outputs = op_output_names.difference(emitted_result_names)
     if omitted_outputs:
         step_context.log.info(
             f"{step_context.op_def.node_type_str} '{str(step.node_handle)}' did not fire "
             f"outputs {repr(omitted_outputs)}"
         )
```

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/compute_generator.py` & `dagster-1.3.3/dagster/_core/execution/plan/compute_generator.py`

 * *Files 2% similar despite different names*

```diff
@@ -65,34 +65,34 @@
             or inspect.iscoroutinefunction(fn)
         ):
             # safe to execute the function, as doing so will not immediately execute user code
             result = invoke_compute_fn(
                 fn, context, kwargs, context_arg_provided, config_arg_cls, resource_arg_mapping
             )
             if inspect.iscoroutine(result):
-                return _coerce_async_solid_to_async_gen(result, context, output_defs)
+                return _coerce_async_op_to_async_gen(result, context, output_defs)
             # already a generator
             return result
         else:
             # we have a regular function, do not execute it before we are in an iterator
             # (as we want all potential failures to happen inside iterators)
-            return _coerce_solid_compute_fn_to_iterator(
+            return _coerce_op_compute_fn_to_iterator(
                 fn,
                 output_defs,
                 context,
                 context_arg_provided,
                 kwargs,
                 config_arg_cls,
                 resource_arg_mapping,
             )
 
     return compute
 
 
-async def _coerce_async_solid_to_async_gen(awaitable, context, output_defs):
+async def _coerce_async_op_to_async_gen(awaitable, context, output_defs):
     result = await awaitable
     for event in validate_and_coerce_op_result_to_iterator(result, context, output_defs):
         yield event
 
 
 def invoke_compute_fn(
     fn: Callable,
@@ -114,25 +114,25 @@
             args_to_pass[arg_name] = context.resources._original_resource_dict[  # noqa: SLF001
                 resource_name
             ]
 
     return fn(context, **args_to_pass) if context_arg_provided else fn(**args_to_pass)
 
 
-def _coerce_solid_compute_fn_to_iterator(
+def _coerce_op_compute_fn_to_iterator(
     fn, output_defs, context, context_arg_provided, kwargs, config_arg_class, resource_arg_mapping
 ):
     result = invoke_compute_fn(
         fn, context, kwargs, context_arg_provided, config_arg_class, resource_arg_mapping
     )
     for event in validate_and_coerce_op_result_to_iterator(result, context, output_defs):
         yield event
 
 
-def _zip_and_iterate_solid_result(
+def _zip_and_iterate_op_result(
     result: Any, context: OpExecutionContext, output_defs: Sequence[OutputDefinition]
 ) -> Iterator[Tuple[int, Any, OutputDefinition]]:
     if len(output_defs) > 1:
         _validate_multi_return(context, result, output_defs)
         for position, (output_def, element) in enumerate(zip(output_defs, result)):
             yield position, output_def, element
     else:
@@ -188,15 +188,15 @@
         )
 
 
 def validate_and_coerce_op_result_to_iterator(
     result: Any, context: OpExecutionContext, output_defs: Sequence[OutputDefinition]
 ) -> Generator[Any, None, None]:
     if inspect.isgenerator(result):
-        # this happens when a user explicitly returns a generator in the solid
+        # this happens when a user explicitly returns a generator in the op
         for event in result:
             yield event
     elif isinstance(result, (AssetMaterialization, ExpectationResult)):
         raise DagsterInvariantViolationError(
             f"Error in {context.describe_op()}: If you are "
             "returning an AssetMaterialization "
             "or an ExpectationResult from "
@@ -209,15 +209,15 @@
     elif result is not None and not output_defs:
         raise DagsterInvariantViolationError(
             f"Error in {context.describe_op()}: Unexpectedly returned output of type"
             f" {type(result)}. {context.op_def.node_type_str.capitalize()} is explicitly defined to"
             " return no results."
         )
     elif output_defs:
-        for position, output_def, element in _zip_and_iterate_solid_result(
+        for position, output_def, element in _zip_and_iterate_op_result(
             result, context, output_defs
         ):
             annotation = _get_annotation_for_output_position(position, context.op_def, output_defs)
             if output_def.is_dynamic:
                 if not isinstance(element, list):
                     raise DagsterInvariantViolationError(
                         f"Error with output for {context.describe_op()}: "
```

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/execute_plan.py` & `dagster-1.3.3/dagster/_core/execution/plan/execute_plan.py`

 * *Files 3% similar despite different names*

```diff
@@ -25,70 +25,64 @@
 )
 from dagster._core.execution.plan.plan import ExecutionPlan
 from dagster._core.storage.captured_log_manager import CapturedLogManager
 from dagster._utils.error import SerializableErrorInfo, serializable_error_info_from_exc_info
 
 
 def inner_plan_execution_iterator(
-    pipeline_context: PlanExecutionContext, execution_plan: ExecutionPlan
+    job_context: PlanExecutionContext, execution_plan: ExecutionPlan
 ) -> Iterator[DagsterEvent]:
-    check.inst_param(pipeline_context, "pipeline_context", PlanExecutionContext)
+    check.inst_param(job_context, "pipeline_context", PlanExecutionContext)
     check.inst_param(execution_plan, "execution_plan", ExecutionPlan)
-    compute_log_manager = pipeline_context.instance.compute_log_manager
+    compute_log_manager = job_context.instance.compute_log_manager
     step_keys = [step.key for step in execution_plan.get_steps_to_execute_in_topo_order()]
-    with execution_plan.start(retry_mode=pipeline_context.retry_mode) as active_execution:
+    with execution_plan.start(retry_mode=job_context.retry_mode) as active_execution:
         with ExitStack() as capture_stack:
             # begin capturing logs for the whole process if this is a captured log manager
             if isinstance(compute_log_manager, CapturedLogManager):
                 file_key = create_compute_log_file_key()
-                log_key = compute_log_manager.build_log_key_for_run(
-                    pipeline_context.run_id, file_key
-                )
+                log_key = compute_log_manager.build_log_key_for_run(job_context.run_id, file_key)
                 try:
                     log_context = capture_stack.enter_context(
                         compute_log_manager.capture_logs(log_key)
                     )
-                    yield DagsterEvent.capture_logs(
-                        pipeline_context, step_keys, log_key, log_context
-                    )
+                    yield DagsterEvent.capture_logs(job_context, step_keys, log_key, log_context)
                 except Exception:
-                    yield from _handle_compute_log_setup_error(pipeline_context, sys.exc_info())
+                    yield from _handle_compute_log_setup_error(job_context, sys.exc_info())
 
             # It would be good to implement a reference tracking algorithm here to
             # garbage collect results that are no longer needed by any steps
             # https://github.com/dagster-io/dagster/issues/811
             while not active_execution.is_complete:
                 step = active_execution.get_next_step()
                 step_context = cast(
                     StepExecutionContext,
-                    pipeline_context.for_step(step, active_execution.get_known_state()),
+                    job_context.for_step(step, active_execution.get_known_state()),
                 )
                 step_event_list = []
 
                 missing_resources = [
                     resource_key
                     for resource_key in step_context.required_resource_keys
                     if not hasattr(step_context.resources, resource_key)
                 ]
                 check.invariant(
                     len(missing_resources) == 0,
                     (
                         "Expected step context for solid {solid_name} to have all required"
                         " resources, but missing {missing_resources}."
-                    ).format(
-                        solid_name=step_context.solid.name, missing_resources=missing_resources
-                    ),
+                    ).format(solid_name=step_context.op.name, missing_resources=missing_resources),
                 )
 
                 with ExitStack() as step_stack:
                     if not isinstance(compute_log_manager, CapturedLogManager):
                         # capture all of the logs for individual steps
                         try:
                             step_stack.enter_context(
-                                pipeline_context.instance.compute_log_manager.watch(
+                                job_context.instance.compute_log_manager.watch(
                                     step_context.dagster_run, step_context.step.key
                                 )
                             )
                             yield DagsterEvent.legacy_compute_log_step_event(step_context)
                         except Exception:
                             yield from _handle_compute_log_setup_error(step_context, sys.exc_info())
 
@@ -96,15 +90,15 @@
                             dagster_event_sequence_for_step(step_context)
                         ):
                             check.inst(step_event, DagsterEvent)
                             step_event_list.append(step_event)
                             yield step_event
                             active_execution.handle_event(step_event)
 
-                        active_execution.verify_complete(pipeline_context, step.key)
+                        active_execution.verify_complete(job_context, step.key)
 
                         try:
                             step_stack.close()
                         except Exception:
                             yield from _handle_compute_log_teardown_error(
                                 step_context, sys.exc_info()
                             )
@@ -115,29 +109,29 @@
                             dagster_event_sequence_for_step(step_context)
                         ):
                             check.inst(step_event, DagsterEvent)
                             step_event_list.append(step_event)
                             yield step_event
                             active_execution.handle_event(step_event)
 
-                        active_execution.verify_complete(pipeline_context, step.key)
+                        active_execution.verify_complete(job_context, step.key)
 
                 # process skips from failures or uncovered inputs
-                for event in active_execution.plan_events_iterator(pipeline_context):
+                for event in active_execution.plan_events_iterator(job_context):
                     step_event_list.append(event)
                     yield event
 
                 # pass a list of step events to hooks
                 for hook_event in _trigger_hook(step_context, step_event_list):
                     yield hook_event
 
             try:
                 capture_stack.close()
             except Exception:
-                yield from _handle_compute_log_teardown_error(pipeline_context, sys.exc_info())
+                yield from _handle_compute_log_teardown_error(job_context, sys.exc_info())
 
 
 def _handle_compute_log_setup_error(
     context: PlanExecutionContext, exc_info
 ) -> Iterator[DagsterEvent]:
     yield DagsterEvent.engine_event(
         plan_context=context,
@@ -156,15 +150,15 @@
     )
 
 
 def _trigger_hook(
     step_context: StepExecutionContext, step_event_list: Sequence[DagsterEvent]
 ) -> Iterator[DagsterEvent]:
     """Trigger hooks and record hook's operatonal events."""
-    hook_defs = step_context.pipeline_def.get_all_hooks_for_handle(step_context.node_handle)
+    hook_defs = step_context.job_def.get_all_hooks_for_handle(step_context.node_handle)
     # when the solid doesn't have a hook configured
     if hook_defs is None:
         return
 
     op_label = step_context.describe_op()
 
     # when there are multiple hooks set on a solid, the hooks will run sequentially for the solid.
```

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/execute_step.py` & `dagster-1.3.3/dagster/_core/execution/plan/execute_step.py`

 * *Files 2% similar despite different names*

```diff
@@ -97,15 +97,15 @@
         if not step.has_step_output(cast(str, output.output_name)):
             raise DagsterInvariantViolationError(
                 f'Core compute for {op_label} returned an output "{output.output_name}" that does '
                 f"not exist. The available outputs are {output_names}"
             )
 
         step_output = step.step_output_named(cast(str, output.output_name))
-        output_def = step_context.pipeline_def.get_node(step_output.node_handle).output_def_named(
+        output_def = step_context.job_def.get_node(step_output.node_handle).output_def_named(
             step_output.name
         )
 
         if isinstance(output, Output):
             if step_context.has_seen_output(output.output_name):
                 raise DagsterInvariantViolationError(
                     f'Compute for {op_label} returned an output "{output.output_name}" multiple '
@@ -342,17 +342,17 @@
     for input_name, input_value in inputs.items():
         for evt in check.generator(
             _type_checked_event_sequence_for_input(step_context, input_name, input_value)
         ):
             yield evt
 
     # The core execution loop expects a compute generator in a specific format: a generator that
-    # takes a context and dictionary of inputs as input, yields output events. If a solid definition
-    # was generated from the @solid or @lambda_solid decorator, then compute_fn needs to be coerced
-    # into this format. If the solid definition was created directly, then it is expected that the
+    # takes a context and dictionary of inputs as input, yields output events. If an op definition
+    # was generated from the @op decorator, then compute_fn needs to be coerced
+    # into this format. If the op definition was created directly, then it is expected that the
     # compute_fn is already in this format.
     if isinstance(step_context.op_def.compute_fn, DecoratedOpFunction):
         core_gen = create_op_compute_wrapper(step_context.op_def)
     else:
         core_gen = step_context.op_def.compute_fn
 
     with time_execution_scope() as timer_result:
@@ -402,27 +402,27 @@
 
     mapping_key = output.mapping_key if isinstance(output, DynamicOutput) else None
 
     step_output_handle = StepOutputHandle(
         step_key=step_context.step.key, output_name=output.output_name, mapping_key=mapping_key
     )
 
-    # If we are executing using the execute_in_process API, then we allow for the outputs of solids
+    # If we are executing using the execute_in_process API, then we allow for the outputs of ops
     # to be directly captured to a dictionary after they are computed.
     if step_context.output_capture is not None:
         step_context.output_capture[step_output_handle] = output.value
     # capture output at the step level for threading the computed output values to hook context
     if step_context.step_output_capture is not None:
         step_context.step_output_capture[step_output_handle] = output.value
 
     version = (
         resolve_step_output_versions(
-            step_context.pipeline_def, step_context.execution_plan, step_context.resolved_run_config
+            step_context.job_def, step_context.execution_plan, step_context.resolved_run_config
         ).get(step_output_handle)
-        if MEMOIZED_RUN_TAG in step_context.pipeline.get_definition().tags
+        if MEMOIZED_RUN_TAG in step_context.job.get_definition().tags
         else None
     )
 
     for output_event in _type_check_output(step_context, step_output_handle, output, version):
         yield output_event
 
     for evt in _store_output(step_context, step_output_handle, output):
@@ -460,15 +460,15 @@
     # Clear any cached record associated with this asset, since we are about to generate a new
     # materialization.
     step_context.wipe_input_asset_record(asset_key)
 
     tags: Dict[str, str]
     if (
         step_context.is_external_input_asset_records_loaded
-        and asset_key in step_context.pipeline_def.asset_layer.asset_keys
+        and asset_key in step_context.job_def.asset_layer.asset_keys
     ):
         assert isinstance(output, Output)
         code_version = _get_code_version(asset_key, step_context)
         input_provenance_data = _get_input_provenance_data(asset_key, step_context)
         data_version = (
             compute_logical_data_version(
                 code_version,
@@ -512,29 +512,29 @@
             warnings.simplefilter("ignore", category=DeprecationWarning)
 
             yield AssetMaterialization(asset_key=asset_key, metadata=all_metadata, tags=tags)
 
 
 def _get_code_version(asset_key: AssetKey, step_context: StepExecutionContext) -> str:
     return (
-        step_context.pipeline_def.asset_layer.code_version_for_asset(asset_key)
+        step_context.job_def.asset_layer.code_version_for_asset(asset_key)
         or step_context.dagster_run.run_id
     )
 
 
 class _InputProvenanceData(TypedDict):
     data_version: DataVersion
     storage_id: Optional[int]
 
 
 def _get_input_provenance_data(
     asset_key: AssetKey, step_context: StepExecutionContext
 ) -> Mapping[AssetKey, _InputProvenanceData]:
     input_provenance: Dict[AssetKey, _InputProvenanceData] = {}
-    deps = step_context.pipeline_def.asset_layer.upstream_assets_for_asset(asset_key)
+    deps = step_context.job_def.asset_layer.upstream_assets_for_asset(asset_key)
     for key in deps:
         # For deps external to this step, this will retrieve the cached record that was stored prior
         # to step execution. For inputs internal to this step, it may trigger a query to retrieve
         # the most recent materialization record (it will retrieve a cached record if it's already
         # been asked for). For this to be correct, the output materializations for the step must be
         # generated in topological order -- we assume this.
         event = step_context.get_input_asset_record(key)
```

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/external_step.py` & `dagster-1.3.3/dagster/_core/execution/plan/external_step.py`

 * *Files 16% similar despite different names*

```diff
@@ -4,23 +4,23 @@
 import subprocess
 import sys
 from typing import TYPE_CHECKING, Callable, Iterator, Optional, Sequence, cast
 
 import dagster._check as check
 from dagster._config import Field, StringSource
 from dagster._core.code_pointer import FileCodePointer, ModuleCodePointer
-from dagster._core.definitions.reconstruct import ReconstructablePipeline, ReconstructableRepository
+from dagster._core.definitions.reconstruct import ReconstructableJob, ReconstructableRepository
 from dagster._core.definitions.resource_definition import resource
 from dagster._core.definitions.step_launcher import StepLauncher, StepRunRef
 from dagster._core.errors import raise_execution_interrupts
 from dagster._core.events import DagsterEvent
 from dagster._core.events.log import EventLogEntry
 from dagster._core.execution.api import create_execution_plan
 from dagster._core.execution.context.system import StepExecutionContext
-from dagster._core.execution.context_creation_pipeline import PlanExecutionContextManager
+from dagster._core.execution.context_creation_job import PlanExecutionContextManager
 from dagster._core.execution.plan.execute_plan import dagster_event_sequence_for_step
 from dagster._core.execution.plan.state import KnownExecutionState
 from dagster._core.instance import DagsterInstance
 from dagster._core.storage.file_manager import LocalFileHandle, LocalFileManager
 from dagster._serdes import deserialize_value
 
 PICKLED_EVENTS_FILE_NAME = "events.pkl"
@@ -108,56 +108,56 @@
     step_context: StepExecutionContext,
     package_dir: Optional[str] = None,
 ) -> StepRunRef:
     """Args:
         step_context (StepExecutionContext): The step context.
         package_dir (Optional[str]): If set, the reconstruction file code pointer will be converted
             to be relative a module pointer relative to the package root.  This enables executing
-            steps in remote setups where the package containing the pipeline resides at a different
+            steps in remote setups where the package containing the job resides at a different
             location on the filesystem in the remote environment than in the environment executing
             the plan process.
 
     Returns (StepRunRef):
         A reference to the step.
     """
     check.inst_param(step_context, "step_context", StepExecutionContext)
 
     retry_mode = step_context.retry_mode
 
-    recon_pipeline = step_context.pipeline
+    recon_job = step_context.job
     if package_dir:
-        if isinstance(recon_pipeline, ReconstructablePipeline) and isinstance(
-            recon_pipeline.repository.pointer, FileCodePointer
+        if isinstance(recon_job, ReconstructableJob) and isinstance(
+            recon_job.repository.pointer, FileCodePointer
         ):
-            recon_pipeline = ReconstructablePipeline(
+            recon_job = ReconstructableJob(
                 repository=ReconstructableRepository(
                     pointer=ModuleCodePointer(
                         _module_in_package_dir(
-                            recon_pipeline.repository.pointer.python_file, package_dir
+                            recon_job.repository.pointer.python_file, package_dir
                         ),
-                        recon_pipeline.repository.pointer.fn_name,
+                        recon_job.repository.pointer.fn_name,
                         working_directory=os.getcwd(),
                     ),
-                    container_image=recon_pipeline.repository.container_image,
-                    executable_path=recon_pipeline.repository.executable_path,
-                    entry_point=recon_pipeline.repository.entry_point,
-                    container_context=recon_pipeline.repository.container_context,
+                    container_image=recon_job.repository.container_image,
+                    executable_path=recon_job.repository.executable_path,
+                    entry_point=recon_job.repository.entry_point,
+                    container_context=recon_job.repository.container_context,
                     repository_load_data=step_context.plan_data.execution_plan.repository_load_data,
                 ),
-                pipeline_name=recon_pipeline.pipeline_name,
-                solids_to_execute=recon_pipeline.solids_to_execute,
+                job_name=recon_job.job_name,
+                solids_to_execute=recon_job.solids_to_execute,
             )
 
     return StepRunRef(
         run_config=step_context.run_config,
         dagster_run=step_context.dagster_run,
         run_id=step_context.dagster_run.run_id,
         step_key=step_context.step.key,
         retry_mode=retry_mode,
-        recon_pipeline=recon_pipeline,  # type: ignore
+        recon_job=recon_job,  # type: ignore
         known_state=step_context.get_known_state(),
     )
 
 
 def external_instance_from_step_run_ref(
     step_run_ref: StepRunRef, event_listener_fn: Optional[Callable[[EventLogEntry], object]] = None
 ) -> DagsterInstance:
@@ -180,36 +180,36 @@
 
 
 def step_run_ref_to_step_context(
     step_run_ref: StepRunRef, instance: DagsterInstance
 ) -> StepExecutionContext:
     check.inst_param(instance, "instance", DagsterInstance)
 
-    pipeline = step_run_ref.recon_pipeline
+    job = step_run_ref.recon_job
 
     solids_to_execute = step_run_ref.dagster_run.solids_to_execute
     if solids_to_execute or step_run_ref.dagster_run.asset_selection:
-        pipeline = step_run_ref.recon_pipeline.subset_for_execution_from_existing_pipeline(
+        job = step_run_ref.recon_job.subset_for_execution_from_existing_job(
             frozenset(solids_to_execute) if solids_to_execute else None,
             asset_selection=step_run_ref.dagster_run.asset_selection,
         )
 
     execution_plan = create_execution_plan(
-        pipeline,
+        job,
         step_run_ref.run_config,
         step_keys_to_execute=[step_run_ref.step_key],
         known_state=step_run_ref.known_state,
-        # we packaged repository_load_data onto the reconstructable pipeline when creating the
+        # we packaged repository_load_data onto the reconstructable job when creating the
         # StepRunRef, rather than putting it in a separate field
-        repository_load_data=pipeline.repository.repository_load_data,
+        repository_load_data=job.repository.repository_load_data,
     )
 
     initialization_manager = PlanExecutionContextManager(
         retry_mode=step_run_ref.retry_mode.for_inner_plan(),
-        pipeline=pipeline,
+        job=job,
         execution_plan=execution_plan,
         run_config=step_run_ref.run_config,
         dagster_run=step_run_ref.dagster_run,
         instance=instance,
     )
     for _ in initialization_manager.prepare_context():
         pass
```

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/handle.py` & `dagster-1.3.3/dagster/_core/execution/plan/handle.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/inputs.py` & `dagster-1.3.3/dagster/_core/execution/plan/inputs.py`

 * *Files 4% similar despite different names*

```diff
@@ -104,22 +104,22 @@
 
     @abstractmethod
     def load_input_object(
         self, step_context: "StepExecutionContext", input_def: InputDefinition
     ) -> Iterator[object]:
         ...
 
-    def required_resource_keys(self, _pipeline_def: JobDefinition) -> AbstractSet[str]:
+    def required_resource_keys(self, _job_def: JobDefinition) -> AbstractSet[str]:
         return set()
 
     @abstractmethod
     def compute_version(
         self,
         step_versions: Mapping[str, Optional[str]],
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         resolved_run_config: ResolvedRunConfig,
     ) -> Optional[str]:
         """See resolve_step_versions in resolve_versions.py for explanation of step_versions."""
         raise NotImplementedError()
 
 
 @whitelist_for_serdes(storage_field_names={"node_handle": "solid_handle"})
@@ -140,15 +140,15 @@
         step_context: "StepExecutionContext",
         input_def: InputDefinition,
     ) -> Iterator[object]:
         from dagster._core.definitions.asset_layer import AssetOutputInfo
         from dagster._core.events import DagsterEvent
         from dagster._core.execution.context.output import OutputContext
 
-        asset_layer = step_context.pipeline_def.asset_layer
+        asset_layer = step_context.job_def.asset_layer
 
         input_asset_key = asset_layer.asset_key_for_input(
             self.node_handle, input_name=self.input_name
         )
         assert input_asset_key is not None
 
         input_manager_key = (
@@ -194,37 +194,35 @@
             manager_key=input_manager_key,
             metadata=metadata,
         )
 
     def compute_version(
         self,
         step_versions: Mapping[str, Optional[str]],
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         resolved_run_config: ResolvedRunConfig,
     ) -> Optional[str]:
         from ..resolve_versions import check_valid_version, resolve_config_version
 
-        op = pipeline_def.get_node(self.node_handle)
+        op = job_def.get_node(self.node_handle)
         input_manager_key = check.not_none(op.input_def_named(self.input_name).input_manager_key)
-        io_manager_def = pipeline_def.resource_defs[input_manager_key]
+        io_manager_def = job_def.resource_defs[input_manager_key]
 
         op_config = check.not_none(resolved_run_config.ops.get(op.name))
         input_config = op_config.inputs.get(self.input_name)
         resource_entry = check.not_none(resolved_run_config.resources.get(input_manager_key))
         resource_config = resource_entry.config
 
         version_context = ResourceVersionContext(
             resource_def=io_manager_def,
             resource_config=resource_config,
         )
 
-        if pipeline_def.version_strategy is not None:
-            io_manager_def_version = pipeline_def.version_strategy.get_resource_version(
-                version_context
-            )
+        if job_def.version_strategy is not None:
+            io_manager_def_version = job_def.version_strategy.get_resource_version(version_context)
         else:
             io_manager_def_version = io_manager_def.version
 
         if io_manager_def_version is None:
             raise DagsterInvariantViolationError(
                 f"While using memoization, version for io manager '{io_manager_def}' was "
                 "None. Please either provide a versioning strategy for your job, or provide a "
@@ -234,31 +232,29 @@
         check_valid_version(io_manager_def_version)
         return join_and_hash(
             resolve_config_version(input_config),
             resolve_config_version(resource_config),
             io_manager_def_version,
         )
 
-    def required_resource_keys(self, pipeline_def: JobDefinition) -> Set[str]:
-        input_asset_key = pipeline_def.asset_layer.asset_key_for_input(
-            self.node_handle, self.input_name
-        )
+    def required_resource_keys(self, job_def: JobDefinition) -> Set[str]:
+        input_asset_key = job_def.asset_layer.asset_key_for_input(self.node_handle, self.input_name)
         if input_asset_key is None:
             check.failed(
                 (
                     f"Must have an asset key associated with input {self.input_name} to load it"
                     " using FromSourceAsset"
                 ),
             )
 
-        input_def = pipeline_def.get_node(self.node_handle).input_def_named(self.input_name)
+        input_def = job_def.get_node(self.node_handle).input_def_named(self.input_name)
         if input_def.input_manager_key is not None:
             input_manager_key = input_def.input_manager_key
         else:
-            input_manager_key = pipeline_def.asset_layer.io_manager_key_for_asset(input_asset_key)
+            input_manager_key = job_def.asset_layer.io_manager_key_for_asset(input_asset_key)
 
         if input_manager_key is None:
             check.failed(
                 f"Must have an io_manager associated with asset {input_asset_key} to load it using"
                 " FromSourceAsset"
             )
         return {input_manager_key}
@@ -291,16 +287,16 @@
                 f"Loading for op {step_context.node_handle}.{input_def.name} "
                 f"but source is {self.node_handle}.{self.input_name}."
             ),
         )
 
         input_def = step_context.op_def.input_def_named(input_def.name)
 
-        solid_config = step_context.resolved_run_config.ops.get(str(self.node_handle))
-        config_data = solid_config.inputs.get(self.input_name) if solid_config else None
+        op_config = step_context.resolved_run_config.ops.get(str(self.node_handle))
+        config_data = op_config.inputs.get(self.input_name) if op_config else None
 
         input_manager_key = check.not_none(
             input_def.root_manager_key
             if input_def.root_manager_key
             else input_def.input_manager_key
         )
 
@@ -325,40 +321,40 @@
             manager_key=input_manager_key,
             metadata=metadata,
         )
 
     def compute_version(
         self,
         step_versions: Mapping[str, Optional[str]],
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         resolved_run_config: ResolvedRunConfig,
     ) -> Optional[str]:
         from ..resolve_versions import check_valid_version, resolve_config_version
 
-        solid = pipeline_def.get_node(self.node_handle)
+        node = job_def.get_node(self.node_handle)
         input_manager_key: str = check.not_none(
-            solid.input_def_named(self.input_name).root_manager_key
-            if solid.input_def_named(self.input_name).root_manager_key
-            else solid.input_def_named(self.input_name).input_manager_key
+            node.input_def_named(self.input_name).root_manager_key
+            if node.input_def_named(self.input_name).root_manager_key
+            else node.input_def_named(self.input_name).input_manager_key
         )
-        input_manager_def = pipeline_def.resource_defs[input_manager_key]
+        input_manager_def = job_def.resource_defs[input_manager_key]
 
-        solid_config = resolved_run_config.ops[solid.name]
-        input_config = solid_config.inputs.get(self.input_name)
+        op_config = resolved_run_config.ops[node.name]
+        input_config = op_config.inputs.get(self.input_name)
         resource_config = check.not_none(
             resolved_run_config.resources.get(input_manager_key)
         ).config
 
         version_context = ResourceVersionContext(
             resource_def=input_manager_def,
             resource_config=resource_config,
         )
 
-        if pipeline_def.version_strategy is not None:
-            root_manager_def_version = pipeline_def.version_strategy.get_resource_version(
+        if job_def.version_strategy is not None:
+            root_manager_def_version = job_def.version_strategy.get_resource_version(
                 version_context
             )
         else:
             root_manager_def_version = input_manager_def.version
 
         if root_manager_def_version is None:
             raise DagsterInvariantViolationError(
@@ -370,16 +366,16 @@
         check_valid_version(root_manager_def_version)
         return join_and_hash(
             resolve_config_version(input_config),
             resolve_config_version(resource_config),
             root_manager_def_version,
         )
 
-    def required_resource_keys(self, pipeline_def: JobDefinition) -> Set[str]:
-        input_def = pipeline_def.get_node(self.node_handle).input_def_named(self.input_name)
+    def required_resource_keys(self, job_def: JobDefinition) -> Set[str]:
+        input_def = job_def.get_node(self.node_handle).input_def_named(self.input_name)
 
         input_manager_key: str = check.not_none(
             input_def.root_manager_key
             if input_def.root_manager_key
             else input_def.input_manager_key
         )
 
@@ -437,15 +433,15 @@
         self,
         step_context: "StepExecutionContext",
         input_def: InputDefinition,
         io_manager_key: Optional[str] = None,
     ) -> "InputContext":
         resolved_io_manager_key = (
             step_context.execution_plan.get_manager_key(
-                self.step_output_handle, step_context.pipeline_def
+                self.step_output_handle, step_context.job_def
             )
             if io_manager_key is None
             else io_manager_key
         )
 
         resource_config = step_context.resolved_run_config.resources[resolved_io_manager_key].config
         resources = build_resources_for_manager(resolved_io_manager_key, step_context)
@@ -483,15 +479,15 @@
                     f'the manager "{manager_key}" to load it, but it is not an InputManager. '
                     "Please ensure that the resource returned for resource key "
                     f'"{manager_key}" is an InputManager.'
                 ),
             )
         else:
             manager_key = step_context.execution_plan.get_manager_key(
-                source_handle, step_context.pipeline_def
+                source_handle, step_context.job_def
             )
             input_manager = step_context.get_io_manager(source_handle)
             check.invariant(
                 isinstance(input_manager, IOManager),
                 (
                     f'Input "{input_def.name}" for step "{step_context.step.key}" is depending on '
                     f'the manager of upstream output "{source_handle.output_name}" from step '
@@ -515,28 +511,28 @@
             upstream_step_key=source_handle.step_key,
             metadata=metadata,
         )
 
     def compute_version(
         self,
         step_versions: Mapping[str, Optional[str]],
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         resolved_run_config: ResolvedRunConfig,
     ) -> Optional[str]:
         if (
             self.step_output_handle.step_key not in step_versions
             or not step_versions[self.step_output_handle.step_key]
         ):
             return None
         else:
             return join_and_hash(
                 step_versions[self.step_output_handle.step_key], self.step_output_handle.output_name
             )
 
-    def required_resource_keys(self, _pipeline_def: JobDefinition) -> Set[str]:
+    def required_resource_keys(self, _job_def: JobDefinition) -> Set[str]:
         return set()
 
 
 @whitelist_for_serdes(storage_field_names={"node_handle": "solid_handle"})
 class FromConfig(
     NamedTuple(
         "_FromConfig",
@@ -555,22 +551,22 @@
     def __new__(cls, node_handle: Optional[NodeHandle], input_name: str):
         return super(FromConfig, cls).__new__(
             cls,
             node_handle=node_handle,
             input_name=input_name,
         )
 
-    def get_associated_input_def(self, pipeline_def: JobDefinition) -> InputDefinition:
+    def get_associated_input_def(self, job_def: JobDefinition) -> InputDefinition:
         """Returns the InputDefinition along the potential composition InputMapping chain
         that the config was provided at.
         """
         if self.node_handle:
-            return pipeline_def.get_node(self.node_handle).input_def_named(self.input_name)
+            return job_def.get_node(self.node_handle).input_def_named(self.input_name)
         else:
-            return pipeline_def.graph.input_def_named(self.input_name)
+            return job_def.graph.input_def_named(self.input_name)
 
     def get_associated_config(self, resolved_run_config: ResolvedRunConfig):
         """Returns the config specified, potentially specified at any point along graph composition
         including the root.
         """
         if self.node_handle:
             op_config = resolved_run_config.ops.get(str(self.node_handle))
@@ -585,33 +581,33 @@
         input_def: InputDefinition,
     ) -> Iterator[object]:
         with user_code_error_boundary(
             DagsterTypeLoadingError,
             msg_fn=lambda: f'Error occurred while loading input "{self.input_name}" of step "{step_context.step.key}":',
             log_manager=step_context.log,
         ):
-            dagster_type = self.get_associated_input_def(step_context.pipeline_def).dagster_type
+            dagster_type = self.get_associated_input_def(step_context.job_def).dagster_type
             config_data = self.get_associated_config(step_context.resolved_run_config)
             loader = check.not_none(dagster_type.loader)
             yield loader.construct_from_config_value(
                 step_context.get_type_loader_context(), config_data
             )
 
-    def required_resource_keys(self, pipeline_def: JobDefinition) -> AbstractSet[str]:
-        dagster_type = self.get_associated_input_def(pipeline_def).dagster_type
+    def required_resource_keys(self, job_def: JobDefinition) -> AbstractSet[str]:
+        dagster_type = self.get_associated_input_def(job_def).dagster_type
         return dagster_type.loader.required_resource_keys() if dagster_type.loader else set()
 
     def compute_version(
         self,
         step_versions: Mapping[str, Optional[str]],
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         resolved_run_config: ResolvedRunConfig,
     ) -> Optional[str]:
         config_data = self.get_associated_config(resolved_run_config)
-        input_def = self.get_associated_input_def(pipeline_def)
+        input_def = self.get_associated_input_def(job_def)
         dagster_type = input_def.dagster_type
         loader = check.not_none(dagster_type.loader)
 
         return loader.compute_loaded_input_version(config_data)
 
 
 @whitelist_for_serdes(storage_field_names={"node_handle": "solid_handle"})
@@ -629,24 +625,24 @@
             cls,
             input_name=input_name,
         )
 
     def load_input_object(
         self, step_context: "StepExecutionContext", input_def: InputDefinition
     ) -> Iterator[object]:
-        job_def = step_context.pipeline_def
+        job_def = step_context.job_def
         yield job_def.get_direct_input_value(self.input_name)
 
-    def required_resource_keys(self, _pipeline_def: JobDefinition) -> Set[str]:
+    def required_resource_keys(self, _job_def: JobDefinition) -> Set[str]:
         return set()
 
     def compute_version(
         self,
         step_versions: Mapping[str, Optional[str]],
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         resolved_run_config: ResolvedRunConfig,
     ) -> Optional[str]:
         return str(self.input_name)
 
 
 @whitelist_for_serdes(storage_field_names={"node_handle": "solid_handle"})
 class FromDefaultValue(
@@ -670,23 +666,23 @@
         )
 
     def load_input_object(
         self,
         step_context: "StepExecutionContext",
         input_def: InputDefinition,
     ) -> Iterator[object]:
-        yield self._load_value(step_context.pipeline_def)
+        yield self._load_value(step_context.job_def)
 
     def compute_version(
         self,
         step_versions: Mapping[str, Optional[str]],
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         resolved_run_config: ResolvedRunConfig,
     ) -> Optional[str]:
-        return join_and_hash(repr(self._load_value(pipeline_def)))
+        return join_and_hash(repr(self._load_value(job_def)))
 
 
 @whitelist_for_serdes(storage_field_names={"node_handle": "solid_handle"})
 class FromMultipleSources(
     NamedTuple(
         "_FromMultipleSources",
         [
@@ -768,29 +764,29 @@
                 if isinstance(event_or_input_value, DagsterEvent):
                     yield event_or_input_value
                 else:
                     values.append(event_or_input_value)
 
         yield values
 
-    def required_resource_keys(self, pipeline_def: JobDefinition) -> Set[str]:
+    def required_resource_keys(self, job_def: JobDefinition) -> Set[str]:
         resource_keys: Set[str] = set()
         for source in self.sources:
-            resource_keys = resource_keys.union(source.required_resource_keys(pipeline_def))
+            resource_keys = resource_keys.union(source.required_resource_keys(job_def))
         return resource_keys
 
     def compute_version(
         self,
         step_versions: Mapping[str, Optional[str]],
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         resolved_run_config: ResolvedRunConfig,
     ) -> Optional[str]:
         return join_and_hash(
             *[
-                inner_source.compute_version(step_versions, pipeline_def, resolved_run_config)
+                inner_source.compute_version(step_versions, job_def, resolved_run_config)
                 for inner_source in self.sources
             ]
         )
 
 
 def _load_input_with_input_manager(
     input_manager: "InputManager", context: "InputContext"
@@ -870,15 +866,15 @@
             fan_in=False,
         )
 
     def get_step_output_handle_dep_with_placeholder(self) -> StepOutputHandle:
         # None mapping_key on StepOutputHandle acts as placeholder
         return self.step_output_handle
 
-    def required_resource_keys(self, _pipeline_def: JobDefinition) -> Set[str]:
+    def required_resource_keys(self, _job_def: JobDefinition) -> Set[str]:
         return set()
 
 
 @whitelist_for_serdes(storage_field_names={"node_handle": "solid_handle"})
 class FromUnresolvedStepOutput(
     NamedTuple(
         "_FromUnresolvedStepOutput",
@@ -929,15 +925,15 @@
             step_output_handle=self.unresolved_step_output_handle.resolve(mapping_key),
             fan_in=False,
         )
 
     def get_step_output_handle_dep_with_placeholder(self) -> StepOutputHandle:
         return self.unresolved_step_output_handle.get_step_output_handle_with_placeholder()
 
-    def required_resource_keys(self, _pipeline_def: JobDefinition) -> Set[str]:
+    def required_resource_keys(self, _job_def: JobDefinition) -> Set[str]:
         return set()
 
 
 @whitelist_for_serdes(storage_field_names={"node_handle": "solid_handle"})
 class FromDynamicCollect(
     NamedTuple(
         "_FromDynamicCollect",
@@ -973,15 +969,15 @@
     @property
     def resolved_by_output_name(self) -> str:
         return self.source.resolved_by_output_name
 
     def get_step_output_handle_dep_with_placeholder(self) -> StepOutputHandle:
         return self.source.get_step_output_handle_dep_with_placeholder()
 
-    def required_resource_keys(self, _pipeline_def: JobDefinition) -> Set[str]:
+    def required_resource_keys(self, _job_def: JobDefinition) -> Set[str]:
         return set()
 
     def resolve(self, mapping_keys: Optional[Sequence[str]]):
         if mapping_keys is None:
             # None means that the dynamic output was skipped, so create
             # a dependency on the dynamic output that will continue cascading the skip
             return FromStepOutput(
```

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/local_external_step_main.py` & `dagster-1.3.3/dagster/_core/execution/plan/local_external_step_main.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/objects.py` & `dagster-1.3.3/dagster/_core/execution/plan/objects.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/outputs.py` & `dagster-1.3.3/dagster/_core/execution/plan/outputs.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/plan.py` & `dagster-1.3.3/dagster/_core/execution/plan/plan.py`

 * *Files 4% similar despite different names*

```diff
@@ -15,26 +15,26 @@
     Union,
     cast,
 )
 
 import dagster._check as check
 from dagster._core.definitions import (
     GraphDefinition,
+    IJob,
     InputDefinition,
-    IPipeline,
     Node,
     NodeHandle,
     NodeOutput,
     OpDefinition,
 )
 from dagster._core.definitions.composition import MappedInputPlaceholder
 from dagster._core.definitions.dependency import DependencyStructure
 from dagster._core.definitions.executor_definition import ExecutorRequirement
 from dagster._core.definitions.job_definition import JobDefinition
-from dagster._core.definitions.reconstruct import ReconstructablePipeline
+from dagster._core.definitions.reconstruct import ReconstructableJob
 from dagster._core.definitions.repository_definition import RepositoryLoadData
 from dagster._core.errors import (
     DagsterExecutionStepNotFoundError,
     DagsterInvariantViolationError,
     DagsterUnmetExecutorRequirementsError,
 )
 from dagster._core.execution.plan.handle import (
@@ -96,32 +96,32 @@
 
 
 class _PlanBuilder:
     """This is the state that is built up during the execution plan build process."""
 
     def __init__(
         self,
-        pipeline: IPipeline,
+        job: IJob,
         resolved_run_config: ResolvedRunConfig,
         step_keys_to_execute: Optional[Sequence[str]],
         known_state: KnownExecutionState,
         instance_ref: Optional[InstanceRef],
         tags: Mapping[str, str],
         repository_load_data: Optional[RepositoryLoadData],
     ):
-        if isinstance(pipeline, ReconstructablePipeline) and repository_load_data is not None:
+        if isinstance(job, ReconstructableJob) and repository_load_data is not None:
             check.invariant(
-                pipeline.repository.repository_load_data == repository_load_data,
+                job.repository.repository_load_data == repository_load_data,
                 (
                     "When building an ExecutionPlan with explicit repository_load_data and a"
-                    " ReconstructablePipeline, the repository_load_data on the pipeline must be"
+                    " ReconstructableJob, the repository_load_data on the job must be"
                     " identical to passed-in repository_load_data."
                 ),
             )
-        self.pipeline = check.inst_param(pipeline, "pipeline", IPipeline)
+        self.job = check.inst_param(job, "job", IJob)
         self.resolved_run_config = check.inst_param(
             resolved_run_config, "resolved_run_config", ResolvedRunConfig
         )
         check.opt_nullable_sequence_param(step_keys_to_execute, "step_keys_to_execute", str)
         self.step_keys_to_execute = step_keys_to_execute
         self._steps: Dict[str, IExecutionStep] = {}
         self.step_output_map: Dict[
@@ -132,16 +132,16 @@
         self._seen_handles: Set[StepHandleUnion] = set()
         self._tags = check.mapping_param(tags, "tags", key_type=str, value_type=str)
         self.repository_load_data = check.opt_inst_param(
             repository_load_data, "repository_load_data", RepositoryLoadData
         )
 
     @property
-    def pipeline_name(self) -> str:
-        return self.pipeline.get_definition().name
+    def job_name(self) -> str:
+        return self.job.get_definition().name
 
     def add_step(self, step: IExecutionStep) -> None:
         # Keep track of the step keys we've seen so far to ensure we don't add duplicates
         if step.handle in self._seen_handles:
             keys = list(self._steps.keys())
             check.failed(
                 "Duplicated key {key}. Full list seen so far: {key_list}.".format(
@@ -154,29 +154,29 @@
     def get_step_by_node_handle(self, handle: NodeHandle) -> IExecutionStep:
         check.inst_param(handle, "handle", NodeHandle)
         return self._steps[handle.to_string()]
 
     def build(self) -> "ExecutionPlan":
         """Builds the execution plan."""
         _check_persistent_storage_requirement(
-            self.pipeline,
+            self.job,
             self.resolved_run_config,
         )
 
-        pipeline_def = self.pipeline.get_definition()
+        job_def = self.job.get_definition()
         root_inputs: List[
             Union[StepInput, UnresolvedMappedStepInput, UnresolvedCollectStepInput]
         ] = []
         # Recursively build the execution plan starting at the root pipeline
-        for input_def in pipeline_def.graph.input_defs:
+        for input_def in job_def.graph.input_defs:
             input_name = input_def.name
 
             input_source = get_root_graph_input_source(
                 plan_builder=self,
-                pipeline_def=pipeline_def,
+                job_def=job_def,
                 input_name=input_name,
                 input_def=input_def,
             )
 
             # If an input with dagster_type "Nothing" doesn't have a value
             # we don't create a StepInput
             if input_source is None:
@@ -187,16 +187,16 @@
                     name=input_name,
                     dagster_type_key=input_def.dagster_type.key,
                     source=input_source,
                 )
             )
 
         self._build_from_sorted_nodes(
-            pipeline_def.nodes_in_topological_order,
-            pipeline_def.dependency_structure,
+            job_def.nodes_in_topological_order,
+            job_def.dependency_structure,
             parent_step_inputs=root_inputs,
         )
 
         step_dict = {step.handle: step for step in self._steps.values()}
         step_dict_by_key = {step.key: step for step in self._steps.values()}
         step_handles_to_execute = [step.handle for step in self._steps.values()]
 
@@ -216,62 +216,62 @@
             resolvable_map,
             step_handles_to_execute,
             self.known_state,
             _compute_artifacts_persisted(
                 step_dict,
                 step_dict_by_key,
                 step_handles_to_execute,
-                pipeline_def,
+                job_def,
                 self.resolved_run_config,
                 executable_map,
             ),
             executor_name=executor_name,
             repository_load_data=self.repository_load_data,
         )
 
         if self.step_keys_to_execute is not None:
             plan = plan.build_subset_plan(
-                self.step_keys_to_execute, pipeline_def, self.resolved_run_config
+                self.step_keys_to_execute, job_def, self.resolved_run_config
             )
 
         # Expects that if step_keys_to_execute was set, that the `plan` variable will have the
         # reflected step_keys_to_execute
-        if pipeline_def.is_using_memoization(self._tags) and len(step_output_versions) == 0:
+        if job_def.is_using_memoization(self._tags) and len(step_output_versions) == 0:
             if self._instance_ref is None:
                 raise DagsterInvariantViolationError(
                     "Attempted to build memoized execution plan without providing a persistent "
                     "DagsterInstance to create_execution_plan."
                 )
             instance = DagsterInstance.from_ref(self._instance_ref)
             plan = plan.build_memoized_plan(
-                pipeline_def, self.resolved_run_config, instance, self.step_keys_to_execute
+                job_def, self.resolved_run_config, instance, self.step_keys_to_execute
             )
 
         return plan
 
     def _build_from_sorted_nodes(
         self,
         nodes: Sequence[Node],
         dependency_structure: DependencyStructure,
         parent_handle: Optional[NodeHandle] = None,
         parent_step_inputs: Optional[Sequence[StepInputUnion]] = None,
     ) -> None:
-        asset_layer = self.pipeline.get_definition().asset_layer
+        asset_layer = self.job.get_definition().asset_layer
         step_output_map: Dict[NodeOutput, Union[StepOutputHandle, UnresolvedStepOutputHandle]] = {}
         for node in nodes:
             handle = NodeHandle(node.name, parent_handle)
 
             ### 1. INPUTS
             # Create and add execution plan steps for node inputs
             has_unresolved_input = False
             has_pending_input = False
             step_inputs: List[StepInputUnion] = []
             for input_name, input_def in node.definition.input_dict.items():
                 step_input_source = get_step_input_source(
-                    self.pipeline.get_definition(),
+                    self.job.get_definition(),
                     node,
                     input_name,
                     input_def,
                     dependency_structure,
                     handle,
                     self.resolved_run_config.ops.get(str(handle)),
                     step_output_map,
@@ -327,35 +327,35 @@
 
                 if has_pending_input and has_unresolved_input:
                     check.failed("Can not have pending and unresolved step inputs")
 
                 elif has_unresolved_input:
                     new_step = UnresolvedMappedExecutionStep(
                         handle=UnresolvedStepHandle(node_handle=handle),
-                        pipeline_name=self.pipeline_name,
+                        job_name=self.job_name,
                         step_inputs=cast(
                             List[Union[StepInput, UnresolvedMappedStepInput]], step_inputs
                         ),
                         step_outputs=step_outputs,
                         tags=node.tags,
                     )
                 elif has_pending_input:
                     new_step = UnresolvedCollectExecutionStep(
                         handle=StepHandle(node_handle=handle),
-                        pipeline_name=self.pipeline_name,
+                        job_name=self.job_name,
                         step_inputs=cast(
                             List[Union[StepInput, UnresolvedCollectStepInput]], step_inputs
                         ),
                         step_outputs=step_outputs,
                         tags=node.tags,
                     )
                 else:
                     new_step = ExecutionStep(
                         handle=StepHandle(node_handle=handle),
-                        pipeline_name=self.pipeline_name,
+                        job_name=self.job_name,
                         step_inputs=cast(List[StepInput], step_inputs),
                         step_outputs=step_outputs,
                         tags=node.tags,
                     )
 
                 self.add_step(new_step)
 
@@ -368,16 +368,17 @@
                     parent_handle=handle,
                     parent_step_inputs=step_inputs,
                 )
 
             else:
                 check.invariant(
                     False,
-                    "Unexpected solid type {type} encountered during execution planning".format(
-                        type=type(node.definition)
+                    (
+                        f"Unexpected node type {type(node.definition)} encountered during execution"
+                        " planning"
                     ),
                 )
 
             ### 3. OUTPUTS
             # Create output handles for node outputs
             for name, output_def in node.definition.output_dict.items():
                 node_output = node.get_output(name)
@@ -405,17 +406,17 @@
                 step_output_map[node_output] = step_output_handle
 
 
 def get_root_graph_input_source(
     plan_builder: _PlanBuilder,
     input_name: str,
     input_def: InputDefinition,
-    pipeline_def: JobDefinition,
+    job_def: JobDefinition,
 ) -> Optional[Union[FromConfig, FromDirectInputValue]]:
-    input_values = pipeline_def.input_values
+    input_values = job_def.input_values
     if input_values and input_name in input_values:
         return FromDirectInputValue(input_name=input_name)
 
     input_config = plan_builder.resolved_run_config.inputs
 
     if input_config and input_name in input_config:
         return FromConfig(input_name=input_name, node_handle=None)
@@ -425,15 +426,15 @@
 
     # Otherwise we throw an error.
     raise DagsterInvariantViolationError(
         (
             "In top-level graph of {described_target}, input {input_name} "
             "must get a value from the inputs section of its configuration."
         ).format(
-            described_target=plan_builder.pipeline.get_definition().describe_target(),
+            described_target=plan_builder.job.get_definition().describe_target(),
             input_name=input_name,
         )
     )
 
 
 def get_step_input_source(
     job_def: JobDefinition,
@@ -550,15 +551,15 @@
             return parent_input.source
         # else fall through to Nothing case or raise
 
     if node.definition.input_has_default(input_name):
         return FromDefaultValue(node_handle=handle, input_name=input_name)
 
     # At this point we have an input that is not hooked up to
-    # the output of another solid or provided via run config.
+    # the output of another op or provided via run config.
 
     # We will allow this for "Nothing" type inputs and continue.
     if input_def.dagster_type.is_nothing:
         return None
 
     # Otherwise we throw an error.
     raise DagsterInvariantViolationError(
@@ -661,17 +662,17 @@
     def get_step_output(self, step_output_handle: StepOutputHandle) -> StepOutput:
         check.inst_param(step_output_handle, "step_output_handle", StepOutputHandle)
         return _get_step_output(self.step_dict_by_key, step_output_handle)
 
     def get_manager_key(
         self,
         step_output_handle: StepOutputHandle,
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
     ) -> str:
-        return _get_manager_key(self.step_dict_by_key, step_output_handle, pipeline_def)
+        return _get_manager_key(self.step_dict_by_key, step_output_handle, job_def)
 
     def has_step(self, handle: StepHandleUnion) -> bool:
         check.inst_param(handle, "handle", StepHandleTypes)
         return handle in self.step_dict
 
     def get_step(self, handle: StepHandleUnion) -> IExecutionStep:
         check.inst_param(handle, "handle", StepHandleTypes)
@@ -740,15 +741,15 @@
         after = self.get_executable_step_deps()
 
         return {key: deps for key, deps in after.items() if key not in previous}
 
     def build_subset_plan(
         self,
         step_keys_to_execute: Sequence[str],
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         resolved_run_config: ResolvedRunConfig,
         step_output_versions: Optional[Mapping[StepOutputHandle, Optional[str]]] = None,
     ) -> "ExecutionPlan":
         check.sequence_param(step_keys_to_execute, "step_keys_to_execute", of_type=str)
         step_output_versions = check.opt_mapping_param(
             step_output_versions, "step_output_versions", key_type=StepOutputHandle, value_type=str
         )
@@ -819,72 +820,72 @@
             resolvable_map,
             step_handles_to_execute,
             known_state,
             _compute_artifacts_persisted(
                 self.step_dict,
                 self.step_dict_by_key,
                 step_handles_to_execute,
-                pipeline_def,
+                job_def,
                 resolved_run_config,
                 executable_map,
             ),
             executor_name=self.executor_name,
             repository_load_data=self.repository_load_data,
         )
 
     def get_version_for_step_output_handle(
         self, step_output_handle: StepOutputHandle
     ) -> Optional[str]:
         return self.step_output_versions.get(step_output_handle)
 
     def build_memoized_plan(
         self,
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         resolved_run_config: ResolvedRunConfig,
         instance: DagsterInstance,
         selected_step_keys: Optional[Sequence[str]],
     ) -> "ExecutionPlan":
         """Returns:
         ExecutionPlan: Execution plan that runs only unmemoized steps.
         """
         from ...storage.memoizable_io_manager import MemoizableIOManager
         from ..build_resources import build_resources, initialize_console_manager
         from ..resources_init import get_dependencies, resolve_resource_dependencies
 
         # Memoization cannot be used with dynamic orchestration yet.
         # Tracking: https://github.com/dagster-io/dagster/issues/4451
-        for node_def in pipeline_def.all_node_defs:
-            if pipeline_def.dependency_structure.is_dynamic_mapped(
+        for node_def in job_def.all_node_defs:
+            if job_def.dependency_structure.is_dynamic_mapped(
                 node_def.name
-            ) or pipeline_def.dependency_structure.has_dynamic_downstreams(node_def.name):
+            ) or job_def.dependency_structure.has_dynamic_downstreams(node_def.name):
                 raise DagsterInvariantViolationError(
                     "Attempted to use memoization with dynamic orchestration, which is not yet "
                     "supported."
                 )
 
         unmemoized_step_keys = set()
 
         log_manager = initialize_console_manager(None)
 
-        step_output_versions = resolve_step_output_versions(pipeline_def, self, resolved_run_config)
+        step_output_versions = resolve_step_output_versions(job_def, self, resolved_run_config)
 
         resource_defs_to_init = {}
         io_manager_keys = {}  # Map step output handles to io manager keys
 
         for step in self.steps:
             for output_name in cast(ExecutionStepUnion, step).step_output_dict.keys():
                 step_output_handle = StepOutputHandle(step.key, output_name)
 
-                io_manager_key = self.get_manager_key(step_output_handle, pipeline_def)
+                io_manager_key = self.get_manager_key(step_output_handle, job_def)
                 io_manager_keys[step_output_handle] = io_manager_key
 
-                resource_deps = resolve_resource_dependencies(pipeline_def.resource_defs)
+                resource_deps = resolve_resource_dependencies(job_def.resource_defs)
                 resource_keys_to_init = get_dependencies(io_manager_key, resource_deps)
                 for resource_key in resource_keys_to_init:
-                    resource_defs_to_init[resource_key] = pipeline_def.resource_defs[resource_key]
+                    resource_defs_to_init[resource_key] = job_def.resource_defs[resource_key]
 
         all_resources_config = resolved_run_config.to_dict().get("resources", {})
         resource_config = {
             resource_key: config_val
             for resource_key, config_val in all_resources_config.items()
             if resource_key in resource_defs_to_init
         }
@@ -895,24 +896,24 @@
             resource_config=resource_config,
             log_manager=log_manager,
         ) as resources:
             for step_output_handle, io_manager_key in io_manager_keys.items():
                 io_manager = getattr(resources, io_manager_key)
                 if not isinstance(io_manager, MemoizableIOManager):
                     raise DagsterInvariantViolationError(
-                        f"{pipeline_def.describe_target().capitalize()} uses memoization, but IO"
+                        f"{job_def.describe_target().capitalize()} uses memoization, but IO"
                         " manager "
                         f"'{io_manager_key}' is not a MemoizableIOManager. In order to use "
                         "memoization, all io managers need to subclass MemoizableIOManager. "
                         "Learn more about MemoizableIOManagers here: "
                         "https://docs.dagster.io/_apidocs/internals#memoizable-io-manager-experimental."
                     )
                 context = get_output_context(
                     execution_plan=self,
-                    pipeline_def=pipeline_def,
+                    job_def=job_def,
                     resolved_run_config=resolved_run_config,
                     step_output_handle=step_output_handle,
                     run_id=None,
                     log_manager=log_manager,
                     step_context=None,
                     resources=resources,
                     version=step_output_versions[step_output_handle],
@@ -923,15 +924,15 @@
         if selected_step_keys is not None:
             # Take the intersection unmemoized steps and selected steps
             step_keys_to_execute = list(unmemoized_step_keys & set(selected_step_keys))
         else:
             step_keys_to_execute = list(unmemoized_step_keys)
         return self.build_subset_plan(
             step_keys_to_execute,
-            pipeline_def,
+            job_def,
             resolved_run_config,
             step_output_versions=step_output_versions,
         )
 
     def start(
         self,
         retry_mode: RetryMode,
@@ -964,31 +965,31 @@
 
             return cast(ExecutionStep, only_step).handle
 
         return None
 
     @staticmethod
     def build(
-        pipeline: IPipeline,
+        job: IJob,
         resolved_run_config: ResolvedRunConfig,
         step_keys_to_execute: Optional[Sequence[str]] = None,
         known_state: Optional[KnownExecutionState] = None,
         instance_ref: Optional[InstanceRef] = None,
         tags: Optional[Mapping[str, str]] = None,
         repository_load_data: Optional[RepositoryLoadData] = None,
     ) -> "ExecutionPlan":
-        """Here we build a new ExecutionPlan from a pipeline definition and the resolved run config.
+        """Here we build a new ExecutionPlan from a job definition and the resolved run config.
 
-        To do this, we iterate through the pipeline's nodes in topological order, and hand off the
+        To do this, we iterate through the job's nodes in topological order, and hand off the
         execution steps for each node to a companion _PlanBuilder object.
 
-        Once we've processed the entire pipeline, we invoke _PlanBuilder.build() to construct the
+        Once we've processed the entire job, we invoke _PlanBuilder.build() to construct the
         ExecutionPlan object.
         """
-        check.inst_param(pipeline, "pipeline", IPipeline)
+        check.inst_param(job, "job", IJob)
         check.inst_param(resolved_run_config, "resolved_run_config", ResolvedRunConfig)
         check.opt_nullable_sequence_param(step_keys_to_execute, "step_keys_to_execute", of_type=str)
         known_state = check.opt_inst_param(
             known_state,
             "known_state",
             KnownExecutionState,
             # may be good to force call sites to specify instead of defaulting to unknown
@@ -996,15 +997,15 @@
         )
         tags = check.opt_mapping_param(tags, "tags", key_type=str, value_type=str)
         repository_load_data = check.opt_inst_param(
             repository_load_data, "repository_load_data", RepositoryLoadData
         )
 
         plan_builder = _PlanBuilder(
-            pipeline,
+            job,
             resolved_run_config=resolved_run_config,
             step_keys_to_execute=step_keys_to_execute,
             known_state=known_state,
             instance_ref=instance_ref,
             tags=tags,
             repository_load_data=repository_load_data,
         )
@@ -1043,15 +1044,15 @@
                 step_input_snap.name,
                 step_input_snap.dagster_type_key,
                 step_input_snap.source,  # type: ignore  # (possible none)
             )
 
     @staticmethod
     def rebuild_from_snapshot(
-        pipeline_name: str,
+        job_name: str,
         execution_plan_snapshot: "ExecutionPlanSnapshot",
     ) -> "ExecutionPlan":
         if not execution_plan_snapshot.can_reconstruct_plan:
             raise DagsterInvariantViolationError(
                 "Tried to reconstruct an old ExecutionPlanSnapshot that was created before"
                 " snapshots had enough information to fully reconstruct the ExecutionPlan"
             )
@@ -1082,34 +1083,34 @@
                     check.inst(
                         cast(
                             Union[StepHandle, ResolvedFromDynamicStepHandle],
                             step_snap.step_handle,
                         ),
                         ttype=(StepHandle, ResolvedFromDynamicStepHandle),
                     ),
-                    pipeline_name,
+                    job_name,
                     step_inputs,  # type: ignore  # (plain StepInput only)
                     step_outputs,
                     step_snap.tags,
                 )
             elif step_snap.kind == StepKind.UNRESOLVED_MAPPED:
                 step = UnresolvedMappedExecutionStep(
                     check.inst(
                         cast(UnresolvedStepHandle, step_snap.step_handle),
                         ttype=UnresolvedStepHandle,
                     ),
-                    pipeline_name,
+                    job_name,
                     step_inputs,  # type: ignore  # (StepInput or UnresolvedMappedStepInput only)
                     step_outputs,
                     step_snap.tags,
                 )
             elif step_snap.kind == StepKind.UNRESOLVED_COLLECT:
                 step = UnresolvedCollectExecutionStep(
                     check.inst(cast(StepHandle, step_snap.step_handle), ttype=StepHandle),
-                    pipeline_name,
+                    job_name,
                     step_inputs,  # type: ignore  # (StepInput or UnresolvedCollectStepInput only)
                     step_outputs,
                     step_snap.tags,
                 )
             else:
                 raise Exception(f"Unexpected step kind {str(step_snap.kind)}")
 
@@ -1176,44 +1177,44 @@
         executable_map[step.key] = step.handle
         step_dict_by_key[step.key] = step
 
     for key_set in key_sets_to_clear:
         del resolvable_map[key_set]
 
 
-def can_isolate_steps(pipeline_def: JobDefinition) -> bool:
+def can_isolate_steps(job_def: JobDefinition) -> bool:
     """Returns true if every output definition in the pipeline uses an IO manager that's not
     the mem_io_manager.
 
     If true, this indicates that it's OK to execute steps in their own processes, because their
     outputs will be available to other processes.
     """
     output_defs = [
-        output_def for node_def in pipeline_def.all_node_defs for output_def in node_def.output_defs
+        output_def for node_def in job_def.all_node_defs for output_def in node_def.output_defs
     ]
     for output_def in output_defs:
-        if pipeline_def.resource_defs[output_def.io_manager_key] == mem_io_manager:
+        if job_def.resource_defs[output_def.io_manager_key] == mem_io_manager:
             return False
 
     return True
 
 
 def _check_persistent_storage_requirement(
-    pipeline: IPipeline,
+    pipeline: IJob,
     resolved_run_config: ResolvedRunConfig,
 ) -> None:
-    pipeline_def = pipeline.get_definition()
-    executor_def = pipeline_def.executor_def
+    job_def = pipeline.get_definition()
+    executor_def = job_def.executor_def
     requirements_lst = executor_def.get_requirements(
         resolved_run_config.execution.execution_engine_config
     )
     if ExecutorRequirement.PERSISTENT_OUTPUTS not in requirements_lst:
         return
 
-    if not can_isolate_steps(pipeline_def):
+    if not can_isolate_steps(job_def):
         raise DagsterUnmetExecutorRequirementsError(
             "You have attempted to use an executor that uses multiple processes, but your"
             " job includes op outputs that will not be stored somewhere where other"
             " processes can retrieve them. Please use a persistent IO manager for these outputs."
             ' E.g. with\n   the_graph.to_job(resource_defs={"io_manager": fs_io_manager})'
         )
```

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/state.py` & `dagster-1.3.3/dagster/_core/execution/plan/state.py`

 * *Files 0% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 from dagster._core.errors import DagsterExecutionPlanSnapshotNotFoundError, DagsterRunNotFoundError
 from dagster._core.events import DagsterEventType
 from dagster._core.execution.plan.handle import StepHandle, UnresolvedStepHandle
 from dagster._core.execution.plan.outputs import StepOutputHandle
 from dagster._core.execution.plan.step import ResolvedFromDynamicStepHandle
 from dagster._core.execution.retries import RetryState
 from dagster._core.instance import DagsterInstance
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._serdes import whitelist_for_serdes
 
 if TYPE_CHECKING:
     from dagster._core.execution.plan.plan import StepHandleUnion
 
 
 @whitelist_for_serdes
```

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/step.py` & `dagster-1.3.3/dagster/_core/execution/plan/step.py`

 * *Files 4% similar despite different names*

```diff
@@ -116,67 +116,67 @@
 
 
 class ExecutionStep(
     NamedTuple(
         "_ExecutionStep",
         [
             ("handle", Union[StepHandle, ResolvedFromDynamicStepHandle]),
-            ("pipeline_name", str),
+            ("job_name", str),
             ("step_input_dict", Mapping[str, StepInput]),
             ("step_output_dict", Mapping[str, StepOutput]),
             ("tags", Mapping[str, str]),
             ("logging_tags", Mapping[str, str]),
             ("key", str),
         ],
     ),
     IExecutionStep,
 ):
     """A fully resolved step in the execution graph."""
 
     def __new__(
         cls,
         handle: Union[StepHandle, ResolvedFromDynamicStepHandle],
-        pipeline_name: str,
+        job_name: str,
         step_inputs: Sequence[StepInput],
         step_outputs: Sequence[StepOutput],
         tags: Optional[Mapping[str, str]],
         logging_tags: Optional[Mapping[str, str]] = None,
         key: Optional[str] = None,
     ):
         return super(ExecutionStep, cls).__new__(
             cls,
             handle=check.inst_param(handle, "handle", (StepHandle, ResolvedFromDynamicStepHandle)),
-            pipeline_name=check.str_param(pipeline_name, "pipeline_name"),
+            job_name=check.str_param(job_name, "job_name"),
             step_input_dict={
                 si.name: si
                 for si in check.sequence_param(step_inputs, "step_inputs", of_type=StepInput)
             },
             step_output_dict={
                 so.name: so
                 for so in check.sequence_param(step_outputs, "step_outputs", of_type=StepOutput)
             },
             tags=validate_tags(check.opt_mapping_param(tags, "tags", key_type=str)),
             logging_tags=merge_dicts(
                 {
                     "step_key": handle.to_key(),
-                    "pipeline_name": pipeline_name,
-                    "solid_name": handle.node_handle.name,
+                    "job_name": job_name,
+                    "op_name": handle.node_handle.name,
                 },
                 check.opt_mapping_param(logging_tags, "logging_tags"),
             ),
             # mypy can't tell that if default is set, this is guaranteed to be a str
             key=cast(str, check.opt_str_param(key, "key", default=handle.to_key())),
         )
 
     @property
     def node_handle(self) -> "NodeHandle":
         return self.handle.node_handle
 
     @property
-    def solid_name(self) -> str:
+    def op_name(self) -> str:
         return self.node_handle.name
 
     @property
     def kind(self) -> StepKind:
         return StepKind.COMPUTE
 
     @property
@@ -217,37 +217,37 @@
 
 
 class UnresolvedMappedExecutionStep(
     NamedTuple(
         "_UnresolvedMappedExecutionStep",
         [
             ("handle", UnresolvedStepHandle),
-            ("pipeline_name", str),
+            ("job_name", str),
             ("step_input_dict", Mapping[str, Union[StepInput, UnresolvedMappedStepInput]]),
             ("step_output_dict", Mapping[str, StepOutput]),
             ("tags", Mapping[str, str]),
         ],
     ),
     IExecutionStep,
 ):
     """A placeholder step that will become N ExecutionSteps once the upstream dynamic output resolves in to N mapping keys.
     """
 
     def __new__(
         cls,
         handle: UnresolvedStepHandle,
-        pipeline_name: str,
+        job_name: str,
         step_inputs: Sequence[Union[StepInput, UnresolvedMappedStepInput]],
         step_outputs: Sequence[StepOutput],
         tags: Optional[Mapping[str, str]],
     ):
         return super(UnresolvedMappedExecutionStep, cls).__new__(
             cls,
             handle=check.inst_param(handle, "handle", UnresolvedStepHandle),
-            pipeline_name=check.str_param(pipeline_name, "pipeline_name"),
+            job_name=check.str_param(job_name, "job_name"),
             step_input_dict={
                 si.name: si
                 for si in check.sequence_param(
                     step_inputs, "step_inputs", of_type=(StepInput, UnresolvedMappedStepInput)
                 )
             },
             step_output_dict={
@@ -351,15 +351,15 @@
 
         for mapped_key in mapping_keys:
             resolved_inputs = [_resolved_input(inp, mapped_key) for inp in self.step_inputs]
 
             execution_steps.append(
                 ExecutionStep(
                     handle=ResolvedFromDynamicStepHandle(self.handle.node_handle, mapped_key),
-                    pipeline_name=self.pipeline_name,
+                    job_name=self.job_name,
                     step_inputs=resolved_inputs,
                     step_outputs=self.step_outputs,
                     tags=self.tags,
                 )
             )
 
         return execution_steps
@@ -376,37 +376,37 @@
 
 
 class UnresolvedCollectExecutionStep(
     NamedTuple(
         "_UnresolvedCollectExecutionStep",
         [
             ("handle", StepHandle),
-            ("pipeline_name", str),
+            ("job_name", str),
             ("step_input_dict", Mapping[str, Union[StepInput, UnresolvedCollectStepInput]]),
             ("step_output_dict", Mapping[str, StepOutput]),
             ("tags", Mapping[str, str]),
         ],
     ),
     IExecutionStep,
 ):
     """A placeholder step that will become 1 ExecutionStep that collects over a dynamic output or downstream from one once it resolves.
     """
 
     def __new__(
         cls,
         handle: StepHandle,
-        pipeline_name: str,
+        job_name: str,
         step_inputs: Sequence[Union[StepInput, UnresolvedCollectStepInput]],
         step_outputs: Sequence[StepOutput],
         tags: Optional[Mapping[str, str]],
     ):
         return super(UnresolvedCollectExecutionStep, cls).__new__(
             cls,
             handle=check.inst_param(handle, "handle", StepHandle),
-            pipeline_name=check.str_param(pipeline_name, "pipeline_name"),
+            job_name=check.str_param(job_name, "job_name"),
             step_input_dict={
                 si.name: si
                 for si in check.sequence_param(
                     step_inputs, "step_inputs", of_type=(StepInput, UnresolvedCollectStepInput)
                 )
             },
             step_output_dict={
@@ -487,12 +487,12 @@
             else:
                 resolved_inputs.append(
                     inp.resolve(mappings[inp.resolved_by_step_key][inp.resolved_by_output_name])
                 )
 
         return ExecutionStep(
             handle=self.handle,
-            pipeline_name=self.pipeline_name,
+            job_name=self.job_name,
             step_inputs=resolved_inputs,
             step_outputs=self.step_outputs,
             tags=self.tags,
         )
```

### Comparing `dagster-1.3.2/dagster/_core/execution/plan/utils.py` & `dagster-1.3.3/dagster/_core/execution/plan/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -44,15 +44,15 @@
 
     check.callable_param(msg_fn, "msg_fn")
     check.class_param(error_cls, "error_cls", superclass=DagsterUserCodeExecutionError)
     check.inst_param(step_context, "step_context", StepExecutionContext)
 
     with raise_execution_interrupts():
         step_context.log.begin_python_log_capture()
-        retry_policy = step_context.solid_retry_policy
+        retry_policy = step_context.op_retry_policy
 
         try:
             yield
         except DagsterError as de:
             # The system has thrown an error that is part of the user-framework contract
             raise de
```

### Comparing `dagster-1.3.2/dagster/_core/execution/poll_compute_logs.py` & `dagster-1.3.3/dagster/_core/execution/poll_compute_logs.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/execution/resolve_versions.py` & `dagster-1.3.3/dagster/_core/execution/resolve_versions.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/execution/resources_init.py` & `dagster-1.3.3/dagster/_core/execution/resources_init.py`

 * *Files 4% similar despite different names*

```diff
@@ -34,15 +34,15 @@
     UnresolvedCollectStepInput,
     UnresolvedMappedStepInput,
 )
 from dagster._core.execution.plan.plan import ExecutionPlan, StepHandleUnion
 from dagster._core.execution.plan.step import ExecutionStep, IExecutionStep
 from dagster._core.instance import DagsterInstance
 from dagster._core.log_manager import DagsterLogManager
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._core.system_config.objects import ResolvedRunConfig, ResourceConfig
 from dagster._core.utils import toposort
 from dagster._utils import EventGenerationManager, ensure_gen
 from dagster._utils.error import serializable_error_info_from_exc_info
 from dagster._utils.timing import format_duration, time_execution_scope
 
 from .context.init import InitResourceContext
@@ -132,32 +132,32 @@
     resource_managers: Deque[EventGenerationManager],
     execution_plan: Optional[ExecutionPlan],
     dagster_run: Optional[DagsterRun],
     resource_keys_to_init: Optional[AbstractSet[str]],
     instance: Optional[DagsterInstance],
     emit_persistent_events: Optional[bool],
 ):
-    pipeline_name = ""  # Must be initialized to a string to satisfy typechecker
+    job_name = ""  # Must be initialized to a string to satisfy typechecker
     contains_generator = False
     if emit_persistent_events:
         check.invariant(
             dagster_run and execution_plan,
             (
                 "If emit_persistent_events is enabled, then dagster_run and execution_plan must be"
                 " provided"
             ),
         )
-        pipeline_name = cast(DagsterRun, dagster_run).pipeline_name
+        job_name = cast(DagsterRun, dagster_run).job_name
     resource_keys_to_init = check.opt_set_param(resource_keys_to_init, "resource_keys_to_init")
     resource_instances: Dict[str, "InitializedResource"] = {}
     resource_init_times = {}
     try:
         if emit_persistent_events and resource_keys_to_init:
             yield DagsterEvent.resource_init_start(
-                pipeline_name,
+                job_name,
                 cast(ExecutionPlan, execution_plan),
                 resource_log_manager,
                 resource_keys_to_init,
             )
 
         resource_dependencies = resolve_resource_dependencies(resource_defs)
         for level in toposort(resource_dependencies):
@@ -192,15 +192,15 @@
                 resource_instances[resource_name] = initialized_resource.resource
                 resource_init_times[resource_name] = initialized_resource.duration
                 contains_generator = contains_generator or initialized_resource.is_generator
                 resource_managers.append(manager)
 
         if emit_persistent_events and resource_keys_to_init:
             yield DagsterEvent.resource_init_success(
-                pipeline_name,
+                job_name,
                 cast(ExecutionPlan, execution_plan),
                 resource_log_manager,
                 resource_instances,
                 resource_init_times,
             )
 
         delta_res_keys = resource_keys_to_init - set(resource_instances.keys())
@@ -210,15 +210,15 @@
         )
         yield ScopedResourcesBuilder(resource_instances, contains_generator)
     except DagsterUserCodeExecutionError as dagster_user_error:
         # Can only end up in this state if we attempt to initialize a resource, so
         # resource_keys_to_init cannot be empty
         if emit_persistent_events:
             yield DagsterEvent.resource_init_failure(
-                pipeline_name,
+                job_name,
                 cast(ExecutionPlan, execution_plan),
                 resource_log_manager,
                 resource_keys_to_init,
                 serializable_error_info_from_exc_info(dagster_user_error.original_exc_info),
             )
         raise dagster_user_error
 
@@ -279,15 +279,15 @@
                 manager = resource_managers.pop()
                 try:
                     yield from manager.generate_teardown_events()
                 except DagsterUserCodeExecutionError as dagster_user_error:
                     error = dagster_user_error
             if error and emit_persistent_events:
                 yield DagsterEvent.resource_teardown_failure(
-                    cast(DagsterRun, dagster_run).pipeline_name,
+                    cast(DagsterRun, dagster_run).job_name,
                     cast(ExecutionPlan, execution_plan),
                     resource_log_manager,
                     resource_keys_to_init,
                     serializable_error_info_from_exc_info(error.original_exc_info),
                 )
 
 
@@ -394,51 +394,51 @@
             set(get_dependencies(resource_key, resource_dependencies))
         )
 
     return transitive_required_resource_keys
 
 
 def get_required_resource_keys_for_step(
-    pipeline_def: JobDefinition, execution_step: IExecutionStep, execution_plan: ExecutionPlan
+    job_def: JobDefinition, execution_step: IExecutionStep, execution_plan: ExecutionPlan
 ) -> AbstractSet[str]:
     resource_keys: Set[str] = set()
 
-    # add all the solid compute resource keys
-    solid_def = pipeline_def.get_node(execution_step.node_handle).definition
-    resource_keys = resource_keys.union(solid_def.required_resource_keys)  # type: ignore  # (should be OpDefinition)
+    # add all the op compute resource keys
+    node_def = job_def.get_node(execution_step.node_handle).definition
+    resource_keys = resource_keys.union(node_def.required_resource_keys)  # type: ignore  # (should be OpDefinition)
 
     # add input type, input loader, and input io manager resource keys
     for step_input in execution_step.step_inputs:
-        input_def = solid_def.input_def_named(step_input.name)
+        input_def = node_def.input_def_named(step_input.name)
 
         resource_keys = resource_keys.union(input_def.dagster_type.required_resource_keys)
 
-        resource_keys = resource_keys.union(step_input.source.required_resource_keys(pipeline_def))
+        resource_keys = resource_keys.union(step_input.source.required_resource_keys(job_def))
 
         if input_def.input_manager_key:
             resource_keys = resource_keys.union([input_def.input_manager_key])
 
         if isinstance(step_input, StepInput):
             source_handles = step_input.get_step_output_handle_dependencies()
         elif isinstance(step_input, (UnresolvedMappedStepInput, UnresolvedCollectStepInput)):
             # Placeholder handles will allow lookup of the unresolved execution steps
             # for what resources will be needed once the steps resolve
             source_handles = step_input.get_step_output_handle_deps_with_placeholders()
         else:
             check.failed(f"Unexpected step input type {step_input}")
 
         for source_handle in source_handles:
-            source_manager_key = execution_plan.get_manager_key(source_handle, pipeline_def)
+            source_manager_key = execution_plan.get_manager_key(source_handle, job_def)
             if source_manager_key:
                 resource_keys = resource_keys.union([source_manager_key])
 
     # add output type and output io manager resource keys
     for step_output in execution_step.step_outputs:
         # Load the output type
-        output_def = solid_def.output_def_named(step_output.name)
+        output_def = node_def.output_def_named(step_output.name)
 
         resource_keys = resource_keys.union(output_def.dagster_type.required_resource_keys)
         if output_def.io_manager_key:
             resource_keys = resource_keys.union([output_def.io_manager_key])
 
     return frozenset(resource_keys)
```

### Comparing `dagster-1.3.2/dagster/_core/execution/results.py` & `dagster-1.3.3/dagster/_core/execution/results.py`

 * *Files 2% similar despite different names*

```diff
@@ -51,25 +51,25 @@
 
 class GraphExecutionResult:
     def __init__(
         self,
         container: GraphDefinition,
         event_list: Sequence[DagsterEvent],
         reconstruct_context: ReconstructContextFn,
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         handle: Optional[NodeHandle] = None,
         output_capture: Optional[Dict[StepOutputHandle, object]] = None,
     ):
         self.container = check.inst_param(container, "container", GraphDefinition)
         self.event_list = check.sequence_param(event_list, "step_event_list", of_type=DagsterEvent)
         self.reconstruct_context = check.callable_param(
             reconstruct_context,
             "reconstruct_context",
         )
-        self.pipeline_def = check.inst_param(pipeline_def, "pipeline_def", JobDefinition)
+        self.job_def = check.inst_param(job_def, "job_def", JobDefinition)
         self.handle = check.opt_inst_param(handle, "handle", NodeHandle)
         self.output_capture = check.opt_dict_param(
             output_capture, "output_capture", key_type=StepOutputHandle
         )
         self._events_by_step_key = _construct_events_by_step_key(event_list)
 
     @property
@@ -151,30 +151,30 @@
                         events.append(event)
 
             return CompositeSolidExecutionResult(
                 node,
                 events,
                 events_by_kind,
                 self.reconstruct_context,
-                self.pipeline_def,
+                self.job_def,
                 handle=handle.with_ancestor(self.handle),
                 output_capture=self.output_capture,
             )
         elif isinstance(node, OpNode):
             for event in self.event_list:
                 if event.is_step_event:
                     event_node_handle = check.not_none(event.node_handle)
                     if event_node_handle.is_or_descends_from(handle.with_ancestor(self.handle)):
                         events_by_kind[event.step_kind].append(event)
 
             return OpExecutionResult(
                 node,
                 events_by_kind,
                 self.reconstruct_context,
-                self.pipeline_def,
+                self.job_def,
                 output_capture=self.output_capture,
             )
         else:
             check.failed("Unexpected node type.")
 
     def result_for_handle(
         self, handle: Union[str, NodeHandle]
@@ -205,28 +205,28 @@
     """The result of executing a pipeline.
 
     Returned by :py:func:`execute_pipeline`. Users should not instantiate this class directly.
     """
 
     def __init__(
         self,
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         run_id: str,
         event_list: Sequence[DagsterEvent],
         reconstruct_context: ReconstructContextFn,
         output_capture: Optional[Dict[StepOutputHandle, object]] = None,
     ):
         self.run_id = check.str_param(run_id, "run_id")
-        check.inst_param(pipeline_def, "pipeline_def", JobDefinition)
+        check.inst_param(job_def, "job_def", JobDefinition)
 
         super(PipelineExecutionResult, self).__init__(
-            container=pipeline_def.graph,
+            container=job_def.graph,
             event_list=event_list,
             reconstruct_context=reconstruct_context,
-            pipeline_def=pipeline_def,
+            job_def=job_def,
             output_capture=output_capture,
         )
 
 
 class CompositeSolidExecutionResult(GraphExecutionResult):
     """Execution result for a composite solid in a pipeline.
 
@@ -235,15 +235,15 @@
 
     def __init__(
         self,
         node: GraphNode,
         event_list: Sequence[DagsterEvent],
         step_events_by_kind: Mapping[StepKind, Sequence[DagsterEvent]],
         reconstruct_context: ReconstructContextFn,
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         handle: Optional[NodeHandle] = None,
         output_capture: Optional[Dict[StepOutputHandle, object]] = None,
     ):
         check.inst_param(node, "node", GraphNode)
         self.node = node
         self.step_events_by_kind = check.dict_param(
             step_events_by_kind, "step_events_by_kind", key_type=StepKind, value_type=list
@@ -251,15 +251,15 @@
         self.output_capture = check.opt_dict_param(
             output_capture, "output_capture", key_type=StepOutputHandle
         )
         super(CompositeSolidExecutionResult, self).__init__(
             container=node.definition,
             event_list=event_list,
             reconstruct_context=reconstruct_context,
-            pipeline_def=pipeline_def,
+            job_def=job_def,
             handle=handle,
             output_capture=output_capture,
         )
 
     def output_values_for_solid(self, name: str) -> Optional[Mapping[str, object]]:
         check.str_param(name, "name")
         return self.result_for_node(name).output_values
@@ -332,28 +332,28 @@
     """
 
     def __init__(
         self,
         node: OpNode,
         step_events_by_kind: Mapping[StepKind, Sequence[DagsterEvent]],
         reconstruct_context: ReconstructContextFn,
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         output_capture: Optional[Dict[StepOutputHandle, object]] = None,
     ):
         check.inst_param(node, "node", OpNode)
         self.node = node
         self.step_events_by_kind = check.dict_param(
             step_events_by_kind, "step_events_by_kind", key_type=StepKind, value_type=list
         )
         self.reconstruct_context = check.callable_param(
             reconstruct_context,
             "reconstruct_context",
         )
         self.output_capture = check.opt_dict_param(output_capture, "output_capture")
-        self.pipeline_def = check.inst_param(pipeline_def, "pipeline_def", JobDefinition)
+        self.job_def = check.inst_param(job_def, "job_def", JobDefinition)
 
     @property
     def compute_input_event_dict(self) -> Mapping[str, DagsterEvent]:
         """Dict[str, DagsterEvent]: All events of type ``STEP_INPUT``, keyed by input name."""
         return {
             cast(StepInputData, se.event_specific_data).input_name: se
             for se in self.input_events_during_compute
@@ -598,15 +598,15 @@
     def _get_value(self, context: StepExecutionContext, step_output_data: StepOutputData) -> object:
         step_output_handle = step_output_data.step_output_handle
         # output capture dictionary will only have values in the in process case, but will not have
         # values from steps launched via step launcher.
         if self.output_capture and step_output_handle in self.output_capture:
             return self.output_capture[step_output_handle]
         manager = context.get_io_manager(step_output_handle)
-        manager_key = context.execution_plan.get_manager_key(step_output_handle, self.pipeline_def)
+        manager_key = context.execution_plan.get_manager_key(step_output_handle, self.job_def)
         res = manager.load_input(
             context.for_input_manager(
                 name=None,  # type: ignore
                 config=None,
                 metadata=None,
                 dagster_type=self.node.output_def_named(step_output_data.output_name).dagster_type,
                 source_handle=step_output_handle,
```

### Comparing `dagster-1.3.2/dagster/_core/execution/retries.py` & `dagster-1.3.3/dagster/_core/execution/retries.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/execution/run_cancellation_thread.py` & `dagster-1.3.3/dagster/_core/execution/run_cancellation_thread.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import threading
 from typing import Tuple, cast
 
 import dagster._check as check
 from dagster._core.instance import DagsterInstance, InstanceRef
-from dagster._core.storage.pipeline_run import DagsterRun, DagsterRunStatus
+from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus
 from dagster._utils import send_interrupt
 
 
 def _kill_on_cancel(instance_ref: InstanceRef, run_id, shutdown_event):
     check.inst_param(instance_ref, "instance_ref", InstanceRef)
     check.str_param(run_id, "run_id")
```

### Comparing `dagster-1.3.2/dagster/_core/execution/stats.py` & `dagster-1.3.3/dagster/_core/execution/stats.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,22 +2,22 @@
 from enum import Enum
 from typing import Any, Dict, Iterable, NamedTuple, Optional, Sequence, cast
 
 import dagster._check as check
 from dagster._core.definitions import ExpectationResult
 from dagster._core.events import MARKER_EVENTS, DagsterEventType, StepExpectationResultData
 from dagster._core.events.log import EventLogEntry
-from dagster._core.storage.pipeline_run import PipelineRunStatsSnapshot
+from dagster._core.storage.dagster_run import DagsterRunStatsSnapshot
 from dagster._serdes import whitelist_for_serdes
 from dagster._utils import datetime_as_float
 
 
 def build_run_stats_from_events(
     run_id: str, records: Iterable[EventLogEntry]
-) -> PipelineRunStatsSnapshot:
+) -> DagsterRunStatsSnapshot:
     try:
         iter(records)
     except TypeError as exc:
         raise check.ParameterCheckError(
             "Invariant violation for parameter 'records'. Description: Expected iterable."
         ) from exc
     for i, record in enumerate(records):
@@ -63,15 +63,15 @@
         ):
             end_time = (
                 event.timestamp
                 if isinstance(event.timestamp, float)
                 else datetime_as_float(event.timestamp)
             )
 
-    return PipelineRunStatsSnapshot(
+    return DagsterRunStatsSnapshot(
         run_id,
         steps_succeeded,
         steps_failed,
         materializations,
         expectations,
         enqueued_time,
         launch_time,
```

### Comparing `dagster-1.3.2/dagster/_core/execution/tags.py` & `dagster-1.3.3/dagster/_core/execution/tags.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/execution/validate_run_config.py` & `dagster-1.3.3/dagster/_core/execution/validate_run_config.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/execution/watch_orphans.py` & `dagster-1.3.3/dagster/_core/execution/watch_orphans.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/execution/with_resources.py` & `dagster-1.3.3/dagster/_core/execution/with_resources.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/executor/base.py` & `dagster-1.3.3/dagster/_core/executor/base.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/executor/child_process_executor.py` & `dagster-1.3.3/dagster/_core/executor/child_process_executor.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/executor/in_process.py` & `dagster-1.3.3/dagster/_core/executor/in_process.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import os
 from typing import Iterator, Optional
 
 import dagster._check as check
 from dagster._core.events import DagsterEvent, EngineEventData
 from dagster._core.execution.api import ExecuteRunWithPlanIterable
 from dagster._core.execution.context.system import PlanOrchestrationContext
-from dagster._core.execution.context_creation_pipeline import PlanExecutionContextManager
+from dagster._core.execution.context_creation_job import PlanExecutionContextManager
 from dagster._core.execution.plan.execute_plan import inner_plan_execution_iterator
 from dagster._core.execution.plan.plan import ExecutionPlan
 from dagster._core.execution.retries import RetryMode
 from dagster._utils.timing import format_duration, time_execution_scope
 
 from .base import Executor
 
@@ -39,15 +39,15 @@
 
         with time_execution_scope() as timer_result:
             yield from iter(
                 ExecuteRunWithPlanIterable(
                     execution_plan=plan_context.execution_plan,
                     iterator=inner_plan_execution_iterator,
                     execution_context_manager=PlanExecutionContextManager(
-                        pipeline=plan_context.pipeline,
+                        job=plan_context.job,
                         retry_mode=plan_context.retry_mode,
                         execution_plan=plan_context.execution_plan,
                         run_config=plan_context.run_config,
                         dagster_run=plan_context.dagster_run,
                         instance=plan_context.instance,
                         raise_on_error=plan_context.raise_on_error,
                         output_capture=plan_context.output_capture,
```

### Comparing `dagster-1.3.2/dagster/_core/executor/init.py` & `dagster-1.3.3/dagster/_core/executor/init.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,47 +1,43 @@
 from typing import Mapping, NamedTuple
 
 import dagster._check as check
 from dagster._annotations import PublicAttr
-from dagster._core.definitions import ExecutorDefinition, IPipeline
+from dagster._core.definitions import ExecutorDefinition, IJob
 from dagster._core.instance import DagsterInstance
 
 
 class InitExecutorContext(
     NamedTuple(
         "InitExecutorContext",
         [
-            ("job", PublicAttr[IPipeline]),
+            ("job", PublicAttr[IJob]),
             ("executor_def", PublicAttr[ExecutorDefinition]),
             ("executor_config", PublicAttr[Mapping[str, object]]),
             ("instance", PublicAttr[DagsterInstance]),
         ],
     )
 ):
     """Executor-specific initialization context.
 
     Attributes:
-        job (IPipeline): The job to be executed.
+        job (IJob): The job to be executed.
         executor_def (ExecutorDefinition): The definition of the executor currently being
             constructed.
         executor_config (dict): The parsed config passed to the executor.
         instance (DagsterInstance): The current instance.
     """
 
     def __new__(
         cls,
-        job: IPipeline,
+        job: IJob,
         executor_def: ExecutorDefinition,
         executor_config: Mapping[str, object],
         instance: DagsterInstance,
     ):
         return super(InitExecutorContext, cls).__new__(
             cls,
-            job=check.inst_param(job, "job", IPipeline),
+            job=check.inst_param(job, "job", IJob),
             executor_def=check.inst_param(executor_def, "executor_def", ExecutorDefinition),
             executor_config=check.mapping_param(executor_config, "executor_config", key_type=str),
             instance=check.inst_param(instance, "instance", DagsterInstance),
         )
-
-    @property
-    def pipeline(self) -> IPipeline:
-        return self.job
```

### Comparing `dagster-1.3.2/dagster/_core/executor/multiprocess.py` & `dagster-1.3.3/dagster/_core/executor/multiprocess.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,28 +1,28 @@
 import multiprocessing
 import os
 import sys
 from multiprocessing.context import BaseContext as MultiprocessingBaseContext
-from typing import Any, Dict, Iterator, List, Optional, Sequence
+from typing import TYPE_CHECKING, Any, Dict, Iterator, List, Mapping, Optional, Sequence
 
 from dagster import (
     _check as check,
 )
 from dagster._core.definitions.metadata import MetadataValue
-from dagster._core.definitions.reconstruct import ReconstructablePipeline
+from dagster._core.definitions.reconstruct import ReconstructableJob
 from dagster._core.definitions.repository_definition import RepositoryLoadData
 from dagster._core.errors import (
     DagsterExecutionInterruptedError,
     DagsterSubprocessError,
     DagsterUnmetExecutorRequirementsError,
 )
 from dagster._core.events import DagsterEvent, EngineEventData
 from dagster._core.execution.api import create_execution_plan, execute_plan_iterator
 from dagster._core.execution.context.system import IStepContext, PlanOrchestrationContext
-from dagster._core.execution.context_creation_pipeline import create_context_free_log_manager
+from dagster._core.execution.context_creation_job import create_context_free_log_manager
 from dagster._core.execution.plan.active import ActiveExecution
 from dagster._core.execution.plan.objects import StepFailureData
 from dagster._core.execution.plan.plan import ExecutionPlan
 from dagster._core.execution.plan.state import KnownExecutionState
 from dagster._core.execution.plan.step import ExecutionStep
 from dagster._core.execution.retries import RetryMode
 from dagster._core.executor.base import Executor
@@ -35,68 +35,72 @@
     ChildProcessCommand,
     ChildProcessCrashException,
     ChildProcessEvent,
     ChildProcessSystemErrorEvent,
     execute_child_process_command,
 )
 
+if TYPE_CHECKING:
+    from dagster._core.instance.ref import InstanceRef
+    from dagster._core.storage.dagster_run import DagsterRun
+
 DELEGATE_MARKER = "multiprocess_subprocess_init"
 
 
 class MultiprocessExecutorChildProcessCommand(ChildProcessCommand):
     def __init__(
         self,
-        run_config,
-        pipeline_run,
-        step_key,
-        instance_ref,
-        term_event,
-        recon_pipeline,
-        retry_mode,
-        known_state,
-        repository_load_data,
+        run_config: Mapping[str, object],
+        dagster_run: "DagsterRun",
+        step_key: str,
+        instance_ref: "InstanceRef",
+        term_event: Any,
+        recon_pipeline: ReconstructableJob,
+        retry_mode: RetryMode,
+        known_state: Optional[KnownExecutionState],
+        repository_load_data: Optional[RepositoryLoadData],
     ):
         self.run_config = run_config
-        self.pipeline_run = pipeline_run
+        self.dagster_run = dagster_run
         self.step_key = step_key
         self.instance_ref = instance_ref
         self.term_event = term_event
         self.recon_pipeline = recon_pipeline
         self.retry_mode = retry_mode
         self.known_state = known_state
         self.repository_load_data = repository_load_data
 
     def execute(self) -> Iterator[DagsterEvent]:
-        pipeline = self.recon_pipeline
+        recon_job = self.recon_pipeline
         with DagsterInstance.from_ref(self.instance_ref) as instance:
             start_termination_thread(self.term_event)
             execution_plan = create_execution_plan(
-                pipeline=pipeline,
+                job=recon_job,
                 run_config=self.run_config,
                 step_keys_to_execute=[self.step_key],
                 known_state=self.known_state,
                 repository_load_data=self.repository_load_data,
             )
 
-            log_manager = create_context_free_log_manager(instance, self.pipeline_run)
+            log_manager = create_context_free_log_manager(instance, self.dagster_run)
 
             yield DagsterEvent.step_worker_started(
                 log_manager,
-                self.pipeline_run.pipeline_name,
+                self.dagster_run.job_name,
                 message=f'Executing step "{self.step_key}" in subprocess.',
                 metadata={
                     "pid": MetadataValue.text(str(os.getpid())),
                 },
                 step_key=self.step_key,
             )
 
             yield from execute_plan_iterator(
                 execution_plan,
-                pipeline,
-                self.pipeline_run,
+                recon_job,
+                self.dagster_run,
                 run_config=self.run_config,
                 retry_mode=self.retry_mode.for_inner_plan(),
                 instance=instance,
             )
 
 
 class MultiprocessExecutor(Executor):
@@ -141,24 +145,24 @@
 
     def execute(
         self, plan_context: PlanOrchestrationContext, execution_plan: ExecutionPlan
     ) -> Iterator[DagsterEvent]:
         check.inst_param(plan_context, "plan_context", PlanOrchestrationContext)
         check.inst_param(execution_plan, "execution_plan", ExecutionPlan)
 
-        pipeline = plan_context.reconstructable_pipeline
+        job = plan_context.reconstructable_job
 
         multiproc_ctx = multiprocessing.get_context(self._start_method)
         if self._start_method == "forkserver":
-            module = pipeline.get_module()
+            module = job.get_module()
             # if explicitly listed in config we will use that
             if self._explicit_forkserver_preload is not None:
                 preload = self._explicit_forkserver_preload
 
-            # or if the reconstructable pipeline has a module target, we will use that
+            # or if the reconstructable job has a module target, we will use that
             elif module is not None:
                 preload = [module]
 
             # base case is to preload the dagster library
             else:
                 preload = ["dagster"]
 
@@ -218,15 +222,15 @@
                             break
 
                         for step in steps:
                             step_context = plan_context.for_step(step)
                             term_events[step.key] = multiproc_ctx.Event()
                             active_iters[step.key] = execute_step_out_of_process(
                                 multiproc_ctx,
-                                pipeline,
+                                job,
                                 step_context,
                                 step,
                                 errors,
                                 term_events,
                                 self.retries,
                                 active_execution.get_known_state(),
                                 execution_plan.repository_load_data,
@@ -322,30 +326,30 @@
             ),
             event_specific_data=EngineEventData.multiprocess(os.getpid()),
         )
 
 
 def execute_step_out_of_process(
     multiproc_ctx: MultiprocessingBaseContext,
-    pipeline: ReconstructablePipeline,
+    recon_job: ReconstructableJob,
     step_context: IStepContext,
     step: ExecutionStep,
     errors: Dict[int, SerializableErrorInfo],
     term_events: Dict[str, Any],
     retries: RetryMode,
     known_state: KnownExecutionState,
     repository_load_data: Optional[RepositoryLoadData],
 ) -> Iterator[Optional[DagsterEvent]]:
     command = MultiprocessExecutorChildProcessCommand(
         run_config=step_context.run_config,
-        pipeline_run=step_context.dagster_run,
+        dagster_run=step_context.dagster_run,
         step_key=step.key,
         instance_ref=step_context.instance.get_ref(),
         term_event=term_events[step.key],
-        recon_pipeline=pipeline,
+        recon_pipeline=recon_job,
         retry_mode=retries,
         known_state=known_state,
         repository_load_data=repository_load_data,
     )
 
     yield DagsterEvent.step_worker_starting(
         step_context,
```

### Comparing `dagster-1.3.2/dagster/_core/executor/step_delegating/step_delegating_executor.py` & `dagster-1.3.3/dagster/_core/executor/step_delegating/step_delegating_executor.py`

 * *Files 1% similar despite different names*

```diff
@@ -80,16 +80,16 @@
         self, plan_context, steps, active_execution
     ) -> StepHandlerContext:
         return StepHandlerContext(
             instance=plan_context.plan_data.instance,
             plan_context=plan_context,
             steps=steps,
             execute_step_args=ExecuteStepArgs(
-                pipeline_origin=plan_context.reconstructable_pipeline.get_python_origin(),
-                pipeline_run_id=plan_context.dagster_run.run_id,
+                job_origin=plan_context.reconstructable_job.get_python_origin(),
+                run_id=plan_context.dagster_run.run_id,
                 step_keys_to_execute=[step.key for step in steps],
                 instance_ref=plan_context.plan_data.instance.get_ref(),
                 retry_mode=self.retries.for_inner_plan(),
                 known_state=active_execution.get_known_state(),
                 should_verify_step=self._should_verify_step,
             ),
             dagster_run=plan_context.dagster_run,
```

### Comparing `dagster-1.3.2/dagster/_core/executor/step_delegating/step_handler/base.py` & `dagster-1.3.3/dagster/_core/executor/step_delegating/step_handler/base.py`

 * *Files 8% similar despite different names*

```diff
@@ -4,59 +4,59 @@
 from dagster import (
     DagsterInstance,
     _check as check,
 )
 from dagster._core.events import DagsterEvent
 from dagster._core.execution.context.system import IStepContext, PlanOrchestrationContext
 from dagster._core.execution.plan.step import ExecutionStep
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._grpc.types import ExecuteStepArgs
 
 
 class StepHandlerContext:
     def __init__(
         self,
         instance: DagsterInstance,
         plan_context: PlanOrchestrationContext,
         steps: Sequence[ExecutionStep],
         execute_step_args: ExecuteStepArgs,
         dagster_run: Optional[DagsterRun] = None,
     ) -> None:
         self._instance = instance
-        self._dagster_run = plan_context
+        self._plan_context = plan_context
         self._steps_by_key = {step.key: step for step in steps}
         self._execute_step_args = execute_step_args
-        self._pipeline_run = dagster_run
+        self._dagster_run = dagster_run
 
     @property
     def execute_step_args(self) -> ExecuteStepArgs:
         return self._execute_step_args
 
     @property
     def dagster_run(self) -> DagsterRun:
         # lazy load
-        if not self._pipeline_run:
-            run_id = self.execute_step_args.pipeline_run_id
+        if not self._dagster_run:
+            run_id = self.execute_step_args.run_id
             run = self._instance.get_run_by_id(run_id)
             if run is None:
                 check.failed(f"Failed to load run {run_id}")
-            self._pipeline_run = run
+            self._dagster_run = run
 
-        return self._pipeline_run
+        return self._dagster_run
 
     @property
     def step_tags(self) -> Mapping[str, Mapping[str, str]]:
         return {step_key: step.tags for step_key, step in self._steps_by_key.items()}
 
     @property
     def instance(self) -> DagsterInstance:
         return self._instance
 
     def get_step_context(self, step_key: str) -> IStepContext:
-        return self._dagster_run.for_step(self._steps_by_key[step_key])
+        return self._plan_context.for_step(self._steps_by_key[step_key])
 
 
 class CheckStepHealthResult(
     NamedTuple(
         "_CheckStepHealthResult", [("is_healthy", bool), ("unhealthy_reason", Optional[str])]
     )
 ):
```

### Comparing `dagster-1.3.2/dagster/_core/host_representation/__init__.py` & `dagster-1.3.3/dagster/_core/host_representation/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -4,59 +4,59 @@
 
 It also contains classes that represent historical representations
 that have been persisted. e.g. HistoricalPipeline
 """
 
 from .external import (
     ExternalExecutionPlan as ExternalExecutionPlan,
+    ExternalJob as ExternalJob,
     ExternalPartitionSet as ExternalPartitionSet,
-    ExternalPipeline as ExternalPipeline,
     ExternalRepository as ExternalRepository,
     ExternalSchedule as ExternalSchedule,
     ExternalSensor as ExternalSensor,
 )
 from .external_data import (
     ExternalExecutionParamsData as ExternalExecutionParamsData,
     ExternalExecutionParamsErrorData as ExternalExecutionParamsErrorData,
+    ExternalJobData as ExternalJobData,
     ExternalJobRef as ExternalJobRef,
+    ExternalJobSubsetResult as ExternalJobSubsetResult,
     ExternalPartitionConfigData as ExternalPartitionConfigData,
     ExternalPartitionExecutionErrorData as ExternalPartitionExecutionErrorData,
     ExternalPartitionNamesData as ExternalPartitionNamesData,
     ExternalPartitionSetData as ExternalPartitionSetData,
     ExternalPartitionSetExecutionParamData as ExternalPartitionSetExecutionParamData,
     ExternalPartitionTagsData as ExternalPartitionTagsData,
-    ExternalPipelineData as ExternalPipelineData,
-    ExternalPipelineSubsetResult as ExternalPipelineSubsetResult,
     ExternalPresetData as ExternalPresetData,
     ExternalRepositoryData as ExternalRepositoryData,
     ExternalRepositoryErrorData as ExternalRepositoryErrorData,
     ExternalScheduleData as ExternalScheduleData,
     ExternalScheduleExecutionErrorData as ExternalScheduleExecutionErrorData,
     ExternalSensorExecutionErrorData as ExternalSensorExecutionErrorData,
     ExternalTargetData as ExternalTargetData,
-    external_pipeline_data_from_def as external_pipeline_data_from_def,
+    external_job_data_from_def as external_job_data_from_def,
     external_repository_data_from_def as external_repository_data_from_def,
 )
 from .handle import (
     JobHandle as JobHandle,
     RepositoryHandle as RepositoryHandle,
 )
-from .historical import HistoricalPipeline as HistoricalPipeline
+from .historical import HistoricalJob as HistoricalJob
 from .origin import (
     IN_PROCESS_NAME as IN_PROCESS_NAME,
     CodeLocationOrigin as CodeLocationOrigin,
     ExternalInstigatorOrigin as ExternalInstigatorOrigin,
-    ExternalPipelineOrigin as ExternalPipelineOrigin,
+    ExternalJobOrigin as ExternalJobOrigin,
     ExternalRepositoryOrigin as ExternalRepositoryOrigin,
     GrpcServerCodeLocationOrigin as GrpcServerCodeLocationOrigin,
     InProcessCodeLocationOrigin as InProcessCodeLocationOrigin,
     ManagedGrpcPythonEnvCodeLocationOrigin as ManagedGrpcPythonEnvCodeLocationOrigin,
 )
 
 # isort: split
 from .code_location import (
     CodeLocation as CodeLocation,
     GrpcServerCodeLocation as GrpcServerCodeLocation,
     InProcessCodeLocation as InProcessCodeLocation,
 )
-from .pipeline_index import PipelineIndex as PipelineIndex
-from .represented import RepresentedPipeline as RepresentedPipeline
+from .job_index import JobIndex as JobIndex
+from .represented import RepresentedJob as RepresentedJob
```

### Comparing `dagster-1.3.2/dagster/_core/host_representation/code_location.py` & `dagster-1.3.3/dagster/_core/host_representation/code_location.py`

 * *Files 6% similar despite different names*

```diff
@@ -6,35 +6,35 @@
 from typing import TYPE_CHECKING, Any, Dict, Mapping, Optional, Sequence, Tuple, Union, cast
 
 import dagster._check as check
 from dagster._api.get_server_id import sync_get_server_id
 from dagster._api.list_repositories import sync_list_repositories_grpc
 from dagster._api.notebook_data import sync_get_streaming_external_notebook_data_grpc
 from dagster._api.snapshot_execution_plan import sync_get_external_execution_plan_grpc
+from dagster._api.snapshot_job import sync_get_external_job_subset_grpc
 from dagster._api.snapshot_partition import (
     sync_get_external_partition_config_grpc,
     sync_get_external_partition_names_grpc,
     sync_get_external_partition_set_execution_param_data_grpc,
     sync_get_external_partition_tags_grpc,
 )
-from dagster._api.snapshot_pipeline import sync_get_external_pipeline_subset_grpc
 from dagster._api.snapshot_repository import sync_get_streaming_external_repositories_data_grpc
 from dagster._api.snapshot_schedule import sync_get_external_schedule_execution_data_grpc
 from dagster._core.code_pointer import CodePointer
-from dagster._core.definitions.reconstruct import ReconstructablePipeline
+from dagster._core.definitions.reconstruct import ReconstructableJob
 from dagster._core.definitions.repository_definition import RepositoryDefinition
-from dagster._core.definitions.selector import PipelineSelector
+from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.errors import DagsterInvariantViolationError, DagsterUserCodeProcessError
 from dagster._core.execution.api import create_execution_plan
 from dagster._core.execution.plan.state import KnownExecutionState
-from dagster._core.host_representation import ExternalPipelineSubsetResult
+from dagster._core.host_representation import ExternalJobSubsetResult
 from dagster._core.host_representation.external import (
     ExternalExecutionPlan,
+    ExternalJob,
     ExternalPartitionSet,
-    ExternalPipeline,
     ExternalRepository,
 )
 from dagster._core.host_representation.external_data import (
     ExternalPartitionNamesData,
     ExternalScheduleExecutionErrorData,
     ExternalSensorExecutionErrorData,
 )
@@ -73,15 +73,15 @@
         ExternalPartitionTagsData,
     )
 
 
 class CodeLocation(AbstractContextManager):
     """A CodeLocation represents a target containing user code which has a set of Dagster
     definition objects. A given location will contain some number of uniquely named
-    RepositoryDefinitions, which therein contains Pipeline, Solid, and other definitions.
+    RepositoryDefinitions, which therein contains job, op, and other definitions.
 
     Dagster tools are typically "host" processes, meaning they load a CodeLocation and
     communicate with it over an IPC/RPC layer. Currently this IPC layer is implemented by
     invoking the dagster CLI in a target python interpreter (e.g. a virtual environment) in either
       a) the current node
       b) a container
 
@@ -111,51 +111,51 @@
     @property
     def name(self) -> str:
         return self.origin.location_name
 
     @abstractmethod
     def get_external_execution_plan(
         self,
-        external_pipeline: ExternalPipeline,
+        external_job: ExternalJob,
         run_config: Mapping[str, object],
         step_keys_to_execute: Optional[Sequence[str]],
         known_state: Optional[KnownExecutionState],
         instance: Optional[DagsterInstance] = None,
     ) -> ExternalExecutionPlan:
         pass
 
-    def get_external_pipeline(self, selector: PipelineSelector) -> ExternalPipeline:
+    def get_external_job(self, selector: JobSubsetSelector) -> ExternalJob:
         """Return the ExternalPipeline for a specific pipeline. Subclasses only
         need to implement get_subset_external_pipeline_result to handle the case where
-        a solid selection is specified, which requires access to the underlying PipelineDefinition
+        an op selection is specified, which requires access to the underlying JobDefinition
         to generate the subsetted pipeline snapshot.
         """
         if not selector.solid_selection and not selector.asset_selection:
             return self.get_repository(selector.repository_name).get_full_external_job(
-                selector.pipeline_name
+                selector.job_name
             )
 
         repo_handle = self.get_repository(selector.repository_name).handle
 
-        subset_result = self.get_subset_external_pipeline_result(selector)
-        external_data = subset_result.external_pipeline_data
+        subset_result = self.get_subset_external_job_result(selector)
+        external_data = subset_result.external_job_data
         if external_data is None:
             check.failed(
                 f"Failed to fetch subset data, success: {subset_result.success} error:"
                 f" {subset_result.error}"
             )
 
-        return ExternalPipeline(external_data, repo_handle)
+        return ExternalJob(external_data, repo_handle)
 
     @abstractmethod
-    def get_subset_external_pipeline_result(
-        self, selector: PipelineSelector
-    ) -> ExternalPipelineSubsetResult:
-        """Returns a snapshot about an ExternalPipeline with a solid selection, which requires
-        access to the underlying PipelineDefinition. Callsites should likely use
+    def get_subset_external_job_result(
+        self, selector: JobSubsetSelector
+    ) -> ExternalJobSubsetResult:
+        """Returns a snapshot about an ExternalPipeline with an op selection, which requires
+        access to the underlying JobDefinition. Callsites should likely use
         `get_external_pipeline` instead.
         """
 
     @abstractmethod
     def get_external_partition_config(
         self,
         repository_handle: RepositoryHandle,
@@ -331,84 +331,82 @@
     def entry_point(self) -> Optional[Sequence[str]]:
         return self._origin.entry_point
 
     @property
     def repository_code_pointer_dict(self) -> Mapping[str, CodePointer]:
         return self._repository_code_pointer_dict
 
-    def get_reconstructable_pipeline(
-        self, repository_name: str, name: str
-    ) -> ReconstructablePipeline:
+    def get_reconstructable_job(self, repository_name: str, name: str) -> ReconstructableJob:
         return self._loaded_repositories.reconstructables_by_name[
             repository_name
-        ].get_reconstructable_pipeline(name)
+        ].get_reconstructable_job(name)
 
     def _get_repo_def(self, name: str) -> RepositoryDefinition:
         return self._loaded_repositories.definitions_by_name[name]
 
     def get_repository(self, name: str) -> ExternalRepository:
         return self._repositories[name]
 
     def has_repository(self, name: str) -> bool:
         return name in self._repositories
 
     def get_repositories(self) -> Mapping[str, ExternalRepository]:
         return self._repositories
 
-    def get_subset_external_pipeline_result(
-        self, selector: PipelineSelector
-    ) -> ExternalPipelineSubsetResult:
-        check.inst_param(selector, "selector", PipelineSelector)
+    def get_subset_external_job_result(
+        self, selector: JobSubsetSelector
+    ) -> ExternalJobSubsetResult:
+        check.inst_param(selector, "selector", JobSubsetSelector)
         check.invariant(
             selector.location_name == self.name,
             "PipelineSelector location_name mismatch, got {selector.location_name} expected"
             " {self.name}".format(self=self, selector=selector),
         )
 
         from dagster._grpc.impl import get_external_pipeline_subset_result
 
         return get_external_pipeline_subset_result(
             self._get_repo_def(selector.repository_name),
-            selector.pipeline_name,
+            selector.job_name,
             selector.solid_selection,
             selector.asset_selection,
         )
 
     def get_external_execution_plan(
         self,
-        external_pipeline: ExternalPipeline,
+        external_job: ExternalJob,
         run_config: Mapping[str, object],
         step_keys_to_execute: Optional[Sequence[str]],
         known_state: Optional[KnownExecutionState],
         instance: Optional[DagsterInstance] = None,
     ) -> ExternalExecutionPlan:
-        check.inst_param(external_pipeline, "external_pipeline", ExternalPipeline)
+        check.inst_param(external_job, "external_job", ExternalJob)
         check.mapping_param(run_config, "run_config")
         step_keys_to_execute = check.opt_nullable_sequence_param(
             step_keys_to_execute, "step_keys_to_execute", of_type=str
         )
         check.opt_inst_param(known_state, "known_state", KnownExecutionState)
         check.opt_inst_param(instance, "instance", DagsterInstance)
 
         execution_plan = create_execution_plan(
-            pipeline=self.get_reconstructable_pipeline(
-                external_pipeline.repository_handle.repository_name, external_pipeline.name
-            ).subset_for_execution_from_existing_pipeline(
-                external_pipeline.solids_to_execute,
-                external_pipeline.asset_selection,
+            job=self.get_reconstructable_job(
+                external_job.repository_handle.repository_name, external_job.name
+            ).subset_for_execution_from_existing_job(
+                external_job.solids_to_execute,
+                external_job.asset_selection,
             ),
             run_config=run_config,
             step_keys_to_execute=step_keys_to_execute,
             known_state=known_state,
             instance_ref=instance.get_ref() if instance and instance.is_persistent else None,
         )
         return ExternalExecutionPlan(
             execution_plan_snapshot=snapshot_from_execution_plan(
                 execution_plan,
-                external_pipeline.identifying_pipeline_snapshot_id,
+                external_job.identifying_job_snapshot_id,
             )
         )
 
     def get_external_partition_config(
         self,
         repository_handle: RepositoryHandle,
         partition_set_name: str,
@@ -712,59 +710,59 @@
         return name in self.get_repositories()
 
     def get_repositories(self) -> Mapping[str, ExternalRepository]:
         return self.external_repositories
 
     def get_external_execution_plan(
         self,
-        external_pipeline: ExternalPipeline,
+        external_job: ExternalJob,
         run_config: Mapping[str, Any],
         step_keys_to_execute: Optional[Sequence[str]],
         known_state: Optional[KnownExecutionState],
         instance: Optional[DagsterInstance] = None,
     ) -> ExternalExecutionPlan:
-        check.inst_param(external_pipeline, "external_pipeline", ExternalPipeline)
+        check.inst_param(external_job, "external_job", ExternalJob)
         run_config = check.mapping_param(run_config, "run_config")
         check.opt_nullable_sequence_param(step_keys_to_execute, "step_keys_to_execute", of_type=str)
         check.opt_inst_param(known_state, "known_state", KnownExecutionState)
         check.opt_inst_param(instance, "instance", DagsterInstance)
 
         asset_selection = (
-            frozenset(check.opt_set_param(external_pipeline.asset_selection, "asset_selection"))
-            if external_pipeline.asset_selection is not None
+            frozenset(check.opt_set_param(external_job.asset_selection, "asset_selection"))
+            if external_job.asset_selection is not None
             else None
         )
 
         execution_plan_snapshot_or_error = sync_get_external_execution_plan_grpc(
             api_client=self.client,
-            pipeline_origin=external_pipeline.get_external_origin(),
+            job_origin=external_job.get_external_origin(),
             run_config=run_config,
-            pipeline_snapshot_id=external_pipeline.identifying_pipeline_snapshot_id,
+            job_snapshot_id=external_job.identifying_job_snapshot_id,
             asset_selection=asset_selection,
-            solid_selection=external_pipeline.solid_selection,
+            solid_selection=external_job.solid_selection,
             step_keys_to_execute=step_keys_to_execute,
             known_state=known_state,
             instance=instance,
         )
 
         return ExternalExecutionPlan(execution_plan_snapshot=execution_plan_snapshot_or_error)
 
-    def get_subset_external_pipeline_result(
-        self, selector: PipelineSelector
-    ) -> "ExternalPipelineSubsetResult":
-        check.inst_param(selector, "selector", PipelineSelector)
+    def get_subset_external_job_result(
+        self, selector: JobSubsetSelector
+    ) -> "ExternalJobSubsetResult":
+        check.inst_param(selector, "selector", JobSubsetSelector)
         check.invariant(
             selector.location_name == self.name,
             "PipelineSelector location_name mismatch, got {selector.location_name} expected"
             " {self.name}".format(self=self, selector=selector),
         )
 
         external_repository = self.get_repository(selector.repository_name)
-        job_handle = JobHandle(selector.pipeline_name, external_repository.handle)
-        return sync_get_external_pipeline_subset_grpc(
+        job_handle = JobHandle(selector.job_name, external_repository.handle)
+        return sync_get_external_job_subset_grpc(
             self.client,
             job_handle.get_external_origin(),
             selector.solid_selection,
             selector.asset_selection,
         )
 
     def get_external_partition_config(
```

### Comparing `dagster-1.3.2/dagster/_core/host_representation/external.py` & `dagster-1.3.3/dagster/_core/host_representation/external.py`

 * *Files 4% similar despite different names*

```diff
@@ -34,48 +34,48 @@
     DEFAULT_SENSOR_DAEMON_INTERVAL,
     DefaultSensorStatus,
     SensorType,
 )
 from dagster._core.execution.plan.handle import ResolvedFromDynamicStepHandle, StepHandle
 from dagster._core.host_representation.origin import (
     ExternalInstigatorOrigin,
+    ExternalJobOrigin,
     ExternalPartitionSetOrigin,
-    ExternalPipelineOrigin,
     ExternalRepositoryOrigin,
 )
 from dagster._core.instance import DagsterInstance
-from dagster._core.origin import PipelinePythonOrigin, RepositoryPythonOrigin
+from dagster._core.origin import JobPythonOrigin, RepositoryPythonOrigin
 from dagster._core.snap import ExecutionPlanSnapshot
 from dagster._core.snap.execution_plan_snapshot import ExecutionStepSnap
 from dagster._core.utils import toposort
 from dagster._serdes import create_snapshot_id
 from dagster._utils.cached_method import cached_method
 from dagster._utils.schedules import schedule_execution_time_iterator
 
 from .external_data import (
     DEFAULT_MODE_NAME,
     EnvVarConsumer,
     ExternalAssetNode,
+    ExternalJobData,
     ExternalJobRef,
     ExternalPartitionSetData,
-    ExternalPipelineData,
     ExternalPresetData,
     ExternalRepositoryData,
     ExternalResourceData,
     ExternalResourceValue,
     ExternalScheduleData,
     ExternalSensorData,
     ExternalSensorMetadata,
     ExternalTargetData,
     NestedResource,
     ResourceJobUsageEntry,
 )
 from .handle import InstigatorHandle, JobHandle, PartitionSetHandle, RepositoryHandle
-from .pipeline_index import PipelineIndex
-from .represented import RepresentedPipeline
+from .job_index import JobIndex
+from .represented import RepresentedJob
 
 if TYPE_CHECKING:
     from dagster._core.scheduler.instigation import InstigatorState
 
 
 class ExternalRepository:
     """ExternalRepository is a object that represents a loaded repository definition that
@@ -83,23 +83,23 @@
     objects such as these to interact with user-defined artifacts.
     """
 
     def __init__(
         self,
         external_repository_data: ExternalRepositoryData,
         repository_handle: RepositoryHandle,
-        ref_to_data_fn: Optional[Callable[[ExternalJobRef], ExternalPipelineData]] = None,
+        ref_to_data_fn: Optional[Callable[[ExternalJobRef], ExternalJobData]] = None,
     ):
         self.external_repository_data = check.inst_param(
             external_repository_data, "external_repository_data", ExternalRepositoryData
         )
 
-        if external_repository_data.external_pipeline_datas is not None:
-            self._job_map: Dict[str, Union[ExternalPipelineData, ExternalJobRef]] = {
-                d.name: d for d in external_repository_data.external_pipeline_datas
+        if external_repository_data.external_job_datas is not None:
+            self._job_map: Dict[str, Union[ExternalJobData, ExternalJobRef]] = {
+                d.name: d for d in external_repository_data.external_job_datas
             }
             self._deferred_snapshots: bool = False
             self._ref_to_data_fn = None
         elif external_repository_data.external_job_refs is not None:
             self._job_map = {r.name: r for r in external_repository_data.external_job_refs}
             self._deferred_snapshots = True
             if ref_to_data_fn is None:
@@ -120,15 +120,15 @@
                 if job_name not in self._asset_jobs:
                     self._asset_jobs[job_name] = [asset_node]
                 else:
                     self._asset_jobs[job_name].append(asset_node)
 
         # memoize job instances to share instances
         self._memo_lock: RLock = RLock()
-        self._cached_jobs: Dict[str, ExternalPipeline] = {}
+        self._cached_jobs: Dict[str, ExternalJob] = {}
 
     @property
     def name(self) -> str:
         return self.external_repository_data.name
 
     @property
     @cached_method
@@ -208,43 +208,43 @@
 
     def get_external_partition_sets(self) -> Sequence[ExternalPartitionSet]:
         return list(self._external_partition_sets.values())
 
     def has_external_job(self, job_name: str) -> bool:
         return job_name in self._job_map
 
-    def get_full_external_job(self, job_name: str) -> ExternalPipeline:
+    def get_full_external_job(self, job_name: str) -> ExternalJob:
         check.str_param(job_name, "job_name")
         check.invariant(
             self.has_external_job(job_name), f'No external job named "{job_name}" found'
         )
         with self._memo_lock:
             if job_name not in self._cached_jobs:
                 job_item = self._job_map[job_name]
                 if self._deferred_snapshots:
                     if not isinstance(job_item, ExternalJobRef):
                         check.failed("unexpected job item")
                     external_ref = job_item
-                    external_data: Optional[ExternalPipelineData] = None
+                    external_data: Optional[ExternalJobData] = None
                 else:
-                    if not isinstance(job_item, ExternalPipelineData):
+                    if not isinstance(job_item, ExternalJobData):
                         check.failed("unexpected job item")
                     external_data = job_item
                     external_ref = None
 
-                self._cached_jobs[job_name] = ExternalPipeline(
-                    external_pipeline_data=external_data,
+                self._cached_jobs[job_name] = ExternalJob(
+                    external_job_data=external_data,
                     repository_handle=self.handle,
                     external_job_ref=external_ref,
                     ref_to_data_fn=self._ref_to_data_fn,
                 )
 
             return self._cached_jobs[job_name]
 
-    def get_all_external_jobs(self) -> Sequence[ExternalPipeline]:
+    def get_all_external_jobs(self) -> Sequence[ExternalJob]:
         return [self.get_full_external_job(pn) for pn in self._job_map]
 
     @property
     def handle(self) -> RepositoryHandle:
         return self._handle
 
     @property
@@ -282,79 +282,79 @@
         ]
         return matching[0] if matching else None
 
     def get_display_metadata(self) -> Mapping[str, str]:
         return self.handle.display_metadata
 
 
-class ExternalPipeline(RepresentedPipeline):
-    """ExternalPipeline is a object that represents a loaded job definition that
+class ExternalJob(RepresentedJob):
+    """ExternalJob is a object that represents a loaded job definition that
     is resident in another process or container. Host processes such as dagit use
     objects such as these to interact with user-defined artifacts.
     """
 
     def __init__(
         self,
-        external_pipeline_data: Optional[ExternalPipelineData],
+        external_job_data: Optional[ExternalJobData],
         repository_handle: RepositoryHandle,
         external_job_ref: Optional[ExternalJobRef] = None,
-        ref_to_data_fn: Optional[Callable[[ExternalJobRef], ExternalPipelineData]] = None,
+        ref_to_data_fn: Optional[Callable[[ExternalJobRef], ExternalJobData]] = None,
     ):
         check.inst_param(repository_handle, "repository_handle", RepositoryHandle)
-        check.opt_inst_param(external_pipeline_data, "external_pipeline_data", ExternalPipelineData)
+        check.opt_inst_param(external_job_data, "external_job_data", ExternalJobData)
 
         self._repository_handle = repository_handle
 
         self._memo_lock = RLock()
-        self._index: Optional[PipelineIndex] = None
+        self._index: Optional[JobIndex] = None
 
-        self._data = external_pipeline_data
+        self._data = external_job_data
         self._ref = external_job_ref
         self._ref_to_data_fn = ref_to_data_fn
 
-        if external_pipeline_data:
-            self._active_preset_dict = {ap.name: ap for ap in external_pipeline_data.active_presets}
-            self._name = external_pipeline_data.name
-            self._snapshot_id = self._pipeline_index.pipeline_snapshot_id
+        if external_job_data:
+            self._active_preset_dict = {ap.name: ap for ap in external_job_data.active_presets}
+            self._name = external_job_data.name
+            self._snapshot_id = self._job_index.job_snapshot_id
 
         elif external_job_ref:
             self._active_preset_dict = {ap.name: ap for ap in external_job_ref.active_presets}
             self._name = external_job_ref.name
             if ref_to_data_fn is None:
                 check.failed("ref_to_data_fn must be passed when using deferred snapshots")
             self._snapshot_id = external_job_ref.snapshot_id
         else:
             check.failed("Expected either job data or ref, got neither")
 
         self._handle = JobHandle(self._name, repository_handle)
 
     @property
-    def _pipeline_index(self) -> PipelineIndex:
+    def _job_index(self) -> JobIndex:
         with self._memo_lock:
             if self._index is None:
-                self._index = PipelineIndex(
-                    self.external_pipeline_data.pipeline_snapshot,
-                    self.external_pipeline_data.parent_pipeline_snapshot,
+                self._index = JobIndex(
+                    self.external_job_data.job_snapshot,
+                    self.external_job_data.parent_job_snapshot,
                 )
             return self._index
 
     @property
     def name(self) -> str:
         return self._name
 
     @property
     def description(self):
-        return self._pipeline_index.pipeline_snapshot.description
+        return self._job_index.job_snapshot.description
 
     @property
-    def solid_names_in_topological_order(self):
-        return self._pipeline_index.pipeline_snapshot.node_names_in_topological_order
+    def node_names_in_topological_order(self):
+        return self._job_index.job_snapshot.node_names_in_topological_order
 
     @property
-    def external_pipeline_data(self):
+    def external_job_data(self):
         with self._memo_lock:
             if self._data is None:
                 if self._ref is None or self._ref_to_data_fn is None:
                     check.failed("unexpected state - unable to load data from ref")
                 self._data = self._ref_to_data_fn(self._ref)
 
             return self._data
@@ -362,46 +362,46 @@
     @property
     def repository_handle(self) -> RepositoryHandle:
         return self._repository_handle
 
     @property
     def solid_selection(self) -> Optional[Sequence[str]]:
         return (
-            self._pipeline_index.pipeline_snapshot.lineage_snapshot.node_selection
-            if self._pipeline_index.pipeline_snapshot.lineage_snapshot
+            self._job_index.job_snapshot.lineage_snapshot.node_selection
+            if self._job_index.job_snapshot.lineage_snapshot
             else None
         )
 
     @property
     def solids_to_execute(self) -> Optional[AbstractSet[str]]:
         return (
-            self._pipeline_index.pipeline_snapshot.lineage_snapshot.nodes_to_execute
-            if self._pipeline_index.pipeline_snapshot.lineage_snapshot
+            self._job_index.job_snapshot.lineage_snapshot.nodes_to_execute
+            if self._job_index.job_snapshot.lineage_snapshot
             else None
         )
 
     @property
     def asset_selection(self) -> Optional[AbstractSet[AssetKey]]:
         return (
-            self._pipeline_index.pipeline_snapshot.lineage_snapshot.asset_selection
-            if self._pipeline_index.pipeline_snapshot.lineage_snapshot
+            self._job_index.job_snapshot.lineage_snapshot.asset_selection
+            if self._job_index.job_snapshot.lineage_snapshot
             else None
         )
 
     @property
     def active_presets(self) -> Sequence[ExternalPresetData]:
         return list(self._active_preset_dict.values())
 
     @property
-    def solid_names(self) -> Sequence[str]:
-        return self._pipeline_index.pipeline_snapshot.node_names
+    def node_names(self) -> Sequence[str]:
+        return self._job_index.job_snapshot.node_names
 
-    def has_solid_invocation(self, solid_name: str):
-        check.str_param(solid_name, "solid_name")
-        return self._pipeline_index.has_solid_invocation(solid_name)
+    def has_node_invocation(self, node_name: str):
+        check.str_param(node_name, "node_name")
+        return self._job_index.has_node_invocation(node_name)
 
     def has_preset(self, preset_name: str) -> bool:
         check.str_param(preset_name, "preset_name")
         return preset_name in self._active_preset_dict
 
     def get_preset(self, preset_name: str) -> ExternalPresetData:
         check.str_param(preset_name, "preset_name")
@@ -409,37 +409,37 @@
 
     @property
     def root_config_key(self) -> Optional[str]:
         return self.get_mode_def_snap(DEFAULT_MODE_NAME).root_config_key
 
     @property
     def tags(self) -> Mapping[str, object]:
-        return self._pipeline_index.pipeline_snapshot.tags
+        return self._job_index.job_snapshot.tags
 
     @property
     def metadata(self) -> Mapping[str, MetadataValue]:
-        return self._pipeline_index.pipeline_snapshot.metadata
+        return self._job_index.job_snapshot.metadata
 
     @property
-    def computed_pipeline_snapshot_id(self) -> str:
+    def computed_job_snapshot_id(self) -> str:
         return self._snapshot_id
 
     @property
-    def identifying_pipeline_snapshot_id(self) -> str:
+    def identifying_job_snapshot_id(self) -> str:
         return self._snapshot_id
 
     @property
     def handle(self) -> JobHandle:
         return self._handle
 
-    def get_python_origin(self) -> PipelinePythonOrigin:
+    def get_python_origin(self) -> JobPythonOrigin:
         repository_python_origin = self.repository_handle.get_python_origin()
-        return PipelinePythonOrigin(self.name, repository_python_origin)
+        return JobPythonOrigin(self.name, repository_python_origin)
 
-    def get_external_origin(self) -> ExternalPipelineOrigin:
+    def get_external_origin(self) -> ExternalJobOrigin:
         return self.handle.get_external_origin()
 
     def get_external_origin_id(self) -> str:
         return self.get_external_origin().get_id()
 
 
 class ExternalExecutionPlan:
@@ -608,16 +608,16 @@
         return self._external_schedule_data.execution_timezone
 
     @property
     def solid_selection(self) -> Optional[Sequence[str]]:
         return self._external_schedule_data.solid_selection
 
     @property
-    def pipeline_name(self) -> str:
-        return self._external_schedule_data.pipeline_name
+    def job_name(self) -> str:
+        return self._external_schedule_data.job_name
 
     @property
     def mode(self) -> Optional[str]:
         return self._external_schedule_data.mode
 
     @property
     def description(self) -> Optional[str]:
@@ -725,17 +725,17 @@
         return self._external_sensor_data.name
 
     @property
     def handle(self) -> InstigatorHandle:
         return self._handle
 
     @property
-    def pipeline_name(self) -> Optional[str]:
+    def job_name(self) -> Optional[str]:
         target = self._get_single_target()
-        return target.pipeline_name if target else None
+        return target.job_name if target else None
 
     @property
     def mode(self) -> Optional[str]:
         target = self._get_single_target()
         return target.mode if target else None
 
     @property
@@ -745,17 +745,17 @@
 
     def _get_single_target(self) -> Optional[ExternalTargetData]:
         if self._external_sensor_data.target_dict:
             return list(self._external_sensor_data.target_dict.values())[0]
         else:
             return None
 
-    def get_target_data(self, pipeline_name: Optional[str] = None) -> Optional[ExternalTargetData]:
-        if pipeline_name:
-            return self._external_sensor_data.target_dict[pipeline_name]
+    def get_target_data(self, job_name: Optional[str] = None) -> Optional[ExternalTargetData]:
+        if job_name:
+            return self._external_sensor_data.target_dict[job_name]
         else:
             return self._get_single_target()
 
     def get_external_targets(self) -> Sequence[ExternalTargetData]:
         return list(self._external_sensor_data.target_dict.values())
 
     @property
@@ -868,16 +868,16 @@
         return self._external_partition_set_data.solid_selection
 
     @property
     def mode(self) -> Optional[str]:
         return self._external_partition_set_data.mode
 
     @property
-    def pipeline_name(self) -> str:
-        return self._external_partition_set_data.pipeline_name
+    def job_name(self) -> str:
+        return self._external_partition_set_data.job_name
 
     @property
     def repository_handle(self) -> RepositoryHandle:
         return self._handle.repository_handle
 
     def get_external_origin(self) -> ExternalPartitionSetOrigin:
         return self._handle.get_external_origin()
```

### Comparing `dagster-1.3.2/dagster/_core/host_representation/external_data.py` & `dagster-1.3.3/dagster/_core/host_representation/external_data.py`

 * *Files 4% similar despite different names*

```diff
@@ -82,48 +82,48 @@
     DefaultSensorStatus,
     SensorDefinition,
     SensorType,
 )
 from dagster._core.definitions.time_window_partitions import TimeWindowPartitionsDefinition
 from dagster._core.definitions.utils import DEFAULT_GROUP_NAME
 from dagster._core.errors import DagsterInvalidDefinitionError
-from dagster._core.snap import PipelineSnapshot
+from dagster._core.snap import JobSnapshot
 from dagster._core.snap.mode import ResourceDefSnap, build_resource_def_snap
 from dagster._serdes import whitelist_for_serdes
 from dagster._utils.error import SerializableErrorInfo
 
 DEFAULT_MODE_NAME = "default"
 DEFAULT_PRESET_NAME = "default"
 
 
-@whitelist_for_serdes
+@whitelist_for_serdes(storage_field_names={"external_job_datas": "external_pipeline_datas"})
 class ExternalRepositoryData(
     NamedTuple(
         "_ExternalRepositoryData",
         [
             ("name", str),
             ("external_schedule_datas", Sequence["ExternalScheduleData"]),
             ("external_partition_set_datas", Sequence["ExternalPartitionSetData"]),
             ("external_sensor_datas", Sequence["ExternalSensorData"]),
             ("external_asset_graph_data", Sequence["ExternalAssetNode"]),
-            ("external_pipeline_datas", Optional[Sequence["ExternalPipelineData"]]),
+            ("external_job_datas", Optional[Sequence["ExternalJobData"]]),
             ("external_job_refs", Optional[Sequence["ExternalJobRef"]]),
             ("external_resource_data", Optional[Sequence["ExternalResourceData"]]),
             ("utilized_env_vars", Optional[Mapping[str, Sequence["EnvVarConsumer"]]]),
         ],
     )
 ):
     def __new__(
         cls,
         name: str,
         external_schedule_datas: Sequence["ExternalScheduleData"],
         external_partition_set_datas: Sequence["ExternalPartitionSetData"],
         external_sensor_datas: Optional[Sequence["ExternalSensorData"]] = None,
         external_asset_graph_data: Optional[Sequence["ExternalAssetNode"]] = None,
-        external_pipeline_datas: Optional[Sequence["ExternalPipelineData"]] = None,
+        external_job_datas: Optional[Sequence["ExternalJobData"]] = None,
         external_job_refs: Optional[Sequence["ExternalJobRef"]] = None,
         external_resource_data: Optional[Sequence["ExternalResourceData"]] = None,
         utilized_env_vars: Optional[Mapping[str, Sequence["EnvVarConsumer"]]] = None,
     ):
         return super(ExternalRepositoryData, cls).__new__(
             cls,
             name=check.str_param(name, "name"),
@@ -141,62 +141,62 @@
                 of_type=ExternalSensorData,
             ),
             external_asset_graph_data=check.opt_sequence_param(
                 external_asset_graph_data,
                 "external_asset_graph_dats",
                 of_type=ExternalAssetNode,
             ),
-            external_pipeline_datas=check.opt_nullable_sequence_param(
-                external_pipeline_datas, "external_pipeline_datas", of_type=ExternalPipelineData
+            external_job_datas=check.opt_nullable_sequence_param(
+                external_job_datas, "external_job_datas", of_type=ExternalJobData
             ),
             external_job_refs=check.opt_nullable_sequence_param(
                 external_job_refs, "external_job_refs", of_type=ExternalJobRef
             ),
             external_resource_data=check.opt_nullable_sequence_param(
                 external_resource_data, "external_resource_data", of_type=ExternalResourceData
             ),
             utilized_env_vars=check.opt_nullable_mapping_param(
                 utilized_env_vars,
                 "utilized_env_vars",
                 key_type=str,
             ),
         )
 
-    def has_pipeline_data(self):
-        return self.external_pipeline_datas is not None
+    def has_job_data(self):
+        return self.external_job_datas is not None
 
-    def get_external_pipeline_datas(self) -> Sequence["ExternalPipelineData"]:
-        if self.external_pipeline_datas is None:
+    def get_external_job_datas(self) -> Sequence["ExternalJobData"]:
+        if self.external_job_datas is None:
             check.failed("Snapshots were deferred, external_pipeline_data not loaded")
-        return self.external_pipeline_datas
+        return self.external_job_datas
 
     def get_external_job_refs(self) -> Sequence["ExternalJobRef"]:
         if self.external_job_refs is None:
             check.failed("Snapshots were not deferred, external_job_refs not loaded")
         return self.external_job_refs
 
-    def get_pipeline_snapshot(self, name):
+    def get_job_snapshot(self, name):
         check.str_param(name, "name")
-        if self.external_pipeline_datas is None:
+        if self.external_job_datas is None:
             check.failed("Snapshots were deferred, external_pipeline_data not loaded")
 
-        for external_pipeline_data in self.external_pipeline_datas:
-            if external_pipeline_data.name == name:
-                return external_pipeline_data.pipeline_snapshot
+        for external_job_data in self.external_job_datas:
+            if external_job_data.name == name:
+                return external_job_data.job_snapshot
 
         check.failed("Could not find pipeline snapshot named " + name)
 
-    def get_external_pipeline_data(self, name):
+    def get_external_job_data(self, name):
         check.str_param(name, "name")
-        if self.external_pipeline_datas is None:
+        if self.external_job_datas is None:
             check.failed("Snapshots were deferred, external_pipeline_data not loaded")
 
-        for external_pipeline_data in self.external_pipeline_datas:
-            if external_pipeline_data.name == name:
-                return external_pipeline_data
+        for external_job_data in self.external_job_datas:
+            if external_job_data.name == name:
+                return external_job_data
 
         check.failed("Could not find external pipeline data named " + name)
 
     def get_external_schedule_data(self, name):
         check.str_param(name, "name")
 
         for external_schedule_data in self.external_schedule_datas:
@@ -220,68 +220,79 @@
         for external_sensor_data in self.external_sensor_datas:
             if external_sensor_data.name == name:
                 return external_sensor_data
 
         check.failed("Could not find sensor data named " + name)
 
 
-@whitelist_for_serdes
-class ExternalPipelineSubsetResult(
+@whitelist_for_serdes(
+    storage_name="ExternalPipelineSubsetResult",
+    storage_field_names={"external_job_data": "external_pipeline_data"},
+)
+class ExternalJobSubsetResult(
     NamedTuple(
-        "_ExternalPipelineSubsetResult",
+        "_ExternalJobSubsetResult",
         [
             ("success", bool),
             ("error", Optional[SerializableErrorInfo]),
-            ("external_pipeline_data", Optional["ExternalPipelineData"]),
+            ("external_job_data", Optional["ExternalJobData"]),
         ],
     )
 ):
     def __new__(
         cls,
         success: bool,
         error: Optional[SerializableErrorInfo] = None,
-        external_pipeline_data: Optional["ExternalPipelineData"] = None,
+        external_job_data: Optional["ExternalJobData"] = None,
     ):
-        return super(ExternalPipelineSubsetResult, cls).__new__(
+        return super(ExternalJobSubsetResult, cls).__new__(
             cls,
             success=check.bool_param(success, "success"),
             error=check.opt_inst_param(error, "error", SerializableErrorInfo),
-            external_pipeline_data=check.opt_inst_param(
-                external_pipeline_data, "external_pipeline_data", ExternalPipelineData
+            external_job_data=check.opt_inst_param(
+                external_job_data, "external_job_data", ExternalJobData
             ),
         )
 
 
-@whitelist_for_serdes(old_fields={"is_job": True})
-class ExternalPipelineData(
+@whitelist_for_serdes(
+    storage_name="ExternalPipelineData",
+    storage_field_names={
+        "job_snapshot": "pipeline_snapshot",
+        "parent_job_snapshot": "parent_pipeline_snapshot",
+    },
+    # There was a period during which `JobDefinition` was a newer subclass of the legacy
+    # `PipelineDefinition`, and `is_job` was a boolean field used to distinguish between the two
+    # cases on this class.
+    old_fields={"is_job": True},
+)
+class ExternalJobData(
     NamedTuple(
-        "_ExternalPipelineData",
+        "_ExternalJobData",
         [
             ("name", str),
-            ("pipeline_snapshot", PipelineSnapshot),
+            ("job_snapshot", JobSnapshot),
             ("active_presets", Sequence["ExternalPresetData"]),
-            ("parent_pipeline_snapshot", Optional[PipelineSnapshot]),
+            ("parent_job_snapshot", Optional[JobSnapshot]),
         ],
     )
 ):
     def __new__(
         cls,
         name: str,
-        pipeline_snapshot: PipelineSnapshot,
+        job_snapshot: JobSnapshot,
         active_presets: Sequence["ExternalPresetData"],
-        parent_pipeline_snapshot: Optional[PipelineSnapshot],
+        parent_job_snapshot: Optional[JobSnapshot],
     ):
-        return super(ExternalPipelineData, cls).__new__(
+        return super(ExternalJobData, cls).__new__(
             cls,
             name=check.str_param(name, "name"),
-            pipeline_snapshot=check.inst_param(
-                pipeline_snapshot, "pipeline_snapshot", PipelineSnapshot
-            ),
-            parent_pipeline_snapshot=check.opt_inst_param(
-                parent_pipeline_snapshot, "parent_pipeline_snapshot", PipelineSnapshot
+            job_snapshot=check.inst_param(job_snapshot, "job_snapshot", JobSnapshot),
+            parent_job_snapshot=check.opt_inst_param(
+                parent_job_snapshot, "parent_job_snapshot", JobSnapshot
             ),
             active_presets=check.sequence_param(
                 active_presets, "active_presets", of_type=ExternalPresetData
             ),
         )
 
 
@@ -367,37 +378,39 @@
                 solid_selection, "solid_selection", of_type=str
             ),
             mode=check.str_param(mode, "mode"),
             tags=check.opt_mapping_param(tags, "tags", key_type=str, value_type=str),
         )
 
 
-@whitelist_for_serdes(skip_when_empty_fields={"default_status"})
+@whitelist_for_serdes(
+    storage_field_names={"job_name": "pipeline_name"}, skip_when_empty_fields={"default_status"}
+)
 class ExternalScheduleData(
     NamedTuple(
         "_ExternalScheduleData",
         [
             ("name", str),
             ("cron_schedule", Union[str, Sequence[str]]),
-            ("pipeline_name", str),
+            ("job_name", str),
             ("solid_selection", Optional[Sequence[str]]),
             ("mode", Optional[str]),
             ("environment_vars", Optional[Mapping[str, str]]),
             ("partition_set_name", Optional[str]),
             ("execution_timezone", Optional[str]),
             ("description", Optional[str]),
             ("default_status", Optional[DefaultScheduleStatus]),
         ],
     )
 ):
     def __new__(
         cls,
         name,
         cron_schedule,
-        pipeline_name,
+        job_name,
         solid_selection,
         mode,
         environment_vars,
         partition_set_name,
         execution_timezone,
         description=None,
         default_status=None,
@@ -406,15 +419,15 @@
         if not isinstance(cron_schedule, str):
             cron_schedule = check.sequence_param(cron_schedule, "cron_schedule", of_type=str)
 
         return super(ExternalScheduleData, cls).__new__(
             cls,
             name=check.str_param(name, "name"),
             cron_schedule=cron_schedule,
-            pipeline_name=check.str_param(pipeline_name, "pipeline_name"),
+            job_name=check.str_param(job_name, "job_name"),
             solid_selection=check.opt_nullable_list_param(solid_selection, "solid_selection", str),
             mode=check.opt_str_param(mode, "mode"),
             environment_vars=check.opt_dict_param(environment_vars, "environment_vars"),
             partition_set_name=check.opt_str_param(partition_set_name, "partition_set_name"),
             execution_timezone=check.opt_str_param(execution_timezone, "execution_timezone"),
             description=check.opt_str_param(description, "description"),
             # Leave default_status as None if it's STOPPED to maintain stable back-compat IDs
@@ -431,25 +444,25 @@
     def __new__(cls, error: Optional[SerializableErrorInfo]):
         return super(ExternalScheduleExecutionErrorData, cls).__new__(
             cls,
             error=check.opt_inst_param(error, "error", SerializableErrorInfo),
         )
 
 
-@whitelist_for_serdes
+@whitelist_for_serdes(storage_field_names={"job_name": "pipeline_name"})
 class ExternalTargetData(
     NamedTuple(
         "_ExternalTargetData",
-        [("pipeline_name", str), ("mode", str), ("solid_selection", Optional[Sequence[str]])],
+        [("job_name", str), ("mode", str), ("solid_selection", Optional[Sequence[str]])],
     )
 ):
-    def __new__(cls, pipeline_name: str, mode: str, solid_selection: Optional[Sequence[str]]):
+    def __new__(cls, job_name: str, mode: str, solid_selection: Optional[Sequence[str]]):
         return super(ExternalTargetData, cls).__new__(
             cls,
-            pipeline_name=check.str_param(pipeline_name, "pipeline_name"),
+            job_name=check.str_param(job_name, "job_name"),
             mode=mode,
             solid_selection=check.opt_nullable_sequence_param(
                 solid_selection, "solid_selection", str
             ),
         )
 
 
@@ -464,64 +477,65 @@
             cls,
             asset_keys=check.opt_nullable_sequence_param(
                 asset_keys, "asset_keys", of_type=AssetKey
             ),
         )
 
 
-@whitelist_for_serdes(skip_when_empty_fields={"default_status", "sensor_type"})
+@whitelist_for_serdes(
+    storage_field_names={"job_name": "pipeline_name"},
+    skip_when_empty_fields={"default_status", "sensor_type"},
+)
 class ExternalSensorData(
     NamedTuple(
         "_ExternalSensorData",
         [
             ("name", str),
-            ("pipeline_name", Optional[str]),
+            ("job_name", Optional[str]),
             ("solid_selection", Optional[Sequence[str]]),
             ("mode", Optional[str]),
             ("min_interval", Optional[int]),
             ("description", Optional[str]),
             ("target_dict", Mapping[str, ExternalTargetData]),
             ("metadata", Optional[ExternalSensorMetadata]),
             ("default_status", Optional[DefaultSensorStatus]),
             ("sensor_type", Optional[SensorType]),
         ],
     )
 ):
     def __new__(
         cls,
         name: str,
-        pipeline_name: Optional[str] = None,
+        job_name: Optional[str] = None,
         solid_selection: Optional[Sequence[str]] = None,
         mode: Optional[str] = None,
         min_interval: Optional[int] = None,
         description: Optional[str] = None,
         target_dict: Optional[Mapping[str, ExternalTargetData]] = None,
         metadata: Optional[ExternalSensorMetadata] = None,
         default_status: Optional[DefaultSensorStatus] = None,
         sensor_type: Optional[SensorType] = None,
     ):
-        if pipeline_name and not target_dict:
+        if job_name and not target_dict:
             # handle the legacy case where the ExternalSensorData was constructed from an earlier
             # version of dagster
             target_dict = {
-                pipeline_name: ExternalTargetData(
-                    pipeline_name=check.str_param(pipeline_name, "pipeline_name"),
+                job_name: ExternalTargetData(
+                    job_name=check.str_param(job_name, "job_name"),
                     mode=check.opt_str_param(mode, "mode", DEFAULT_MODE_NAME),
                     solid_selection=check.opt_nullable_sequence_param(
                         solid_selection, "solid_selection", str
                     ),
                 )
             }
 
         return super(ExternalSensorData, cls).__new__(
             cls,
             name=check.str_param(name, "name"),
-            pipeline_name=check.opt_str_param(
-                pipeline_name, "pipeline_name"
-            ),  # keep legacy field populated
+            job_name=check.opt_str_param(job_name, "job_name"),  # keep legacy field populated
             solid_selection=check.opt_nullable_sequence_param(
                 solid_selection, "solid_selection", str
             ),  # keep legacy field populated
             mode=check.opt_str_param(mode, "mode"),  # keep legacy field populated
             min_interval=check.opt_int_param(min_interval, "min_interval"),
             description=check.opt_str_param(description, "description"),
             target_dict=check.opt_mapping_param(
@@ -730,39 +744,39 @@
     ExternalPartitionsDefinitionData,
     NamedTuple("_ExternalDynamicPartitionsDefinitionData", [("name", str)]),
 ):
     def get_partitions_definition(self):
         return DynamicPartitionsDefinition(name=self.name)
 
 
-@whitelist_for_serdes
+@whitelist_for_serdes(storage_field_names={"job_name": "pipeline_name"})
 class ExternalPartitionSetData(
     NamedTuple(
         "_ExternalPartitionSetData",
         [
             ("name", str),
-            ("pipeline_name", str),
+            ("job_name", str),
             ("solid_selection", Optional[Sequence[str]]),
             ("mode", Optional[str]),
             ("external_partitions_data", Optional[ExternalPartitionsDefinitionData]),
         ],
     )
 ):
     def __new__(
         cls,
         name: str,
-        pipeline_name: str,
+        job_name: str,
         solid_selection: Optional[Sequence[str]],
         mode: Optional[str],
         external_partitions_data: Optional[ExternalPartitionsDefinitionData] = None,
     ):
         return super(ExternalPartitionSetData, cls).__new__(
             cls,
             name=check.str_param(name, "name"),
-            pipeline_name=check.str_param(pipeline_name, "pipeline_name"),
+            job_name=check.str_param(job_name, "job_name"),
             solid_selection=check.opt_nullable_sequence_param(
                 solid_selection, "solid_selection", str
             ),
             mode=check.opt_str_param(mode, "mode"),
             external_partitions_data=check.opt_inst_param(
                 external_partitions_data,
                 "external_partitions_data",
@@ -1163,59 +1177,59 @@
         for resource_req in node.get_resource_requirements(pipeline.graph):
             yield NodeHandleResourceUse(resource_req.key, handle)
     elif isinstance(node, GraphNode):
         for nested_node in node.definition.nodes:
             yield from _get_resource_usage_from_node(pipeline, nested_node, handle)
 
 
-def _get_resource_job_usage(pipelines: Sequence[JobDefinition]) -> ResourceJobUsageMap:
+def _get_resource_job_usage(job_defs: Sequence[JobDefinition]) -> ResourceJobUsageMap:
     resource_job_usage_map: Dict[str, List[ResourceJobUsageEntry]] = defaultdict(list)
 
-    for pipeline in pipelines:
-        pipeline_name = pipeline.name
-        if is_base_asset_job_name(pipeline_name):
+    for job_def in job_defs:
+        job_name = job_def.name
+        if is_base_asset_job_name(job_name):
             continue
 
         resource_usage: List[NodeHandleResourceUse] = []
-        for solid in pipeline.nodes_in_topological_order:
-            resource_usage += [use for use in _get_resource_usage_from_node(pipeline, solid)]
+        for solid in job_def.nodes_in_topological_order:
+            resource_usage += [use for use in _get_resource_usage_from_node(job_def, solid)]
         node_use_by_key: Dict[str, List[NodeHandle]] = defaultdict(list)
         for use in resource_usage:
             node_use_by_key[use.resource_key].append(use.node_handle)
         for resource_key in node_use_by_key:
             resource_job_usage_map[resource_key].append(
-                ResourceJobUsageEntry(pipeline.name, node_use_by_key[resource_key])
+                ResourceJobUsageEntry(job_def.name, node_use_by_key[resource_key])
             )
 
     return resource_job_usage_map
 
 
 def external_repository_data_from_def(
     repository_def: RepositoryDefinition,
     defer_snapshots: bool = False,
 ) -> ExternalRepositoryData:
     check.inst_param(repository_def, "repository_def", RepositoryDefinition)
 
-    pipelines = repository_def.get_all_jobs()
+    jobs = repository_def.get_all_jobs()
     if defer_snapshots:
-        pipeline_datas = None
+        job_datas = None
         job_refs = sorted(
-            list(map(external_job_ref_from_def, pipelines)),
+            list(map(external_job_ref_from_def, jobs)),
             key=lambda pd: pd.name,
         )
     else:
-        pipeline_datas = sorted(
-            list(map(external_pipeline_data_from_def, pipelines)),
+        job_datas = sorted(
+            list(map(external_job_data_from_def, jobs)),
             key=lambda pd: pd.name,
         )
         job_refs = None
 
     resource_datas = repository_def.get_top_level_resources()
     asset_graph = external_asset_graph_from_defs(
-        pipelines,
+        jobs,
         source_assets_by_key=repository_def.source_assets_by_key,
     )
 
     nested_resource_map = _get_nested_resources_map(
         resource_datas, repository_def.get_resource_key_mapping()
     )
     inverted_nested_resources_map: Dict[str, Dict[str, str]] = defaultdict(dict)
@@ -1226,15 +1240,15 @@
 
     resource_asset_usage_map: Dict[str, List[AssetKey]] = defaultdict(list)
     for asset in asset_graph:
         if asset.required_top_level_resources:
             for resource_key in asset.required_top_level_resources:
                 resource_asset_usage_map[resource_key].append(asset.asset_key)
 
-    resource_job_usage_map: ResourceJobUsageMap = _get_resource_job_usage(pipelines)
+    resource_job_usage_map: ResourceJobUsageMap = _get_resource_job_usage(jobs)
 
     return ExternalRepositoryData(
         name=repository_def.name,
         external_schedule_datas=sorted(
             list(map(external_schedule_data_from_def, repository_def.schedule_defs)),
             key=lambda sd: sd.name,
         ),
@@ -1255,15 +1269,15 @@
             [
                 external_sensor_data_from_def(sensor_def, repository_def)
                 for sensor_def in repository_def.sensor_defs
             ],
             key=lambda sd: sd.name,
         ),
         external_asset_graph_data=asset_graph,
-        external_pipeline_datas=pipeline_datas,
+        external_job_datas=job_datas,
         external_job_refs=job_refs,
         external_resource_data=sorted(
             [
                 external_resource_data_from_def(
                     res_name,
                     res_data,
                     nested_resource_map[res_name],
@@ -1282,15 +1296,15 @@
             ]
             for env_var, res_names in repository_def.get_env_vars_by_top_level_resource().items()
         },
     )
 
 
 def external_asset_graph_from_defs(
-    pipelines: Sequence[JobDefinition],
+    job_defs: Sequence[JobDefinition],
     source_assets_by_key: Mapping[AssetKey, SourceAsset],
 ) -> Sequence[ExternalAssetNode]:
     node_defs_by_asset_key: Dict[
         AssetKey, List[Tuple[NodeOutputHandle, JobDefinition]]
     ] = defaultdict(list)
     asset_info_by_asset_key: Dict[AssetKey, AssetOutputInfo] = dict()
     freshness_policy_by_asset_key: Dict[AssetKey, FreshnessPolicy] = dict()
@@ -1302,16 +1316,16 @@
     all_upstream_asset_keys: Set[AssetKey] = set()
     op_names_by_asset_key: Dict[AssetKey, Sequence[str]] = {}
     code_version_by_asset_key: Dict[AssetKey, Optional[str]] = dict()
     group_name_by_asset_key: Dict[AssetKey, str] = {}
     descriptions_by_asset_key: Dict[AssetKey, str] = {}
     atomic_execution_unit_ids_by_asset_key: Dict[AssetKey, str] = {}
 
-    for pipeline_def in pipelines:
-        asset_layer = pipeline_def.asset_layer
+    for job_def in job_defs:
+        asset_layer = job_def.asset_layer
         asset_info_by_node_output = asset_layer.asset_info_by_node_output_handle
 
         for node_output_handle, asset_info in asset_info_by_node_output.items():
             if not asset_info.is_required:
                 continue
             output_key = asset_info.key
             if output_key not in op_names_by_asset_key:
@@ -1320,15 +1334,15 @@
                     for handle in asset_layer.dependency_node_handles_by_asset_key.get(
                         output_key, []
                     )
                 ]
             code_version_by_asset_key[output_key] = asset_info.code_version
             upstream_asset_keys = asset_layer.upstream_assets_for_asset(output_key)
             all_upstream_asset_keys.update(upstream_asset_keys)
-            node_defs_by_asset_key[output_key].append((node_output_handle, pipeline_def))
+            node_defs_by_asset_key[output_key].append((node_output_handle, job_def))
             asset_info_by_asset_key[output_key] = asset_info
 
             for upstream_key in upstream_asset_keys:
                 partition_mapping = asset_layer.partition_mapping_for_node_input(
                     node_output_handle.node_handle, upstream_key
                 )
                 deps[output_key][upstream_key] = ExternalAssetDependency(
@@ -1372,18 +1386,26 @@
     ]
 
     for source_asset in source_assets_by_key.values():
         if source_asset.key not in node_defs_by_asset_key:
             job_names = (
                 [
                     job_def.name
-                    for job_def in pipelines
+                    for job_def in job_defs
                     if source_asset.key in job_def.asset_layer.source_assets_by_key
-                    and source_asset.partitions_def is None
-                    or source_asset.partitions_def == job_def.partitions_def
+                    and (
+                        # explicit source-asset observation job
+                        not job_def.asset_layer.has_assets_defs
+                        # "base asset job" will have both source and materializable assets
+                        or is_base_asset_job_name(job_def.name)
+                        and (
+                            source_asset.partitions_def is None
+                            or source_asset.partitions_def == job_def.partitions_def
+                        )
+                    )
                 ]
                 if source_asset.node_def is not None
                 else []
             )
             asset_nodes.append(
                 ExternalAssetNode(
                     asset_key=source_asset.key,
@@ -1468,32 +1490,32 @@
                 required_top_level_resources=required_top_level_resources,
             )
         )
 
     return asset_nodes
 
 
-def external_pipeline_data_from_def(pipeline_def: JobDefinition) -> ExternalPipelineData:
-    check.inst_param(pipeline_def, "pipeline_def", JobDefinition)
-    return ExternalPipelineData(
-        name=pipeline_def.name,
-        pipeline_snapshot=pipeline_def.get_pipeline_snapshot(),
-        parent_pipeline_snapshot=pipeline_def.get_parent_pipeline_snapshot(),
-        active_presets=active_presets_from_job_def(pipeline_def),
+def external_job_data_from_def(job_def: JobDefinition) -> ExternalJobData:
+    check.inst_param(job_def, "job_def", JobDefinition)
+    return ExternalJobData(
+        name=job_def.name,
+        job_snapshot=job_def.get_job_snapshot(),
+        parent_job_snapshot=job_def.get_parent_job_snapshot(),
+        active_presets=active_presets_from_job_def(job_def),
     )
 
 
-def external_job_ref_from_def(pipeline_def: JobDefinition) -> ExternalJobRef:
-    check.inst_param(pipeline_def, "pipeline_def", JobDefinition)
+def external_job_ref_from_def(job_def: JobDefinition) -> ExternalJobRef:
+    check.inst_param(job_def, "job_def", JobDefinition)
 
     return ExternalJobRef(
-        name=pipeline_def.name,
-        snapshot_id=pipeline_def.get_pipeline_snapshot_id(),
+        name=job_def.name,
+        snapshot_id=job_def.get_job_snapshot_id(),
         parent_snapshot_id=None,
-        active_presets=active_presets_from_job_def(pipeline_def),
+        active_presets=active_presets_from_job_def(job_def),
     )
 
 
 def external_resource_value_from_raw(v: Any) -> ExternalResourceValue:
     if isinstance(v, dict) and set(v.keys()) == {"env"}:
         return ExternalResourceConfigEnvVar(name=v["env"])
     return json.dumps(v)
@@ -1600,15 +1622,15 @@
 
 
 def external_schedule_data_from_def(schedule_def: ScheduleDefinition) -> ExternalScheduleData:
     check.inst_param(schedule_def, "schedule_def", ScheduleDefinition)
     return ExternalScheduleData(
         name=schedule_def.name,
         cron_schedule=schedule_def.cron_schedule,
-        pipeline_name=schedule_def.job_name,
+        job_name=schedule_def.job_name,
         solid_selection=schedule_def._target.solid_selection,  # noqa: SLF001
         mode=DEFAULT_MODE_NAME,
         environment_vars=schedule_def.environment_vars,
         partition_set_name=None,
         execution_timezone=schedule_def.execution_timezone,
         description=schedule_def.description,
         default_status=schedule_def.default_status,
@@ -1703,15 +1725,15 @@
     elif isinstance(partitions_def, MultiPartitionsDefinition):
         partitions_def_data = external_multi_partitions_definition_from_def(partitions_def)
     else:
         partitions_def_data = None
 
     return ExternalPartitionSetData(
         name=external_partition_set_name_for_job_name(job_def.name),
-        pipeline_name=job_def.name,
+        job_name=job_def.name,
         solid_selection=None,
         mode=DEFAULT_MODE_NAME,
         external_partitions_data=partitions_def_data,
     )
 
 
 EXTERNAL_PARTITION_SET_NAME_SUFFIX: Final = "_partition_set"
@@ -1734,31 +1756,31 @@
     asset_keys = None
     if isinstance(sensor_def, AssetSensorDefinition):
         asset_keys = [sensor_def.asset_key]
 
     if sensor_def.asset_selection is not None:
         target_dict = {
             base_asset_job_name: ExternalTargetData(
-                pipeline_name=base_asset_job_name, mode=DEFAULT_MODE_NAME, solid_selection=None
+                job_name=base_asset_job_name, mode=DEFAULT_MODE_NAME, solid_selection=None
             )
             for base_asset_job_name in repository_def.get_implicit_asset_job_names()
         }
     else:
         target_dict = {
-            target.pipeline_name: ExternalTargetData(
-                pipeline_name=target.pipeline_name,
+            target.job_name: ExternalTargetData(
+                job_name=target.job_name,
                 mode=DEFAULT_MODE_NAME,
                 solid_selection=target.solid_selection,
             )
             for target in sensor_def.targets
         }
 
     return ExternalSensorData(
         name=sensor_def.name,
-        pipeline_name=first_target.pipeline_name if first_target else None,
+        job_name=first_target.job_name if first_target else None,
         mode=None,
         solid_selection=first_target.solid_selection if first_target else None,
         target_dict=target_dict,
         min_interval=sensor_def.minimum_interval_seconds,
         description=sensor_def.description,
         metadata=ExternalSensorMetadata(asset_keys=asset_keys),
         default_status=sensor_def.default_status,
```

### Comparing `dagster-1.3.2/dagster/_core/host_representation/grpc_server_registry.py` & `dagster-1.3.3/dagster/_core/host_representation/grpc_server_registry.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/host_representation/grpc_server_state_subscriber.py` & `dagster-1.3.3/dagster/_core/host_representation/grpc_server_state_subscriber.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/host_representation/handle.py` & `dagster-1.3.3/dagster/_core/host_representation/handle.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import TYPE_CHECKING, Mapping, NamedTuple
 
 import dagster._check as check
-from dagster._core.definitions.selector import PipelineSelector
+from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.host_representation.origin import (
     CodeLocationOrigin,
     ExternalRepositoryOrigin,
 )
 from dagster._core.origin import RepositoryPythonOrigin
 
 if TYPE_CHECKING:
@@ -67,21 +67,21 @@
         return self.repository_handle.repository_name
 
     @property
     def location_name(self):
         return self.repository_handle.location_name
 
     def get_external_origin(self):
-        return self.repository_handle.get_external_origin().get_pipeline_origin(self.job_name)
+        return self.repository_handle.get_external_origin().get_job_origin(self.job_name)
 
     def get_python_origin(self):
-        return self.repository_handle.get_python_origin().get_pipeline_origin(self.job_name)
+        return self.repository_handle.get_python_origin().get_job_origin(self.job_name)
 
     def to_selector(self):
-        return PipelineSelector(self.location_name, self.repository_name, self.job_name, None)
+        return JobSubsetSelector(self.location_name, self.repository_name, self.job_name, None)
 
 
 class InstigatorHandle(
     NamedTuple(
         "_InstigatorHandle", [("instigator_name", str), ("repository_handle", RepositoryHandle)]
     )
 ):
```

### Comparing `dagster-1.3.2/dagster/_core/host_representation/historical.py` & `dagster-1.3.3/dagster/_core/host_representation/historical.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,49 +1,49 @@
 from typing import Optional
 
 import dagster._check as check
-from dagster._core.snap import PipelineSnapshot
+from dagster._core.snap import JobSnapshot
 
-from .pipeline_index import PipelineIndex
-from .represented import RepresentedPipeline
+from .job_index import JobIndex
+from .represented import RepresentedJob
 
 
-class HistoricalPipeline(RepresentedPipeline):
+class HistoricalJob(RepresentedJob):
     """HistoricalPipeline represents a pipeline that executed in the past
     and has been reloaded into process by querying the instance. Notably
     the user must pass in the pipeline snapshot id that was originally
     assigned to the snapshot, rather than recomputing it which could
     end up different if the schema of the snapshot has changed
     since persistence.
     """
 
     def __init__(
         self,
-        pipeline_snapshot: PipelineSnapshot,
-        identifying_pipeline_snapshot_id: str,
-        parent_pipeline_snapshot: Optional[PipelineSnapshot],
+        job_snapshot: JobSnapshot,
+        identifying_job_snapshot_id: str,
+        parent_job_snapshot: Optional[JobSnapshot],
     ):
-        self._snapshot = check.inst_param(pipeline_snapshot, "pipeline_snapshot", PipelineSnapshot)
+        self._snapshot = check.inst_param(job_snapshot, "job_snapshot", JobSnapshot)
         self._parent_snapshot = check.opt_inst_param(
-            parent_pipeline_snapshot, "parent_pipeline_snapshot", PipelineSnapshot
+            parent_job_snapshot, "parent_job_snapshot", JobSnapshot
         )
-        self._identifying_pipeline_snapshot_id = check.str_param(
-            identifying_pipeline_snapshot_id, "identifying_pipeline_snapshot_id"
+        self._identifying_job_snapshot_id = check.str_param(
+            identifying_job_snapshot_id, "identifying_job_snapshot_id"
         )
         self._index = None
 
     @property
-    def _pipeline_index(self):
+    def _job_index(self):
         if self._index is None:
-            self._index = PipelineIndex(
+            self._index = JobIndex(
                 self._snapshot,
                 self._parent_snapshot,
             )
         return self._index
 
     @property
-    def identifying_pipeline_snapshot_id(self):
-        return self._identifying_pipeline_snapshot_id
+    def identifying_job_snapshot_id(self):
+        return self._identifying_job_snapshot_id
 
     @property
-    def computed_pipeline_snapshot_id(self):
-        return self._pipeline_index.pipeline_snapshot_id
+    def computed_job_snapshot_id(self):
+        return self._job_index.job_snapshot_id
```

### Comparing `dagster-1.3.2/dagster/_core/host_representation/origin.py` & `dagster-1.3.3/dagster/_core/host_representation/origin.py`

 * *Files 3% similar despite different names*

```diff
@@ -372,44 +372,46 @@
         return create_snapshot_id(
             RepositorySelector(self.code_location_origin.location_name, self.repository_name)
         )
 
     def get_label(self) -> str:
         return f"{self.repository_name}@{self.code_location_origin.location_name}"
 
-    def get_pipeline_origin(self, pipeline_name: str) -> "ExternalPipelineOrigin":
-        return ExternalPipelineOrigin(self, pipeline_name)
+    def get_job_origin(self, job_name: str) -> "ExternalJobOrigin":
+        return ExternalJobOrigin(self, job_name)
 
     def get_instigator_origin(self, instigator_name: str) -> "ExternalInstigatorOrigin":
         return ExternalInstigatorOrigin(self, instigator_name)
 
     def get_partition_set_origin(self, partition_set_name: str) -> "ExternalPartitionSetOrigin":
         return ExternalPartitionSetOrigin(self, partition_set_name)
 
 
-@whitelist_for_serdes
-class ExternalPipelineOrigin(
+@whitelist_for_serdes(
+    storage_name="ExternalPipelineOrigin", storage_field_names={"job_name": "pipeline_name"}
+)
+class ExternalJobOrigin(
     NamedTuple(
-        "_ExternalPipelineOrigin",
-        [("external_repository_origin", ExternalRepositoryOrigin), ("pipeline_name", str)],
+        "_ExternalJobOrigin",
+        [("external_repository_origin", ExternalRepositoryOrigin), ("job_name", str)],
     )
 ):
     """Serializable representation of an ExternalPipeline that can be used to
     uniquely it or reload it in across process boundaries.
     """
 
-    def __new__(cls, external_repository_origin: ExternalRepositoryOrigin, pipeline_name: str):
-        return super(ExternalPipelineOrigin, cls).__new__(
+    def __new__(cls, external_repository_origin: ExternalRepositoryOrigin, job_name: str):
+        return super(ExternalJobOrigin, cls).__new__(
             cls,
             check.inst_param(
                 external_repository_origin,
                 "external_repository_origin",
                 ExternalRepositoryOrigin,
             ),
-            check.str_param(pipeline_name, "pipeline_name"),
+            check.str_param(job_name, "job_name"),
         )
 
     def get_id(self) -> str:
         return create_snapshot_id(self)
 
     @property
     def location_name(self) -> str:
```

### Comparing `dagster-1.3.2/dagster/_core/host_representation/pipeline_index.py` & `dagster-1.3.3/dagster/_core/host_representation/job_index.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,138 +1,131 @@
 from threading import Lock
 from typing import Any, Mapping, Optional, Sequence, Union
 
 import dagster._check as check
 from dagster._config import ConfigSchemaSnapshot
 from dagster._core.snap import (
     DependencyStructureIndex,
-    PipelineSnapshot,
-    create_pipeline_snapshot_id,
+    JobSnapshot,
+    create_job_snapshot_id,
 )
 from dagster._core.snap.dagster_types import DagsterTypeSnap
 from dagster._core.snap.mode import ModeDefSnap
 from dagster._core.snap.node import GraphDefSnap, OpDefSnap
 
 
-class PipelineIndex:
-    pipeline_snapshot: PipelineSnapshot
-    parent_pipeline_snapshot: Optional[PipelineSnapshot]
+class JobIndex:
+    job_snapshot: JobSnapshot
+    parent_job_snapshot: Optional[JobSnapshot]
     _node_defs_snaps_index: Mapping[str, Union[OpDefSnap, GraphDefSnap]]
     _dagster_type_snaps_by_name_index: Mapping[str, DagsterTypeSnap]
     dep_structure_index: DependencyStructureIndex
     _comp_dep_structures: Mapping[str, DependencyStructureIndex]
-    _pipeline_snapshot_id: Optional[str]
+    _job_snapshot_id: Optional[str]
 
     def __init__(
         self,
-        pipeline_snapshot: PipelineSnapshot,
-        parent_pipeline_snapshot: Optional[PipelineSnapshot],
+        job_snapshot: JobSnapshot,
+        parent_job_snapshot: Optional[JobSnapshot],
     ):
-        self.pipeline_snapshot = check.inst_param(
-            pipeline_snapshot, "pipeline_snapshot", PipelineSnapshot
-        )
-        self.parent_pipeline_snapshot = check.opt_inst_param(
-            parent_pipeline_snapshot, "parent_pipeline_snapshot", PipelineSnapshot
+        self.job_snapshot = check.inst_param(job_snapshot, "job_snapshot", JobSnapshot)
+        self.parent_job_snapshot = check.opt_inst_param(
+            parent_job_snapshot, "parent_job_snapshot", JobSnapshot
         )
 
-        if self.pipeline_snapshot.lineage_snapshot:
+        if self.job_snapshot.lineage_snapshot:
             check.invariant(
-                self.parent_pipeline_snapshot is not None,
-                (
-                    "Can not create PipelineIndex for pipeline_snapshot with lineage without"
-                    " parent_pipeline_snapshot"
-                ),
+                self.parent_job_snapshot is not None,
+                "Can not create JobIndex for job_snapshot with lineage without parent_job_snapshot",
             )
 
         node_def_snaps: Sequence[Union[OpDefSnap, GraphDefSnap]] = [
-            *pipeline_snapshot.node_defs_snapshot.op_def_snaps,
-            *pipeline_snapshot.node_defs_snapshot.graph_def_snaps,
+            *job_snapshot.node_defs_snapshot.op_def_snaps,
+            *job_snapshot.node_defs_snapshot.graph_def_snaps,
         ]
         self._node_defs_snaps_index = {sd.name: sd for sd in node_def_snaps}
 
         self._dagster_type_snaps_by_name_index = {
             dagster_type_snap.name: dagster_type_snap
-            for dagster_type_snap in pipeline_snapshot.dagster_type_namespace_snapshot.all_dagster_type_snaps_by_key.values()
+            for dagster_type_snap in job_snapshot.dagster_type_namespace_snapshot.all_dagster_type_snaps_by_key.values()
             if dagster_type_snap.name
         }
 
-        self.dep_structure_index = DependencyStructureIndex(
-            pipeline_snapshot.dep_structure_snapshot
-        )
+        self.dep_structure_index = DependencyStructureIndex(job_snapshot.dep_structure_snapshot)
 
         self._comp_dep_structures = {
             comp_snap.name: DependencyStructureIndex(comp_snap.dep_structure_snapshot)
-            for comp_snap in pipeline_snapshot.node_defs_snapshot.graph_def_snaps
+            for comp_snap in job_snapshot.node_defs_snapshot.graph_def_snaps
         }
 
         self._memo_lock = Lock()
-        self._pipeline_snapshot_id = None
+        self._job_snapshot_id = None
 
     @property
     def name(self) -> str:
-        return self.pipeline_snapshot.name
+        return self.job_snapshot.name
 
     @property
     def description(self) -> Optional[str]:
-        return self.pipeline_snapshot.description
+        return self.job_snapshot.description
 
     @property
     def tags(self) -> Mapping[str, Any]:
-        return self.pipeline_snapshot.tags
+        return self.job_snapshot.tags
 
     @property
     def metadata(self):
-        return self.pipeline_snapshot.metadata
+        return self.job_snapshot.metadata
 
     @property
-    def pipeline_snapshot_id(self) -> str:
+    def job_snapshot_id(self) -> str:
         with self._memo_lock:
-            if not self._pipeline_snapshot_id:
-                self._pipeline_snapshot_id = create_pipeline_snapshot_id(self.pipeline_snapshot)
-            return self._pipeline_snapshot_id
+            if not self._job_snapshot_id:
+                self._job_snapshot_id = create_job_snapshot_id(self.job_snapshot)
+            return self._job_snapshot_id
 
     def has_dagster_type_name(self, type_name: str) -> bool:
         return type_name in self._dagster_type_snaps_by_name_index
 
     def get_dagster_type_from_name(self, type_name: str) -> DagsterTypeSnap:
         return self._dagster_type_snaps_by_name_index[type_name]
 
     def get_node_def_snap(self, node_def_name: str) -> Union[OpDefSnap, GraphDefSnap]:
         check.str_param(node_def_name, "node_def_name")
         return self._node_defs_snaps_index[node_def_name]
 
-    def get_dep_structure_index(self, comp_solid_def_name: str) -> DependencyStructureIndex:
-        return self._comp_dep_structures[comp_solid_def_name]
+    def get_dep_structure_index(self, graph_def_name: str) -> DependencyStructureIndex:
+        return self._comp_dep_structures[graph_def_name]
 
     def get_dagster_type_snaps(self) -> Sequence[DagsterTypeSnap]:
-        dt_namespace = self.pipeline_snapshot.dagster_type_namespace_snapshot
+        dt_namespace = self.job_snapshot.dagster_type_namespace_snapshot
         return list(dt_namespace.all_dagster_type_snaps_by_key.values())
 
-    def has_solid_invocation(self, solid_name: str) -> bool:
-        return self.dep_structure_index.has_invocation(solid_name)
+    def has_node_invocation(self, node_name: str) -> bool:
+        return self.dep_structure_index.has_invocation(node_name)
 
     def get_default_mode_name(self) -> str:
-        return self.pipeline_snapshot.mode_def_snaps[0].name
+        return self.job_snapshot.mode_def_snaps[0].name
 
     def has_mode_def(self, name: str) -> bool:
         check.str_param(name, "name")
-        for mode_def_snap in self.pipeline_snapshot.mode_def_snaps:
+        for mode_def_snap in self.job_snapshot.mode_def_snaps:
             if mode_def_snap.name == name:
                 return True
 
         return False
 
     @property
     def available_modes(self) -> Sequence[str]:
-        return [mode_def_snap.name for mode_def_snap in self.pipeline_snapshot.mode_def_snaps]
+        return [mode_def_snap.name for mode_def_snap in self.job_snapshot.mode_def_snaps]
 
     def get_mode_def_snap(self, name: str) -> ModeDefSnap:
         check.str_param(name, "name")
-        for mode_def_snap in self.pipeline_snapshot.mode_def_snaps:
+        for mode_def_snap in self.job_snapshot.mode_def_snaps:
             if mode_def_snap.name == name:
                 return mode_def_snap
 
         check.failed(f"Mode {name} not found")
 
     @property
     def config_schema_snapshot(self) -> ConfigSchemaSnapshot:
-        return self.pipeline_snapshot.config_schema_snapshot
+        return self.job_snapshot.config_schema_snapshot
```

### Comparing `dagster-1.3.2/dagster/_core/host_representation/represented.py` & `dagster-1.3.3/dagster/_core/host_representation/represented.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,117 +1,117 @@
 from abc import ABC, abstractmethod
 from typing import AbstractSet, Optional, Sequence, Union
 
 import dagster._check as check
 from dagster._config import ConfigSchemaSnapshot
 from dagster._core.snap.dagster_types import DagsterTypeSnap
 from dagster._core.snap.dep_snapshot import DependencyStructureIndex
+from dagster._core.snap.job_snapshot import JobSnapshot
 from dagster._core.snap.mode import ModeDefSnap
 from dagster._core.snap.node import GraphDefSnap, OpDefSnap
-from dagster._core.snap.pipeline_snapshot import PipelineSnapshot
 
-from .pipeline_index import PipelineIndex
+from .job_index import JobIndex
 
 
-class RepresentedPipeline(ABC):
-    """RepresentedPipeline is a base class for ExternalPipeline or HistoricalPipeline.
+class RepresentedJob(ABC):
+    """RepresentedJob is a base class for ExternalPipeline or HistoricalPipeline.
 
-    The name is "represented" because this is an in-memory representation of a pipeline.
-    The representation of a pipeline could be referring to a pipeline resident in
-    another process *or* could be referring to a historical view of the pipeline.
+    The name is "represented" because this is an in-memory representation of a job.
+    The representation of a job could be referring to a job resident in
+    another process *or* could be referring to a historical view of the job.
     """
 
     @property
     @abstractmethod
-    def _pipeline_index(self) -> PipelineIndex:
+    def _job_index(self) -> JobIndex:
         ...
 
     @property
     def name(self) -> str:
-        return self._pipeline_index.name
+        return self._job_index.name
 
     @property
     def description(self) -> Optional[str]:
-        return self._pipeline_index.description
+        return self._job_index.description
 
     # Snapshot things
 
     @property
     @abstractmethod
-    def computed_pipeline_snapshot_id(self) -> str:
+    def computed_job_snapshot_id(self) -> str:
         pass
 
     @property
     @abstractmethod
-    def identifying_pipeline_snapshot_id(self) -> str:
+    def identifying_job_snapshot_id(self) -> str:
         pass
 
     @property
-    def pipeline_snapshot(self) -> PipelineSnapshot:
-        return self._pipeline_index.pipeline_snapshot
+    def job_snapshot(self) -> JobSnapshot:
+        return self._job_index.job_snapshot
 
     @property
-    def parent_pipeline_snapshot(self) -> Optional[PipelineSnapshot]:
-        return self._pipeline_index.parent_pipeline_snapshot
+    def parent_job_snapshot(self) -> Optional[JobSnapshot]:
+        return self._job_index.parent_job_snapshot
 
     @property
     def solid_selection(self) -> Optional[Sequence[str]]:
         return (
-            self._pipeline_index.pipeline_snapshot.lineage_snapshot.node_selection
-            if self._pipeline_index.pipeline_snapshot.lineage_snapshot
+            self._job_index.job_snapshot.lineage_snapshot.node_selection
+            if self._job_index.job_snapshot.lineage_snapshot
             else None
         )
 
     @property
     def solids_to_execute(self) -> Optional[AbstractSet[str]]:
         return (
-            self._pipeline_index.pipeline_snapshot.lineage_snapshot.nodes_to_execute
-            if self._pipeline_index.pipeline_snapshot.lineage_snapshot
+            self._job_index.job_snapshot.lineage_snapshot.nodes_to_execute
+            if self._job_index.job_snapshot.lineage_snapshot
             else None
         )
 
     # Config
 
     @property
     def config_schema_snapshot(self) -> ConfigSchemaSnapshot:
-        return self._pipeline_index.config_schema_snapshot
+        return self._job_index.config_schema_snapshot
 
     # DagsterTypes
 
     @property
     def dagster_type_snaps(self) -> Sequence[DagsterTypeSnap]:
-        return self._pipeline_index.get_dagster_type_snaps()
+        return self._job_index.get_dagster_type_snaps()
 
     def has_dagster_type_named(self, type_name: str) -> bool:
-        return self._pipeline_index.has_dagster_type_name(type_name)
+        return self._job_index.has_dagster_type_name(type_name)
 
     def get_dagster_type_by_name(self, type_name: str) -> DagsterTypeSnap:
-        return self._pipeline_index.get_dagster_type_from_name(type_name)
+        return self._job_index.get_dagster_type_from_name(type_name)
 
     # Modes
 
     @property
     def mode_def_snaps(self) -> Sequence[ModeDefSnap]:
-        return self._pipeline_index.pipeline_snapshot.mode_def_snaps
+        return self._job_index.job_snapshot.mode_def_snaps
 
     def get_mode_def_snap(self, mode_name: str) -> ModeDefSnap:
-        return self._pipeline_index.get_mode_def_snap(mode_name)
+        return self._job_index.get_mode_def_snap(mode_name)
 
     # Deps
 
     @property
     def dep_structure_index(self) -> DependencyStructureIndex:
-        return self._pipeline_index.dep_structure_index
+        return self._job_index.dep_structure_index
 
-    # Solids
-    def get_node_def_snap(self, solid_def_name: str) -> Union[OpDefSnap, GraphDefSnap]:
-        check.str_param(solid_def_name, "solid_def_name")
-        return self._pipeline_index.get_node_def_snap(solid_def_name)
-
-    def get_dep_structure_index(self, solid_def_name: str) -> DependencyStructureIndex:
-        check.str_param(solid_def_name, "solid_def_name")
-        return self._pipeline_index.get_dep_structure_index(solid_def_name)
+    # Nodes
+    def get_node_def_snap(self, node_def_name: str) -> Union[OpDefSnap, GraphDefSnap]:
+        check.str_param(node_def_name, "node_def_name")
+        return self._job_index.get_node_def_snap(node_def_name)
+
+    def get_dep_structure_index(self, node_def_name: str) -> DependencyStructureIndex:
+        check.str_param(node_def_name, "node_def_name")
+        return self._job_index.get_dep_structure_index(node_def_name)
 
     # Graph
 
     def get_graph_name(self) -> str:
-        return self._pipeline_index.pipeline_snapshot.graph_def_name
+        return self._job_index.job_snapshot.graph_def_name
```

### Comparing `dagster-1.3.2/dagster/_core/instance/__init__.py` & `dagster-1.3.3/dagster/_core/instance/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -30,30 +30,30 @@
 
 import yaml
 from typing_extensions import Protocol, Self, TypeAlias, TypeVar, runtime_checkable
 
 import dagster._check as check
 from dagster._annotations import public
 from dagster._core.definitions.events import AssetKey
-from dagster._core.definitions.pipeline_base import InMemoryPipeline
+from dagster._core.definitions.job_base import InMemoryJob
 from dagster._core.errors import (
     DagsterHomeNotSetError,
     DagsterInvalidInvocationError,
     DagsterInvariantViolationError,
     DagsterRunAlreadyExists,
     DagsterRunConflict,
 )
 from dagster._core.log_manager import DagsterLogRecord
-from dagster._core.origin import PipelinePythonOrigin
-from dagster._core.storage.pipeline_run import (
+from dagster._core.origin import JobPythonOrigin
+from dagster._core.storage.dagster_run import (
     IN_PROGRESS_RUN_STATUSES,
     DagsterRun,
+    DagsterRunStatsSnapshot,
     DagsterRunStatus,
     JobBucket,
-    PipelineRunStatsSnapshot,
     RunPartitionData,
     RunRecord,
     RunsFilter,
     TagBucket,
 )
 from dagster._core.storage.tags import (
     ASSET_PARTITION_RANGE_END_TAG,
@@ -100,32 +100,32 @@
     from dagster._core.events.log import EventLogEntry
     from dagster._core.execution.backfill import BulkActionStatus, PartitionBackfill
     from dagster._core.execution.plan.plan import ExecutionPlan
     from dagster._core.execution.plan.resume_retry import ReexecutionStrategy
     from dagster._core.execution.stats import RunStepKeyStatsSnapshot
     from dagster._core.host_representation import (
         CodeLocation,
-        ExternalPipeline,
-        ExternalPipelineOrigin,
+        ExternalJob,
+        ExternalJobOrigin,
         ExternalSensor,
-        HistoricalPipeline,
+        HistoricalJob,
     )
     from dagster._core.host_representation.external import ExternalSchedule
     from dagster._core.launcher import RunLauncher
     from dagster._core.run_coordinator import RunCoordinator
     from dagster._core.scheduler import Scheduler, SchedulerDebugInfo
     from dagster._core.scheduler.instigation import (
         InstigatorState,
         InstigatorStatus,
         InstigatorTick,
         TickData,
         TickStatus,
     )
     from dagster._core.secrets import SecretsLoader
-    from dagster._core.snap import ExecutionPlanSnapshot, PipelineSnapshot
+    from dagster._core.snap import ExecutionPlanSnapshot, JobSnapshot
     from dagster._core.storage.compute_log_manager import ComputeLogManager
     from dagster._core.storage.daemon_cursor import DaemonCursorStorage
     from dagster._core.storage.event_log import EventLogStorage
     from dagster._core.storage.event_log.base import (
         AssetRecord,
         EventLogConnection,
         EventLogRecord,
@@ -203,15 +203,15 @@
                 # Swallow user-generated log failures so that the entire step/run doesn't fail, but
                 # raise failures writing system-generated log events since they are the source of
                 # truth for the state of the run
                 raise
             elif event.run_id:
                 self._instance.report_engine_event(
                     "Exception while writing logger call to event log",
-                    pipeline_name=event.pipeline_name,
+                    job_name=event.job_name,
                     run_id=event.run_id,
                     step_key=event.step_key,
                     engine_event_data=EngineEventData(
                         error=serializable_error_info_from_exc_info(sys.exc_info()),
                     ),
                 )
 
@@ -306,15 +306,15 @@
             :py:class:`dagster._core.storage.runs.SqliteRunStorage`. Configurable in ``dagster.yaml``
             using the :py:class:`~dagster.serdes.ConfigurableClass` machinery.
         event_storage (EventLogStorage): Used to store the structured event logs generated by
             pipeline runs. By default, this will be a
             :py:class:`dagster._core.storage.event_log.SqliteEventLogStorage`. Configurable in
             ``dagster.yaml`` using the :py:class:`~dagster.serdes.ConfigurableClass` machinery.
         compute_log_manager (ComputeLogManager): The compute log manager handles stdout and stderr
-            logging for solid compute functions. By default, this will be a
+            logging for op compute functions. By default, this will be a
             :py:class:`dagster._core.storage.local_compute_log_manager.LocalComputeLogManager`.
             Configurable in ``dagster.yaml`` using the
             :py:class:`~dagster.serdes.ConfigurableClass` machinery.
         run_coordinator (RunCoordinator): A runs coordinator may be used to manage the execution
             of pipeline runs.
         run_launcher (Optional[RunLauncher]): Optionally, a run launcher may be used to enable
             a Dagster instance to launch pipeline runs, e.g. on a remote Kubernetes cluster, in
@@ -885,47 +885,47 @@
     def get_run_record_by_id(self, run_id: str) -> Optional[RunRecord]:
         records = self._run_storage.get_run_records(RunsFilter(run_ids=[run_id]))
         if not records:
             return None
         return records[0]
 
     @traced
-    def get_pipeline_snapshot(self, snapshot_id: str) -> "PipelineSnapshot":
-        return self._run_storage.get_pipeline_snapshot(snapshot_id)
+    def get_job_snapshot(self, snapshot_id: str) -> "JobSnapshot":
+        return self._run_storage.get_job_snapshot(snapshot_id)
 
     @traced
-    def has_pipeline_snapshot(self, snapshot_id: str) -> bool:
-        return self._run_storage.has_pipeline_snapshot(snapshot_id)
+    def has_job_snapshot(self, snapshot_id: str) -> bool:
+        return self._run_storage.has_job_snapshot(snapshot_id)
 
     @traced
     def has_snapshot(self, snapshot_id: str) -> bool:
         return self._run_storage.has_snapshot(snapshot_id)
 
     @traced
-    def get_historical_pipeline(self, snapshot_id: str) -> "HistoricalPipeline":
-        from dagster._core.host_representation import HistoricalPipeline
+    def get_historical_job(self, snapshot_id: str) -> "HistoricalJob":
+        from dagster._core.host_representation import HistoricalJob
 
-        snapshot = self._run_storage.get_pipeline_snapshot(snapshot_id)
+        snapshot = self._run_storage.get_job_snapshot(snapshot_id)
         parent_snapshot = (
-            self._run_storage.get_pipeline_snapshot(snapshot.lineage_snapshot.parent_snapshot_id)
+            self._run_storage.get_job_snapshot(snapshot.lineage_snapshot.parent_snapshot_id)
             if snapshot.lineage_snapshot
             else None
         )
-        return HistoricalPipeline(snapshot, snapshot_id, parent_snapshot)
+        return HistoricalJob(snapshot, snapshot_id, parent_snapshot)
 
     @traced
-    def has_historical_pipeline(self, snapshot_id: str) -> bool:
-        return self._run_storage.has_pipeline_snapshot(snapshot_id)
+    def has_historical_job(self, snapshot_id: str) -> bool:
+        return self._run_storage.has_job_snapshot(snapshot_id)
 
     @traced
     def get_execution_plan_snapshot(self, snapshot_id: str) -> "ExecutionPlanSnapshot":
         return self._run_storage.get_execution_plan_snapshot(snapshot_id)
 
     @traced
-    def get_run_stats(self, run_id: str) -> PipelineRunStatsSnapshot:
+    def get_run_stats(self, run_id: str) -> DagsterRunStatsSnapshot:
         return self._event_storage.get_stats_for_run(run_id)
 
     @traced
     def get_run_step_stats(
         self, run_id: str, step_keys: Optional[Sequence[str]] = None
     ) -> Sequence["RunStepKeyStatsSnapshot"]:
         return self._event_storage.get_step_stats_for_run(run_id, step_keys)
@@ -945,222 +945,219 @@
     def get_run_tag_keys(self) -> Sequence[str]:
         return self._run_storage.get_run_tag_keys()
 
     @traced
     def get_run_group(self, run_id: str) -> Optional[Tuple[str, Sequence[DagsterRun]]]:
         return self._run_storage.get_run_group(run_id)
 
-    def create_run_for_pipeline(
+    def create_run_for_job(
         self,
-        pipeline_def: "JobDefinition",
+        job_def: "JobDefinition",
         execution_plan: Optional["ExecutionPlan"] = None,
         run_id: Optional[str] = None,
         run_config: Optional[Mapping[str, object]] = None,
         solids_to_execute: Optional[AbstractSet[str]] = None,
         status: Optional[Union[DagsterRunStatus, str]] = None,
         tags: Optional[Mapping[str, str]] = None,
         root_run_id: Optional[str] = None,
         parent_run_id: Optional[str] = None,
         solid_selection: Optional[Sequence[str]] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
-        external_pipeline_origin: Optional["ExternalPipelineOrigin"] = None,
-        pipeline_code_origin: Optional[PipelinePythonOrigin] = None,
+        external_job_origin: Optional["ExternalJobOrigin"] = None,
+        job_code_origin: Optional[JobPythonOrigin] = None,
         repository_load_data: Optional["RepositoryLoadData"] = None,
     ) -> DagsterRun:
         from dagster._core.definitions.job_definition import JobDefinition
         from dagster._core.execution.api import create_execution_plan
         from dagster._core.execution.plan.plan import ExecutionPlan
         from dagster._core.snap import snapshot_from_execution_plan
 
-        check.inst_param(pipeline_def, "pipeline_def", JobDefinition)
+        check.inst_param(job_def, "pipeline_def", JobDefinition)
         check.opt_inst_param(execution_plan, "execution_plan", ExecutionPlan)
 
         # note that solids_to_execute is required to execute the solid subset, which is the
         # frozenset version of the previous solid_subset.
         # solid_selection is not required and will not be converted to solids_to_execute here.
         # i.e. this function doesn't handle solid queries.
         # solid_selection is only used to pass the user queries further down.
         check.opt_set_param(solids_to_execute, "solids_to_execute", of_type=str)
         check.opt_list_param(solid_selection, "solid_selection", of_type=str)
         check.opt_set_param(asset_selection, "asset_selection", of_type=AssetKey)
 
         # solids_to_execute never provided
         if asset_selection or solid_selection:
             # for cases when `create_run_for_pipeline` is directly called
-            pipeline_def = pipeline_def.get_job_def_for_subset_selection(
+            job_def = job_def.get_job_def_for_subset_selection(
                 asset_selection=asset_selection,
                 op_selection=solid_selection,
             )
         step_keys_to_execute = None
 
         if execution_plan:
             step_keys_to_execute = execution_plan.step_keys_to_execute
 
         else:
             execution_plan = create_execution_plan(
-                pipeline=InMemoryPipeline(pipeline_def),
+                job=InMemoryJob(job_def),
                 run_config=run_config,
                 instance_ref=self.get_ref() if self.is_persistent else None,
                 tags=tags,
                 repository_load_data=repository_load_data,
             )
 
         return self.create_run(
-            pipeline_name=pipeline_def.name,
+            job_name=job_def.name,
             run_id=run_id,
             run_config=run_config,
             solid_selection=solid_selection,
             asset_selection=asset_selection,
             solids_to_execute=solids_to_execute,
             step_keys_to_execute=step_keys_to_execute,
             status=DagsterRunStatus(status) if status else None,
             tags=tags,
             root_run_id=root_run_id,
             parent_run_id=parent_run_id,
-            pipeline_snapshot=pipeline_def.get_pipeline_snapshot(),
+            job_snapshot=job_def.get_job_snapshot(),
             execution_plan_snapshot=snapshot_from_execution_plan(
                 execution_plan,
-                pipeline_def.get_pipeline_snapshot_id(),
+                job_def.get_job_snapshot_id(),
             ),
-            parent_pipeline_snapshot=pipeline_def.get_parent_pipeline_snapshot(),
-            external_pipeline_origin=external_pipeline_origin,
-            pipeline_code_origin=pipeline_code_origin,
+            parent_job_snapshot=job_def.get_parent_job_snapshot(),
+            external_job_origin=external_job_origin,
+            job_code_origin=job_code_origin,
         )
 
     def _construct_run_with_snapshots(
         self,
-        pipeline_name: str,
+        job_name: str,
         run_id: str,
         run_config: Optional[Mapping[str, object]],
         solids_to_execute: Optional[AbstractSet[str]],
         step_keys_to_execute: Optional[Sequence[str]],
         status: Optional[DagsterRunStatus],
         tags: Mapping[str, str],
         root_run_id: Optional[str],
         parent_run_id: Optional[str],
-        pipeline_snapshot: Optional[PipelineSnapshot],
+        job_snapshot: Optional[JobSnapshot],
         execution_plan_snapshot: Optional[ExecutionPlanSnapshot],
-        parent_pipeline_snapshot: Optional[PipelineSnapshot],
+        parent_job_snapshot: Optional[JobSnapshot],
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
         solid_selection: Optional[Sequence[str]] = None,
-        external_pipeline_origin: Optional["ExternalPipelineOrigin"] = None,
-        pipeline_code_origin: Optional[PipelinePythonOrigin] = None,
+        external_job_origin: Optional["ExternalJobOrigin"] = None,
+        job_code_origin: Optional[JobPythonOrigin] = None,
     ) -> DagsterRun:
         # https://github.com/dagster-io/dagster/issues/2403
         if tags and IS_AIRFLOW_INGEST_PIPELINE_STR in tags:
             if AIRFLOW_EXECUTION_DATE_STR not in tags:
                 tags = {
                     **tags,
                     AIRFLOW_EXECUTION_DATE_STR: get_current_datetime_in_utc().isoformat(),
                 }
 
         check.invariant(
-            not (not pipeline_snapshot and execution_plan_snapshot),
+            not (not job_snapshot and execution_plan_snapshot),
             (
                 "It is illegal to have an execution plan snapshot and not have a pipeline snapshot."
                 " It is possible to have no execution plan snapshot since we persist runs that do"
                 " not successfully compile execution plans in the scheduled case."
             ),
         )
 
-        pipeline_snapshot_id = (
-            self._ensure_persisted_pipeline_snapshot(pipeline_snapshot, parent_pipeline_snapshot)
-            if pipeline_snapshot
+        job_snapshot_id = (
+            self._ensure_persisted_job_snapshot(job_snapshot, parent_job_snapshot)
+            if job_snapshot
             else None
         )
 
         execution_plan_snapshot_id = (
             self._ensure_persisted_execution_plan_snapshot(
-                execution_plan_snapshot, pipeline_snapshot_id, step_keys_to_execute
+                execution_plan_snapshot, job_snapshot_id, step_keys_to_execute
             )
-            if execution_plan_snapshot and pipeline_snapshot_id
+            if execution_plan_snapshot and job_snapshot_id
             else None
         )
 
         return DagsterRun(
-            pipeline_name=pipeline_name,
+            job_name=job_name,
             run_id=run_id,
             run_config=run_config,
             asset_selection=asset_selection,
             solid_selection=solid_selection,
             solids_to_execute=solids_to_execute,
             step_keys_to_execute=step_keys_to_execute,
             status=status,
             tags=tags,
             root_run_id=root_run_id,
             parent_run_id=parent_run_id,
-            pipeline_snapshot_id=pipeline_snapshot_id,
+            job_snapshot_id=job_snapshot_id,
             execution_plan_snapshot_id=execution_plan_snapshot_id,
-            external_pipeline_origin=external_pipeline_origin,
-            pipeline_code_origin=pipeline_code_origin,
+            external_job_origin=external_job_origin,
+            job_code_origin=job_code_origin,
             has_repository_load_data=execution_plan_snapshot is not None
             and execution_plan_snapshot.repository_load_data is not None,
         )
 
-    def _ensure_persisted_pipeline_snapshot(
+    def _ensure_persisted_job_snapshot(
         self,
-        pipeline_snapshot: "PipelineSnapshot",
-        parent_pipeline_snapshot: "Optional[PipelineSnapshot]",
+        job_snapshot: "JobSnapshot",
+        parent_job_snapshot: "Optional[JobSnapshot]",
     ) -> str:
-        from dagster._core.snap import PipelineSnapshot, create_pipeline_snapshot_id
+        from dagster._core.snap import JobSnapshot, create_job_snapshot_id
 
-        check.inst_param(pipeline_snapshot, "pipeline_snapshot", PipelineSnapshot)
-        check.opt_inst_param(parent_pipeline_snapshot, "parent_pipeline_snapshot", PipelineSnapshot)
+        check.inst_param(job_snapshot, "job_snapshot", JobSnapshot)
+        check.opt_inst_param(parent_job_snapshot, "parent_job_snapshot", JobSnapshot)
 
-        if pipeline_snapshot.lineage_snapshot:
-            if not self._run_storage.has_pipeline_snapshot(
-                pipeline_snapshot.lineage_snapshot.parent_snapshot_id
+        if job_snapshot.lineage_snapshot:
+            if not self._run_storage.has_job_snapshot(
+                job_snapshot.lineage_snapshot.parent_snapshot_id
             ):
                 check.invariant(
-                    create_pipeline_snapshot_id(parent_pipeline_snapshot)  # type: ignore  # (possible none)
-                    == pipeline_snapshot.lineage_snapshot.parent_snapshot_id,
+                    create_job_snapshot_id(parent_job_snapshot)  # type: ignore  # (possible none)
+                    == job_snapshot.lineage_snapshot.parent_snapshot_id,
                     "Parent pipeline snapshot id out of sync with passed parent pipeline snapshot",
                 )
 
-                returned_pipeline_snapshot_id = self._run_storage.add_pipeline_snapshot(
-                    parent_pipeline_snapshot  # type: ignore  # (possible none)
+                returned_job_snapshot_id = self._run_storage.add_job_snapshot(
+                    parent_job_snapshot  # type: ignore  # (possible none)
                 )
                 check.invariant(
-                    pipeline_snapshot.lineage_snapshot.parent_snapshot_id
-                    == returned_pipeline_snapshot_id
+                    job_snapshot.lineage_snapshot.parent_snapshot_id == returned_job_snapshot_id
                 )
 
-        pipeline_snapshot_id = create_pipeline_snapshot_id(pipeline_snapshot)
-        if not self._run_storage.has_pipeline_snapshot(pipeline_snapshot_id):
-            returned_pipeline_snapshot_id = self._run_storage.add_pipeline_snapshot(
-                pipeline_snapshot
-            )
-            check.invariant(pipeline_snapshot_id == returned_pipeline_snapshot_id)
+        job_snapshot_id = create_job_snapshot_id(job_snapshot)
+        if not self._run_storage.has_job_snapshot(job_snapshot_id):
+            returned_job_snapshot_id = self._run_storage.add_job_snapshot(job_snapshot)
+            check.invariant(job_snapshot_id == returned_job_snapshot_id)
 
-        return pipeline_snapshot_id
+        return job_snapshot_id
 
     def _ensure_persisted_execution_plan_snapshot(
         self,
         execution_plan_snapshot: "ExecutionPlanSnapshot",
-        pipeline_snapshot_id: str,
+        job_snapshot_id: str,
         step_keys_to_execute: Optional[Sequence[str]],
     ) -> str:
         from dagster._core.snap.execution_plan_snapshot import (
             ExecutionPlanSnapshot,
             create_execution_plan_snapshot_id,
         )
 
         check.inst_param(execution_plan_snapshot, "execution_plan_snapshot", ExecutionPlanSnapshot)
-        check.str_param(pipeline_snapshot_id, "pipeline_snapshot_id")
+        check.str_param(job_snapshot_id, "job_snapshot_id")
         check.opt_nullable_sequence_param(step_keys_to_execute, "step_keys_to_execute", of_type=str)
 
         check.invariant(
-            execution_plan_snapshot.pipeline_snapshot_id == pipeline_snapshot_id,
+            execution_plan_snapshot.job_snapshot_id == job_snapshot_id,
             (
                 "Snapshot mismatch: Snapshot ID in execution plan snapshot is "
                 '"{ep_pipeline_snapshot_id}" and snapshot_id created in memory is '
-                '"{pipeline_snapshot_id}"'
+                '"{job_snapshot_id}"'
             ).format(
-                ep_pipeline_snapshot_id=execution_plan_snapshot.pipeline_snapshot_id,
-                pipeline_snapshot_id=pipeline_snapshot_id,
+                ep_pipeline_snapshot_id=execution_plan_snapshot.job_snapshot_id,
+                job_snapshot_id=job_snapshot_id,
             ),
         )
 
         execution_plan_snapshot_id = create_execution_plan_snapshot_id(execution_plan_snapshot)
 
         if not self._run_storage.has_execution_plan_snapshot(execution_plan_snapshot_id):
             returned_execution_plan_snapshot_id = self._run_storage.add_execution_plan_snapshot(
@@ -1176,82 +1173,86 @@
     ) -> None:
         from dagster._core.events import (
             AssetMaterializationPlannedData,
             DagsterEvent,
             DagsterEventType,
         )
 
-        pipeline_name = dagster_run.pipeline_name
+        job_name = dagster_run.job_name
 
         for step in execution_plan_snapshot.steps:
             if step.key in execution_plan_snapshot.step_keys_to_execute:
                 for output in step.outputs:
                     asset_key = check.not_none(output.properties).asset_key
                     if asset_key:
                         # Logs and stores asset_materialization_planned event
                         partition_tag = dagster_run.tags.get(PARTITION_NAME_TAG)
                         partition_range_start, partition_range_end = dagster_run.tags.get(
                             ASSET_PARTITION_RANGE_START_TAG
                         ), dagster_run.tags.get(ASSET_PARTITION_RANGE_END_TAG)
 
-                        check.invariant(
-                            not (partition_tag and partition_range_start),
-                            "Cannot have both a partition and a partition range",
-                        )
-
-                        if partition_range_start:
-                            check.invariant(
-                                partition_range_end, "Partition range start set but not end"
+                        if partition_tag and (partition_range_start or partition_range_end):
+                            raise DagsterInvariantViolationError(
+                                f"Cannot have {ASSET_PARTITION_RANGE_START_TAG} or"
+                                f" {ASSET_PARTITION_RANGE_END_TAG} set along with"
+                                f" {PARTITION_NAME_TAG}"
                             )
+
+                        if partition_range_start or partition_range_end:
+                            if not partition_range_start or not partition_range_end:
+                                raise DagsterInvariantViolationError(
+                                    f"Cannot have {ASSET_PARTITION_RANGE_START_TAG} or"
+                                    f" {ASSET_PARTITION_RANGE_END_TAG} set without the other"
+                                )
+
                             # TODO: resolve which partitions are in the range, and emit an event for each
 
                         partition = (
                             partition_tag
                             if check.not_none(output.properties).is_asset_partitioned
                             else None
                         )
 
                         event = DagsterEvent(
                             event_type_value=DagsterEventType.ASSET_MATERIALIZATION_PLANNED.value,
-                            pipeline_name=pipeline_name,
+                            job_name=job_name,
                             message=(
-                                f"{pipeline_name} intends to materialize asset"
-                                f" {asset_key.to_string()}"
+                                f"{job_name} intends to materialize asset {asset_key.to_string()}"
                             ),
                             event_specific_data=AssetMaterializationPlannedData(
                                 asset_key, partition=partition
                             ),
                         )
                         self.report_dagster_event(event, dagster_run.run_id, logging.DEBUG)
 
     def create_run(
         self,
         *,
-        pipeline_name: str,
+        job_name: str,
         run_id: Optional[str],
         run_config: Optional[Mapping[str, object]],
         status: Optional[DagsterRunStatus],
         tags: Optional[Mapping[str, Any]],
         root_run_id: Optional[str],
         parent_run_id: Optional[str],
         step_keys_to_execute: Optional[Sequence[str]],
         execution_plan_snapshot: Optional[ExecutionPlanSnapshot],
-        pipeline_snapshot: Optional[PipelineSnapshot],
-        parent_pipeline_snapshot: Optional[PipelineSnapshot],
+        job_snapshot: Optional[JobSnapshot],
+        parent_job_snapshot: Optional[JobSnapshot],
         asset_selection: Optional[AbstractSet[AssetKey]],
         solids_to_execute: Optional[AbstractSet[str]],
         solid_selection: Optional[Sequence[str]],
-        external_pipeline_origin: Optional["ExternalPipelineOrigin"],
-        pipeline_code_origin: Optional[PipelinePythonOrigin],
+        external_job_origin: Optional["ExternalJobOrigin"],
+        job_code_origin: Optional[JobPythonOrigin],
     ) -> DagsterRun:
         from dagster._core.definitions.utils import validate_tags
-        from dagster._core.host_representation.origin import ExternalPipelineOrigin
-        from dagster._core.snap import ExecutionPlanSnapshot, PipelineSnapshot
+        from dagster._core.host_representation.origin import ExternalJobOrigin
+        from dagster._core.snap import ExecutionPlanSnapshot, JobSnapshot
 
-        check.str_param(pipeline_name, "pipeline_name")
+        check.str_param(job_name, "job_name")
         check.opt_str_param(
             run_id, "run_id"
         )  # will be assigned to make_new_run_id() lower in callstack
         check.opt_mapping_param(run_config, "run_config", key_type=str)
 
         check.opt_inst_param(status, "status", DagsterRunStatus)
         check.opt_mapping_param(tags, "tags", key_type=str)
@@ -1275,29 +1276,29 @@
                 root_run_id and parent_run_id,
                 (
                     "If root_run_id or parent_run_id is passed, this is a re-execution scenario and"
                     " root_run_id and parent_run_id must both be passed."
                 ),
             )
 
-        # The pipeline_snapshot should always be set in production scenarios. In tests
+        # The job_snapshot should always be set in production scenarios. In tests
         # we have sometimes omitted it out of convenience.
 
-        check.opt_inst_param(pipeline_snapshot, "pipeline_snapshot", PipelineSnapshot)
-        check.opt_inst_param(parent_pipeline_snapshot, "parent_pipeline_snapshot", PipelineSnapshot)
+        check.opt_inst_param(job_snapshot, "job_snapshot", JobSnapshot)
+        check.opt_inst_param(parent_job_snapshot, "parent_job_snapshot", JobSnapshot)
 
-        if parent_pipeline_snapshot:
+        if parent_job_snapshot:
             check.invariant(
-                pipeline_snapshot,
-                "If parent_pipeline_snapshot is set, pipeline_snapshot should also be.",
+                job_snapshot,
+                "If parent_job_snapshot is set, job_snapshot should also be.",
             )
 
         # solid_selection is a sequence of selection queries assigned by the user.
         # *Most* callers expand the solid_selection into an explicit set of
-        # solids_to_execute via accessing external_pipeline.solids_to_execute
+        # solids_to_execute via accessing external_job.solids_to_execute
         # but not all do. Some (launch execution mutation in graphql and backfill run
         # creation, for example) actually pass the solid *selection* into the
         # solids_to_execute parameter, but just as a frozen set, rather than
         # fully resolving the selection, as the daemon launchers do. Given the
         # state of callers we just check to ensure that the arguments are well-formed.
         #
         # asset_selection adds another dimension to this lovely dance. solid_selection
@@ -1327,82 +1328,80 @@
                 "Cannot pass both asset_selection and solids_to_execute",
             )
 
         # The "python origin" arguments exist so a job can be reconstructed in memory
         # after a DagsterRun has been fetched from the database.
         #
         # There are cases (notably in _logged_execute_job with Reconstructable jobs)
-        # where pipeline_code_origin and is not. In some cloud test cases only
-        # external_pipeline_origin is passed But they are almost always passed together.
+        # where job_code_origin and is not. In some cloud test cases only
+        # external_job_origin is passed But they are almost always passed together.
         # If these are not set the created run will never be able to be relaunched from
         # the information just in the run or in another process.
 
-        check.opt_inst_param(
-            external_pipeline_origin, "external_pipeline_origin", ExternalPipelineOrigin
-        )
-        check.opt_inst_param(pipeline_code_origin, "pipeline_code_origin", PipelinePythonOrigin)
+        check.opt_inst_param(external_job_origin, "external_job_origin", ExternalJobOrigin)
+        check.opt_inst_param(job_code_origin, "job_code_origin", JobPythonOrigin)
 
-        pipeline_run = self._construct_run_with_snapshots(
-            pipeline_name=pipeline_name,
+        dagster_run = self._construct_run_with_snapshots(
+            job_name=job_name,
             run_id=run_id,  # type: ignore  # (possible none)
             run_config=run_config,
             asset_selection=asset_selection,
             solid_selection=solid_selection,
             solids_to_execute=solids_to_execute,
             step_keys_to_execute=step_keys_to_execute,
             status=status,
             tags=validated_tags,
             root_run_id=root_run_id,
             parent_run_id=parent_run_id,
-            pipeline_snapshot=pipeline_snapshot,
+            job_snapshot=job_snapshot,
             execution_plan_snapshot=execution_plan_snapshot,
-            parent_pipeline_snapshot=parent_pipeline_snapshot,
-            external_pipeline_origin=external_pipeline_origin,
-            pipeline_code_origin=pipeline_code_origin,
+            parent_job_snapshot=parent_job_snapshot,
+            external_job_origin=external_job_origin,
+            job_code_origin=job_code_origin,
         )
 
-        pipeline_run = self._run_storage.add_run(pipeline_run)
+        dagster_run = self._run_storage.add_run(dagster_run)
 
         if execution_plan_snapshot:
-            self._log_asset_materialization_planned_events(pipeline_run, execution_plan_snapshot)
+            self._log_asset_materialization_planned_events(dagster_run, execution_plan_snapshot)
 
-        return pipeline_run
+        return dagster_run
 
     def create_reexecuted_run(
         self,
         *,
         parent_run: DagsterRun,
         code_location: "CodeLocation",
-        external_pipeline: "ExternalPipeline",
+        external_job: "ExternalJob",
         strategy: "ReexecutionStrategy",
         extra_tags: Optional[Mapping[str, Any]] = None,
         run_config: Optional[Mapping[str, Any]] = None,
         use_parent_run_tags: bool = False,
     ) -> DagsterRun:
         from dagster._core.execution.plan.resume_retry import (
             ReexecutionStrategy,
         )
         from dagster._core.execution.plan.state import KnownExecutionState
-        from dagster._core.host_representation import CodeLocation, ExternalPipeline
+        from dagster._core.host_representation import CodeLocation, ExternalJob
 
         check.inst_param(parent_run, "parent_run", DagsterRun)
         check.inst_param(code_location, "code_location", CodeLocation)
-        check.inst_param(external_pipeline, "external_pipeline", ExternalPipeline)
+        check.inst_param(external_job, "external_job", ExternalJob)
         check.inst_param(strategy, "strategy", ReexecutionStrategy)
         check.opt_mapping_param(extra_tags, "extra_tags", key_type=str)
         check.opt_mapping_param(run_config, "run_config", key_type=str)
 
         check.bool_param(use_parent_run_tags, "use_parent_run_tags")
 
         root_run_id = parent_run.root_run_id or parent_run.run_id
         parent_run_id = parent_run.run_id
 
         tags = merge_dicts(
-            external_pipeline.tags,
-            # these can differ from external_pipeline.tags if tags were added at launch time
+            external_job.tags,
+            # these can differ from external_job.tags if tags were added at launch time
             parent_run.tags if use_parent_run_tags else {},
             extra_tags or {},
             {
                 PARENT_RUN_ID_TAG: parent_run_id,
                 ROOT_RUN_ID_TAG: root_run_id,
             },
         )
@@ -1426,115 +1425,115 @@
         elif strategy == ReexecutionStrategy.ALL_STEPS:
             step_keys_to_execute = None
             known_state = None
         else:
             raise DagsterInvariantViolationError(f"Unknown reexecution strategy: {strategy}")
 
         external_execution_plan = code_location.get_external_execution_plan(
-            external_pipeline,
+            external_job,
             run_config,
             step_keys_to_execute=step_keys_to_execute,
             known_state=known_state,
             instance=self,
         )
 
         return self.create_run(
-            pipeline_name=parent_run.pipeline_name,
+            job_name=parent_run.job_name,
             run_id=None,
             run_config=run_config,
             solids_to_execute=parent_run.solids_to_execute,
             step_keys_to_execute=step_keys_to_execute,
             status=DagsterRunStatus.NOT_STARTED,
             tags=tags,
             root_run_id=root_run_id,
             parent_run_id=parent_run_id,
-            pipeline_snapshot=external_pipeline.pipeline_snapshot,
+            job_snapshot=external_job.job_snapshot,
             execution_plan_snapshot=external_execution_plan.execution_plan_snapshot,
-            parent_pipeline_snapshot=external_pipeline.parent_pipeline_snapshot,
+            parent_job_snapshot=external_job.parent_job_snapshot,
             solid_selection=parent_run.solid_selection,
             asset_selection=parent_run.asset_selection,
-            external_pipeline_origin=external_pipeline.get_external_origin(),
-            pipeline_code_origin=external_pipeline.get_python_origin(),
+            external_job_origin=external_job.get_external_origin(),
+            job_code_origin=external_job.get_python_origin(),
         )
 
     def register_managed_run(
         self,
-        pipeline_name: str,
+        job_name: str,
         run_id: str,
         run_config: Optional[Mapping[str, object]],
         solids_to_execute: Optional[AbstractSet[str]],
         step_keys_to_execute: Optional[Sequence[str]],
         tags: Mapping[str, str],
         root_run_id: Optional[str],
         parent_run_id: Optional[str],
-        pipeline_snapshot: Optional[PipelineSnapshot],
+        job_snapshot: Optional[JobSnapshot],
         execution_plan_snapshot: Optional[ExecutionPlanSnapshot],
-        parent_pipeline_snapshot: Optional[PipelineSnapshot],
+        parent_job_snapshot: Optional[JobSnapshot],
         solid_selection: Optional[Sequence[str]] = None,
-        pipeline_code_origin: Optional[PipelinePythonOrigin] = None,
+        job_code_origin: Optional[JobPythonOrigin] = None,
     ) -> DagsterRun:
         # The usage of this method is limited to dagster-airflow, specifically in Dagster
         # Operators that are executed in Airflow. Because a common workflow in Airflow is to
         # retry dags from arbitrary tasks, we need any node to be capable of creating a
-        # PipelineRun.
+        # DagsterRun.
         #
         # The try-except DagsterRunAlreadyExists block handles the race when multiple "root" tasks
-        # simultaneously execute self._run_storage.add_run(pipeline_run). When this happens, only
+        # simultaneously execute self._run_storage.add_run(dagster_run). When this happens, only
         # one task succeeds in creating the run, while the others get DagsterRunAlreadyExists
         # error; at this point, the failed tasks try again to fetch the existing run.
         # https://github.com/dagster-io/dagster/issues/2412
 
-        pipeline_run = self._construct_run_with_snapshots(
-            pipeline_name=pipeline_name,
+        dagster_run = self._construct_run_with_snapshots(
+            job_name=job_name,
             run_id=run_id,
             run_config=run_config,
             solid_selection=solid_selection,
             solids_to_execute=solids_to_execute,
             step_keys_to_execute=step_keys_to_execute,
             status=DagsterRunStatus.MANAGED,
             tags=tags,
             root_run_id=root_run_id,
             parent_run_id=parent_run_id,
-            pipeline_snapshot=pipeline_snapshot,
+            job_snapshot=job_snapshot,
             execution_plan_snapshot=execution_plan_snapshot,
-            parent_pipeline_snapshot=parent_pipeline_snapshot,
-            pipeline_code_origin=pipeline_code_origin,
+            parent_job_snapshot=parent_job_snapshot,
+            job_code_origin=job_code_origin,
         )
 
         def get_run() -> DagsterRun:
-            candidate_run = self.get_run_by_id(pipeline_run.run_id)
+            candidate_run = self.get_run_by_id(dagster_run.run_id)
 
-            field_diff = _check_run_equality(pipeline_run, candidate_run)  # type: ignore  # (possible none)
+            field_diff = _check_run_equality(dagster_run, candidate_run)  # type: ignore  # (possible none)
 
             if field_diff:
                 raise DagsterRunConflict(
                     "Found conflicting existing run with same id {run_id}. Runs differ in:"
                     "\n{field_diff}".format(
-                        run_id=pipeline_run.run_id,
+                        run_id=dagster_run.run_id,
                         field_diff=_format_field_diff(field_diff),
                     ),
                 )
             return candidate_run  # type: ignore  # (possible none)
 
-        if self.has_run(pipeline_run.run_id):
+        if self.has_run(dagster_run.run_id):
             return get_run()
 
         try:
-            return self._run_storage.add_run(pipeline_run)
+            return self._run_storage.add_run(dagster_run)
         except DagsterRunAlreadyExists:
             return get_run()
 
     @traced
-    def add_run(self, pipeline_run: DagsterRun) -> DagsterRun:
-        return self._run_storage.add_run(pipeline_run)
+    def add_run(self, dagster_run: DagsterRun) -> DagsterRun:
+        return self._run_storage.add_run(dagster_run)
 
     @traced
     def add_snapshot(
         self,
-        snapshot: Union["PipelineSnapshot", "ExecutionPlanSnapshot"],
+        snapshot: Union["JobSnapshot", "ExecutionPlanSnapshot"],
         snapshot_id: Optional[str] = None,
     ) -> None:
         return self._run_storage.add_snapshot(snapshot, snapshot_id)
 
     @traced
     def handle_run_event(self, run_id: str, event: "DagsterEvent") -> None:
         return self._run_storage.handle_run_event(run_id, event)
@@ -1859,49 +1858,49 @@
         self._event_storage.store_event(event)
 
     def handle_new_event(self, event: EventLogEntry) -> None:
         run_id = event.run_id
 
         self._event_storage.store_event(event)
 
-        if event.is_dagster_event and event.get_dagster_event().is_pipeline_event:
+        if event.is_dagster_event and event.get_dagster_event().is_job_event:
             self._run_storage.handle_run_event(run_id, event.get_dagster_event())
 
         for sub in self._subscribers[run_id]:
             sub(event)
 
     def add_event_listener(self, run_id: str, cb) -> None:
         self._subscribers[run_id].append(cb)
 
     def report_engine_event(
         self,
         message: str,
-        pipeline_run: Optional[DagsterRun] = None,
+        dagster_run: Optional[DagsterRun] = None,
         engine_event_data: Optional[EngineEventData] = None,
         cls: Optional[Type[object]] = None,
         step_key: Optional[str] = None,
-        pipeline_name: Optional[str] = None,
+        job_name: Optional[str] = None,
         run_id: Optional[str] = None,
     ) -> DagsterEvent:
-        """Report a EngineEvent that occurred outside of a pipeline execution context."""
+        """Report a EngineEvent that occurred outside of a job execution context."""
         from dagster._core.events import DagsterEvent, DagsterEventType, EngineEventData
 
         check.opt_class_param(cls, "cls")
         check.str_param(message, "message")
-        check.opt_inst_param(pipeline_run, "pipeline_run", DagsterRun)
+        check.opt_inst_param(dagster_run, "dagster_run", DagsterRun)
         check.opt_str_param(run_id, "run_id")
-        check.opt_str_param(pipeline_name, "pipeline_name")
+        check.opt_str_param(job_name, "job_name")
 
         check.invariant(
-            pipeline_run or (pipeline_name and run_id),
-            "Must include either pipeline_run or pipeline_name and run_id",
+            dagster_run or (job_name and run_id),
+            "Must include either dagster_run or job_name and run_id",
         )
 
-        run_id = run_id if run_id else pipeline_run.run_id  # type: ignore
-        pipeline_name = pipeline_name if pipeline_name else pipeline_run.pipeline_name  # type: ignore
+        run_id = run_id if run_id else dagster_run.run_id  # type: ignore
+        job_name = job_name if job_name else dagster_run.job_name  # type: ignore
 
         engine_event_data = check.opt_inst_param(
             engine_event_data,
             "engine_event_data",
             EngineEventData,
             EngineEventData({}),
         )
@@ -1911,36 +1910,36 @@
 
         log_level = logging.INFO
         if engine_event_data and engine_event_data.error:
             log_level = logging.ERROR
 
         dagster_event = DagsterEvent(
             event_type_value=DagsterEventType.ENGINE_EVENT.value,
-            pipeline_name=pipeline_name,
+            job_name=job_name,
             message=message,
             event_specific_data=engine_event_data,
             step_key=step_key,
         )
         self.report_dagster_event(dagster_event, run_id=run_id, log_level=log_level)
         return dagster_event
 
     def report_dagster_event(
         self,
         dagster_event: "DagsterEvent",
         run_id: str,
         log_level: Union[str, int] = logging.INFO,
     ) -> None:
-        """Takes a DagsterEvent and stores it in persistent storage for the corresponding PipelineRun.
+        """Takes a DagsterEvent and stores it in persistent storage for the corresponding DagsterRun.
         """
         from dagster._core.events.log import EventLogEntry
 
         event_record = EventLogEntry(
             user_message="",
             level=log_level,
-            pipeline_name=dagster_event.pipeline_name,
+            job_name=dagster_event.job_name,
             run_id=run_id,
             error_info=None,
             timestamp=time.time(),
             step_key=dagster_event.step_key,
             dagster_event=dagster_event,
         )
         self.handle_new_event(event_record)
@@ -1952,65 +1951,61 @@
         message = check.opt_str_param(
             message,
             "message",
             "Sending run termination request.",
         )
         canceling_event = DagsterEvent(
             event_type_value=DagsterEventType.PIPELINE_CANCELING.value,
-            pipeline_name=run.pipeline_name,
+            job_name=run.job_name,
             message=message,
         )
         self.report_dagster_event(canceling_event, run_id=run.run_id)
 
     def report_run_canceled(
         self,
-        pipeline_run: DagsterRun,
+        dagster_run: DagsterRun,
         message: Optional[str] = None,
     ) -> DagsterEvent:
         from dagster._core.events import DagsterEvent, DagsterEventType
 
-        check.inst_param(pipeline_run, "pipeline_run", DagsterRun)
+        check.inst_param(dagster_run, "dagster_run", DagsterRun)
 
         message = check.opt_str_param(
             message,
             "mesage",
             "This run has been marked as canceled from outside the execution context.",
         )
 
         dagster_event = DagsterEvent(
             event_type_value=DagsterEventType.PIPELINE_CANCELED.value,
-            pipeline_name=pipeline_run.pipeline_name,
+            job_name=dagster_run.job_name,
             message=message,
         )
-        self.report_dagster_event(
-            dagster_event, run_id=pipeline_run.run_id, log_level=logging.ERROR
-        )
+        self.report_dagster_event(dagster_event, run_id=dagster_run.run_id, log_level=logging.ERROR)
         return dagster_event
 
     def report_run_failed(
-        self, pipeline_run: DagsterRun, message: Optional[str] = None
+        self, dagster_run: DagsterRun, message: Optional[str] = None
     ) -> DagsterEvent:
         from dagster._core.events import DagsterEvent, DagsterEventType
 
-        check.inst_param(pipeline_run, "pipeline_run", DagsterRun)
+        check.inst_param(dagster_run, "dagster_run", DagsterRun)
 
         message = check.opt_str_param(
             message,
             "message",
             "This run has been marked as failed from outside the execution context.",
         )
 
         dagster_event = DagsterEvent(
             event_type_value=DagsterEventType.PIPELINE_FAILURE.value,
-            pipeline_name=pipeline_run.pipeline_name,
+            job_name=dagster_run.job_name,
             message=message,
         )
-        self.report_dagster_event(
-            dagster_event, run_id=pipeline_run.run_id, log_level=logging.ERROR
-        )
+        self.report_dagster_event(dagster_event, run_id=dagster_run.run_id, log_level=logging.ERROR)
         return dagster_event
 
     # directories
 
     def file_manager_directory(self, run_id: str) -> str:
         return self._local_artifact_storage.file_manager_dir(run_id)
 
@@ -2031,31 +2026,31 @@
         ``DagsterInstance.create_run()``) *before* this method is called, and
         should be in the ``PipelineRunStatus.NOT_STARTED`` state. They also must have a non-null
         ExternalPipelineOrigin.
 
         Args:
             run_id (str): The id of the run.
         """
-        from dagster._core.host_representation import ExternalPipelineOrigin
+        from dagster._core.host_representation import ExternalJobOrigin
         from dagster._core.run_coordinator import SubmitRunContext
 
         run = self.get_run_by_id(run_id)
         if run is None:
             raise DagsterInvariantViolationError(
                 f"Could not load run {run_id} that was passed to submit_run"
             )
 
         check.inst(
-            run.external_pipeline_origin,
-            ExternalPipelineOrigin,
+            run.external_job_origin,
+            ExternalJobOrigin,
             "External pipeline origin must be set for submitted runs",
         )
         check.inst(
-            run.pipeline_code_origin,
-            PipelinePythonOrigin,
+            run.job_code_origin,
+            JobPythonOrigin,
             "Python origin must be set for submitted runs",
         )
 
         try:
             submitted_run = self._run_coordinator.submit_run(
                 SubmitRunContext(run, workspace=workspace)
             )
@@ -2095,15 +2090,15 @@
         if run is None:
             raise DagsterInvariantViolationError(
                 f"Could not load run {run_id} that was passed to launch_run"
             )
 
         launch_started_event = DagsterEvent(
             event_type_value=DagsterEventType.PIPELINE_STARTING.value,
-            pipeline_name=run.pipeline_name,
+            job_name=run.job_name,
         )
         self.report_dagster_event(launch_started_event, run_id=run.run_id)
 
         run = self.get_run_by_id(run_id)
         if run is None:
             check.failed(f"Failed to reload run {run_id}")
```

### Comparing `dagster-1.3.2/dagster/_core/instance/config.py` & `dagster-1.3.3/dagster/_core/instance/config.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/instance/ref.py` & `dagster-1.3.3/dagster/_core/instance/ref.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/instance_for_test.py` & `dagster-1.3.3/dagster/_core/instance_for_test.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/launcher/base.py` & `dagster-1.3.3/dagster/_core/launcher/base.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,39 +1,39 @@
 from abc import ABC, abstractmethod
 from enum import Enum
 from typing import NamedTuple, Optional
 
 from dagster._core.instance import MayHaveInstanceWeakref, T_DagsterInstance
-from dagster._core.origin import PipelinePythonOrigin
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.origin import JobPythonOrigin
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._core.workspace.workspace import IWorkspace
 from dagster._serdes import whitelist_for_serdes
 
 
 class LaunchRunContext(NamedTuple):
     """Context available within a run launcher's launch_run call."""
 
     dagster_run: DagsterRun
     workspace: Optional[IWorkspace]
 
     @property
-    def pipeline_code_origin(self) -> Optional[PipelinePythonOrigin]:
-        return self.dagster_run.pipeline_code_origin
+    def job_code_origin(self) -> Optional[JobPythonOrigin]:
+        return self.dagster_run.job_code_origin
 
 
 class ResumeRunContext(NamedTuple):
     """Context available within a run launcher's resume_run call."""
 
     dagster_run: DagsterRun
     workspace: Optional[IWorkspace]
     resume_attempt_number: Optional[int] = None
 
     @property
-    def pipeline_code_origin(self) -> Optional[PipelinePythonOrigin]:
-        return self.dagster_run.pipeline_code_origin
+    def job_code_origin(self) -> Optional[JobPythonOrigin]:
+        return self.dagster_run.job_code_origin
 
 
 @whitelist_for_serdes
 class WorkerStatus(Enum):
     RUNNING = "RUNNING"
     NOT_FOUND = "NOT_FOUND"
     FAILED = "FAILED"
```

### Comparing `dagster-1.3.2/dagster/_core/launcher/default_run_launcher.py` & `dagster-1.3.3/dagster/_core/launcher/default_run_launcher.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,29 +1,33 @@
 import time
-from typing import Any, Mapping, Optional, cast
+from typing import TYPE_CHECKING, Any, Mapping, Optional, cast
 
 from typing_extensions import Self
 
 import dagster._seven as seven
 from dagster import (
     _check as check,
 )
 from dagster._config.config_schema import UserConfigSchema
 from dagster._core.errors import DagsterInvariantViolationError, DagsterLaunchFailedError
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._core.storage.tags import GRPC_INFO_TAG
 from dagster._serdes import (
     ConfigurableClass,
     deserialize_value,
 )
 from dagster._serdes.config_class import ConfigurableClassData
 from dagster._utils.merger import merge_dicts
 
 from .base import LaunchRunContext, RunLauncher
 
+if TYPE_CHECKING:
+    from dagster._core.instance import DagsterInstance
+    from dagster._grpc.client import DagsterGrpcClient
+
 
 # note: this class is a top level export, so we defer many imports til use for performance
 class DefaultRunLauncher(RunLauncher, ConfigurableClass):
     """Launches runs against running GRPC servers."""
 
     def __init__(
         self,
@@ -46,17 +50,19 @@
     @classmethod
     def from_config_value(
         cls, inst_data: ConfigurableClassData, config_value: Mapping[str, Any]
     ) -> Self:
         return DefaultRunLauncher(inst_data=inst_data)
 
     @staticmethod
-    def launch_run_from_grpc_client(instance, run, grpc_client):
+    def launch_run_from_grpc_client(
+        instance: "DagsterInstance", run: DagsterRun, grpc_client: "DagsterGrpcClient"
+    ):
         # defer for perf
-        from dagster._grpc.types import ExecuteExternalPipelineArgs, StartRunResult
+        from dagster._grpc.types import ExecuteExternalJobArgs, StartRunResult
 
         instance.add_run_tags(
             run.run_id,
             {
                 GRPC_INFO_TAG: seven.json.dumps(
                     merge_dicts(
                         {"host": grpc_client.host},
@@ -69,21 +75,21 @@
                     )
                 )
             },
         )
 
         res = deserialize_value(
             grpc_client.start_run(
-                ExecuteExternalPipelineArgs(
-                    pipeline_origin=run.external_pipeline_origin,
-                    pipeline_run_id=run.run_id,
+                ExecuteExternalJobArgs(
+                    job_origin=run.external_job_origin,  # type: ignore  # (possible none)
+                    run_id=run.run_id,
                     instance_ref=instance.get_ref(),
                 )
             ),
-            StartRunResult,
+            StartRunResult,  # type: ignore
         )
         if not res.success:
             raise (
                 DagsterLaunchFailedError(
                     res.message, serializable_error_info=res.serializable_error_info
                 )
             )
@@ -99,17 +105,17 @@
         check.inst_param(run, "run", DagsterRun)
 
         if not context.workspace:
             raise DagsterInvariantViolationError(
                 "DefaultRunLauncher requires a workspace to be included in its LaunchRunContext"
             )
 
-        external_pipeline_origin = check.not_none(run.external_pipeline_origin)
+        external_job_origin = check.not_none(run.external_job_origin)
         code_location = context.workspace.get_code_location(
-            external_pipeline_origin.external_repository_origin.code_location_origin.location_name
+            external_job_origin.external_repository_origin.code_location_origin.location_name
         )
 
         check.inst(
             code_location,
             GrpcServerCodeLocation,
             "DefaultRunLauncher: Can't launch runs for pipeline not loaded from a GRPC server",
         )
@@ -158,15 +164,15 @@
             return False
 
         client = self._get_grpc_client_for_termination(run_id)
 
         if not client:
             self._instance.report_engine_event(
                 message="Unable to get grpc client to send termination request to.",
-                pipeline_run=run,
+                dagster_run=run,
                 cls=self.__class__,
             )
             return False
 
         self._instance.report_run_canceling(run)
         res = deserialize_value(
             client.cancel_execution(CancelExecutionRequest(run_id=run_id)), CancelExecutionResult
```

### Comparing `dagster-1.3.2/dagster/_core/launcher/sync_in_memory_run_launcher.py` & `dagster-1.3.3/dagster/_core/launcher/sync_in_memory_run_launcher.py`

 * *Files 14% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 
 import dagster._check as check
 from dagster._config.config_schema import UserConfigSchema
 from dagster._core.execution.api import execute_run
 from dagster._core.launcher import LaunchRunContext, RunLauncher
 from dagster._serdes import ConfigurableClass
 from dagster._serdes.config_class import ConfigurableClassData
-from dagster._utils.hosted_user_process import recon_pipeline_from_origin
+from dagster._utils.hosted_user_process import recon_job_from_origin
 
 
 class SyncInMemoryRunLauncher(RunLauncher, ConfigurableClass):
     """This run launcher launches runs synchronously, in memory, and is intended only for test.
 
     Use the :py:class:`dagster.DefaultRunLauncher`.
     """
@@ -35,12 +35,12 @@
     @classmethod
     def from_config_value(
         cls, inst_data: ConfigurableClassData, config_value: Mapping[str, Any]
     ) -> Self:
         return SyncInMemoryRunLauncher(inst_data=inst_data)
 
     def launch_run(self, context: LaunchRunContext) -> None:
-        recon_pipeline = recon_pipeline_from_origin(context.pipeline_code_origin)  # type: ignore
-        execute_run(recon_pipeline, context.dagster_run, self._instance)
+        recon_job = recon_job_from_origin(context.job_code_origin)  # type: ignore
+        execute_run(recon_job, context.dagster_run, self._instance)
 
     def terminate(self, run_id):
         check.not_implemented("Termination not supported.")
```

### Comparing `dagster-1.3.2/dagster/_core/log_manager.py` & `dagster-1.3.3/dagster/_core/log_manager.py`

 * *Files 3% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 import datetime
 import logging
 from typing import TYPE_CHECKING, Any, Mapping, NamedTuple, Optional, Sequence, Union, cast
 
 from typing_extensions import Protocol
 
 import dagster._check as check
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._core.utils import coerce_valid_log_level, make_new_run_id
 from dagster._utils.log import get_dagster_logger
 
 if TYPE_CHECKING:
     from dagster import DagsterInstance
     from dagster._core.events import DagsterEvent
 
@@ -104,61 +104,61 @@
 
 
 class DagsterLoggingMetadata(
     NamedTuple(
         "_DagsterLoggingMetadata",
         [
             ("run_id", Optional[str]),
-            ("pipeline_name", Optional[str]),
-            ("pipeline_tags", Mapping[str, str]),
+            ("job_name", Optional[str]),
+            ("job_tags", Mapping[str, str]),
             ("step_key", Optional[str]),
-            ("solid_name", Optional[str]),
+            ("op_name", Optional[str]),
             ("resource_name", Optional[str]),
             ("resource_fn_name", Optional[str]),
         ],
     )
 ):
     """Internal class used to represent the context in which a given message was logged (i.e. the
     step, pipeline run, resource, etc.).
     """
 
     def __new__(
         cls,
         run_id: Optional[str] = None,
-        pipeline_name: Optional[str] = None,
-        pipeline_tags: Optional[Mapping[str, str]] = None,
+        job_name: Optional[str] = None,
+        job_tags: Optional[Mapping[str, str]] = None,
         step_key: Optional[str] = None,
-        solid_name: Optional[str] = None,
+        op_name: Optional[str] = None,
         resource_name: Optional[str] = None,
         resource_fn_name: Optional[str] = None,
     ):
         return super().__new__(
             cls,
             run_id=run_id,
-            pipeline_name=pipeline_name,
-            pipeline_tags=pipeline_tags or {},
+            job_name=job_name,
+            job_tags=job_tags or {},
             step_key=step_key,
-            solid_name=solid_name,
+            op_name=op_name,
             resource_name=resource_name,
             resource_fn_name=resource_fn_name,
         )
 
     @property
     def log_source(self) -> str:
         if self.resource_name is None:
-            return self.pipeline_name or "system"
+            return self.job_name or "system"
         return f"resource:{self.resource_name}"
 
     def all_tags(self) -> Mapping[str, str]:
         # converts all values into strings
         return {k: str(v) for k, v in self._asdict().items()}
 
     def event_tags(self) -> Mapping[str, str]:
         # Exclude pipeline_tags since it can be quite large and can be found on the run
-        return {k: str(v) for k, v in self._asdict().items() if k != "pipeline_tags"}
+        return {k: str(v) for k, v in self._asdict().items() if k != "job_tags"}
 
 
 def construct_log_string(
     logging_metadata: DagsterLoggingMetadata, message_props: DagsterMessageProps
 ) -> str:
     from dagster._core.events import EVENT_TYPE_VALUE_TO_DISPLAY_STRING
 
@@ -362,16 +362,16 @@
                 # set all loggers to the declared logging level
                 for logger in managed_loggers:
                     logger.setLevel(python_log_level)
 
         if dagster_run:
             logging_metadata = DagsterLoggingMetadata(
                 run_id=dagster_run.run_id,
-                pipeline_name=dagster_run.pipeline_name,
-                pipeline_tags=dagster_run.tags,
+                job_name=dagster_run.job_name,
+                job_tags=dagster_run.tags,
             )
         else:
             logging_metadata = DagsterLoggingMetadata()
 
         return cls(
             dagster_handler=DagsterLogHandler(
                 logging_metadata=logging_metadata,
```

### Comparing `dagster-1.3.2/dagster/_core/nux.py` & `dagster-1.3.3/dagster/_core/nux.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/origin.py` & `dagster-1.3.3/dagster/_core/origin.py`

 * *Files 10% similar despite different names*

```diff
@@ -63,33 +63,36 @@
                 else None
             ),
         )
 
     def get_id(self) -> str:
         return create_snapshot_id(self)
 
-    def get_pipeline_origin(self, pipeline_name: str) -> "PipelinePythonOrigin":
-        check.str_param(pipeline_name, "pipeline_name")
-        return PipelinePythonOrigin(pipeline_name, self)
+    def get_job_origin(self, job_name: str) -> "JobPythonOrigin":
+        check.str_param(job_name, "pipeline_name")
+        return JobPythonOrigin(job_name, self)
 
 
-@whitelist_for_serdes
-class PipelinePythonOrigin(
+@whitelist_for_serdes(
+    storage_name="PipelinePythonOrigin",
+    storage_field_names={"job_name": "pipeline_name"},
+)
+class JobPythonOrigin(
     NamedTuple(
-        "_PipelinePythonOrigin",
+        "_JobPythonOrigin",
         [
-            ("pipeline_name", str),
+            ("job_name", str),
             ("repository_origin", RepositoryPythonOrigin),
         ],
     )
 ):
-    def __new__(cls, pipeline_name: str, repository_origin: RepositoryPythonOrigin):
-        return super(PipelinePythonOrigin, cls).__new__(
+    def __new__(cls, job_name: str, repository_origin: RepositoryPythonOrigin):
+        return super(JobPythonOrigin, cls).__new__(
             cls,
-            check.str_param(pipeline_name, "pipeline_name"),
+            check.str_param(job_name, "job_name"),
             check.inst_param(repository_origin, "repository_origin", RepositoryPythonOrigin),
         )
 
     def get_id(self) -> str:
         return create_snapshot_id(self)
 
     @property
```

### Comparing `dagster-1.3.2/dagster/_core/run_coordinator/base.py` & `dagster-1.3.3/dagster/_core/run_coordinator/base.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,22 +1,26 @@
 from abc import ABC, abstractmethod
-from typing import NamedTuple, Optional
+from typing import TYPE_CHECKING, NamedTuple, Optional
 
 from dagster._core.instance import MayHaveInstanceWeakref, T_DagsterInstance
-from dagster._core.storage.pipeline_run import DagsterRun
-from dagster._core.workspace.context import IWorkspace, WorkspaceRequestContext
+from dagster._core.storage.dagster_run import DagsterRun
+
+if TYPE_CHECKING:
+    from dagster._core.workspace.context import IWorkspace
 
 
 class SubmitRunContext(NamedTuple):
     """Context available within a run coordinator's submit_run method."""
 
-    pipeline_run: DagsterRun
-    workspace: IWorkspace
+    dagster_run: DagsterRun
+    workspace: "IWorkspace"
 
     def get_request_header(self, key: str) -> Optional[str]:
+        from dagster._core.workspace.context import WorkspaceRequestContext
+
         # if there is a source
         if isinstance(self.workspace, WorkspaceRequestContext) and self.workspace.source:
             headers = getattr(self.workspace.source, "headers", None)
             # and it has a headers property
             if headers:
                 # do a get against it
                 return headers.get(key)
```

### Comparing `dagster-1.3.2/dagster/_core/run_coordinator/default_run_coordinator.py` & `dagster-1.3.3/dagster/_core/run_coordinator/default_run_coordinator.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import logging
 from typing import Mapping, Optional
 
 from typing_extensions import Self
 
 import dagster._check as check
 from dagster._config.config_schema import UserConfigSchema
-from dagster._core.storage.pipeline_run import DagsterRun, DagsterRunStatus
+from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus
 from dagster._serdes import ConfigurableClass, ConfigurableClassData
 
 from .base import RunCoordinator, SubmitRunContext
 
 
 class DefaultRunCoordinator(RunCoordinator, ConfigurableClass):
     """Immediately send runs to the run launcher."""
@@ -30,24 +30,24 @@
     @classmethod
     def from_config_value(
         cls, inst_data: Optional[ConfigurableClassData], config_value: Mapping[str, object]
     ) -> Self:
         return cls(inst_data=inst_data, **config_value)
 
     def submit_run(self, context: SubmitRunContext) -> DagsterRun:
-        pipeline_run = context.pipeline_run
+        dagster_run = context.dagster_run
 
-        if pipeline_run.status == DagsterRunStatus.NOT_STARTED:
-            self._instance.launch_run(pipeline_run.run_id, context.workspace)
+        if dagster_run.status == DagsterRunStatus.NOT_STARTED:
+            self._instance.launch_run(dagster_run.run_id, context.workspace)
         else:
             self._logger.warning(
-                f"submit_run called for run {pipeline_run.run_id} with status "
-                f"{pipeline_run.status.value}, skipping launch."
+                f"submit_run called for run {dagster_run.run_id} with status "
+                f"{dagster_run.status.value}, skipping launch."
             )
 
-        run = self._instance.get_run_by_id(pipeline_run.run_id)
+        run = self._instance.get_run_by_id(dagster_run.run_id)
         if run is None:
-            check.failed(f"Failed to reload run {pipeline_run.run_id}")
+            check.failed(f"Failed to reload run {dagster_run.run_id}")
         return run
 
     def cancel_run(self, run_id: str) -> bool:
         return self._instance.run_launcher.terminate(run_id)
```

### Comparing `dagster-1.3.2/dagster/_core/run_coordinator/queued_run_coordinator.py` & `dagster-1.3.3/dagster/_core/run_coordinator/queued_run_coordinator.py`

 * *Files 6% similar despite different names*

```diff
@@ -10,15 +10,15 @@
     String,
     _check as check,
 )
 from dagster._builtins import Bool
 from dagster._config import Array, Field, Noneable, ScalarUnion, Shape
 from dagster._config.config_schema import UserConfigSchema
 from dagster._core.instance import T_DagsterInstance
-from dagster._core.storage.pipeline_run import DagsterRun, DagsterRunStatus
+from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus
 from dagster._serdes import ConfigurableClass, ConfigurableClassData
 
 from .base import RunCoordinator, SubmitRunContext
 
 
 class RunQueueConfig(
     NamedTuple(
@@ -220,32 +220,32 @@
             dequeue_use_threads=config_value.get("dequeue_use_threads"),
             dequeue_num_workers=config_value.get("dequeue_num_workers"),
             max_user_code_failure_retries=config_value.get("max_user_code_failure_retries"),
             user_code_failure_retry_delay=config_value.get("user_code_failure_retry_delay"),
         )
 
     def submit_run(self, context: SubmitRunContext) -> DagsterRun:
-        pipeline_run = context.pipeline_run
+        dagster_run = context.dagster_run
 
-        if pipeline_run.status == DagsterRunStatus.NOT_STARTED:
+        if dagster_run.status == DagsterRunStatus.NOT_STARTED:
             enqueued_event = DagsterEvent(
                 event_type_value=DagsterEventType.PIPELINE_ENQUEUED.value,
-                pipeline_name=pipeline_run.pipeline_name,
+                job_name=dagster_run.job_name,
             )
-            self._instance.report_dagster_event(enqueued_event, run_id=pipeline_run.run_id)
+            self._instance.report_dagster_event(enqueued_event, run_id=dagster_run.run_id)
         else:
             # the run was already submitted, this is a no-op
             self._logger.warning(
-                f"submit_run called for run {pipeline_run.run_id} with status "
-                f"{pipeline_run.status.value}, skipping enqueue."
+                f"submit_run called for run {dagster_run.run_id} with status "
+                f"{dagster_run.status.value}, skipping enqueue."
             )
 
-        run = self._instance.get_run_by_id(pipeline_run.run_id)
+        run = self._instance.get_run_by_id(dagster_run.run_id)
         if run is None:
-            check.failed(f"Failed to reload run {pipeline_run.run_id}")
+            check.failed(f"Failed to reload run {dagster_run.run_id}")
         return run
 
     def cancel_run(self, run_id: str) -> bool:
         run = self._instance.get_run_by_id(run_id)
         if not run:
             return False
         # NOTE: possible race condition if the dequeuer acts on this run at the same time
```

### Comparing `dagster-1.3.2/dagster/_core/scheduler/__init__.py` & `dagster-1.3.3/dagster/_core/scheduler/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/scheduler/execution.py` & `dagster-1.3.3/dagster/_core/scheduler/execution.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/scheduler/instigation.py` & `dagster-1.3.3/dagster/_core/scheduler/instigation.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/scheduler/scheduler.py` & `dagster-1.3.3/dagster/_core/scheduler/scheduler.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/secrets/env_file.py` & `dagster-1.3.3/dagster/_core/secrets/env_file.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/selector/subset_selector.py` & `dagster-1.3.3/dagster/_core/selector/subset_selector.py`

 * *Files 1% similar despite different names*

```diff
@@ -126,19 +126,19 @@
             )
             for upstream_key in upstream_asset_keys:
                 upstream[asset_key].add(upstream_key)
                 downstream[upstream_key] = downstream.get(upstream_key, set()) | {asset_key}
     return {"upstream": upstream, "downstream": downstream}
 
 
-def generate_dep_graph(pipeline_def: "JobDefinition") -> DependencyGraph[str]:
+def generate_dep_graph(job_def: "JobDefinition") -> DependencyGraph[str]:
     """Pipeline to dependency graph. It currently only supports top-level solids.
 
     Args:
-        pipeline (PipelineDefinition): The pipeline to execute.
+        pipeline (JobDefinition): The pipeline to execute.
 
     Returns:
         graph (Dict[str, Dict[str, Set[str]]]): the input and output dependency graph. e.g.
             ```
             {
                 "upstream": {
                     "solid_one_1": set(),
@@ -152,17 +152,17 @@
                     "solid_two": {"solid_three"},
                     "solid_three": set(),
                 },
             }
             ```
     """
     dependency_structure = check.inst_param(
-        pipeline_def.dependency_structure, "dependency_structure", DependencyStructure
+        job_def.dependency_structure, "dependency_structure", DependencyStructure
     )
-    item_names = [i.name for i in pipeline_def.nodes]
+    item_names = [i.name for i in job_def.nodes]
 
     # defaultdict isn't appropriate because we also want to include items without dependencies
     graph: Dict[Direction, Dict[str, MutableSet[str]]] = {"upstream": {}, "downstream": {}}
     for item_name in item_names:
         graph["upstream"][item_name] = set()
         upstream_dep = dependency_structure.input_to_upstream_outputs_for_node(item_name)
         for upstreams in upstream_dep.values():
@@ -404,15 +404,15 @@
     return {
         top_level_op: SELECTION_TREE_LEAF_NODE
         for top_level_op in parse_solid_selection(job_def, op_selection)
     }
 
 
 def parse_solid_selection(
-    pipeline_def: "JobDefinition",
+    job_def: "JobDefinition",
     solid_selection: Sequence[str],
 ) -> FrozenSet[str]:
     """Take pipeline definition and a list of solid selection queries (inlcuding names of solid
         invocations. See syntax examples below) and return a set of the qualified solid names.
 
     It currently only supports top-level solids.
 
@@ -425,29 +425,29 @@
     - "some_solid+++": select "some_solid" and its descendants within 3 levels down
 
     Note:
     - If one of the query clauses is invalid, we will skip that one and continue to parse the valid
         ones.
 
     Args:
-        pipeline_def (PipelineDefinition): the pipeline to execute.
+        pipeline_def (JobDefinition): the pipeline to execute.
         solid_selection (List[str]): a list of the solid selection queries (including single solid
             names) to execute.
 
     Returns:
         FrozenSet[str]: a frozenset of qualified deduplicated solid names, empty if no qualified
             subset selected.
     """
     check.sequence_param(solid_selection, "solid_selection", of_type=str)
 
     # special case: select all
     if len(solid_selection) == 1 and solid_selection[0] == "*":
-        return frozenset(pipeline_def.graph.node_names())
+        return frozenset(job_def.graph.node_names())
 
-    graph = generate_dep_graph(pipeline_def)
+    graph = generate_dep_graph(job_def)
     solids_set: Set[str] = set()
 
     # loop over clauses
     for clause in solid_selection:
         subset = clause_to_subset(graph, clause, lambda x: x)
         if len(subset) == 0:
             raise DagsterInvalidSubsetError(
```

### Comparing `dagster-1.3.2/dagster/_core/snap/__init__.py` & `dagster-1.3.3/dagster/_core/snap/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 """This module contains serializable classes that contain all the meta information
 in our definitions and type systems. The purpose is to be able to represent
-user-defined code artifacts (e.g. Pipelines Solids) in a serializable format
+user-defined code artifacts (e.g. jobs, ops) in a serializable format
 so that they can be persisted and manipulated in remote processes.
 
 This will have a number of uses, but the most immediately germane are:
 
 1) Persist *historical* pipeline and repository structures. This
 will enable, in the short term, for the user to be able to go to a historical
 run and view the meta information at that point in time.
@@ -49,21 +49,21 @@
     ExecutionPlanSnapshot as ExecutionPlanSnapshot,
     ExecutionStepInputSnap as ExecutionStepInputSnap,
     ExecutionStepOutputSnap as ExecutionStepOutputSnap,
     ExecutionStepSnap as ExecutionStepSnap,
     create_execution_plan_snapshot_id as create_execution_plan_snapshot_id,
     snapshot_from_execution_plan as snapshot_from_execution_plan,
 )
+from .job_snapshot import (
+    JobSnapshot as JobSnapshot,
+    create_job_snapshot_id as create_job_snapshot_id,
+)
 from .mode import (
     LoggerDefSnap as LoggerDefSnap,
     ModeDefSnap as ModeDefSnap,
     ResourceDefSnap as ResourceDefSnap,
 )
 from .node import (
     GraphDefSnap as GraphDefSnap,
     OpDefSnap as OpDefSnap,
     build_graph_def_snap as build_graph_def_snap,
 )
-from .pipeline_snapshot import (
-    PipelineSnapshot as PipelineSnapshot,
-    create_pipeline_snapshot_id as create_pipeline_snapshot_id,
-)
```

### Comparing `dagster-1.3.2/dagster/_core/snap/dagster_types.py` & `dagster-1.3.3/dagster/_core/snap/dagster_types.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/snap/dep_snapshot.py` & `dagster-1.3.3/dagster/_core/snap/dep_snapshot.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/snap/execution_plan_snapshot.py` & `dagster-1.3.3/dagster/_core/snap/execution_plan_snapshot.py`

 * *Files 1% similar despite different names*

```diff
@@ -29,22 +29,25 @@
 
 
 def create_execution_plan_snapshot_id(execution_plan_snapshot: "ExecutionPlanSnapshot") -> str:
     check.inst_param(execution_plan_snapshot, "execution_plan_snapshot", ExecutionPlanSnapshot)
     return create_snapshot_id(execution_plan_snapshot)
 
 
-@whitelist_for_serdes(skip_when_empty_fields={"repository_load_data"})
+@whitelist_for_serdes(
+    storage_field_names={"job_snapshot_id": "pipeline_snapshot_id"},
+    skip_when_empty_fields={"repository_load_data"},
+)
 class ExecutionPlanSnapshot(
     NamedTuple(
         "_ExecutionPlanSnapshot",
         [
             ("steps", Sequence["ExecutionStepSnap"]),
             ("artifacts_persisted", bool),
-            ("pipeline_snapshot_id", str),
+            ("job_snapshot_id", str),
             ("step_keys_to_execute", Sequence[str]),
             ("initial_known_state", Optional[KnownExecutionState]),
             ("snapshot_version", Optional[int]),
             ("executor_name", Optional[str]),
             ("repository_load_data", Optional[RepositoryLoadData]),
         ],
     )
@@ -54,30 +57,31 @@
     # added step_keys_to_execute
     # added initial_known_state
     # added snapshot_version (if >=1, can be used to fully reconstruct the ExecutionPlan -
     #   can be used to track breaking changes to snapshot execution format if needed)
     # added step_output_versions
     # removed step_output_versions
     # added repository_load_data
+
     def __new__(
         cls,
         steps: Sequence["ExecutionStepSnap"],
         artifacts_persisted: bool,
-        pipeline_snapshot_id: str,
+        job_snapshot_id: str,
         step_keys_to_execute: Optional[Sequence[str]] = None,
         initial_known_state: Optional[KnownExecutionState] = None,
         snapshot_version: Optional[int] = None,
         executor_name: Optional[str] = None,
         repository_load_data: Optional[RepositoryLoadData] = None,
     ):
         return super(ExecutionPlanSnapshot, cls).__new__(
             cls,
             steps=check.sequence_param(steps, "steps", of_type=ExecutionStepSnap),
             artifacts_persisted=check.bool_param(artifacts_persisted, "artifacts_persisted"),
-            pipeline_snapshot_id=check.str_param(pipeline_snapshot_id, "pipeline_snapshot_id"),
+            job_snapshot_id=check.str_param(job_snapshot_id, "job_snapshot_id"),
             step_keys_to_execute=check.opt_sequence_param(
                 step_keys_to_execute, "step_keys_to_execute", of_type=str
             ),
             initial_known_state=check.opt_inst_param(
                 initial_known_state,
                 "initial_known_state",
                 KnownExecutionState,
@@ -298,14 +302,14 @@
     check.str_param(pipeline_snapshot_id, "pipeline_snapshot_id")
 
     return ExecutionPlanSnapshot(
         steps=sorted(
             list(map(_snapshot_from_execution_step, execution_plan.steps)), key=lambda es: es.key
         ),
         artifacts_persisted=execution_plan.artifacts_persisted,
-        pipeline_snapshot_id=pipeline_snapshot_id,
+        job_snapshot_id=pipeline_snapshot_id,
         step_keys_to_execute=execution_plan.step_keys_to_execute,
         initial_known_state=execution_plan.known_state,
         snapshot_version=CURRENT_SNAPSHOT_VERSION,
         executor_name=execution_plan.executor_name,
         repository_load_data=execution_plan.repository_load_data,
     )
```

### Comparing `dagster-1.3.2/dagster/_core/snap/mode.py` & `dagster-1.3.3/dagster/_core/snap/mode.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/snap/node.py` & `dagster-1.3.3/dagster/_core/snap/node.py`

 * *Files 1% similar despite different names*

```diff
@@ -342,19 +342,19 @@
                     of_type=GraphDefSnap,
                 ),
                 key=lambda graph_def: graph_def.name,
             ),
         )
 
 
-def build_node_defs_snapshot(pipeline_def: JobDefinition) -> NodeDefsSnapshot:
-    check.inst_param(pipeline_def, "pipeline_def", JobDefinition)
+def build_node_defs_snapshot(job_def: JobDefinition) -> NodeDefsSnapshot:
+    check.inst_param(job_def, "job_def", JobDefinition)
     op_def_snaps = []
     graph_def_snaps = []
-    for node_def in pipeline_def.all_node_defs:
+    for node_def in job_def.all_node_defs:
         if isinstance(node_def, OpDefinition):
             op_def_snaps.append(build_op_def_snap(node_def))
         elif isinstance(node_def, GraphDefinition):
             graph_def_snaps.append(build_graph_def_snap(node_def))
         else:
             check.failed(f"Unexpected NodeDefinition type {node_def}")
```

### Comparing `dagster-1.3.2/dagster/_core/snap/pipeline_snapshot.py` & `dagster-1.3.3/dagster/_core/snap/job_snapshot.py`

 * *Files 14% similar despite different names*

```diff
@@ -50,20 +50,20 @@
     GraphDefSnap,
     NodeDefsSnapshot,
     OpDefSnap,
     build_node_defs_snapshot,
 )
 
 
-def create_pipeline_snapshot_id(snapshot: "PipelineSnapshot") -> str:
-    check.inst_param(snapshot, "snapshot", PipelineSnapshot)
+def create_job_snapshot_id(snapshot: "JobSnapshot") -> str:
+    check.inst_param(snapshot, "snapshot", JobSnapshot)
     return create_snapshot_id(snapshot)
 
 
-class PipelineSnapshotSerializer(NamedTupleSerializer["PipelineSnapshot"]):
+class JobSnapshotSerializer(NamedTupleSerializer["JobSnapshot"]):
     # v0
     # v1:
     #     - lineage added
     # v2:
     #     - graph_def_name
     # v3:
     #     - metadata added
@@ -85,32 +85,33 @@
         return unpacked_dict
 
 
 # Note that unlike other serdes-whitelisted objects that hold metadata, the field here has always
 # been called `metadata` instead of `metadata_entries`, so we don't need to rename the field for
 # serialization.
 @whitelist_for_serdes(
-    serializer=PipelineSnapshotSerializer,
+    storage_name="PipelineSnapshot",
+    serializer=JobSnapshotSerializer,
     skip_when_empty_fields={"metadata"},
     field_serializers={"metadata": MetadataFieldSerializer},
     storage_field_names={"node_defs_snapshot": "solid_definitions_snapshot"},
 )
-class PipelineSnapshot(
+class JobSnapshot(
     NamedTuple(
-        "_PipelineSnapshot",
+        "_JobSnapshot",
         [
             ("name", str),
             ("description", Optional[str]),
             ("tags", Mapping[str, Any]),
             ("config_schema_snapshot", ConfigSchemaSnapshot),
             ("dagster_type_namespace_snapshot", DagsterTypeNamespaceSnapshot),
             ("node_defs_snapshot", NodeDefsSnapshot),
             ("dep_structure_snapshot", DependencyStructureSnapshot),
             ("mode_def_snaps", Sequence[ModeDefSnap]),
-            ("lineage_snapshot", Optional["PipelineSnapshotLineage"]),
+            ("lineage_snapshot", Optional["JobLineageSnapshot"]),
             ("graph_def_name", str),
             ("metadata", Mapping[str, MetadataValue]),
         ],
     )
 ):
     def __new__(
         cls,
@@ -118,19 +119,19 @@
         description: Optional[str],
         tags: Optional[Mapping[str, Any]],
         config_schema_snapshot: ConfigSchemaSnapshot,
         dagster_type_namespace_snapshot: DagsterTypeNamespaceSnapshot,
         node_defs_snapshot: NodeDefsSnapshot,
         dep_structure_snapshot: DependencyStructureSnapshot,
         mode_def_snaps: Sequence[ModeDefSnap],
-        lineage_snapshot: Optional["PipelineSnapshotLineage"],
+        lineage_snapshot: Optional["JobLineageSnapshot"],
         graph_def_name: str,
         metadata: Optional[Mapping[str, RawMetadataValue]],
     ):
-        return super(PipelineSnapshot, cls).__new__(
+        return super(JobSnapshot, cls).__new__(
             cls,
             name=check.str_param(name, "name"),
             description=check.opt_str_param(description, "description"),
             tags=check.opt_mapping_param(tags, "tags"),
             config_schema_snapshot=check.inst_param(
                 config_schema_snapshot, "config_schema_snapshot", ConfigSchemaSnapshot
             ),
@@ -145,54 +146,54 @@
             dep_structure_snapshot=check.inst_param(
                 dep_structure_snapshot, "dep_structure_snapshot", DependencyStructureSnapshot
             ),
             mode_def_snaps=check.sequence_param(
                 mode_def_snaps, "mode_def_snaps", of_type=ModeDefSnap
             ),
             lineage_snapshot=check.opt_inst_param(
-                lineage_snapshot, "lineage_snapshot", PipelineSnapshotLineage
+                lineage_snapshot, "lineage_snapshot", JobLineageSnapshot
             ),
             graph_def_name=check.str_param(graph_def_name, "graph_def_name"),
             metadata=normalize_metadata(
                 check.opt_mapping_param(metadata, "metadata", key_type=str)
             ),
         )
 
     @classmethod
-    def from_pipeline_def(cls, pipeline_def: JobDefinition) -> "PipelineSnapshot":
-        check.inst_param(pipeline_def, "pipeline_def", JobDefinition)
+    def from_job_def(cls, job_def: JobDefinition) -> "JobSnapshot":
+        check.inst_param(job_def, "job_def", JobDefinition)
         lineage = None
-        if pipeline_def.op_selection_data:
-            lineage = PipelineSnapshotLineage(
-                parent_snapshot_id=create_pipeline_snapshot_id(
-                    cls.from_pipeline_def(pipeline_def.op_selection_data.parent_job_def)
+        if job_def.op_selection_data:
+            lineage = JobLineageSnapshot(
+                parent_snapshot_id=create_job_snapshot_id(
+                    cls.from_job_def(job_def.op_selection_data.parent_job_def)
                 ),
-                node_selection=sorted(pipeline_def.op_selection_data.op_selection),
-                nodes_to_execute=pipeline_def.op_selection_data.resolved_op_selection,
+                node_selection=sorted(job_def.op_selection_data.op_selection),
+                nodes_to_execute=job_def.op_selection_data.resolved_op_selection,
             )
-        if pipeline_def.asset_selection_data:
-            lineage = PipelineSnapshotLineage(
-                parent_snapshot_id=create_pipeline_snapshot_id(
-                    cls.from_pipeline_def(pipeline_def.asset_selection_data.parent_job_def)
+        if job_def.asset_selection_data:
+            lineage = JobLineageSnapshot(
+                parent_snapshot_id=create_job_snapshot_id(
+                    cls.from_job_def(job_def.asset_selection_data.parent_job_def)
                 ),
-                asset_selection=pipeline_def.asset_selection_data.asset_selection,
+                asset_selection=job_def.asset_selection_data.asset_selection,
             )
 
-        return PipelineSnapshot(
-            name=pipeline_def.name,
-            description=pipeline_def.description,
-            tags=pipeline_def.tags,
-            metadata=pipeline_def.metadata,
-            config_schema_snapshot=build_config_schema_snapshot(pipeline_def),
-            dagster_type_namespace_snapshot=build_dagster_type_namespace_snapshot(pipeline_def),
-            node_defs_snapshot=build_node_defs_snapshot(pipeline_def),
-            dep_structure_snapshot=build_dep_structure_snapshot_from_graph_def(pipeline_def.graph),
-            mode_def_snaps=[build_mode_def_snap(pipeline_def)],
+        return JobSnapshot(
+            name=job_def.name,
+            description=job_def.description,
+            tags=job_def.tags,
+            metadata=job_def.metadata,
+            config_schema_snapshot=build_config_schema_snapshot(job_def),
+            dagster_type_namespace_snapshot=build_dagster_type_namespace_snapshot(job_def),
+            node_defs_snapshot=build_node_defs_snapshot(job_def),
+            dep_structure_snapshot=build_dep_structure_snapshot_from_graph_def(job_def.graph),
+            mode_def_snaps=[build_mode_def_snap(job_def)],
             lineage_snapshot=lineage,
-            graph_def_name=pipeline_def.graph.name,
+            graph_def_name=job_def.graph.name,
         )
 
     def get_node_def_snap(self, node_def_name: str) -> Union[OpDefSnap, GraphDefSnap]:
         check.str_param(node_def_name, "node_def_name")
         for node_def_snap in self.node_defs_snapshot.op_def_snaps:
             if node_def_snap.name == node_def_name:
                 return node_def_snap
@@ -396,22 +397,23 @@
         return _construct_map_from_snap(config_type_snap, config_snap_map)
     elif config_type_snap.kind == ConfigTypeKind.NONEABLE:
         return _construct_noneable_from_snap(config_type_snap, config_snap_map)
     check.failed(f"Could not evaluate config type snap kind: {config_type_snap.kind}")
 
 
 @whitelist_for_serdes(
+    storage_name="PipelineSnapshotLineage",
     storage_field_names={
         "node_selection": "solid_selection",
         "nodes_to_execute": "solids_to_execute",
     },
 )
-class PipelineSnapshotLineage(
+class JobLineageSnapshot(
     NamedTuple(
-        "_PipelineSnapshotLineage",
+        "_JobLineageSnapshot",
         [
             ("parent_snapshot_id", str),
             ("node_selection", Optional[Sequence[str]]),
             ("nodes_to_execute", Optional[AbstractSet[str]]),
             ("asset_selection", Optional[AbstractSet[AssetKey]]),
         ],
     )
@@ -420,14 +422,14 @@
         cls,
         parent_snapshot_id: str,
         node_selection: Optional[Sequence[str]] = None,
         nodes_to_execute: Optional[AbstractSet[str]] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
     ):
         check.opt_set_param(nodes_to_execute, "nodes_to_execute", of_type=str)
-        return super(PipelineSnapshotLineage, cls).__new__(
+        return super(JobLineageSnapshot, cls).__new__(
             cls,
             check.str_param(parent_snapshot_id, parent_snapshot_id),
             node_selection,
             nodes_to_execute,
             asset_selection,
         )
```

### Comparing `dagster-1.3.2/dagster/_core/storage/DEVELOPING.md` & `dagster-1.3.3/dagster/_core/storage/DEVELOPING.md`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/README.md` & `dagster-1.3.3/dagster/_core/storage/alembic/README.md`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/env.py` & `dagster-1.3.3/dagster/_core/storage/alembic/env.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/001_initial_1.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/001_initial_1.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_postgres.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_sqlite.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/002_cascade_run_deletion_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_postgres.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_sqlite.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/003_add_step_key_pipeline_name_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/004_add_snapshots_to_run_storage.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/004_add_snapshots_to_run_storage.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/005_add_asset_key_postgres.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/005_add_asset_key_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/005_add_asset_key_sqlite.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/005_add_asset_key_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/006_scheduler_update_postgres.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/006_scheduler_update_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/007_create_run_id_idx_postgres.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/007_create_run_id_idx_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/007_create_run_id_idx_sqlite.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/007_create_run_id_idx_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/008_add_run_tags_index_postgres.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/008_add_run_tags_index_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/008_add_run_tags_index_sqlite.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/008_add_run_tags_index_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/009_add_partition_column_postgres.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/009_add_partition_column_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/009_add_partition_column_sqlite.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/009_add_partition_column_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_postgres.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_sqlite.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/010_add_run_partition_columns_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_postgres.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_1.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_1.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_2.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/011_wipe_schedules_table_for_0_10_0_sqlite_2.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_postgres.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_sqlite.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/015_change_varchar_to_text_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/017_add_run_status_index_postgres.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/017_add_run_status_index_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/017_add_run_status_index_sqlite.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/017_add_run_status_index_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_postgres.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_sqlite.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/019_0_11_0_db_text_to_db_string_unique_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/021_add_column_mode_mysql.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/021_add_column_mode_mysql.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/021_add_column_mode_postgres.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/021_add_column_mode_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/021_add_column_mode_sqlite.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/021_add_column_mode_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_mysql.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_mysql.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_postgres.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_postgres.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_sqlite.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/024_add_columns_start_time_and_end_time_sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/026_convert_start_end_times_format_mysql.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/026_convert_start_end_times_format_mysql.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/030_add_columns_action_type_and_selector_id_.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/030_add_columns_action_type_and_selector_id_.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/031_add_kvs_table.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/031_add_kvs_table.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/033_add_asset_event_tags_table.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/033_add_asset_event_tags_table.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/036_add_dynamic_partitions_table.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/036_add_dynamic_partitions_table.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/alembic/versions/037_d9092588866f_add_primary_key_cols.py` & `dagster-1.3.3/dagster/_core/storage/alembic/versions/037_d9092588866f_add_primary_key_cols.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/asset_value_loader.py` & `dagster-1.3.3/dagster/_core/storage/asset_value_loader.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/base_storage.py` & `dagster-1.3.3/dagster/_core/storage/base_storage.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/branching/branching_io_manager.py` & `dagster-1.3.3/dagster/_core/storage/branching/branching_io_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/captured_log_manager.py` & `dagster-1.3.3/dagster/_core/storage/captured_log_manager.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,35 +2,56 @@
 
 from abc import ABC, abstractmethod
 from contextlib import contextmanager
 from typing import IO, Callable, Generator, Iterator, NamedTuple, Optional, Sequence
 
 from typing_extensions import Final, Self
 
+import dagster._check as check
 from dagster._core.storage.compute_log_manager import ComputeIOType
 
 MAX_BYTES_CHUNK_READ: Final = 4194304  # 4 MB
 
 
 class CapturedLogContext(
     NamedTuple(
         "_CapturedLogContext",
         [
             ("log_key", Sequence[str]),
             ("external_url", Optional[str]),
+            ("external_stdout_url", Optional[str]),
+            ("external_stderr_url", Optional[str]),
         ],
     )
 ):
     """Object representing the context in which logs are captured.  Can be used by external logging
     sidecar implementations to point dagit to an external url to view compute logs instead of a
     Dagster-managed location.
     """
 
-    def __new__(cls, log_key: Sequence[str], external_url: Optional[str] = None):
-        return super(CapturedLogContext, cls).__new__(cls, log_key, external_url=external_url)
+    def __new__(
+        cls,
+        log_key: Sequence[str],
+        external_stdout_url: Optional[str] = None,
+        external_stderr_url: Optional[str] = None,
+        external_url: Optional[str] = None,
+    ):
+        if external_url and (external_stdout_url or external_stderr_url):
+            check.failed(
+                "Cannot specify both `external_url` and one of"
+                " `external_stdout_url`/`external_stderr_url`"
+            )
+
+        return super(CapturedLogContext, cls).__new__(
+            cls,
+            log_key,
+            external_stdout_url=external_stdout_url,
+            external_stderr_url=external_stderr_url,
+            external_url=external_url,
+        )
 
 
 class CapturedLogData(
     NamedTuple(
         "_CapturedLogData",
         [
             ("log_key", Sequence[str]),
```

### Comparing `dagster-1.3.2/dagster/_core/storage/cloud_storage_compute_log_manager.py` & `dagster-1.3.3/dagster/_core/storage/cloud_storage_compute_log_manager.py`

 * *Files 6% similar despite different names*

```diff
@@ -203,32 +203,32 @@
 
     ###############################################
     #
     # Methods for the ComputeLogManager interface
     #
     ###############################################
     @contextmanager
-    def _watch_logs(self, pipeline_run, step_key=None):
+    def _watch_logs(self, dagster_run, step_key=None):
         # proxy watching to the local compute log manager, interacting with the filesystem
         log_key = self.local_manager.build_log_key_for_run(
-            pipeline_run.run_id, step_key or pipeline_run.pipeline_name
+            dagster_run.run_id, step_key or dagster_run.job_name
         )
         with self.local_manager.capture_logs(log_key):
             yield
         self.upload_to_cloud_storage(log_key, ComputeIOType.STDOUT)
         self.upload_to_cloud_storage(log_key, ComputeIOType.STDERR)
 
     def get_local_path(self, run_id, key, io_type):
         return self.local_manager.get_local_path(run_id, key, io_type)
 
-    def on_watch_start(self, pipeline_run, step_key):
-        self.local_manager.on_watch_start(pipeline_run, step_key)
+    def on_watch_start(self, dagster_run, step_key):
+        self.local_manager.on_watch_start(dagster_run, step_key)
 
-    def on_watch_finish(self, pipeline_run, step_key):
-        self.local_manager.on_watch_finish(pipeline_run, step_key)
+    def on_watch_finish(self, dagster_run, step_key):
+        self.local_manager.on_watch_finish(dagster_run, step_key)
 
     def is_watch_completed(self, run_id, key):
         return self.local_manager.is_watch_completed(run_id, key) or self.cloud_storage_has_logs(
             self.local_manager.build_log_key_for_run(run_id, key), ComputeIOType.STDERR
         )
 
     def download_url(self, run_id, key, io_type):
```

### Comparing `dagster-1.3.2/dagster/_core/storage/compute_log_manager.py` & `dagster-1.3.3/dagster/_core/storage/compute_log_manager.py`

 * *Files 5% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 from enum import Enum
 from typing import Callable, Iterator, NamedTuple, Optional
 
 from typing_extensions import Self
 
 import dagster._check as check
 from dagster._core.instance import MayHaveInstanceWeakref, T_DagsterInstance
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 
 MAX_BYTES_FILE_READ = 33554432  # 32 MB
 MAX_BYTES_CHUNK_READ = 4194304  # 4 MB
 
 
 class ComputeIOType(Enum):
     STDOUT = "stdout"
@@ -47,44 +47,44 @@
 
 class ComputeLogManager(ABC, MayHaveInstanceWeakref[T_DagsterInstance]):
     """Abstract base class for storing unstructured compute logs (stdout/stderr) from the compute
     steps of pipeline solids.
     """
 
     @contextmanager
-    def watch(self, pipeline_run: DagsterRun, step_key: Optional[str] = None) -> Iterator[None]:
+    def watch(self, dagster_run: DagsterRun, step_key: Optional[str] = None) -> Iterator[None]:
         """Watch the stdout/stderr for a given execution for a given run_id / step_key and persist it.
 
         Args:
-            pipeline_run (PipelineRun): The pipeline run config
+            dagster_run (DagsterRun): The run config
             step_key (Optional[String]): The step_key for a compute step
         """
-        check.inst_param(pipeline_run, "pipeline_run", DagsterRun)
+        check.inst_param(dagster_run, "dagster_run", DagsterRun)
         check.opt_str_param(step_key, "step_key")
 
-        if not self.enabled(pipeline_run, step_key):
+        if not self.enabled(dagster_run, step_key):
             yield
             return
 
-        self.on_watch_start(pipeline_run, step_key)
-        with self._watch_logs(pipeline_run, step_key):
+        self.on_watch_start(dagster_run, step_key)
+        with self._watch_logs(dagster_run, step_key):
             yield
-        self.on_watch_finish(pipeline_run, step_key)
+        self.on_watch_finish(dagster_run, step_key)
 
     @contextmanager
     @abstractmethod
     def _watch_logs(
-        self, pipeline_run: DagsterRun, step_key: Optional[str] = None
+        self, dagster_run: DagsterRun, step_key: Optional[str] = None
     ) -> Iterator[None]:
         """Method to watch the stdout/stderr logs for a given run_id / step_key.  Kept separate from
         blessed `watch` method, which triggers all the start/finish hooks that are necessary to
         implement the different remote implementations.
 
         Args:
-            pipeline_run (PipelineRun): The pipeline run config
+            dagster_run (DagsterRun): The run config
             step_key (Optional[String]): The step_key for a compute step
         """
 
     @abstractmethod
     def get_local_path(self, run_id: str, key: str, io_type: ComputeIOType) -> str:
         """Get the local path of the logfile for a given execution step.  This determines the
         location on the local filesystem to which stdout/stderr will be rerouted.
@@ -109,24 +109,24 @@
             key (str): The unique descriptor of the execution step (e.g. `solid_invocation.compute`)
 
         Returns:
             Boolean
         """
 
     @abstractmethod
-    def on_watch_start(self, pipeline_run: DagsterRun, step_key: Optional[str]) -> None:
+    def on_watch_start(self, dagster_run: DagsterRun, step_key: Optional[str]) -> None:
         """Hook called when starting to watch compute logs.
 
         Args:
             pipeline_run (PipelineRun): The pipeline run config
             step_key (Optional[String]): The step_key for a compute step
         """
 
     @abstractmethod
-    def on_watch_finish(self, pipeline_run: DagsterRun, step_key: Optional[str]) -> None:
+    def on_watch_finish(self, dagster_run: DagsterRun, step_key: Optional[str]) -> None:
         """Hook called when computation for a given execution step is finished.
 
         Args:
             pipeline_run (PipelineRun): The pipeline run config
             step_key (Optional[String]): The step_key for a compute step
         """
 
@@ -161,15 +161,15 @@
             cursor (Optional[Int]): Starting cursor (byte) of log file
             max_bytes (Optional[Int]): Maximum number of bytes to be read and returned
 
         Returns:
             ComputeLogFileData
         """
 
-    def enabled(self, _pipeline_run: DagsterRun, _step_key: Optional[str]) -> bool:
+    def enabled(self, _dagster_run: DagsterRun, _step_key: Optional[str]) -> bool:
         """Hook for disabling compute log capture.
 
         Args:
             _step_key (Optional[String]): The step_key for a compute step
 
         Returns:
             Boolean
```

### Comparing `dagster-1.3.2/dagster/_core/storage/config.py` & `dagster-1.3.3/dagster/_core/storage/config.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/db_io_manager.py` & `dagster-1.3.3/dagster/_core/storage/db_io_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/event_log/__init__.py` & `dagster-1.3.3/dagster/_core/storage/event_log/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/event_log/base.py` & `dagster-1.3.3/dagster/_core/storage/event_log/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 from dagster._core.events.log import EventLogEntry
 from dagster._core.execution.stats import (
     RunStepKeyStatsSnapshot,
     build_run_stats_from_events,
     build_run_step_stats_from_events,
 )
 from dagster._core.instance import MayHaveInstanceWeakref, T_DagsterInstance
-from dagster._core.storage.pipeline_run import PipelineRunStatsSnapshot
+from dagster._core.storage.dagster_run import DagsterRunStatsSnapshot
 from dagster._core.storage.sql import AlembicVersion
 from dagster._seven import json
 from dagster._utils import PrintFn
 
 if TYPE_CHECKING:
     from dagster._core.storage.partition_status_cache import AssetStatusCacheValue
 
@@ -183,15 +183,15 @@
         Args:
             run_id (str): The id of the run for which to fetch logs.
             cursor (Optional[str]): Cursor value to track paginated queries.
             of_type (Optional[DagsterEventType]): the dagster event type to filter the logs.
             limit (Optional[int]): Max number of records to return.
         """
 
-    def get_stats_for_run(self, run_id: str) -> PipelineRunStatsSnapshot:
+    def get_stats_for_run(self, run_id: str) -> DagsterRunStatsSnapshot:
         """Get a summary of events that have ocurred in a run."""
         return build_run_stats_from_events(run_id, self.get_logs_for_run(run_id))
 
     def get_step_stats_for_run(
         self, run_id: str, step_keys: Optional[Sequence[str]] = None
     ) -> Sequence[RunStepKeyStatsSnapshot]:
         """Get per-step stats for a pipeline run."""
```

### Comparing `dagster-1.3.2/dagster/_core/storage/event_log/in_memory.py` & `dagster-1.3.3/dagster/_core/storage/event_log/in_memory.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/event_log/migration.py` & `dagster-1.3.3/dagster/_core/storage/event_log/migration.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/event_log/polling_event_watcher.py` & `dagster-1.3.3/dagster/_core/storage/event_log/polling_event_watcher.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,13 @@
 import threading
 from typing import Callable, List, MutableMapping, NamedTuple, Optional
 
 import dagster._check as check
 from dagster._core.events.log import EventLogEntry
-from dagster._core.storage.event_log.base import EventLogCursor
-
-from .sql_event_log import SqlEventLogStorage
+from dagster._core.storage.event_log.base import EventLogCursor, EventLogStorage
 
 POLLING_CADENCE = 0.1  # 100 ms
 
 
 class CallbackAfterCursor(NamedTuple):
     """Callback passed from Observer class in event polling.
 
@@ -28,17 +26,17 @@
     Uses one thread (SqlPollingRunIdEventWatcherThread) per watched run_id.
 
     LOCKING INFO:
         ORDER: _dict_lock -> run_id_thread.callback_fn_list_lock
         INVARIANTS: _dict_lock protects _run_id_to_watcher_dict
     """
 
-    def __init__(self, event_log_storage: SqlEventLogStorage):
+    def __init__(self, event_log_storage: EventLogStorage):
         self._event_log_storage = check.inst_param(
-            event_log_storage, "event_log_storage", SqlEventLogStorage
+            event_log_storage, "event_log_storage", EventLogStorage
         )
 
         # INVARIANT: dict_lock protects _run_id_to_watcher_dict
         self._dict_lock: threading.Lock = threading.Lock()
         self._run_id_to_watcher_dict: MutableMapping[str, SqlPollingRunIdEventWatcherThread] = {}
         self._disposed = False
 
@@ -96,24 +94,24 @@
     Exits when `self.should_thread_exit` is set.
 
     LOCKING INFO:
         INVARIANTS: _callback_fn_list_lock protects _callback_fn_list
 
     """
 
-    def __init__(self, event_log_storage: SqlEventLogStorage, run_id: str):
+    def __init__(self, event_log_storage: EventLogStorage, run_id: str):
         super(SqlPollingRunIdEventWatcherThread, self).__init__()
         self._event_log_storage = check.inst_param(
-            event_log_storage, "event_log_storage", SqlEventLogStorage
+            event_log_storage, "event_log_storage", EventLogStorage
         )
         self._run_id = check.str_param(run_id, "run_id")
         self._callback_fn_list_lock: threading.Lock = threading.Lock()
         self._callback_fn_list: List[CallbackAfterCursor] = []
         self._should_thread_exit = threading.Event()
-        self.name = f"mysql-event-watch-run-id-{self._run_id}"
+        self.name = f"sql-event-watch-run-id-{self._run_id}"
 
     @property
     def should_thread_exit(self) -> threading.Event:
         return self._should_thread_exit
 
     def add_callback(self, cursor: Optional[str], callback: Callable[[EventLogEntry, str], None]):
         """Observer has started watching this run.
```

### Comparing `dagster-1.3.2/dagster/_core/storage/event_log/schema.py` & `dagster-1.3.3/dagster/_core/storage/event_log/schema.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/event_log/sql_event_log.py` & `dagster-1.3.3/dagster/_core/storage/event_log/sql_event_log.py`

 * *Files 1% similar despite different names*

```diff
@@ -46,15 +46,15 @@
 from dagster._utils import (
     PrintFn,
     datetime_as_float,
     utc_datetime_from_naive,
     utc_datetime_from_timestamp,
 )
 
-from ..pipeline_run import PipelineRunStatsSnapshot
+from ..dagster_run import DagsterRunStatsSnapshot
 from .base import (
     AssetEntry,
     AssetRecord,
     EventLogConnection,
     EventLogCursor,
     EventLogEntry,
     EventLogRecord,
@@ -470,15 +470,15 @@
 
         return EventLogConnection(
             records=records,
             cursor=next_cursor,
             has_more=bool(limit and len(results) == limit),
         )
 
-    def get_stats_for_run(self, run_id: str) -> PipelineRunStatsSnapshot:
+    def get_stats_for_run(self, run_id: str) -> DagsterRunStatsSnapshot:
         check.str_param(run_id, "run_id")
 
         query = (
             db.select(
                 [
                     SqlEventLogStorageTable.c.dagster_event_type,
                     db.func.count().label("n_events_of_type"),
@@ -513,15 +513,15 @@
                 DagsterEventType.PIPELINE_SUCCESS.value,
                 times.get(
                     DagsterEventType.PIPELINE_FAILURE.value,
                     times.get(DagsterEventType.PIPELINE_CANCELED.value, None),
                 ),
             )
 
-            return PipelineRunStatsSnapshot(
+            return DagsterRunStatsSnapshot(
                 run_id=run_id,
                 steps_succeeded=counts.get(DagsterEventType.STEP_SUCCESS.value, 0),
                 steps_failed=counts.get(DagsterEventType.STEP_FAILURE.value, 0),
                 materializations=counts.get(DagsterEventType.ASSET_MATERIALIZATION.value, 0),
                 expectations=counts.get(DagsterEventType.STEP_EXPECTATION_RESULT.value, 0),
                 enqueued_time=datetime_as_float(enqueued_time) if enqueued_time else None,
                 launch_time=datetime_as_float(launch_time) if launch_time else None,
@@ -650,15 +650,15 @@
             db.select([SqlEventLogStorageTable.c.asset_key])
             .where(SqlEventLogStorageTable.c.run_id == run_id)
             .where(SqlEventLogStorageTable.c.asset_key != None)  # noqa: E711
             .group_by(SqlEventLogStorageTable.c.asset_key)
         )
 
         removed_asset_keys = [
-            AssetKey.from_db_string(row[0])
+            AssetKey.from_db_string(cast(Optional[str], row[0]))
             for row in conn.execute(removed_asset_key_query).fetchall()
         ]
         conn.execute(delete_statement)
         if len(removed_asset_keys) > 0:
             keys_to_check = []
             keys_to_check.extend([key.to_string() for key in removed_asset_keys])  # type: ignore  # (bad sig?)
             remaining_asset_keys = [
@@ -1084,18 +1084,19 @@
                 ),
             )
         )
         with self.index_connection() as conn:
             event_rows = conn.execute(backcompat_query).fetchall()
 
         for row in event_rows:
-            asset_key = AssetKey.from_db_string(row[0])
+            asset_key = AssetKey.from_db_string(cast(Optional[str], row[0]))
             if asset_key:
                 results[asset_key] = EventLogRecord(
-                    storage_id=row[1], event_log_entry=deserialize_value(row[2], EventLogEntry)
+                    storage_id=cast(int, row[1]),
+                    event_log_entry=deserialize_value(cast(str, row[2]), EventLogEntry),
                 )
         return results
 
     def can_cache_asset_status_data(self) -> bool:
         return self.has_asset_key_col("cached_status_data")
 
     def wipe_asset_cached_status(self, asset_key: AssetKey) -> None:
@@ -1252,23 +1253,23 @@
         with self.index_connection() as conn:
             rows = conn.execute(query).fetchall()
 
         wiped_timestamps_by_asset_key: Dict[AssetKey, float] = {}
         row_by_asset_key: Dict[AssetKey, SqlAlchemyRow] = OrderedDict()
 
         for row in rows:
-            asset_key = AssetKey.from_db_string(row[1])
+            asset_key = AssetKey.from_db_string(cast(str, row[1]))
             if not asset_key:
                 continue
             asset_details = AssetDetails.from_db_string(row[4])
             if not asset_details or not asset_details.last_wipe_timestamp:
                 row_by_asset_key[asset_key] = row
                 continue
             materialization_or_event_or_record = (
-                deserialize_value(row[2], NamedTuple) if row[2] else None
+                deserialize_value(cast(str, row[2]), NamedTuple) if row[2] else None
             )
             if isinstance(materialization_or_event_or_record, (EventLogRecord, EventLogEntry)):
                 if isinstance(materialization_or_event_or_record, EventLogRecord):
                     event_timestamp = materialization_or_event_or_record.event_log_entry.timestamp
                 else:
                     event_timestamp = materialization_or_event_or_record.timestamp
 
@@ -1388,15 +1389,17 @@
                     AssetKeyTable.c.asset_key.in_(
                         [asset_key.to_string() for asset_key in asset_keys]
                     ),
                 )
             ).fetchall()
 
             asset_key_to_details = {
-                row[0]: (deserialize_value(row[1], AssetDetails) if row[1] else None)
+                cast(str, row[0]): (
+                    deserialize_value(cast(str, row[1]), AssetDetails) if row[1] else None
+                )
                 for row in rows
             }
 
             # returns a list of the corresponding asset_details to provided asset_keys
             return [
                 asset_key_to_details.get(asset_key.to_string(), None) for asset_key in asset_keys
             ]
@@ -1661,17 +1664,17 @@
         with self.index_connection() as conn:
             results = conn.execute(query).fetchall()
 
         materialization_count_by_partition: Dict[AssetKey, Dict[str, int]] = {
             asset_key: {} for asset_key in asset_keys
         }
         for row in results:
-            asset_key = AssetKey.from_db_string(row[0])
+            asset_key = AssetKey.from_db_string(cast(Optional[str], row[0]))
             if asset_key:
-                materialization_count_by_partition[asset_key][row[1]] = row[2]
+                materialization_count_by_partition[asset_key][cast(str, row[1])] = cast(int, row[2])
 
         return materialization_count_by_partition
 
     def get_latest_asset_partition_materialization_attempts_without_materializations(
         self, asset_key: AssetKey
     ) -> Mapping[str, Tuple[str, int]]:
         """Fetch the latest materialzation and materialization planned events for each partition of the given asset.
@@ -1757,22 +1760,24 @@
         )
 
         with self.index_connection() as conn:
             materialization_planned_rows = conn.execute(materialization_planned_events).fetchall()
             materialization_rows = conn.execute(materialization_events).fetchall()
 
         materialization_planned_rows_by_partition = {
-            row["partition"]: (row["run_id"], row["id"]) for row in materialization_planned_rows
+            cast(str, row["partition"]): (cast(str, row["run_id"]), cast(int, row["id"]))
+            for row in materialization_planned_rows
         }
         for row in materialization_rows:
             if (
                 row["partition"] in materialization_planned_rows_by_partition
-                and materialization_planned_rows_by_partition[row["partition"]][0] == row["run_id"]
+                and materialization_planned_rows_by_partition[cast(str, row["partition"])][0]
+                == row["run_id"]
             ):
-                materialization_planned_rows_by_partition.pop(row["partition"])
+                materialization_planned_rows_by_partition.pop(cast(str, row["partition"]))
 
         return materialization_planned_rows_by_partition
 
     def _check_partitions_table(self) -> None:
         # Guards against cases where the user is not running the latest migration for
         # partitions storage. Should be updated when the partitions storage schema changes.
         if not self.has_table("dynamic_partitions"):
@@ -1791,15 +1796,15 @@
             db.select(columns)
             .where(DynamicPartitionsTable.c.partitions_def_name == partitions_def_name)
             .order_by(DynamicPartitionsTable.c.id)
         )
         with self.index_connection() as conn:
             rows = conn.execute(query).fetchall()
 
-        return [row[1] for row in rows]
+        return [cast(str, row[1]) for row in rows]
 
     def get_dynamic_partitions(self, partitions_def_name: str) -> Sequence[str]:
         """Get the list of partition keys for a partition definition."""
         self._check_partitions_table()
         return self._fetch_partition_keys_for_partition_def(partitions_def_name)
 
     def has_dynamic_partition(self, partitions_def_name: str, partition_key: str) -> bool:
```

### Comparing `dagster-1.3.2/dagster/_core/storage/event_log/sqlite/alembic/alembic.ini` & `dagster-1.3.3/dagster/_core/storage/event_log/sqlite/alembic/alembic.ini`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/event_log/sqlite/consolidated_sqlite_event_log.py` & `dagster-1.3.3/dagster/_core/storage/event_log/sqlite/consolidated_sqlite_event_log.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,16 +7,16 @@
 from sqlalchemy.pool import NullPool
 from typing_extensions import Self
 from watchdog.events import PatternMatchingEventHandler
 from watchdog.observers import Observer
 
 import dagster._check as check
 from dagster._config import StringSource
+from dagster._core.storage.dagster_run import DagsterRunStatus
 from dagster._core.storage.event_log.base import EventLogCursor
-from dagster._core.storage.pipeline_run import DagsterRunStatus
 from dagster._core.storage.sql import (
     check_alembic_revision,
     create_engine,
     get_alembic_config,
     run_alembic_upgrade,
     stamp_alembic_rev,
 )
```

### Comparing `dagster-1.3.2/dagster/_core/storage/event_log/sqlite/sqlite_event_log.py` & `dagster-1.3.3/dagster/_core/storage/event_log/sqlite/sqlite_event_log.py`

 * *Files 1% similar despite different names*

```diff
@@ -22,16 +22,16 @@
 from dagster._config import StringSource
 from dagster._config.config_schema import UserConfigSchema
 from dagster._core.definitions.events import AssetKey
 from dagster._core.errors import DagsterInvariantViolationError
 from dagster._core.event_api import EventHandlerFn
 from dagster._core.events import ASSET_EVENTS
 from dagster._core.events.log import EventLogEntry
+from dagster._core.storage.dagster_run import DagsterRunStatus, RunsFilter
 from dagster._core.storage.event_log.base import EventLogCursor, EventLogRecord, EventRecordsFilter
-from dagster._core.storage.pipeline_run import DagsterRunStatus, RunsFilter
 from dagster._core.storage.sql import (
     AlembicVersion,
     check_alembic_revision,
     create_engine,
     get_alembic_config,
     run_alembic_upgrade,
     stamp_alembic_rev,
```

### Comparing `dagster-1.3.2/dagster/_core/storage/file_manager.py` & `dagster-1.3.3/dagster/_core/storage/file_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/fs_io_manager.py` & `dagster-1.3.3/dagster/_core/storage/fs_io_manager.py`

 * *Files 0% similar despite different names*

```diff
@@ -245,15 +245,15 @@
         super().__init__(base_path=UPath(base_dir, **kwargs))
 
     def dump_to_path(self, context: OutputContext, obj: Any, path: UPath):
         try:
             with path.open("wb") as file:
                 pickle.dump(obj, file, PICKLE_PROTOCOL)
         except (AttributeError, RecursionError, ImportError, pickle.PicklingError) as e:
-            executor = context.step_context.pipeline_def.executor_def
+            executor = context.step_context.job_def.executor_def
 
             if isinstance(e, RecursionError):
                 # if obj can't be pickled because of RecursionError then __str__() will also
                 # throw a RecursionError
                 obj_repr = f"{obj.__class__} exceeds recursion limit and"
             else:
                 obj_repr = obj.__str__()
@@ -307,15 +307,15 @@
         mkdir_p(os.path.dirname(filepath))
         context.log.debug(f"Writing file at: {filepath}")
 
         with open(filepath, self.write_mode) as write_obj:
             pickle.dump(obj, write_obj, PICKLE_PROTOCOL)
 
         return AssetMaterialization(
-            asset_key=AssetKey([context.pipeline_name, context.step_key, context.name]),
+            asset_key=AssetKey([context.job_name, context.step_key, context.name]),
             metadata={"path": MetadataValue.path(os.path.abspath(filepath))},
         )
 
     def load_input(self, context: InputContext) -> object:
         """Unpickle the file from a given file path and Load it to a data object."""
         check.inst_param(context, "context", InputContext)
         metadata = context.upstream_output.metadata  # type: ignore  # (possible none)
```

### Comparing `dagster-1.3.2/dagster/_core/storage/input_manager.py` & `dagster-1.3.3/dagster/_core/storage/input_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/io_manager.py` & `dagster-1.3.3/dagster/_core/storage/io_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/legacy_storage.py` & `dagster-1.3.3/dagster/_core/storage/legacy_storage.py`

 * *Files 2% similar despite different names*

```diff
@@ -29,35 +29,35 @@
 if TYPE_CHECKING:
     from dagster._core.definitions.events import AssetKey
     from dagster._core.definitions.run_request import InstigatorType
     from dagster._core.events import DagsterEvent, DagsterEventType
     from dagster._core.events.log import EventLogEntry
     from dagster._core.execution.backfill import BulkActionStatus, PartitionBackfill
     from dagster._core.execution.stats import RunStepKeyStatsSnapshot
-    from dagster._core.host_representation.origin import ExternalPipelineOrigin
+    from dagster._core.host_representation.origin import ExternalJobOrigin
     from dagster._core.instance import DagsterInstance
     from dagster._core.scheduler.instigation import (
         InstigatorState,
         InstigatorStatus,
         InstigatorTick,
         TickData,
         TickStatus,
     )
     from dagster._core.snap.execution_plan_snapshot import ExecutionPlanSnapshot
-    from dagster._core.snap.pipeline_snapshot import PipelineSnapshot
-    from dagster._core.storage.partition_status_cache import AssetStatusCacheValue
-    from dagster._core.storage.pipeline_run import (
+    from dagster._core.snap.job_snapshot import JobSnapshot
+    from dagster._core.storage.dagster_run import (
         DagsterRun,
+        DagsterRunStatsSnapshot,
         JobBucket,
-        PipelineRunStatsSnapshot,
         RunPartitionData,
         RunRecord,
         RunsFilter,
         TagBucket,
     )
+    from dagster._core.storage.partition_status_cache import AssetStatusCacheValue
     from dagster._daemon.types import DaemonHeartbeat
 
 
 class CompositeStorage(DagsterStorage, ConfigurableClass):
     """Utiltity class for combining the individually configured run, event_log, schedule storages
     into the single dagster storage.
     """
@@ -177,16 +177,16 @@
         storage = ConfigurableClassData(
             module_name=config_value["module_name"],
             class_name=config_value["class_name"],
             config_yaml=config_value["config_yaml"],
         ).rehydrate(as_type=DagsterStorage)
         return LegacyRunStorage(storage, inst_data=inst_data)
 
-    def add_run(self, pipeline_run: "DagsterRun") -> "DagsterRun":
-        return self._storage.run_storage.add_run(pipeline_run)
+    def add_run(self, dagster_run: "DagsterRun") -> "DagsterRun":
+        return self._storage.run_storage.add_run(dagster_run)
 
     def handle_run_event(self, run_id: str, event: "DagsterEvent") -> None:
         return self._storage.run_storage.handle_run_event(run_id, event)
 
     def get_runs(
         self,
         filters: Optional["RunsFilter"] = None,
@@ -238,32 +238,32 @@
         return self._storage.run_storage.add_run_tags(run_id, new_tags)
 
     def has_run(self, run_id: str) -> bool:
         return self._storage.run_storage.has_run(run_id)
 
     def add_snapshot(
         self,
-        snapshot: Union["PipelineSnapshot", "ExecutionPlanSnapshot"],
+        snapshot: Union["JobSnapshot", "ExecutionPlanSnapshot"],
         snapshot_id: Optional[str] = None,
     ) -> None:
         return self._storage.run_storage.add_snapshot(snapshot, snapshot_id)
 
     def has_snapshot(self, snapshot_id: str) -> bool:
         return self._storage.run_storage.has_snapshot(snapshot_id)
 
-    def has_pipeline_snapshot(self, pipeline_snapshot_id: str) -> bool:
-        return self._storage.run_storage.has_pipeline_snapshot(pipeline_snapshot_id)
+    def has_job_snapshot(self, job_snapshot_id: str) -> bool:
+        return self._storage.run_storage.has_job_snapshot(job_snapshot_id)
 
-    def add_pipeline_snapshot(
-        self, pipeline_snapshot: "PipelineSnapshot", snapshot_id: Optional[str] = None
+    def add_job_snapshot(
+        self, job_snapshot: "JobSnapshot", snapshot_id: Optional[str] = None
     ) -> str:
-        return self._storage.run_storage.add_pipeline_snapshot(pipeline_snapshot, snapshot_id)
+        return self._storage.run_storage.add_job_snapshot(job_snapshot, snapshot_id)
 
-    def get_pipeline_snapshot(self, pipeline_snapshot_id: str) -> "PipelineSnapshot":
-        return self._storage.run_storage.get_pipeline_snapshot(pipeline_snapshot_id)
+    def get_job_snapshot(self, job_snapshot_id: str) -> "JobSnapshot":
+        return self._storage.run_storage.get_job_snapshot(job_snapshot_id)
 
     def has_execution_plan_snapshot(self, execution_plan_snapshot_id: str) -> bool:
         return self._storage.run_storage.has_execution_plan_snapshot(execution_plan_snapshot_id)
 
     def add_execution_plan_snapshot(
         self, execution_plan_snapshot: "ExecutionPlanSnapshot", snapshot_id: Optional[str] = None
     ) -> str:
@@ -329,15 +329,15 @@
 
     def get_cursor_values(self, keys: Set[str]) -> Mapping[str, str]:
         return self._storage.run_storage.get_cursor_values(keys)
 
     def set_cursor_values(self, pairs: Mapping[str, str]) -> None:
         return self._storage.run_storage.set_cursor_values(pairs)
 
-    def replace_job_origin(self, run: "DagsterRun", job_origin: "ExternalPipelineOrigin") -> None:
+    def replace_job_origin(self, run: "DagsterRun", job_origin: "ExternalJobOrigin") -> None:
         return self._storage.run_storage.replace_job_origin(run, job_origin)
 
 
 class LegacyEventLogStorage(EventLogStorage, ConfigurableClass):
     def __init__(self, storage: DagsterStorage, inst_data: Optional[ConfigurableClassData] = None):
         self._storage = check.inst_param(storage, "storage", DagsterStorage)
         self._inst_data = check.opt_inst_param(inst_data, "inst_data", ConfigurableClassData)
@@ -381,15 +381,15 @@
         run_id: str,
         cursor: Optional[Union[str, int]] = None,
         of_type: Optional[Union["DagsterEventType", Set["DagsterEventType"]]] = None,
         limit: Optional[int] = None,
     ) -> Iterable["EventLogEntry"]:
         return self._storage.event_log_storage.get_logs_for_run(run_id, cursor, of_type, limit)
 
-    def get_stats_for_run(self, run_id: str) -> "PipelineRunStatsSnapshot":
+    def get_stats_for_run(self, run_id: str) -> "DagsterRunStatsSnapshot":
         return self._storage.event_log_storage.get_stats_for_run(run_id)
 
     def get_step_stats_for_run(
         self, run_id: str, step_keys: Optional[Sequence[str]] = None
     ) -> Sequence["RunStepKeyStatsSnapshot"]:
         return self._storage.event_log_storage.get_step_stats_for_run(run_id, step_keys)
```

### Comparing `dagster-1.3.2/dagster/_core/storage/local_compute_log_manager.py` & `dagster-1.3.3/dagster/_core/storage/local_compute_log_manager.py`

 * *Files 6% similar despite different names*

```diff
@@ -14,15 +14,15 @@
     Field,
     Float,
     StringSource,
     _check as check,
 )
 from dagster._config.config_schema import UserConfigSchema
 from dagster._core.execution.compute_logs import mirror_stream_to_file
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._serdes import ConfigurableClass, ConfigurableClassData
 from dagster._seven import json
 from dagster._utils import ensure_dir, ensure_file, touch_file
 
 from .captured_log_manager import (
     CapturedLogContext,
     CapturedLogData,
@@ -241,22 +241,20 @@
     ###############################################
     #
     # Methods for the ComputeLogManager interface
     #
     ###############################################
     @contextmanager
     def _watch_logs(
-        self, pipeline_run: DagsterRun, step_key: Optional[str] = None
+        self, dagster_run: DagsterRun, step_key: Optional[str] = None
     ) -> Iterator[None]:
-        check.inst_param(pipeline_run, "pipeline_run", DagsterRun)
+        check.inst_param(dagster_run, "dagster_run", DagsterRun)
         check.opt_str_param(step_key, "step_key")
 
-        log_key = self.build_log_key_for_run(
-            pipeline_run.run_id, step_key or pipeline_run.pipeline_name
-        )
+        log_key = self.build_log_key_for_run(dagster_run.run_id, step_key or dagster_run.job_name)
         with self.capture_logs(log_key):
             yield
 
     def get_local_path(self, run_id: str, key: str, io_type: ComputeIOType) -> str:
         """Legacy adapter from compute log manager to more generic captured log manager API."""
         check.inst_param(io_type, "io_type", ComputeIOType)
         log_key = self.build_log_key_for_run(run_id, key)
@@ -288,32 +286,30 @@
             path=path,
             data=data.decode("utf-8"),
             cursor=cursor,
             size=stats.st_size,
             download_url=download_url,
         )
 
-    def get_key(self, pipeline_run: DagsterRun, step_key: Optional[str]):
-        check.inst_param(pipeline_run, "pipeline_run", DagsterRun)
+    def get_key(self, dagster_run: DagsterRun, step_key: Optional[str]):
+        check.inst_param(dagster_run, "dagster_run", DagsterRun)
         check.opt_str_param(step_key, "step_key")
-        return step_key or pipeline_run.pipeline_name
+        return step_key or dagster_run.job_name
 
     def is_watch_completed(self, run_id: str, key: str) -> bool:
         log_key = self.build_log_key_for_run(run_id, key)
         return self.is_capture_complete(log_key)
 
-    def on_watch_start(self, pipeline_run: DagsterRun, step_key: Optional[str]):
+    def on_watch_start(self, dagster_run: DagsterRun, step_key: Optional[str]):
         pass
 
-    def on_watch_finish(self, pipeline_run: DagsterRun, step_key: Optional[str] = None):
-        check.inst_param(pipeline_run, "pipeline_run", DagsterRun)
+    def on_watch_finish(self, dagster_run: DagsterRun, step_key: Optional[str] = None):
+        check.inst_param(dagster_run, "dagster_run", DagsterRun)
         check.opt_str_param(step_key, "step_key")
-        log_key = self.build_log_key_for_run(
-            pipeline_run.run_id, step_key or pipeline_run.pipeline_name
-        )
+        log_key = self.build_log_key_for_run(dagster_run.run_id, step_key or dagster_run.job_name)
         touchpath = self.complete_artifact_path(log_key)
         touch_file(touchpath)
 
     def download_url(self, run_id: str, key: str, io_type: ComputeIOType):
         check.inst_param(io_type, "io_type", ComputeIOType)
         return f"/download/{run_id}/{key}/{io_type.value}"
```

### Comparing `dagster-1.3.2/dagster/_core/storage/mem_io_manager.py` & `dagster-1.3.3/dagster/_core/storage/mem_io_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/memoizable_io_manager.py` & `dagster-1.3.3/dagster/_core/storage/memoizable_io_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/migration/utils.py` & `dagster-1.3.3/dagster/_core/storage/migration/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/noop_compute_log_manager.py` & `dagster-1.3.3/dagster/_core/storage/noop_compute_log_manager.py`

 * *Files 6% similar despite different names*

```diff
@@ -35,30 +35,30 @@
 
     @classmethod
     def from_config_value(
         cls, inst_data: ConfigurableClassData, config_value: Mapping[str, Any]
     ) -> Self:
         return NoOpComputeLogManager(inst_data=inst_data, **config_value)
 
-    def enabled(self, _pipeline_run, _step_key):
+    def enabled(self, _dagster_run, _step_key):
         return False
 
-    def _watch_logs(self, pipeline_run, step_key=None):
+    def _watch_logs(self, dagster_run, step_key=None):
         pass
 
     def get_local_path(self, run_id: str, key: str, io_type: ComputeIOType) -> str:
         raise NotImplementedError()
 
     def is_watch_completed(self, run_id, key):
         return True
 
-    def on_watch_start(self, pipeline_run, step_key):
+    def on_watch_start(self, dagster_run, step_key):
         pass
 
-    def on_watch_finish(self, pipeline_run, step_key):
+    def on_watch_finish(self, dagster_run, step_key):
         pass
 
     def download_url(self, run_id, key, io_type):
         return None
 
     def read_logs_file(self, run_id, key, io_type, cursor=0, max_bytes=MAX_BYTES_FILE_READ):
         return ComputeLogFileData(
```

### Comparing `dagster-1.3.2/dagster/_core/storage/output_manager.py` & `dagster-1.3.3/dagster/_core/storage/output_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/partition_status_cache.py` & `dagster-1.3.3/dagster/_core/storage/partition_status_cache.py`

 * *Files 1% similar despite different names*

```diff
@@ -17,15 +17,15 @@
     DynamicPartitionsDefinition,
     PartitionsDefinition,
     PartitionsSubset,
     StaticPartitionsDefinition,
 )
 from dagster._core.definitions.time_window_partitions import TimeWindowPartitionsDefinition
 from dagster._core.instance import DynamicPartitionsStore
-from dagster._core.storage.pipeline_run import FINISHED_STATUSES, RunsFilter
+from dagster._core.storage.dagster_run import FINISHED_STATUSES, RunsFilter
 from dagster._core.storage.tags import (
     MULTIDIMENSIONAL_PARTITION_PREFIX,
     get_dimension_from_partition_tag,
 )
 from dagster._serdes import whitelist_for_serdes
 from dagster._serdes.errors import DeserializationError
 from dagster._serdes.serdes import deserialize_value
```

### Comparing `dagster-1.3.2/dagster/_core/storage/pipeline_run.py` & `dagster-1.3.3/dagster/_core/storage/dagster_run.py`

 * *Files 8% similar despite different names*

```diff
@@ -12,17 +12,17 @@
     Sequence,
     Union,
 )
 
 from typing_extensions import Self
 
 import dagster._check as check
-from dagster._annotations import public
+from dagster._annotations import PublicAttr, public
 from dagster._core.definitions.events import AssetKey
-from dagster._core.origin import PipelinePythonOrigin
+from dagster._core.origin import JobPythonOrigin
 from dagster._core.storage.tags import PARENT_RUN_ID_TAG, ROOT_RUN_ID_TAG
 from dagster._core.utils import make_new_run_id
 from dagster._serdes.serdes import (
     NamedTupleSerializer,
     whitelist_for_serdes,
 )
 
@@ -32,15 +32,15 @@
     RESUME_RETRY_TAG,
     SCHEDULE_NAME_TAG,
     SENSOR_NAME_TAG,
 )
 
 if TYPE_CHECKING:
     from dagster._core.host_representation.external import ExternalSchedule, ExternalSensor
-    from dagster._core.host_representation.origin import ExternalPipelineOrigin
+    from dagster._core.host_representation.origin import ExternalJobOrigin
 
 
 @whitelist_for_serdes(storage_name="PipelineRunStatus")
 class DagsterRunStatus(Enum):
     """The status of run execution."""
 
     # Runs waiting to be launched by the Dagster Daemon.
@@ -92,18 +92,18 @@
 FINISHED_STATUSES = [
     DagsterRunStatus.SUCCESS,
     DagsterRunStatus.FAILURE,
     DagsterRunStatus.CANCELED,
 ]
 
 
-@whitelist_for_serdes
-class PipelineRunStatsSnapshot(
+@whitelist_for_serdes(storage_name="PipelineRunStatsSnapshot")
+class DagsterRunStatsSnapshot(
     NamedTuple(
-        "_PipelineRunStatsSnapshot",
+        "_DagsterRunStatsSnapshot",
         [
             ("run_id", str),
             ("steps_succeeded", int),
             ("steps_failed", int),
             ("materializations", int),
             ("expectations", int),
             ("enqueued_time", Optional[float]),
@@ -121,15 +121,15 @@
         materializations: int,
         expectations: int,
         enqueued_time: Optional[float],
         launch_time: Optional[float],
         start_time: Optional[float],
         end_time: Optional[float],
     ):
-        return super(PipelineRunStatsSnapshot, cls).__new__(
+        return super(DagsterRunStatsSnapshot, cls).__new__(
             cls,
             run_id=check.str_param(run_id, "run_id"),
             steps_succeeded=check.int_param(steps_succeeded, "steps_succeeded"),
             steps_failed=check.int_param(steps_failed, "steps_failed"),
             materializations=check.int_param(materializations, "materializations"),
             expectations=check.int_param(expectations, "expectations"),
             enqueued_time=check.opt_float_param(enqueued_time, "enqueued_time"),
@@ -174,23 +174,23 @@
             selector = unpacked_dict["selector"]
 
             if not isinstance(selector, ExecutionSelector):
                 check.failed(f"unexpected entry for 'select', {selector}")
             selector_name = selector.name
             selector_subset = selector.solid_subset
 
-            pipeline_name = unpacked_dict.get("pipeline_name")
+            job_name = unpacked_dict.get("pipeline_name")
             check.invariant(
-                pipeline_name is None or selector_name == pipeline_name,
+                job_name is None or selector_name == job_name,
                 (
-                    f"Conflicting pipeline name {pipeline_name} in arguments to PipelineRun: "
+                    f"Conflicting pipeline name {job_name} in arguments to PipelineRun: "
                     f"selector was passed with pipeline {selector_name}"
                 ),
             )
-            if pipeline_name is None:
+            if job_name is None:
                 unpacked_dict["pipeline_name"] = selector_name
 
             solids_to_execute = unpacked_dict.get("solids_to_execute")
             check.invariant(
                 solids_to_execute is None
                 or (selector_subset and set(selector_subset) == solids_to_execute),
                 (
@@ -212,59 +212,65 @@
 
 @whitelist_for_serdes(
     serializer=DagsterRunSerializer,
     # DagsterRun is serialized as PipelineRun so that it can be read by older (pre 0.13.x) version
     # of Dagster, but is read back in as a DagsterRun.
     storage_name="PipelineRun",
     old_fields={"mode": None},
+    storage_field_names={
+        "job_name": "pipeline_name",
+        "job_snapshot_id": "pipeline_snapshot_id",
+        "external_job_origin": "external_pipeline_origin",
+        "job_code_origin": "pipeline_code_origin",
+    },
 )
 class DagsterRun(
     NamedTuple(
         "_DagsterRun",
         [
-            ("pipeline_name", str),
+            ("job_name", PublicAttr[str]),
             ("run_id", str),
             ("run_config", Mapping[str, object]),
             ("asset_selection", Optional[AbstractSet[AssetKey]]),
             ("solid_selection", Optional[Sequence[str]]),
             ("solids_to_execute", Optional[AbstractSet[str]]),
             ("step_keys_to_execute", Optional[Sequence[str]]),
             ("status", DagsterRunStatus),
             ("tags", Mapping[str, str]),
             ("root_run_id", Optional[str]),
             ("parent_run_id", Optional[str]),
-            ("pipeline_snapshot_id", Optional[str]),
+            ("job_snapshot_id", Optional[str]),
             ("execution_plan_snapshot_id", Optional[str]),
-            ("external_pipeline_origin", Optional["ExternalPipelineOrigin"]),
-            ("pipeline_code_origin", Optional[PipelinePythonOrigin]),
+            ("external_job_origin", Optional["ExternalJobOrigin"]),
+            ("job_code_origin", Optional[JobPythonOrigin]),
             ("has_repository_load_data", bool),
         ],
     )
 ):
     """Serializable internal representation of a dagster run, as stored in a
     :py:class:`~dagster._core.storage.runs.RunStorage`.
     """
 
     def __new__(
         cls,
-        pipeline_name: str,
+        job_name: str,
         run_id: Optional[str] = None,
         run_config: Optional[Mapping[str, object]] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
         solid_selection: Optional[Sequence[str]] = None,
         solids_to_execute: Optional[AbstractSet[str]] = None,
         step_keys_to_execute: Optional[Sequence[str]] = None,
         status: Optional[DagsterRunStatus] = None,
         tags: Optional[Mapping[str, str]] = None,
         root_run_id: Optional[str] = None,
         parent_run_id: Optional[str] = None,
-        pipeline_snapshot_id: Optional[str] = None,
+        job_snapshot_id: Optional[str] = None,
         execution_plan_snapshot_id: Optional[str] = None,
-        external_pipeline_origin: Optional["ExternalPipelineOrigin"] = None,
-        pipeline_code_origin: Optional[PipelinePythonOrigin] = None,
+        external_job_origin: Optional["ExternalJobOrigin"] = None,
+        job_code_origin: Optional[JobPythonOrigin] = None,
         has_repository_load_data: Optional[bool] = None,
     ):
         check.invariant(
             (root_run_id is not None and parent_run_id is not None)
             or (root_run_id is None and parent_run_id is None),
             (
                 "Must set both root_run_id and parent_run_id when creating a PipelineRun that "
@@ -284,94 +290,94 @@
 
         asset_selection = check.opt_nullable_set_param(
             asset_selection, "asset_selection", of_type=AssetKey
         )
 
         # Placing this with the other imports causes a cyclic import
         # https://github.com/dagster-io/dagster/issues/3181
-        from dagster._core.host_representation.origin import ExternalPipelineOrigin
+        from dagster._core.host_representation.origin import ExternalJobOrigin
 
         if status == DagsterRunStatus.QUEUED:
             check.inst_param(
-                external_pipeline_origin,
-                "external_pipeline_origin",
-                ExternalPipelineOrigin,
-                "external_pipeline_origin is required for queued runs",
+                external_job_origin,
+                "external_job_origin",
+                ExternalJobOrigin,
+                "external_job_origin is required for queued runs",
             )
 
         if run_id is None:
             run_id = make_new_run_id()
 
         return super(DagsterRun, cls).__new__(
             cls,
-            pipeline_name=check.str_param(pipeline_name, "pipeline_name"),
+            job_name=check.str_param(job_name, "job_name"),
             run_id=check.str_param(run_id, "run_id"),
             run_config=check.opt_mapping_param(run_config, "run_config", key_type=str),
             solid_selection=solid_selection,
             asset_selection=asset_selection,
             solids_to_execute=solids_to_execute,
             step_keys_to_execute=step_keys_to_execute,
             status=check.opt_inst_param(
                 status, "status", DagsterRunStatus, DagsterRunStatus.NOT_STARTED
             ),
             tags=check.opt_mapping_param(tags, "tags", key_type=str, value_type=str),
             root_run_id=check.opt_str_param(root_run_id, "root_run_id"),
             parent_run_id=check.opt_str_param(parent_run_id, "parent_run_id"),
-            pipeline_snapshot_id=check.opt_str_param(pipeline_snapshot_id, "pipeline_snapshot_id"),
+            job_snapshot_id=check.opt_str_param(job_snapshot_id, "job_snapshot_id"),
             execution_plan_snapshot_id=check.opt_str_param(
                 execution_plan_snapshot_id, "execution_plan_snapshot_id"
             ),
-            external_pipeline_origin=check.opt_inst_param(
-                external_pipeline_origin, "external_pipeline_origin", ExternalPipelineOrigin
+            external_job_origin=check.opt_inst_param(
+                external_job_origin, "external_job_origin", ExternalJobOrigin
             ),
-            pipeline_code_origin=check.opt_inst_param(
-                pipeline_code_origin, "pipeline_code_origin", PipelinePythonOrigin
+            job_code_origin=check.opt_inst_param(
+                job_code_origin, "job_code_origin", JobPythonOrigin
             ),
             has_repository_load_data=check.opt_bool_param(
                 has_repository_load_data, "has_repository_load_data", default=False
             ),
         )
 
     def with_status(self, status: DagsterRunStatus) -> Self:
         if status == DagsterRunStatus.QUEUED:
             # Placing this with the other imports causes a cyclic import
             # https://github.com/dagster-io/dagster/issues/3181
-            from dagster._core.host_representation.origin import ExternalPipelineOrigin
+            from dagster._core.host_representation.origin import ExternalJobOrigin
 
             check.inst(
-                self.external_pipeline_origin,
-                ExternalPipelineOrigin,
+                self.external_job_origin,
+                ExternalJobOrigin,
                 "external_pipeline_origin is required for queued runs",
             )
 
         return self._replace(status=status)
 
-    def with_job_origin(self, origin: "ExternalPipelineOrigin") -> Self:
-        from dagster._core.host_representation.origin import ExternalPipelineOrigin
+    def with_job_origin(self, origin: "ExternalJobOrigin") -> Self:
+        from dagster._core.host_representation.origin import ExternalJobOrigin
 
-        check.inst_param(origin, "origin", ExternalPipelineOrigin)
-        return self._replace(external_pipeline_origin=origin)
+        check.inst_param(origin, "origin", ExternalJobOrigin)
+        return self._replace(external_job_origin=origin)
 
     def with_tags(self, tags: Mapping[str, str]) -> Self:
         return self._replace(tags=tags)
 
     def get_root_run_id(self) -> Optional[str]:
         return self.tags.get(ROOT_RUN_ID_TAG)
 
     def get_parent_run_id(self) -> Optional[str]:
         return self.tags.get(PARENT_RUN_ID_TAG)
 
     def tags_for_storage(self) -> Mapping[str, str]:
         repository_tags = {}
-        if self.external_pipeline_origin:
+        if self.external_job_origin:
             # tag the run with a label containing the repository name / location name, to allow for
             # per-repository filtering of runs from dagit.
             repository_tags[
                 REPOSITORY_LABEL_TAG
-            ] = self.external_pipeline_origin.external_repository_origin.get_label()
+            ] = self.external_job_origin.external_repository_origin.get_label()
 
         if not self.tags:
             return repository_tags
 
         return {**repository_tags, **self.tags}
 
     @public
@@ -400,19 +406,14 @@
         return self.tags.get(RESUME_RETRY_TAG) == "true"
 
     @property
     def previous_run_id(self) -> Optional[str]:
         # Compat
         return self.parent_run_id
 
-    @public
-    @property
-    def job_name(self) -> str:
-        return self.pipeline_name
-
     @staticmethod
     def tags_for_schedule(schedule) -> Mapping[str, str]:
         return {SCHEDULE_NAME_TAG: schedule.name}
 
     @staticmethod
     def tags_for_sensor(sensor) -> Mapping[str, str]:
         return {SENSOR_NAME_TAG: sensor.name}
@@ -469,33 +470,29 @@
         statuses (Optional[List[DagsterRunStatus]]):
             A list of run statuses to filter by. If blank, all run statuses will be allowed.
         tags (Optional[Dict[str, Union[str, List[str]]]]):
             A dictionary of run tags to query by. All tags specified here must be present for a given run to pass the filter.
         snapshot_id (Optional[str]): The ID of the job snapshot to query for. Intended for internal use.
         updated_after (Optional[DateTime]): Filter by runs that were last updated before this datetime.
         created_before (Optional[DateTime]): Filter by runs that were created before this datetime.
-        pipeline_name (Optional[str]): (deprecated)
 
     """
 
     def __new__(
         cls,
         run_ids: Optional[Sequence[str]] = None,
         job_name: Optional[str] = None,
         statuses: Optional[Sequence[DagsterRunStatus]] = None,
         tags: Optional[Mapping[str, Union[str, Sequence[str]]]] = None,
         snapshot_id: Optional[str] = None,
         updated_after: Optional[datetime] = None,
         updated_before: Optional[datetime] = None,
         created_after: Optional[datetime] = None,
         created_before: Optional[datetime] = None,
-        pipeline_name: Optional[str] = None,  # for backcompat purposes
     ):
-        job_name = job_name or pipeline_name
-
         check.invariant(run_ids != [], "When filtering on run ids, a non-empty list must be used.")
 
         return super(RunsFilter, cls).__new__(
             cls,
             run_ids=check.opt_sequence_param(run_ids, "run_ids", of_type=str),
             job_name=check.opt_str_param(job_name, "job_name"),
             statuses=check.opt_sequence_param(statuses, "statuses", of_type=DagsterRunStatus),
@@ -503,18 +500,14 @@
             snapshot_id=check.opt_str_param(snapshot_id, "snapshot_id"),
             updated_after=check.opt_inst_param(updated_after, "updated_after", datetime),
             updated_before=check.opt_inst_param(updated_before, "updated_before", datetime),
             created_after=check.opt_inst_param(created_after, "created_after", datetime),
             created_before=check.opt_inst_param(created_before, "created_before", datetime),
         )
 
-    @property
-    def pipeline_name(self) -> Optional[str]:
-        return self.job_name
-
     @staticmethod
     def for_schedule(schedule: "ExternalSchedule") -> "RunsFilter":
         return RunsFilter(tags=DagsterRun.tags_for_schedule(schedule))
 
     @staticmethod
     def for_sensor(sensor: "ExternalSensor") -> "RunsFilter":
         return RunsFilter(tags=DagsterRun.tags_for_sensor(sensor))
```

### Comparing `dagster-1.3.2/dagster/_core/storage/root.py` & `dagster-1.3.3/dagster/_core/storage/root.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/root_input_manager.py` & `dagster-1.3.3/dagster/_core/storage/root_input_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/runs/base.py` & `dagster-1.3.3/dagster/_core/storage/runs/base.py`

 * *Files 8% similar despite different names*

```diff
@@ -2,31 +2,31 @@
 from typing import TYPE_CHECKING, Mapping, Optional, Sequence, Set, Tuple, Union
 
 from typing_extensions import TypedDict
 
 from dagster._core.events import DagsterEvent
 from dagster._core.execution.backfill import BulkActionStatus, PartitionBackfill
 from dagster._core.instance import MayHaveInstanceWeakref, T_DagsterInstance
-from dagster._core.snap import ExecutionPlanSnapshot, PipelineSnapshot
-from dagster._core.storage.pipeline_run import (
+from dagster._core.snap import ExecutionPlanSnapshot, JobSnapshot
+from dagster._core.storage.dagster_run import (
     DagsterRun,
     JobBucket,
     RunPartitionData,
     RunRecord,
     RunsFilter,
     TagBucket,
 )
 from dagster._core.storage.sql import AlembicVersion
 from dagster._daemon.types import DaemonHeartbeat
 from dagster._utils import PrintFn
 
 from ..daemon_cursor import DaemonCursorStorage
 
 if TYPE_CHECKING:
-    from dagster._core.host_representation.origin import ExternalPipelineOrigin
+    from dagster._core.host_representation.origin import ExternalJobOrigin
 
 
 class RunGroupInfo(TypedDict):
     count: int
     runs: Sequence[DagsterRun]
 
 
@@ -39,22 +39,22 @@
     Users should not directly instantiate concrete subclasses of this class; they are instantiated
     by internal machinery when ``dagit`` and ``dagster-graphql`` load, based on the values in the
     ``dagster.yaml`` file in ``$DAGSTER_HOME``. Configuration of concrete subclasses of this class
     should be done by setting values in that file.
     """
 
     @abstractmethod
-    def add_run(self, pipeline_run: DagsterRun) -> DagsterRun:
+    def add_run(self, dagster_run: DagsterRun) -> DagsterRun:
         """Add a run to storage.
 
         If a run already exists with the same ID, raise DagsterRunAlreadyExists
         If the run's snapshot ID does not exist raise DagsterSnapshotDoesNotExist
 
         Args:
-            pipeline_run (PipelineRun): The run to add.
+            dagster_run (DagsterRun): The run to add.
         """
 
     @abstractmethod
     def handle_run_event(self, run_id: str, event: DagsterEvent) -> None:
         """Update run storage in accordance to a pipeline run related DagsterEvent.
 
         Args:
@@ -216,75 +216,71 @@
 
         Returns:
             bool
         """
 
     def add_snapshot(
         self,
-        snapshot: Union[PipelineSnapshot, ExecutionPlanSnapshot],
+        snapshot: Union[JobSnapshot, ExecutionPlanSnapshot],
         snapshot_id: Optional[str] = None,
     ) -> None:
         """Add a snapshot to the storage.
 
         Args:
             snapshot (Union[PipelineSnapshot, ExecutionPlanSnapshot])
             snapshot_id (Optional[str]): [Internal] The id of the snapshot. If not provided, the
                 snapshot id will be generated from a hash of the snapshot. This should only be used
                 in debugging, where we might want to import a historical run whose snapshots were
                 calculated using a different hash function than the current code.
         """
-        if isinstance(snapshot, PipelineSnapshot):
-            self.add_pipeline_snapshot(snapshot, snapshot_id)
+        if isinstance(snapshot, JobSnapshot):
+            self.add_job_snapshot(snapshot, snapshot_id)
         else:
             self.add_execution_plan_snapshot(snapshot, snapshot_id)
 
     def has_snapshot(self, snapshot_id: str):
-        return self.has_pipeline_snapshot(snapshot_id) or self.has_execution_plan_snapshot(
-            snapshot_id
-        )
+        return self.has_job_snapshot(snapshot_id) or self.has_execution_plan_snapshot(snapshot_id)
 
     @abstractmethod
-    def has_pipeline_snapshot(self, pipeline_snapshot_id: str) -> bool:
+    def has_job_snapshot(self, job_snapshot_id: str) -> bool:
         """Check to see if storage contains a pipeline snapshot.
 
         Args:
             pipeline_snapshot_id (str): The id of the run.
 
         Returns:
             bool
         """
 
     @abstractmethod
-    def add_pipeline_snapshot(
-        self, pipeline_snapshot: PipelineSnapshot, snapshot_id: Optional[str] = None
-    ) -> str:
+    def add_job_snapshot(self, job_snapshot: JobSnapshot, snapshot_id: Optional[str] = None) -> str:
         """Add a pipeline snapshot to the run store.
 
         Pipeline snapshots are content-addressable, meaning
         that the ID for a snapshot is a hash based on the
         body of the snapshot. This function returns
         that snapshot ID.
 
         Args:
-            pipeline_snapshot (PipelineSnapshot)
+            job_snapshot (PipelineSnapshot)
             snapshot_id (Optional[str]): [Internal] The id of the snapshot. If not provided, the
                 snapshot id will be generated from a hash of the snapshot. This should only be used
                 in debugging, where we might want to import a historical run whose snapshots were
                 calculated using a different hash function than the current code.
 
         Return:
-            str: The pipeline_snapshot_id
+            str: The job_snapshot_id
         """
 
     @abstractmethod
-    def get_pipeline_snapshot(self, pipeline_snapshot_id: str) -> PipelineSnapshot:
+    def get_job_snapshot(self, job_snapshot_id: str) -> JobSnapshot:
         """Fetch a snapshot by ID.
 
         Args:
-            pipeline_snapshot_id (str)
+            job_snapshot_id (str)
 
         Returns:
             PipelineSnapshot
         """
 
     @abstractmethod
     def has_execution_plan_snapshot(self, execution_plan_snapshot_id: str) -> bool:
@@ -400,9 +396,9 @@
     def update_backfill(self, partition_backfill: PartitionBackfill):
         """Update a partition backfill in run storage."""
 
     def alembic_version(self) -> Optional[AlembicVersion]:
         return None
 
     @abstractmethod
-    def replace_job_origin(self, run: "DagsterRun", job_origin: "ExternalPipelineOrigin") -> None:
+    def replace_job_origin(self, run: "DagsterRun", job_origin: "ExternalJobOrigin") -> None:
         ...
```

### Comparing `dagster-1.3.2/dagster/_core/storage/runs/migration.py` & `dagster-1.3.3/dagster/_core/storage/runs/migration.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 from contextlib import ExitStack
-from typing import AbstractSet, Any, Callable, Iterator, Mapping, Optional
+from typing import AbstractSet, Any, Callable, Iterator, Mapping, Optional, cast
 
 import sqlalchemy as db
 import sqlalchemy.exc as db_exc
 from sqlalchemy.engine import Connection
 from tqdm import tqdm
 from typing_extensions import Final, TypeAlias
 
 import dagster._check as check
 from dagster._serdes import deserialize_value
 
 from ...execution.job_backfill import PartitionBackfill
-from ..pipeline_run import DagsterRun, DagsterRunStatus, RunRecord
+from ..dagster_run import DagsterRun, DagsterRunStatus, RunRecord
 from ..runs.base import RunStorage
 from ..runs.schema import BulkActionsTable, RunsTable, RunTagsTable
 from ..tags import PARTITION_NAME_TAG, PARTITION_SET_TAG, REPOSITORY_LABEL_TAG
 
 RUN_PARTITIONS = "run_partitions"
 RUN_START_END = (  # was run_start_end, but renamed to overwrite bad timestamps written
     "run_start_end_overwritten"
@@ -190,25 +190,25 @@
         with run_storage.connect() as conn:
             result_proxy = conn.execute(query)
             rows = result_proxy.fetchall()
             result_proxy.close()
 
             has_more = len(rows) >= CHUNK_SIZE
             for row in rows:
-                run = deserialize_value(row[0], DagsterRun)
+                run = deserialize_value(cast(str, row[0]), DagsterRun)
                 cursor = row[1]
                 write_repo_tag(conn, run)
 
 
 def write_repo_tag(conn: Connection, run: DagsterRun) -> None:
-    if not run.external_pipeline_origin:
+    if not run.external_job_origin:
         # nothing to do
         return
 
-    repository_label = run.external_pipeline_origin.external_repository_origin.get_label()
+    repository_label = run.external_job_origin.external_repository_origin.get_label()
     try:
         conn.execute(
             RunTagsTable.insert().values(
                 run_id=run.run_id,
                 key=REPOSITORY_LABEL_TAG,
                 value=repository_label,
             )
```

### Comparing `dagster-1.3.2/dagster/_core/storage/runs/schema.py` & `dagster-1.3.3/dagster/_core/storage/runs/schema.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/runs/sql_run_storage.py` & `dagster-1.3.3/dagster/_core/storage/runs/sql_run_storage.py`

 * *Files 3% similar despite different names*

```diff
@@ -32,20 +32,20 @@
     DagsterInvariantViolationError,
     DagsterRunAlreadyExists,
     DagsterRunNotFoundError,
     DagsterSnapshotDoesNotExist,
 )
 from dagster._core.events import EVENT_TYPE_TO_PIPELINE_RUN_STATUS, DagsterEvent, DagsterEventType
 from dagster._core.execution.backfill import BulkActionStatus, PartitionBackfill
-from dagster._core.host_representation.origin import ExternalPipelineOrigin
+from dagster._core.host_representation.origin import ExternalJobOrigin
 from dagster._core.snap import (
     ExecutionPlanSnapshot,
-    PipelineSnapshot,
+    JobSnapshot,
     create_execution_plan_snapshot_id,
-    create_pipeline_snapshot_id,
+    create_job_snapshot_id,
 )
 from dagster._core.storage.sql import SqlAlchemyQuery, SqlAlchemyRow
 from dagster._core.storage.tags import (
     PARTITION_NAME_TAG,
     PARTITION_SET_TAG,
     REPOSITORY_LABEL_TAG,
     ROOT_RUN_ID_TAG,
@@ -55,15 +55,15 @@
     deserialize_value,
     serialize_value,
 )
 from dagster._seven import JSONDecodeError
 from dagster._utils import PrintFn, utc_datetime_from_timestamp
 from dagster._utils.merger import merge_dicts
 
-from ..pipeline_run import (
+from ..dagster_run import (
     DagsterRun,
     DagsterRunStatus,
     JobBucket,
     RunPartitionData,
     RunRecord,
     RunsFilter,
     TagBucket,
@@ -117,70 +117,68 @@
         with self.connect() as conn:
             result_proxy = conn.execute(query)
             row = result_proxy.fetchone()
             result_proxy.close()
 
         return row
 
-    def add_run(self, pipeline_run: DagsterRun) -> DagsterRun:
-        check.inst_param(pipeline_run, "pipeline_run", DagsterRun)
+    def add_run(self, dagster_run: DagsterRun) -> DagsterRun:
+        check.inst_param(dagster_run, "dagster_run", DagsterRun)
 
-        if pipeline_run.pipeline_snapshot_id and not self.has_pipeline_snapshot(
-            pipeline_run.pipeline_snapshot_id
-        ):
+        if dagster_run.job_snapshot_id and not self.has_job_snapshot(dagster_run.job_snapshot_id):
             raise DagsterSnapshotDoesNotExist(
                 "Snapshot {ss_id} does not exist in run storage".format(
-                    ss_id=pipeline_run.pipeline_snapshot_id
+                    ss_id=dagster_run.job_snapshot_id
                 )
             )
 
-        has_tags = pipeline_run.tags and len(pipeline_run.tags) > 0
-        partition = pipeline_run.tags.get(PARTITION_NAME_TAG) if has_tags else None
-        partition_set = pipeline_run.tags.get(PARTITION_SET_TAG) if has_tags else None
+        has_tags = dagster_run.tags and len(dagster_run.tags) > 0
+        partition = dagster_run.tags.get(PARTITION_NAME_TAG) if has_tags else None
+        partition_set = dagster_run.tags.get(PARTITION_SET_TAG) if has_tags else None
 
         runs_insert = RunsTable.insert().values(
-            run_id=pipeline_run.run_id,
-            pipeline_name=pipeline_run.pipeline_name,
-            status=pipeline_run.status.value,
-            run_body=serialize_value(pipeline_run),
-            snapshot_id=pipeline_run.pipeline_snapshot_id,
+            run_id=dagster_run.run_id,
+            pipeline_name=dagster_run.job_name,
+            status=dagster_run.status.value,
+            run_body=serialize_value(dagster_run),
+            snapshot_id=dagster_run.job_snapshot_id,
             partition=partition,
             partition_set=partition_set,
         )
         with self.connect() as conn:
             try:
                 conn.execute(runs_insert)
             except db_exc.IntegrityError as exc:
                 raise DagsterRunAlreadyExists from exc
 
-            tags_to_insert = pipeline_run.tags_for_storage()
+            tags_to_insert = dagster_run.tags_for_storage()
             if tags_to_insert:
                 conn.execute(
                     RunTagsTable.insert(),
                     [
-                        dict(run_id=pipeline_run.run_id, key=k, value=v)
+                        dict(run_id=dagster_run.run_id, key=k, value=v)
                         for k, v in tags_to_insert.items()
                     ],
                 )
 
-        return pipeline_run
+        return dagster_run
 
     def handle_run_event(self, run_id: str, event: DagsterEvent) -> None:
         check.str_param(run_id, "run_id")
         check.inst_param(event, "event", DagsterEvent)
 
         if event.event_type not in EVENT_TYPE_TO_PIPELINE_RUN_STATUS:
             return
 
         run = self._get_run_by_id(run_id)
         if not run:
             # TODO log?
             return
 
-        new_pipeline_status = EVENT_TYPE_TO_PIPELINE_RUN_STATUS[event.event_type]
+        new_job_status = EVENT_TYPE_TO_PIPELINE_RUN_STATUS[event.event_type]
 
         run_stats_cols_in_index = self.has_run_stats_index_cols()
 
         kwargs = {}
 
         # consider changing the `handle_run_event` signature to get timestamp off of the
         # EventLogEntry instead of the DagsterEvent, for consistency
@@ -197,16 +195,16 @@
             kwargs["end_time"] = now.timestamp()
 
         with self.connect() as conn:
             conn.execute(
                 RunsTable.update()
                 .where(RunsTable.c.run_id == run_id)
                 .values(
-                    run_body=serialize_value(run.with_status(new_pipeline_status)),
-                    status=new_pipeline_status.value,
+                    run_body=serialize_value(run.with_status(new_job_status)),
+                    status=new_job_status.value,
                     update_timestamp=now,
                     **kwargs,
                 )
             )
 
     def _row_to_run(self, row: SqlAlchemyRow) -> DagsterRun:
         run = deserialize_value(row["run_body"], DagsterRun)
@@ -598,22 +596,22 @@
                 conn.execute(
                     RunTagsTable.insert(),
                     [dict(run_id=run_id, key=tag, value=new_tags[tag]) for tag in added_tags],
                 )
 
     def get_run_group(self, run_id: str) -> Tuple[str, Sequence[DagsterRun]]:
         check.str_param(run_id, "run_id")
-        pipeline_run = self._get_run_by_id(run_id)
-        if not pipeline_run:
+        dagster_run = self._get_run_by_id(run_id)
+        if not dagster_run:
             raise DagsterRunNotFoundError(
                 f"Run {run_id} was not found in instance.", invalid_run_id=run_id
             )
 
         # find root_run
-        root_run_id = pipeline_run.root_run_id if pipeline_run.root_run_id else pipeline_run.run_id
+        root_run_id = dagster_run.root_run_id if dagster_run.root_run_id else dagster_run.run_id
         root_run = self._get_run_by_id(root_run_id)
         if not root_run:
             raise DagsterRunNotFoundError(
                 (
                     f"Run id {root_run_id} set as root run id for run {run_id} was not found in"
                     " instance."
                 ),
@@ -773,21 +771,21 @@
         with self.connect() as conn:
             res = conn.execute(runs_and_root_runs_with_descendant_counts).fetchall()
 
         # Postprocess: descendant runs get aggregated with their roots
         root_run_id_to_group: Dict[str, List[DagsterRun]] = defaultdict(list)
         root_run_id_to_count: Dict[str, int] = defaultdict(int)
         for row in res:
-            pipeline_run = self._row_to_run(row)
-            root_run_id = pipeline_run.get_root_run_id()
+            dagster_run = self._row_to_run(row)
+            root_run_id = dagster_run.get_root_run_id()
             if root_run_id is not None:
-                root_run_id_to_group[root_run_id].append(pipeline_run)
+                root_run_id_to_group[root_run_id].append(dagster_run)
             else:
-                root_run_id_to_group[pipeline_run.run_id].append(pipeline_run)
-                root_run_id_to_count[pipeline_run.run_id] = row["child_counts"] + 1
+                root_run_id_to_group[dagster_run.run_id].append(dagster_run)
+                root_run_id_to_count[dagster_run.run_id] = cast(int, row["child_counts"]) + 1
 
         return {
             root_run_id: {
                 "runs": list(run_group),
                 "count": root_run_id_to_count[root_run_id],
             }
             for root_run_id, run_group in root_run_id_to_group.items()
@@ -799,36 +797,34 @@
 
     def delete_run(self, run_id: str) -> None:
         check.str_param(run_id, "run_id")
         query = db.delete(RunsTable).where(RunsTable.c.run_id == run_id)
         with self.connect() as conn:
             conn.execute(query)
 
-    def has_pipeline_snapshot(self, pipeline_snapshot_id: str) -> bool:
-        check.str_param(pipeline_snapshot_id, "pipeline_snapshot_id")
-        return self._has_snapshot_id(pipeline_snapshot_id)
+    def has_job_snapshot(self, job_snapshot_id: str) -> bool:
+        check.str_param(job_snapshot_id, "job_snapshot_id")
+        return self._has_snapshot_id(job_snapshot_id)
 
-    def add_pipeline_snapshot(
-        self, pipeline_snapshot: PipelineSnapshot, snapshot_id: Optional[str] = None
-    ) -> str:
-        check.inst_param(pipeline_snapshot, "pipeline_snapshot", PipelineSnapshot)
+    def add_job_snapshot(self, job_snapshot: JobSnapshot, snapshot_id: Optional[str] = None) -> str:
+        check.inst_param(job_snapshot, "job_snapshot", JobSnapshot)
         check.opt_str_param(snapshot_id, "snapshot_id")
 
         if not snapshot_id:
-            snapshot_id = create_pipeline_snapshot_id(pipeline_snapshot)
+            snapshot_id = create_job_snapshot_id(job_snapshot)
 
         return self._add_snapshot(
             snapshot_id=snapshot_id,
-            snapshot_obj=pipeline_snapshot,
+            snapshot_obj=job_snapshot,
             snapshot_type=SnapshotType.PIPELINE,
         )
 
-    def get_pipeline_snapshot(self, pipeline_snapshot_id: str) -> PipelineSnapshot:
-        check.str_param(pipeline_snapshot_id, "pipeline_snapshot_id")
-        return self._get_snapshot(pipeline_snapshot_id)  # type: ignore  # (allowed to return None?)
+    def get_job_snapshot(self, job_snapshot_id: str) -> JobSnapshot:
+        check.str_param(job_snapshot_id, "job_snapshot_id")
+        return self._get_snapshot(job_snapshot_id)  # type: ignore  # (allowed to return None?)
 
     def has_execution_plan_snapshot(self, execution_plan_snapshot_id: str) -> bool:
         check.str_param(execution_plan_snapshot_id, "execution_plan_snapshot_id")
         return bool(self.get_execution_plan_snapshot(execution_plan_snapshot_id))
 
     def add_execution_plan_snapshot(
         self, execution_plan_snapshot: ExecutionPlanSnapshot, snapshot_id: Optional[str] = None
@@ -879,15 +875,15 @@
             SnapshotsTable.c.snapshot_id == snapshot_id
         )
 
         row = self.fetchone(query)
 
         return bool(row)
 
-    def _get_snapshot(self, snapshot_id: str) -> Optional[PipelineSnapshot]:
+    def _get_snapshot(self, snapshot_id: str) -> Optional[JobSnapshot]:
         query = db.select([SnapshotsTable.c.snapshot_body]).where(
             SnapshotsTable.c.snapshot_id == snapshot_id
         )
 
         row = self.fetchone(query)
 
         return defensively_unpack_execution_plan_snapshot_query(logging, row) if row else None  # type: ignore
@@ -1156,15 +1152,15 @@
                 conn.execute(
                     KeyValueStoreTable.update()
                     .where(KeyValueStoreTable.c.key.in_(pairs.keys()))
                     .values(value=db.sql.case(pairs, value=KeyValueStoreTable.c.key))
                 )
 
     # Migrating run history
-    def replace_job_origin(self, run: DagsterRun, job_origin: ExternalPipelineOrigin) -> None:
+    def replace_job_origin(self, run: DagsterRun, job_origin: ExternalJobOrigin) -> None:
         new_label = job_origin.external_repository_origin.get_label()
         with self.connect() as conn:
             conn.execute(
                 RunsTable.update()
                 .where(RunsTable.c.run_id == run.run_id)
                 .values(
                     run_body=serialize_value(run.with_job_origin(job_origin)),
@@ -1179,15 +1175,15 @@
 
 
 GET_PIPELINE_SNAPSHOT_QUERY_ID = "get-pipeline-snapshot"
 
 
 def defensively_unpack_execution_plan_snapshot_query(
     logger: logging.Logger, row: SqlAlchemyRow
-) -> Optional[Union[ExecutionPlanSnapshot, PipelineSnapshot]]:
+) -> Optional[Union[ExecutionPlanSnapshot, JobSnapshot]]:
     # no checking here because sqlalchemy returns a special
     # row proxy and don't want to instance check on an internal
     # implementation detail
 
     def _warn(msg: str) -> None:
         logger.warning(f"get-pipeline-snapshot: {msg}")
 
@@ -1204,11 +1200,11 @@
     try:
         decoded_str = uncompressed_bytes.decode("utf-8")
     except UnicodeDecodeError:
         _warn("Could not unicode decode decompressed bytes stored in snapshot table.")
         return None
 
     try:
-        return deserialize_value(decoded_str, (ExecutionPlanSnapshot, PipelineSnapshot))
+        return deserialize_value(decoded_str, (ExecutionPlanSnapshot, JobSnapshot))
     except JSONDecodeError:
         _warn("Could not parse json in snapshot table.")
         return None
```

### Comparing `dagster-1.3.2/dagster/_core/storage/runs/sqlite/alembic/alembic.ini` & `dagster-1.3.3/dagster/_core/storage/runs/sqlite/alembic/alembic.ini`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/runs/sqlite/sqlite_run_storage.py` & `dagster-1.3.3/dagster/_core/storage/runs/sqlite/sqlite_run_storage.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/schedules/base.py` & `dagster-1.3.3/dagster/_core/storage/schedules/base.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/schedules/migration.py` & `dagster-1.3.3/dagster/_core/storage/schedules/migration.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/schedules/schema.py` & `dagster-1.3.3/dagster/_core/storage/schedules/schema.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/schedules/sql_schedule_storage.py` & `dagster-1.3.3/dagster/_core/storage/schedules/sql_schedule_storage.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/schedules/sqlite/alembic/alembic.ini` & `dagster-1.3.3/dagster/_core/storage/schedules/sqlite/alembic/alembic.ini`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/schedules/sqlite/sqlite_schedule_storage.py` & `dagster-1.3.3/dagster/_core/storage/schedules/sqlite/sqlite_schedule_storage.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/sql.py` & `dagster-1.3.3/dagster/_core/storage/sql.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/sqlite.py` & `dagster-1.3.3/dagster/_core/storage/sqlite.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/sqlite_storage.py` & `dagster-1.3.3/dagster/_core/storage/sqlite_storage.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/tags.py` & `dagster-1.3.3/dagster/_core/storage/tags.py`

 * *Files 2% similar despite different names*

```diff
@@ -55,15 +55,15 @@
 
 MAX_RETRIES_TAG = f"{SYSTEM_TAG_PREFIX}max_retries"
 RETRY_NUMBER_TAG = f"{SYSTEM_TAG_PREFIX}retry_number"
 RETRY_STRATEGY_TAG = f"{SYSTEM_TAG_PREFIX}retry_strategy"
 
 MAX_RUNTIME_SECONDS_TAG = f"{SYSTEM_TAG_PREFIX}max_runtime"
 
-CREATED_BY_TAG = f"{SYSTEM_TAG_PREFIX}created_by"
+AUTO_MATERIALIZE_TAG = f"{SYSTEM_TAG_PREFIX}auto_materialize"
 
 USER_EDITABLE_SYSTEM_TAGS = [
     PRIORITY_TAG,
     MAX_RETRIES_TAG,
     RETRY_STRATEGY_TAG,
     MAX_RUNTIME_SECONDS_TAG,
 ]
```

### Comparing `dagster-1.3.2/dagster/_core/storage/temp_file_manager.py` & `dagster-1.3.3/dagster/_core/storage/temp_file_manager.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/storage/upath_io_manager.py` & `dagster-1.3.3/dagster/_core/storage/upath_io_manager.py`

 * *Files 14% similar despite different names*

```diff
@@ -22,23 +22,22 @@
      - handles loading multiple upstream partitions (with respect to <PyObject object="PartitionMapping" />)
      - the `get_metadata` method can be customized to add additional metadata to the output
      - the `allow_missing_partitions` metadata value can be set to `True` to skip missing partitions
        (the default behavior is to raise an error)
 
     """
 
-    extension: str = ""  # override in child class
+    extension: Optional[str] = None  # override in child class
 
     def __init__(
         self,
-        base_path: UPath,
+        base_path: Optional[UPath] = None,
     ):
-        assert self.extension == "" or "." in self.extension
-
-        self._base_path = base_path
+        assert not self.extension or "." in self.extension
+        self._base_path = base_path or UPath(".")
 
     @abstractmethod
     def dump_to_path(self, context: OutputContext, obj: Any, path: UPath):
         """Child classes should override this method to write the object to the filesystem."""
 
     @abstractmethod
     def load_from_path(self, context: InputContext, path: UPath) -> Any:
@@ -48,34 +47,61 @@
         self,
         context: OutputContext,
         obj: Any,
     ) -> Dict[str, MetadataValue]:
         """Child classes should override this method to add custom metadata to the outputs."""
         return {}
 
+    # Read/write operations on paths can generally be handled by methods on the
+    # UPath class, but when the backend requires credentials, this isn't
+    # always possible. Override these path_* methods to provide custom
+    # implementations for targeting backends that require authentication.
+
+    def unlink(self, path: UPath) -> None:
+        """Remove the file or object at the provided path."""
+        path.unlink()
+
+    def path_exists(self, path: UPath) -> bool:
+        """Check if a file or object exists at the provided path."""
+        return path.exists()
+
+    def make_directory(self, path: UPath):
+        """Create a directory at the provided path.
+
+        Override as a no-op if the target backend doesn't use directories.
+        """
+        path.mkdir(parents=True, exist_ok=True)
+
     def has_output(self, context: OutputContext) -> bool:
-        return self._get_path(context).exists()
+        return self.path_exists(self._get_path(context))
 
     def _with_extension(self, path: UPath) -> UPath:
-        # Can't just call path.with_suffix(self.extension) because if
-        # self.extension is "" then this trims off any extension that
-        # was in the path previously.
-        return path.parent / (path.name + self.extension)
+        return UPath(f"{path}{self.extension}") if self.extension else path
 
     def _get_path_without_extension(self, context: Union[InputContext, OutputContext]) -> UPath:
         if context.has_asset_key:
-            # we are dealing with an asset
-
-            # we are not using context.get_asset_identifier() because it already includes the partition_key
-            context_path = list(context.asset_key.path)
+            context_path = self.get_asset_relative_path(context)
         else:
             # we are dealing with an op output
-            context_path = list(context.get_identifier())
+            context_path = self.get_op_output_relative_path(context)
+
+        return self._base_path.joinpath(context_path)
 
-        return self._base_path.joinpath(*context_path)
+    def get_asset_relative_path(self, context: Union[InputContext, OutputContext]) -> UPath:
+        # we are not using context.get_asset_identifier() because it already includes the partition_key
+        return UPath(*context.asset_key.path)
+
+    def get_op_output_relative_path(self, context: Union[InputContext, OutputContext]) -> UPath:
+        return UPath(*context.get_identifier())
+
+    def get_loading_input_log_message(self, path: UPath) -> str:
+        return f"Loading file from: {path}"
+
+    def get_writing_output_log_message(self, path: UPath) -> str:
+        return f"Writing file at: {path}"
 
     def _get_path(self, context: Union[InputContext, OutputContext]) -> UPath:
         """Returns the I/O path for a given context.
         Should not be used with partitions (use `_get_paths_for_partitions` instead).
         """
         path = self._get_path_without_extension(context)
         return self._with_extension(path)
@@ -125,15 +151,15 @@
             for partition_key in partition_keys
             if isinstance(partition_key, MultiPartitionKey)
         }
 
     def _load_single_input(
         self, path: UPath, context: InputContext, backcompat_path: Optional[UPath] = None
     ) -> Any:
-        context.log.debug(f"Loading file from: {path}")
+        context.log.debug(self.get_loading_input_log_message(path))
         try:
             obj = self.load_from_path(context=context, path=path)
         except FileNotFoundError as e:
             if backcompat_path is not None:
                 try:
                     obj = self.load_from_path(context=context, path=backcompat_path)
                     context.log.debug(
@@ -181,47 +207,42 @@
                     "because the input metadata includes allow_missing_partitions=True"
                 )
 
         # TODO: context.add_output_metadata fails in the partitioned context. this should be fixed?
         return objs
 
     def load_input(self, context: InputContext) -> Union[Any, Dict[str, Any]]:
-        if not context.has_asset_key:
-            # we are dealing with an op output which is always non-partitioned
+        # If no asset key, we are dealing with an op output which is always non-partitioned
+        if not context.has_asset_key or not context.has_asset_partitions:
             path = self._get_path(context)
             return self._load_single_input(path, context)
         else:
-            if not context.has_asset_partitions:
-                # we are dealing with a non-partitioned asset
-                path = self._get_path(context)
-                return self._load_single_input(path, context)
-            else:
-                asset_partition_keys = context.asset_partition_keys
-                if len(asset_partition_keys) == 0:
-                    return None
-                elif len(asset_partition_keys) == 1:
-                    paths = self._get_paths_for_partitions(context)
-                    check.invariant(len(paths) == 1, f"Expected 1 path, but got {len(paths)}")
-                    path = list(paths.values())[0]
-                    backcompat_paths = self._get_multipartition_backcompat_paths(context)
-                    backcompat_path = (
-                        None if not backcompat_paths else list(backcompat_paths.values())[0]
-                    )
+            asset_partition_keys = context.asset_partition_keys
+            if len(asset_partition_keys) == 0:
+                return None
+            elif len(asset_partition_keys) == 1:
+                paths = self._get_paths_for_partitions(context)
+                check.invariant(len(paths) == 1, f"Expected 1 path, but got {len(paths)}")
+                path = list(paths.values())[0]
+                backcompat_paths = self._get_multipartition_backcompat_paths(context)
+                backcompat_path = (
+                    None if not backcompat_paths else list(backcompat_paths.values())[0]
+                )
 
-                    return self._load_single_input(path, context, backcompat_path)
-                else:  # we are dealing with multiple partitions of an asset
-                    type_annotation = context.dagster_type.typing_type
-                    if type_annotation != Any and not is_dict_type(type_annotation):
-                        check.failed(
-                            "Loading an input that corresponds to multiple partitions, but the"
-                            " type annotation on the op input is not a dict, Dict, Mapping, or"
-                            f" Any: is '{type_annotation}'."
-                        )
+                return self._load_single_input(path, context, backcompat_path)
+            else:  # we are dealing with multiple partitions of an asset
+                type_annotation = context.dagster_type.typing_type
+                if type_annotation != Any and not is_dict_type(type_annotation):
+                    check.failed(
+                        "Loading an input that corresponds to multiple partitions, but the"
+                        " type annotation on the op input is not a dict, Dict, Mapping, or"
+                        f" Any: is '{type_annotation}'."
+                    )
 
-                    return self._load_multiple_inputs(context)
+                return self._load_multiple_inputs(context)
 
     def handle_output(self, context: OutputContext, obj: Any):
         if context.dagster_type.typing_type == type(None):
             check.invariant(
                 obj is None,
                 (
                     "Output had Nothing type or 'None' annotation, but handle_output received"
@@ -232,16 +253,16 @@
 
         if context.has_asset_partitions:
             paths = self._get_paths_for_partitions(context)
             assert len(paths) == 1
             path = list(paths.values())[0]
         else:
             path = self._get_path(context)
-        path.parent.mkdir(parents=True, exist_ok=True)
-        context.log.debug(f"Writing file at: {path}")
+        self.make_directory(path.parent)
+        context.log.debug(self.get_writing_output_log_message(path))
         self.dump_to_path(context=context, obj=obj, path=path)
 
         metadata = {"path": MetadataValue.path(str(path))}
         custom_metadata = self.get_metadata(context=context, obj=obj)
         metadata.update(custom_metadata)  # type: ignore
 
         context.add_output_metadata(metadata)
```

### Comparing `dagster-1.3.2/dagster/_core/system_config/composite_descent.py` & `dagster-1.3.3/dagster/_core/system_config/composite_descent.py`

 * *Files 4% similar despite different names*

```diff
@@ -34,84 +34,84 @@
 
 # This is a dummy handle used to simplify the code, corresponding to the root container (graph). It
 # doesn't actually represent a node during execution.
 _ROOT_HANDLE = NodeHandle("root", None)
 
 
 class DescentStack(
-    NamedTuple("_DescentStack", [("pipeline_def", JobDefinition), ("handle", NodeHandle)])
+    NamedTuple("_DescentStack", [("job_def", JobDefinition), ("handle", NodeHandle)])
 ):
-    def __new__(cls, pipeline_def: JobDefinition, handle: NodeHandle):
+    def __new__(cls, job_def: JobDefinition, handle: NodeHandle):
         return super(DescentStack, cls).__new__(
             cls,
-            pipeline_def=check.inst_param(pipeline_def, "pipeline_def", JobDefinition),
+            job_def=check.inst_param(job_def, "job_def", JobDefinition),
             handle=check.inst_param(handle, "handle", NodeHandle),
         )
 
     @property
     def current_container(self) -> GraphDefinition:
         if self.handle == _ROOT_HANDLE:
-            return self.pipeline_def.graph
+            return self.job_def.graph
         else:
             assert isinstance(self.current_node, GraphNode)
             return self.current_node.definition
 
     @property
     def current_node(self) -> Node:
         assert self.handle is not None
-        return self.pipeline_def.get_node(self.handle)
+        return self.job_def.get_node(self.handle)
 
     @property
     def current_handle_str(self) -> str:
         return check.not_none(self.handle).to_string()
 
     def descend(self, node: Node) -> "DescentStack":
         parent = self.handle if self.handle != _ROOT_HANDLE else None
         return self._replace(handle=NodeHandle(node.name, parent=parent))
 
 
 def composite_descent(
-    pipeline_def: JobDefinition,
+    job_def: JobDefinition,
     ops_config: Mapping[str, RawNodeConfig],
     resource_defs: Mapping[str, ResourceDefinition],
 ) -> Mapping[str, OpConfig]:
     """This function is responsible for constructing the dictionary of OpConfig (indexed by handle)
     that will be passed into the ResolvedRunConfig. Critically this is the codepath that manages
     config mapping, where the runtime calls into user-defined config mapping functions to produce
-    config for child solids of composites.
+    config for child nodes of graphs.
 
     Args:
-        pipeline_def (PipelineDefinition): PipelineDefinition
+        job_def (JobDefinition): JobDefinition
         ops_config (dict): Configuration for the ops in the pipeline. The "ops" entry
             of the run_config. Assumed to have already been validated.
 
     Returns:
         Dict[str, OpConfig]: A dictionary mapping string representations of NodeHandles to
             OpConfig objects. It includes an entry for ops at every level of the
             composite tree - i.e. not just leaf ops, but composite ops as well
     """
-    check.inst_param(pipeline_def, "pipeline_def", JobDefinition)
-    check.dict_param(ops_config, "solids_config")
+    check.inst_param(job_def, "job_def", JobDefinition)
+    check.dict_param(ops_config, "ops_config")
     check.dict_param(resource_defs, "resource_defs", key_type=str, value_type=ResourceDefinition)
 
     # If top-level graph has config mapping, apply that config mapping before descending.
-    if pipeline_def.graph.has_config_mapping:
+    if job_def.graph.has_config_mapping:
         ops_config = _apply_top_level_config_mapping(
-            pipeline_def,
+            job_def,
             ops_config,
             resource_defs,
         )
 
     return {
         handle.to_string(): op_config
         for handle, op_config in _composite_descent(
-            parent_stack=DescentStack(pipeline_def, _ROOT_HANDLE),
+            parent_stack=DescentStack(job_def, _ROOT_HANDLE),
             ops_config_dict=ops_config,
             resource_defs=resource_defs,
-            asset_layer=pipeline_def.asset_layer,
+            asset_layer=job_def.asset_layer,
         )
     }
 
 
 def _composite_descent(
     parent_stack: DescentStack,
     ops_config_dict: Mapping[str, RawNodeConfig],
@@ -158,16 +158,16 @@
                     {
                         "inputs": current_op_config.get("inputs"),
                         "outputs": current_op_config.get("outputs"),
                     }
                 ),
             )
 
-            # If there is a config mapping, invoke it and get the descendent solids
-            # config that way. Else just grabs the solids entry of the current config
+            # If there is a config mapping, invoke it and get the descendent nodes
+            # config that way. Else just grabs the ops entry of the current config
             mapped_nodes_config = (
                 _apply_config_mapping(
                     node,
                     current_stack,
                     current_op_config,
                     resource_defs,
                     asset_layer,
@@ -183,75 +183,75 @@
                 asset_layer,
             )
         else:
             check.failed(f"Unexpected node type {type(node)}")
 
 
 def _apply_top_level_config_mapping(
-    pipeline_def: JobDefinition,
+    job_def: JobDefinition,
     outer_config: Mapping[str, Mapping[str, object]],
     resource_defs: Mapping[str, ResourceDefinition],
 ) -> Mapping[str, RawNodeConfig]:
-    graph_def = pipeline_def.graph
+    graph_def = job_def.graph
     config_mapping = graph_def.config_mapping
     if config_mapping is None:
         return outer_config
 
     else:
         mapped_config_evr = graph_def.apply_config_mapping(outer_config)
         if not mapped_config_evr.success:
             raise DagsterInvalidConfigError(
                 f"Error in config for graph {graph_def.name}",
                 mapped_config_evr.errors,
                 outer_config,
             )
 
         with user_code_error_boundary(
-            DagsterConfigMappingFunctionError, _get_top_level_error_lambda(pipeline_def)
+            DagsterConfigMappingFunctionError, _get_top_level_error_lambda(job_def)
         ):
             mapped_graph_config = config_mapping.resolve_from_validated_config(
                 mapped_config_evr.value.get("config", {})  # type: ignore  # (possible none)
             )
 
         # Dynamically construct the type that the output of the config mapping function will
         # be evaluated against
 
         type_to_evaluate_against = define_node_shape(
             nodes=graph_def.nodes,
             ignored_nodes=None,
             dependency_structure=graph_def.dependency_structure,
             resource_defs=resource_defs,
-            asset_layer=pipeline_def.asset_layer,
+            asset_layer=job_def.asset_layer,
             node_input_source_assets=graph_def.node_input_source_assets,
         )
 
         # process against that new type
 
         evr = process_config(type_to_evaluate_against, mapped_graph_config)
 
         if not evr.success:
-            raise_top_level_config_error(pipeline_def, mapped_graph_config, evr)
+            raise_top_level_config_error(job_def, mapped_graph_config, evr)
 
         return evr.value  # type: ignore  # (unknown evr type)
 
 
 def _apply_config_mapping(
     graph_node: GraphNode,
     current_stack: DescentStack,
     current_node_config: RawNodeConfig,
     resource_defs: Mapping[str, ResourceDefinition],
     asset_layer: AssetLayer,
 ) -> Mapping[str, RawNodeConfig]:
     # the spec of the config mapping function is that it takes the dictionary at:
-    # solid_name:
+    # op_name:
     #    config: {dict_passed_to_user}
 
-    # and it returns the dictionary rooted at solids
-    # solid_name:
-    #    solids: {return_value_of_config_fn}
+    # and it returns the dictionary rooted at ops
+    # op_name:
+    #    ops: {return_value_of_config_fn}
 
     # We must call the config mapping function and then validate it against
     # the child schema.
 
     # apply @configured config mapping to the composite's incoming config before we get to the
     # composite's own config mapping process
     graph_def = graph_node.definition
@@ -263,94 +263,94 @@
             config_mapped_node_config,
         )
 
     with user_code_error_boundary(
         DagsterConfigMappingFunctionError, _get_error_lambda(current_stack)
     ):
         config_mapping = check.not_none(graph_def.config_mapping)
-        mapped_solids_config = config_mapping.resolve_from_validated_config(
+        mapped_ops_config = config_mapping.resolve_from_validated_config(
             config_mapped_node_config.value.get("config", {})  # type: ignore  # (unknown EVR type)
         )
 
     # Dynamically construct the type that the output of the config mapping function will
     # be evaluated against
 
     # diff original graph and the subselected graph to find nodes to ignore so the system knows to
     # skip the validation then when config mapping generates values where the nodes are not selected
-    ignored_solids = (
+    ignored_nodes = (
         graph_def.get_top_level_omitted_nodes()
         if isinstance(graph_def, SubselectedGraphDefinition)
         else None
     )
 
     type_to_evaluate_against = define_node_shape(
         nodes=graph_def.nodes,
-        ignored_nodes=ignored_solids,
+        ignored_nodes=ignored_nodes,
         dependency_structure=graph_def.dependency_structure,
         parent_handle=current_stack.handle,
         resource_defs=resource_defs,
         asset_layer=asset_layer,
         node_input_source_assets=graph_def.node_input_source_assets,
     )
 
     # process against that new type
 
-    evr = process_config(type_to_evaluate_against, mapped_solids_config)
+    evr = process_config(type_to_evaluate_against, mapped_ops_config)
 
     if not evr.success:
-        raise_composite_descent_config_error(current_stack, mapped_solids_config, evr)
+        raise_composite_descent_config_error(current_stack, mapped_ops_config, evr)
 
     return evr.value  # type: ignore  # (unknown evr type)
 
 
 def _get_error_lambda(current_stack: DescentStack) -> Callable[[], str]:
     return lambda: (
         "The config mapping function on {described_node} in {described_target} "
         "has thrown an unexpected error during its execution. The definition is "
         'instantiated at stack "{stack_str}".'
     ).format(
         described_node=current_stack.current_node.describe_node(),
-        described_target=current_stack.pipeline_def.describe_target(),
+        described_target=current_stack.job_def.describe_target(),
         stack_str=":".join(current_stack.handle.path),
     )
 
 
-def _get_top_level_error_lambda(pipeline_def: JobDefinition) -> Callable[[], str]:
+def _get_top_level_error_lambda(job_def: JobDefinition) -> Callable[[], str]:
     return (
-        lambda: f"The config mapping function on top-level graph {pipeline_def.graph.name} in job {pipeline_def.name} has thrown an unexpected error during its execution."
+        lambda: f"The config mapping function on top-level graph {job_def.graph.name} in job {job_def.name} has thrown an unexpected error during its execution."
     )
 
 
 def raise_top_level_config_error(
-    pipeline_def: JobDefinition, failed_config_value: object, evr: EvaluateValueResult
+    job_def: JobDefinition, failed_config_value: object, evr: EvaluateValueResult
 ) -> NoReturn:
     message = (
-        f"In job '{pipeline_def.name}', top level graph '{pipeline_def.graph.name}' has a "
+        f"In job '{job_def.name}', top level graph '{job_def.graph.name}' has a "
         "configuration error."
     )
 
     raise DagsterInvalidConfigError(message, evr.errors, failed_config_value)
 
 
 def raise_composite_descent_config_error(
     descent_stack: DescentStack, failed_config_value: object, evr: EvaluateValueResult
 ) -> NoReturn:
     check.inst_param(descent_stack, "descent_stack", DescentStack)
     check.inst_param(evr, "evr", EvaluateValueResult)
 
-    solid = descent_stack.current_node
+    node = descent_stack.current_node
     message = "In job {job_name} at stack {stack}: \n".format(
-        job_name=descent_stack.pipeline_def.name,
+        job_name=descent_stack.job_def.name,
         stack=":".join(descent_stack.handle.path),
     )
     message += (
-        f'Op "{solid.name}" with definition "{solid.definition.name}" has a '
+        f'Op "{node.name}" with definition "{node.definition.name}" has a '
         "configuration error. "
         "It has produced config a via its config_fn that fails to "
-        "pass validation in the solids that it contains. "
+        "pass validation in the ops that it contains. "
         "This indicates an error in the config mapping function itself. It must "
-        "produce correct config for its constiuent solids in all cases. The correct "
+        "produce correct config for its constituent ops in all cases. The correct "
         "resolution is to fix the mapping function. Details on the error (and the paths "
         'on this error are relative to config mapping function "root", not the entire document): '
     )
 
     raise DagsterInvalidConfigError(message, evr.errors, failed_config_value)
```

### Comparing `dagster-1.3.2/dagster/_core/system_config/objects.py` & `dagster-1.3.3/dagster/_core/system_config/objects.py`

 * *Files 4% similar despite different names*

```diff
@@ -125,65 +125,65 @@
             loggers=check.opt_mapping_param(loggers, "loggers", key_type=str, value_type=Mapping),
             original_config_dict=original_config_dict,
             inputs=inputs,
         )
 
     @staticmethod
     def build(
-        pipeline_def: JobDefinition,
+        job_def: JobDefinition,
         run_config: Optional[Mapping[str, object]] = None,
     ) -> "ResolvedRunConfig":
         """This method validates a given run config against the pipeline config schema. If
         successful, we instantiate an ResolvedRunConfig object.
 
         In case the run_config is invalid, this method raises a DagsterInvalidConfigError
         """
         from dagster._config import process_config
 
         from .composite_descent import composite_descent
 
-        check.inst_param(pipeline_def, "pipeline_def", JobDefinition)
+        check.inst_param(job_def, "job_def", JobDefinition)
         run_config = check.opt_mapping_param(run_config, "run_config")
 
-        run_config_schema = pipeline_def.run_config_schema
+        run_config_schema = job_def.run_config_schema
         if run_config_schema.config_mapping:
             # add user code boundary
             run_config = run_config_schema.config_mapping.resolve_from_unvalidated_config(
                 run_config
             )
 
         config_evr = process_config(
             run_config_schema.run_config_schema_type, check.not_none(run_config)
         )
         if not config_evr.success:
             raise DagsterInvalidConfigError(
-                f"Error in config for job {pipeline_def.name}",
+                f"Error in config for job {job_def.name}",
                 config_evr.errors,
                 run_config,
             )
 
         config_value = cast(Dict[str, Any], config_evr.value)
 
         # If using the `execute_in_process` executor, we ignore the execution config value, since it
         # may be pointing to the executor for the job rather than the `execute_in_process` executor.
-        if pipeline_def.executor_def == execute_in_process_executor:
+        if job_def.executor_def == execute_in_process_executor:
             config_mapped_execution_configs: Optional[Mapping[str, Any]] = {}
         else:
             executor_config = config_value.get("execution", {})
             config_mapped_execution_configs = config_map_executor(
-                executor_config, pipeline_def.executor_def
+                executor_config, job_def.executor_def
             )
 
-        resource_defs = pipeline_def.get_required_resource_defs()
+        resource_defs = job_def.get_required_resource_defs()
         resource_configs = config_value.get("resources", {})
         config_mapped_resource_configs = config_map_resources(resource_defs, resource_configs)
-        config_mapped_logger_configs = config_map_loggers(pipeline_def, config_value)
+        config_mapped_logger_configs = config_map_loggers(job_def, config_value)
 
         op_config_dict = composite_descent(
-            pipeline_def, config_value.get("ops", {}), pipeline_def.resource_defs
+            job_def, config_value.get("ops", {}), job_def.resource_defs
         )
         input_configs = config_value.get("inputs", {})
         return ResolvedRunConfig(
             ops=op_config_dict,
             execution=ExecutionConfig.from_dict(config_mapped_execution_configs),
             loggers=config_mapped_logger_configs,
             original_config_dict=run_config,
@@ -258,15 +258,15 @@
                 resource_config_evr.value
             )
 
     return config_mapped_resource_configs
 
 
 def config_map_loggers(
-    pipeline_def: JobDefinition,
+    job_def: JobDefinition,
     config_value: Mapping[str, Any],
 ) -> Mapping[str, Any]:
     """This function executes the config mappings for loggers with respect to ConfigurableDefinition.
     It uses the `loggers` key on the run_config to determine which loggers will be initialized (and
     thus which ones need config mapping) and then iterates over each, looking up the corresponding
     LoggerDefinition in `mode_def.loggers`.
 
@@ -285,15 +285,15 @@
     in the other.
     """
     logger_configs = config_value.get("loggers", {})
 
     config_mapped_logger_configs = {}
 
     for logger_key, logger_config in logger_configs.items():
-        logger_def = pipeline_def.loggers.get(logger_key)
+        logger_def = job_def.loggers.get(logger_key)
         if logger_def is None:
             check.failed(f"No logger found for key {logger_key}")
 
         logger_config_evr = logger_def.apply_config_mapping(logger_config)
         if not logger_config_evr.success:
             raise DagsterInvalidConfigError(
                 f"Error in config for logger {logger_key}",
```

### Comparing `dagster-1.3.2/dagster/_core/telemetry.py` & `dagster-1.3.3/dagster/_core/telemetry.py`

 * *Files 8% similar despite different names*

```diff
@@ -35,30 +35,30 @@
 
 import click
 import yaml
 from typing_extensions import ParamSpec
 
 import dagster._check as check
 from dagster._core.definitions.auto_materialize_policy import AutoMaterializePolicyType
-from dagster._core.definitions.pipeline_base import IPipeline
+from dagster._core.definitions.job_base import IJob
 from dagster._core.definitions.reconstruct import (
-    ReconstructablePipeline,
+    ReconstructableJob,
     ReconstructableRepository,
     get_ephemeral_repository_name,
 )
 from dagster._core.errors import DagsterInvariantViolationError
 from dagster._core.events import DagsterEvent
 from dagster._core.execution.context.system import PlanOrchestrationContext
 from dagster._core.execution.plan.objects import StepSuccessData
 from dagster._core.instance import DagsterInstance
 from dagster._utils.merger import merge_dicts
 from dagster.version import __version__ as dagster_module_version
 
 if TYPE_CHECKING:
-    from dagster._core.host_representation.external import ExternalPipeline, ExternalRepository
+    from dagster._core.host_representation.external import ExternalJob, ExternalRepository
     from dagster._core.workspace.context import IWorkspaceProcessContext
 
 TELEMETRY_STR = ".telemetry"
 INSTANCE_ID_STR = "instance_id"
 ENABLED_STR = "enabled"
 DAGSTER_HOME_FALLBACK = "~/.dagster"
 MAX_BYTES = 10485760  # 10 MB = 10 * 1024 * 1024 bytes
@@ -538,111 +538,111 @@
     }
 
 
 def log_external_repo_stats(
     instance: DagsterInstance,
     source: str,
     external_repo: "ExternalRepository",
-    external_pipeline: Optional["ExternalPipeline"] = None,
+    external_job: Optional["ExternalJob"] = None,
 ):
-    from dagster._core.host_representation.external import ExternalPipeline, ExternalRepository
+    from dagster._core.host_representation.external import ExternalJob, ExternalRepository
 
     check.inst_param(instance, "instance", DagsterInstance)
     check.str_param(source, "source")
     check.inst_param(external_repo, "external_repo", ExternalRepository)
-    check.opt_inst_param(external_pipeline, "external_pipeline", ExternalPipeline)
+    check.opt_inst_param(external_job, "external_job", ExternalJob)
 
     if _get_instance_telemetry_enabled(instance):
         instance_id = get_or_set_instance_id()
 
-        pipeline_name_hash = hash_name(external_pipeline.name) if external_pipeline else ""
+        job_name_hash = hash_name(external_job.name) if external_job else ""
         repo_hash = hash_name(external_repo.name)
         location_name_hash = hash_name(external_repo.handle.location_name)
 
         write_telemetry_log_line(
             TelemetryEntry(
                 action=UPDATE_REPO_STATS,
                 client_time=str(datetime.datetime.now()),
                 event_id=str(uuid.uuid4()),
                 instance_id=instance_id,
                 metadata={
                     **get_stats_from_external_repo(external_repo),
                     "source": source,
-                    "pipeline_name_hash": pipeline_name_hash,
+                    "pipeline_name_hash": job_name_hash,
                     "repo_hash": repo_hash,
                     "location_name_hash": location_name_hash,
                 },
             )._asdict()
         )
 
 
 def log_repo_stats(
     instance: DagsterInstance,
     source: str,
-    pipeline: Optional[IPipeline] = None,
+    job: Optional[IJob] = None,
     repo: Optional[ReconstructableRepository] = None,
 ) -> None:
     from dagster._core.definitions.assets import AssetsDefinition
     from dagster._core.definitions.partition import DynamicPartitionsDefinition
 
     check.inst_param(instance, "instance", DagsterInstance)
     check.str_param(source, "source")
-    check.opt_inst_param(pipeline, "pipeline", IPipeline)
+    check.opt_inst_param(job, "job", IJob)
     check.opt_inst_param(repo, "repo", ReconstructableRepository)
 
     def _get_num_dynamic_partitioned_assets(asset_defs: Sequence[AssetsDefinition]) -> int:
         return sum(
             1
             for asset in asset_defs
             if asset.partitions_def
             and isinstance(asset.partitions_def, DynamicPartitionsDefinition)
         )
 
     if _get_instance_telemetry_enabled(instance):
         instance_id = get_or_set_instance_id()
 
-        if isinstance(pipeline, ReconstructablePipeline):
-            pipeline_name_hash = hash_name(pipeline.get_definition().name)
-            repository = pipeline.get_reconstructable_repository().get_definition()
+        if isinstance(job, ReconstructableJob):
+            job_name_hash = hash_name(job.get_definition().name)
+            repository = job.get_reconstructable_repository().get_definition()
             repo_hash = hash_name(repository.name)
-            num_pipelines_in_repo = len(repository.pipeline_names)
+            num_jobs_in_repo = len(repository.job_names)
             num_schedules_in_repo = len(repository.schedule_defs)
             num_sensors_in_repo = len(repository.sensor_defs)
             all_assets = list(repository.assets_defs_by_key.values())
             num_assets_in_repo = len(all_assets)
             num_dynamic_partitioned_assets_in_repo = _get_num_dynamic_partitioned_assets(all_assets)
         elif isinstance(repo, ReconstructableRepository):
-            pipeline_name_hash = ""
+            job_name_hash = ""
             repository = repo.get_definition()
             repo_hash = hash_name(repository.name)
-            num_pipelines_in_repo = len(repository.pipeline_names)
+            num_jobs_in_repo = len(repository.job_names)
             num_schedules_in_repo = len(repository.schedule_defs)
             num_sensors_in_repo = len(repository.sensor_defs)
             all_assets = list(repository.assets_defs_by_key.values())
             num_assets_in_repo = len(all_assets)
             num_dynamic_partitioned_assets_in_repo = _get_num_dynamic_partitioned_assets(all_assets)
         else:
-            pipeline_name_hash = hash_name(pipeline.get_definition().name)  # type: ignore
-            repo_hash = hash_name(get_ephemeral_repository_name(pipeline.get_definition().name))  # type: ignore
-            num_pipelines_in_repo = 1
+            job_name_hash = hash_name(job.get_definition().name)  # type: ignore
+            repo_hash = hash_name(get_ephemeral_repository_name(job.get_definition().name))  # type: ignore
+            num_jobs_in_repo = 1
             num_schedules_in_repo = 0
             num_sensors_in_repo = 0
             num_assets_in_repo = 0
             num_dynamic_partitioned_assets_in_repo = 0
 
         write_telemetry_log_line(
             TelemetryEntry(
                 action=UPDATE_REPO_STATS,
                 client_time=str(datetime.datetime.now()),
                 event_id=str(uuid.uuid4()),
                 instance_id=instance_id,
                 metadata={
                     "source": source,
-                    "pipeline_name_hash": pipeline_name_hash,
-                    "num_pipelines_in_repo": str(num_pipelines_in_repo),
+                    "pipeline_name_hash": job_name_hash,
+                    "num_pipelines_in_repo": str(num_jobs_in_repo),
                     "num_schedules_in_repo": str(num_schedules_in_repo),
                     "num_sensors_in_repo": str(num_sensors_in_repo),
                     "num_assets_in_repo": str(num_assets_in_repo),
                     "repo_hash": repo_hash,
                     "num_dynamic_partitioned_assets_in_repo": str(
                         num_dynamic_partitioned_assets_in_repo
                     ),
@@ -694,34 +694,34 @@
                 instance_id=instance_id,
                 metadata=metadata,
                 run_storage_id=run_storage_id,
             )._asdict()
         )
 
 
-def log_dagster_event(event: DagsterEvent, pipeline_context: PlanOrchestrationContext) -> None:
+def log_dagster_event(event: DagsterEvent, job_context: PlanOrchestrationContext) -> None:
     if not any((event.is_step_start, event.is_step_success, event.is_step_failure)):
         return
 
     metadata = {
-        "run_id_hash": hash_name(pipeline_context.run_id),
+        "run_id_hash": hash_name(job_context.run_id),
         "step_key_hash": hash_name(event.step_key),  # type: ignore
     }
 
     if event.is_step_start:
         action = STEP_START_EVENT
     elif event.is_step_success:
         action = STEP_SUCCESS_EVENT
         if isinstance(event.event_specific_data, StepSuccessData):  # make mypy happy
             metadata["duration_ms"] = event.event_specific_data.duration_ms  # type: ignore
     else:  # event.is_step_failure
         action = STEP_FAILURE_EVENT
 
     log_action(
-        instance=pipeline_context.instance,
+        instance=job_context.instance,
         action=action,
         client_time=datetime.datetime.now(),
         metadata=metadata,
     )
 
 
 TELEMETRY_TEXT = """
```

### Comparing `dagster-1.3.2/dagster/_core/telemetry_upload.py` & `dagster-1.3.3/dagster/_core/telemetry_upload.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/test_utils.py` & `dagster-1.3.3/dagster/_core/test_utils.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,19 +1,21 @@
 import asyncio
 import os
 import re
 import time
+import warnings
 from collections import defaultdict
 from concurrent.futures import Future, ThreadPoolExecutor
 from contextlib import contextmanager
 from signal import Signals
 from typing import (
     TYPE_CHECKING,
     AbstractSet,
     Any,
+    Callable,
     Dict,
     Iterator,
     Mapping,
     NamedTuple,
     NoReturn,
     Optional,
     Sequence,
@@ -35,22 +37,22 @@
 from dagster._core.definitions.decorators import op
 from dagster._core.definitions.decorators.graph_decorator import graph
 from dagster._core.definitions.graph_definition import GraphDefinition
 from dagster._core.definitions.node_definition import NodeDefinition
 from dagster._core.errors import DagsterUserCodeUnreachableError
 from dagster._core.events import DagsterEvent
 from dagster._core.host_representation.origin import (
-    ExternalPipelineOrigin,
+    ExternalJobOrigin,
     InProcessCodeLocationOrigin,
 )
 from dagster._core.instance import DagsterInstance
 from dagster._core.launcher import RunLauncher
 from dagster._core.run_coordinator import RunCoordinator, SubmitRunContext
 from dagster._core.secrets import SecretsLoader
-from dagster._core.storage.pipeline_run import DagsterRun, DagsterRunStatus, RunsFilter
+from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus, RunsFilter
 from dagster._core.types.loadable_target_origin import LoadableTargetOrigin
 from dagster._core.workspace.context import WorkspaceProcessContext, WorkspaceRequestContext
 from dagster._core.workspace.load_target import WorkspaceLoadTarget
 from dagster._serdes import ConfigurableClass
 from dagster._serdes.config_class import ConfigurableClassData
 from dagster._seven.compat.pendulum import create_pendulum_time, mock_pendulum_timezone
 from dagster._utils import Counter, get_terminate_signal, traced, traced_counter
@@ -91,15 +93,15 @@
 def step_output_event_filter(pipe_iterator: Iterator[DagsterEvent]):
     for step_event in pipe_iterator:
         if step_event.is_successful_output:
             yield step_event
 
 
 def nesting_graph(depth: int, num_children: int, name: Optional[str] = None) -> GraphDefinition:
-    """Creates a pipeline of nested composite solids up to "depth" layers, with a fan-out of
+    """Creates a job of nested graphs up to "depth" layers, with a fan-out of
     num_children at each layer.
 
     Total number of solids will be num_children ^ depth
     """
 
     @op
     def leaf_node(_):
@@ -122,82 +124,82 @@
             graph_def = create_wrap(graph_def, "layer_%d" % (depth - (i + 1)))
 
         graph_def.alias("outer")()
 
     return nested_graph
 
 
-TEST_PIPELINE_NAME = "_test_pipeline_"
+TEST_JOB_NAME = "_test_job_"
 
 
 def create_run_for_test(
     instance: DagsterInstance,
-    pipeline_name: str = TEST_PIPELINE_NAME,
+    job_name: str = TEST_JOB_NAME,
     run_id=None,
     run_config=None,
     solids_to_execute=None,
     step_keys_to_execute=None,
     status=None,
     tags=None,
     root_run_id=None,
     parent_run_id=None,
-    pipeline_snapshot=None,
+    job_snapshot=None,
     execution_plan_snapshot=None,
-    parent_pipeline_snapshot=None,
-    external_pipeline_origin=None,
-    pipeline_code_origin=None,
+    parent_job_snapshot=None,
+    external_job_origin=None,
+    job_code_origin=None,
     asset_selection=None,
     solid_selection=None,
 ):
     return instance.create_run(
-        pipeline_name=pipeline_name,
+        job_name=job_name,
         run_id=run_id,
         run_config=run_config,
         solids_to_execute=solids_to_execute,
         step_keys_to_execute=step_keys_to_execute,
         status=status,
         tags=tags,
         root_run_id=root_run_id,
         parent_run_id=parent_run_id,
-        pipeline_snapshot=pipeline_snapshot,
+        job_snapshot=job_snapshot,
         execution_plan_snapshot=execution_plan_snapshot,
-        parent_pipeline_snapshot=parent_pipeline_snapshot,
-        external_pipeline_origin=external_pipeline_origin,
-        pipeline_code_origin=pipeline_code_origin,
+        parent_job_snapshot=parent_job_snapshot,
+        external_job_origin=external_job_origin,
+        job_code_origin=job_code_origin,
         asset_selection=asset_selection,
         solid_selection=solid_selection,
     )
 
 
 def register_managed_run_for_test(
     instance,
-    pipeline_name=TEST_PIPELINE_NAME,
+    job_name=TEST_JOB_NAME,
     run_id=None,
     run_config=None,
     solids_to_execute=None,
     step_keys_to_execute=None,
     tags=None,
     root_run_id=None,
     parent_run_id=None,
-    pipeline_snapshot=None,
+    job_snapshot=None,
     execution_plan_snapshot=None,
-    parent_pipeline_snapshot=None,
+    parent_job_snapshot=None,
 ):
     return instance.register_managed_run(
-        pipeline_name,
+        job_name,
         run_id,
         run_config,
         solids_to_execute,
         step_keys_to_execute,
         tags,
         root_run_id,
         parent_run_id,
-        pipeline_snapshot,
+        job_snapshot,
         execution_plan_snapshot,
-        parent_pipeline_snapshot,
+        parent_job_snapshot,
     )
 
 
 def wait_for_runs_to_finish(
     instance: DagsterInstance, timeout: float = 20, run_tags: Optional[Mapping[str, str]] = None
 ) -> None:
     total_time = 0
@@ -391,18 +393,18 @@
     def __init__(self, inst_data: Optional[ConfigurableClassData] = None):
         self._inst_data = inst_data
         self._queue = []
 
         super().__init__()
 
     def submit_run(self, context: SubmitRunContext):
-        pipeline_run = context.pipeline_run
-        check.inst(pipeline_run.external_pipeline_origin, ExternalPipelineOrigin)
-        self._queue.append(pipeline_run)
-        return pipeline_run
+        dagster_run = context.dagster_run
+        check.inst(dagster_run.external_job_origin, ExternalJobOrigin)
+        self._queue.append(dagster_run)
+        return dagster_run
 
     def queue(self):
         return self._queue
 
     @classmethod
     def config_type(cls):
         return Shape({})
@@ -621,7 +623,20 @@
 class SingleThreadPoolExecutor(ThreadPoolExecutor):
     """Utility class for testing threadpool executor logic which executes functions in a single
     thread, for easier unit testing.
     """
 
     def __init__(self):
         super().__init__(max_workers=1, thread_name_prefix="sensor_daemon_worker")
+
+
+def ignore_warning(message_substr: str):
+    """Ignores warnings within the decorated function that contain the given string."""
+
+    def decorator(func: Callable):
+        def wrapper(*args, **kwargs):
+            warnings.filterwarnings("ignore", message=message_substr)
+            return func(*args, **kwargs)
+
+        return wrapper
+
+    return decorator
```

### Comparing `dagster-1.3.2/dagster/_core/types/builtin_config_schemas.py` & `dagster-1.3.3/dagster/_core/types/builtin_config_schemas.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/types/config_schema.py` & `dagster-1.3.3/dagster/_core/types/config_schema.py`

 * *Files 2% similar despite different names*

```diff
@@ -180,20 +180,18 @@
     EXPECTED_POSITIONALS = ["context", "*"]
 
     def wrapper(func: DagsterTypeLoaderFn) -> DagsterTypeLoaderFromDecorator:
         params = get_function_params(func)
         missing_positional = validate_expected_params(params, EXPECTED_POSITIONALS)
         if missing_positional:
             raise DagsterInvalidDefinitionError(
-                "@dagster_type_loader '{solid_name}' decorated function does not have required"
-                " positional parameter '{missing_param}'. @dagster_type_loader decorated functions"
-                " should only have keyword arguments that match input names and a first positional"
-                " parameter named 'context'.".format(
-                    solid_name=func.__name__, missing_param=missing_positional
-                )
+                f"@dagster_type_loader '{func.__name__}' decorated function does not have required"
+                f" positional parameter '{missing_positional}'. @dagster_type_loader decorated"
+                " functions should only have keyword arguments that match input names and a first"
+                " positional parameter named 'context'."
             )
 
         return _create_type_loader_for_decorator(
             config_type, func, required_resource_keys, loader_version, external_version_fn
         )
 
     return wrapper
```

### Comparing `dagster-1.3.2/dagster/_core/types/dagster_type.py` & `dagster-1.3.3/dagster/_core/types/dagster_type.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/types/decorator.py` & `dagster-1.3.3/dagster/_core/types/decorator.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/types/loadable_target_origin.py` & `dagster-1.3.3/dagster/_core/types/loadable_target_origin.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/types/primitive_mapping.py` & `dagster-1.3.3/dagster/_core/types/primitive_mapping.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/types/python_dict.py` & `dagster-1.3.3/dagster/_core/types/python_dict.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/types/python_set.py` & `dagster-1.3.3/dagster/_core/types/python_set.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/types/python_tuple.py` & `dagster-1.3.3/dagster/_core/types/python_tuple.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/types/transform_typing.py` & `dagster-1.3.3/dagster/_core/types/transform_typing.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/utility_solids.py` & `dagster-1.3.3/dagster/_core/utility_ops.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/utils.py` & `dagster-1.3.3/dagster/_core/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/workspace/autodiscovery.py` & `dagster-1.3.3/dagster/_core/workspace/autodiscovery.py`

 * *Files 9% similar despite different names*

```diff
@@ -4,16 +4,16 @@
 
 from dagster import (
     DagsterInvariantViolationError,
     GraphDefinition,
     RepositoryDefinition,
 )
 from dagster._core.code_pointer import load_python_file, load_python_module
-from dagster._core.definitions import AssetGroup
 from dagster._core.definitions.definitions_class import Definitions
+from dagster._core.definitions.load_assets_from_modules import assets_from_modules
 from dagster._core.definitions.repository_definition import PendingRepositoryDefinition
 
 LOAD_ALL_ASSETS = "<<LOAD_ALL_ASSETS>>"
 
 
 class LoadableTarget(NamedTuple):
     attribute: str
@@ -66,31 +66,31 @@
 
     loadable_repos = _loadable_targets_of_type(
         module, (RepositoryDefinition, PendingRepositoryDefinition)
     )
     if loadable_repos:
         return loadable_repos
 
-    loadable_pipelines = _loadable_targets_of_type(module, JobDefinition)
+    loadable_jobs = _loadable_targets_of_type(module, JobDefinition)
     loadable_jobs = _loadable_targets_of_type(module, JobDefinition)
 
-    if len(loadable_pipelines) == 1:
-        return loadable_pipelines
+    if len(loadable_jobs) == 1:
+        return loadable_jobs
 
-    elif len(loadable_pipelines) > 1:
+    elif len(loadable_jobs) > 1:
         target_type = "job" if len(loadable_jobs) > 1 else "pipeline"
         raise DagsterInvariantViolationError(
             (
                 'No repository and more than one {target_type} found in "{module_name}". If you'
                 " load a file or module directly it must have only one {target_type} in scope."
                 " Found {target_type}s defined in variables or decorated functions:"
                 " {pipeline_symbols}."
             ).format(
                 module_name=module.__name__,
-                pipeline_symbols=repr([p.attribute for p in loadable_pipelines]),
+                pipeline_symbols=repr([p.attribute for p in loadable_jobs]),
                 target_type=target_type,
             )
         )
 
     loadable_graphs = _loadable_targets_of_type(module, GraphDefinition)
 
     if len(loadable_graphs) == 1:
@@ -105,36 +105,20 @@
                 "Found graphs defined in variables or decorated functions: {graph_symbols}."
             ).format(
                 module_name=module.__name__,
                 graph_symbols=repr([g.attribute for g in loadable_graphs]),
             )
         )
 
-    loadable_asset_groups = _loadable_targets_of_type(module, AssetGroup)
-    if len(loadable_asset_groups) == 1:
-        return loadable_asset_groups
-
-    elif len(loadable_asset_groups) > 1:
-        var_names = repr([a.attribute for a in loadable_asset_groups])
-        raise DagsterInvariantViolationError(
-            f'More than one asset group found in "{module.__name__}". '
-            "If you load a file or module directly and it has no repositories, jobs, "
-            "pipeline, or graphs in scope, it must have no more than one asset group in scope. "
-            f"Found asset groups defined in variables: {var_names}."
-        )
-
-    asset_group_from_module_assets = AssetGroup.from_modules([module])
-    if (
-        len(asset_group_from_module_assets.assets) > 0
-        or len(asset_group_from_module_assets.source_assets) > 0
-    ):
-        return [LoadableTarget(LOAD_ALL_ASSETS, asset_group_from_module_assets)]
+    module_assets, module_source_assets, _ = assets_from_modules([module])
+    if len(module_assets) > 0 or len(module_source_assets) > 0:
+        return [LoadableTarget(LOAD_ALL_ASSETS, [*module_assets, *module_source_assets])]
 
     raise DagsterInvariantViolationError(
-        "No repositories, jobs, pipelines, graphs, asset groups, or asset definitions found in "
+        "No repositories, jobs, pipelines, graphs, or asset definitions found in "
         f'"{module.__name__}".'
     )
 
 
 def _loadable_targets_of_type(
     module: ModuleType, klass: Union[Type, Tuple[Type, ...]]
 ) -> Sequence[LoadableTarget]:
```

### Comparing `dagster-1.3.2/dagster/_core/workspace/config_schema.py` & `dagster-1.3.3/dagster/_core/workspace/config_schema.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/workspace/context.py` & `dagster-1.3.3/dagster/_core/workspace/context.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,26 +6,26 @@
 from contextlib import ExitStack
 from itertools import count
 from typing import TYPE_CHECKING, Any, Dict, Mapping, Optional, Sequence, Set, TypeVar, Union
 
 from typing_extensions import Self
 
 import dagster._check as check
-from dagster._core.definitions.selector import PipelineSelector
+from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.errors import (
     DagsterCodeLocationLoadError,
     DagsterCodeLocationNotFoundError,
 )
 from dagster._core.execution.plan.state import KnownExecutionState
 from dagster._core.host_representation import (
     CodeLocation,
     CodeLocationOrigin,
     ExternalExecutionPlan,
+    ExternalJob,
     ExternalPartitionSet,
-    ExternalPipeline,
     GrpcServerCodeLocation,
     RepositoryHandle,
 )
 from dagster._core.host_representation.grpc_server_registry import (
     GrpcServerRegistry,
 )
 from dagster._core.host_representation.grpc_server_state_subscriber import (
@@ -201,42 +201,42 @@
     def shutdown_code_location(self, name: str):
         self.process_context.shutdown_code_location(name)
 
     def reload_workspace(self) -> Self:
         self.process_context.reload_workspace()
         return self.process_context.create_request_context()
 
-    def has_external_job(self, selector: PipelineSelector) -> bool:
-        check.inst_param(selector, "selector", PipelineSelector)
+    def has_external_job(self, selector: JobSubsetSelector) -> bool:
+        check.inst_param(selector, "selector", JobSubsetSelector)
         if not self.has_code_location(selector.location_name):
             return False
 
         loc = self.get_code_location(selector.location_name)
         return loc.has_repository(selector.repository_name) and loc.get_repository(
             selector.repository_name
-        ).has_external_job(selector.pipeline_name)
+        ).has_external_job(selector.job_name)
 
-    def get_full_external_job(self, selector: PipelineSelector) -> ExternalPipeline:
+    def get_full_external_job(self, selector: JobSubsetSelector) -> ExternalJob:
         return (
             self.get_code_location(selector.location_name)
             .get_repository(selector.repository_name)
-            .get_full_external_job(selector.pipeline_name)
+            .get_full_external_job(selector.job_name)
         )
 
     def get_external_execution_plan(
         self,
-        external_pipeline: ExternalPipeline,
+        external_job: ExternalJob,
         run_config: Mapping[str, object],
         step_keys_to_execute: Optional[Sequence[str]],
         known_state: Optional[KnownExecutionState],
     ) -> ExternalExecutionPlan:
         return self.get_code_location(
-            external_pipeline.handle.location_name
+            external_job.handle.location_name
         ).get_external_execution_plan(
-            external_pipeline=external_pipeline,
+            external_job=external_job,
             run_config=run_config,
             step_keys_to_execute=step_keys_to_execute,
             known_state=known_state,
             instance=self.instance,
         )
 
     def get_external_partition_config(
```

### Comparing `dagster-1.3.2/dagster/_core/workspace/load.py` & `dagster-1.3.3/dagster/_core/workspace/load.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/workspace/load_target.py` & `dagster-1.3.3/dagster/_core/workspace/load_target.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/workspace/permissions.py` & `dagster-1.3.3/dagster/_core/workspace/permissions.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_core/workspace/workspace.py` & `dagster-1.3.3/dagster/_core/workspace/workspace.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_daemon/__init__.py` & `dagster-1.3.3/dagster/_daemon/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_daemon/asset_daemon.py` & `dagster-1.3.3/dagster/_daemon/asset_daemon.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 import dagster._check as check
 from dagster._core.definitions.asset_reconciliation_sensor import (
     AssetReconciliationCursor,
     reconcile,
 )
 from dagster._core.definitions.external_asset_graph import ExternalAssetGraph
-from dagster._core.definitions.selector import PipelineSelector
+from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.instance import DagsterInstance
-from dagster._core.storage.pipeline_run import DagsterRunStatus
-from dagster._core.storage.tags import CREATED_BY_TAG
+from dagster._core.storage.dagster_run import DagsterRunStatus
+from dagster._core.storage.tags import AUTO_MATERIALIZE_TAG
 from dagster._core.workspace.context import IWorkspaceProcessContext
 from dagster._daemon.daemon import DaemonIterator, IntervalDaemon
 
 CURSOR_KEY = "ASSET_DAEMON_CURSOR"
 ASSET_DAEMON_PAUSED_KEY = "ASSET_DAEMON_PAUSED"
 
 
@@ -91,53 +91,53 @@
                 check.invariant(repo_handle == asset_graph.get_repository_handle(key))
 
             location_name = repo_handle.code_location_origin.location_name
             repository_name = repo_handle.repository_name
             job_name = check.not_none(asset_graph.get_implicit_job_name_for_assets(asset_keys))
 
             code_location = workspace.get_code_location(location_name)
-            external_pipeline = code_location.get_external_pipeline(
-                PipelineSelector(
+            external_job = code_location.get_external_job(
+                JobSubsetSelector(
                     location_name=location_name,
                     repository_name=repository_name,
-                    pipeline_name=job_name,
+                    job_name=job_name,
                     solid_selection=None,
                     asset_selection=asset_keys,
                 )
             )
 
             tags = {
                 **run_request.tags,
-                CREATED_BY_TAG: "auto_materialize",
+                AUTO_MATERIALIZE_TAG: "true",
                 **instance.auto_materialize_run_tags,
             }
 
             external_execution_plan = code_location.get_external_execution_plan(
-                external_pipeline,
+                external_job,
                 run_request.run_config,
                 step_keys_to_execute=None,
                 known_state=None,
                 instance=instance,
             )
             execution_plan_snapshot = external_execution_plan.execution_plan_snapshot
 
             run = instance.create_run(
-                pipeline_name=external_pipeline.name,
+                job_name=external_job.name,
                 run_id=None,
                 run_config=None,
                 solids_to_execute=None,
                 step_keys_to_execute=None,
                 status=DagsterRunStatus.NOT_STARTED,
                 solid_selection=None,
                 root_run_id=None,
                 parent_run_id=None,
                 tags=tags,
-                pipeline_snapshot=external_pipeline.pipeline_snapshot,
+                job_snapshot=external_job.job_snapshot,
                 execution_plan_snapshot=execution_plan_snapshot,
-                parent_pipeline_snapshot=external_pipeline.parent_pipeline_snapshot,
-                external_pipeline_origin=external_pipeline.get_external_origin(),
-                pipeline_code_origin=external_pipeline.get_python_origin(),
+                parent_job_snapshot=external_job.parent_job_snapshot,
+                external_job_origin=external_job.get_external_origin(),
+                job_code_origin=external_job.get_python_origin(),
                 asset_selection=frozenset(asset_keys),
             )
             instance.submit_run(run.run_id, workspace)
 
         instance.daemon_cursor_storage.set_cursor_values({CURSOR_KEY: new_cursor.serialize()})
```

### Comparing `dagster-1.3.2/dagster/_daemon/auto_run_reexecution/auto_run_reexecution.py` & `dagster-1.3.3/dagster/_daemon/auto_run_reexecution/auto_run_reexecution.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import sys
 from typing import Iterator, Optional, Sequence, Tuple, cast
 
 from dagster._core.definitions.metadata import MetadataValue
-from dagster._core.definitions.selector import PipelineSelector
+from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.events import EngineEventData
 from dagster._core.execution.plan.resume_retry import ReexecutionStrategy
 from dagster._core.instance import DagsterInstance
-from dagster._core.storage.pipeline_run import DagsterRun, DagsterRunStatus, RunRecord
+from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus, RunRecord
 from dagster._core.storage.tags import MAX_RETRIES_TAG, RETRY_NUMBER_TAG, RETRY_STRATEGY_TAG
 from dagster._core.workspace.context import IWorkspaceProcessContext
 from dagster._utils.error import serializable_error_info_from_exc_info
 
 DEFAULT_REEXECUTION_POLICY = ReexecutionStrategy.FROM_FAILURE
 
 
@@ -83,22 +83,22 @@
     retry_number: int,
     workspace_context: IWorkspaceProcessContext,
 ) -> None:
     """Submit a retry as a re-execute from failure."""
     instance = workspace_context.instance
     tags = {RETRY_NUMBER_TAG: str(retry_number)}
     workspace = workspace_context.create_request_context()
-    if not failed_run.external_pipeline_origin:
+    if not failed_run.external_job_origin:
         instance.report_engine_event(
-            "Run does not have an external pipeline origin, unable to retry the run.",
+            "Run does not have an external job origin, unable to retry the run.",
             failed_run,
         )
         return
 
-    origin = failed_run.external_pipeline_origin.external_repository_origin
+    origin = failed_run.external_job_origin.external_repository_origin
     code_location = workspace.get_code_location(origin.code_location_origin.location_name)
     repo_name = origin.repository_name
 
     if not code_location.has_repository(repo_name):
         instance.report_engine_event(
             (
                 f"Could not find repository {repo_name} in location {code_location.name}, unable to"
@@ -106,42 +106,42 @@
             ),
             failed_run,
         )
         return
 
     external_repo = code_location.get_repository(repo_name)
 
-    if not external_repo.has_external_job(failed_run.pipeline_name):
+    if not external_repo.has_external_job(failed_run.job_name):
         instance.report_engine_event(
             (
-                f"Could not find job {failed_run.pipeline_name} in repository {repo_name}, unable"
+                f"Could not find job {failed_run.job_name} in repository {repo_name}, unable"
                 " to retry the run. It was likely renamed or deleted."
             ),
             failed_run,
         )
         return
 
-    external_pipeline = code_location.get_external_pipeline(
-        PipelineSelector(
+    external_job = code_location.get_external_job(
+        JobSubsetSelector(
             location_name=origin.code_location_origin.location_name,
             repository_name=repo_name,
-            pipeline_name=failed_run.pipeline_name,
+            job_name=failed_run.job_name,
             solid_selection=failed_run.solid_selection,
             asset_selection=None
             if failed_run.asset_selection is None
             else list(failed_run.asset_selection),
         )
     )
 
     strategy = get_reexecution_strategy(failed_run, instance) or DEFAULT_REEXECUTION_POLICY
 
     new_run = instance.create_reexecuted_run(
         parent_run=failed_run,
         code_location=code_location,
-        external_pipeline=external_pipeline,
+        external_job=external_job,
         strategy=strategy,
         extra_tags=tags,
         use_parent_run_tags=True,
     )
 
     instance.report_engine_event(
         "Retrying the run",
```

### Comparing `dagster-1.3.2/dagster/_daemon/auto_run_reexecution/event_log_consumer.py` & `dagster-1.3.3/dagster/_daemon/auto_run_reexecution/event_log_consumer.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 import os
 from typing import Callable, Dict, Iterator, List, Mapping, Optional, Sequence
 
 import dagster._check as check
 from dagster import DagsterEventType
 from dagster._core.events.log import EventLogEntry
 from dagster._core.instance import DagsterInstance
-from dagster._core.storage.pipeline_run import RunRecord, RunsFilter
+from dagster._core.storage.dagster_run import RunRecord, RunsFilter
 from dagster._core.workspace.context import IWorkspaceProcessContext
 
 from ..daemon import IntervalDaemon
 from .auto_run_reexecution import consume_new_runs_for_automatic_reexecution
 
 _INTERVAL_SECONDS = int(os.environ.get("DAGSTER_EVENT_LOG_CONSUMER_DAEMON_INTERVAL_SECONDS", 5))
 _EVENT_LOG_FETCH_LIMIT = int(os.environ.get("DAGSTER_EVENT_LOG_CONSUMER_DAEMON_FETCH_LIMIT", 500))
```

### Comparing `dagster-1.3.2/dagster/_daemon/backfill.py` & `dagster-1.3.3/dagster/_daemon/backfill.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_daemon/cli/__init__.py` & `dagster-1.3.3/dagster/_daemon/cli/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_daemon/controller.py` & `dagster-1.3.3/dagster/_daemon/controller.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_daemon/daemon.py` & `dagster-1.3.3/dagster/_daemon/daemon.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_daemon/monitoring/monitoring_daemon.py` & `dagster-1.3.3/dagster/_daemon/monitoring/monitoring_daemon.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 
 from dagster import (
     DagsterInstance,
     _check as check,
 )
 from dagster._core.events import DagsterEventType, EngineEventData
 from dagster._core.launcher import WorkerStatus
-from dagster._core.storage.pipeline_run import (
+from dagster._core.storage.dagster_run import (
     IN_PROGRESS_RUN_STATUSES,
     DagsterRunStatus,
     RunRecord,
     RunsFilter,
 )
 from dagster._core.storage.tags import MAX_RUNTIME_SECONDS_TAG
 from dagster._core.workspace.context import IWorkspace, IWorkspaceProcessContext
@@ -184,15 +184,15 @@
             if instance.run_launcher.terminate(run_id=run_record.dagster_run.run_id):
                 instance.report_run_failed(
                     run_record.dagster_run, f"Exceeded maximum runtime of {int(max_time)} seconds."
                 )
         except:
             instance.report_engine_event(
                 "Exception while attempting to terminate run. Run will still be marked as failed.",
-                pipeline_name=run_record.dagster_run.job_name,
+                job_name=run_record.dagster_run.job_name,
                 run_id=run_record.dagster_run.run_id,
                 engine_event_data=EngineEventData(
                     error=serializable_error_info_from_exc_info(sys.exc_info()),
                 ),
             )
         _force_mark_as_failed(instance, run_record.dagster_run.run_id)
```

### Comparing `dagster-1.3.2/dagster/_daemon/run_coordinator/queued_run_coordinator_daemon.py` & `dagster-1.3.3/dagster/_daemon/run_coordinator/queued_run_coordinator_daemon.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 from dagster._core.events import EngineEventData
 from dagster._core.instance import DagsterInstance
 from dagster._core.launcher import LaunchRunContext
 from dagster._core.run_coordinator.queued_run_coordinator import (
     QueuedRunCoordinator,
     RunQueueConfig,
 )
-from dagster._core.storage.pipeline_run import (
+from dagster._core.storage.dagster_run import (
     IN_PROGRESS_RUN_STATUSES,
     DagsterRun,
     DagsterRunStatus,
     RunsFilter,
 )
 from dagster._core.storage.tags import PRIORITY_TAG
 from dagster._core.workspace.context import IWorkspaceProcessContext
@@ -241,15 +241,15 @@
             if max_concurrent_runs_enabled and len(batch) >= max_runs_to_launch:
                 break
 
             if tag_concurrency_limits_counter.is_blocked(run):
                 continue
 
             location_name = (
-                run.external_pipeline_origin.location_name if run.external_pipeline_origin else None
+                run.external_job_origin.location_name if run.external_job_origin else None
             )
             if location_name and location_name in paused_location_names:
                 continue
 
             tag_concurrency_limits_counter.update_counters_with_launched_item(run)
             batch.append(run)
 
@@ -302,31 +302,29 @@
                 run.run_id,
                 run.status,
             )
             return False
 
         # Very old (pre 0.10.0) runs and programatically submitted runs may not have an
         # attached code location name
-        location_name = (
-            run.external_pipeline_origin.location_name if run.external_pipeline_origin else None
-        )
+        location_name = run.external_job_origin.location_name if run.external_job_origin else None
 
         if location_name and self._is_location_pausing_dequeues(location_name, now):
             self._logger.info(
                 (
                     "Pausing dequeues for runs from code location %s to give its code server time"
                     " to recover"
                 ),
                 location_name,
             )
             return False
 
         launch_started_event = DagsterEvent(
             event_type_value=DagsterEventType.PIPELINE_STARTING.value,
-            pipeline_name=run.pipeline_name,
+            job_name=run.job_name,
         )
 
         instance.report_dagster_event(launch_started_event, run_id=run.run_id)
 
         run = check.not_none(instance.get_run_by_id(run.run_id))
 
         try:
@@ -390,15 +388,15 @@
                         message,
                         run,
                         EngineEventData.engine_error(error),
                     )
                     # Re-submit the run into the queue
                     enqueued_event = DagsterEvent(
                         event_type_value=DagsterEventType.PIPELINE_ENQUEUED.value,
-                        pipeline_name=run.pipeline_name,
+                        job_name=run.job_name,
                     )
                     instance.report_dagster_event(enqueued_event, run_id=run.run_id)
                     return False
             else:
                 message = (
                     "Caught an unrecoverable error while dequeuing the run. Marking the run as"
                     " failed and dropping it from the queue"
```

### Comparing `dagster-1.3.2/dagster/_daemon/sensor.py` & `dagster-1.3.3/dagster/_daemon/sensor.py`

 * *Files 5% similar despite different names*

```diff
@@ -28,31 +28,31 @@
 import dagster._seven as seven
 from dagster._core.definitions.run_request import (
     AddDynamicPartitionsRequest,
     DeleteDynamicPartitionsRequest,
     InstigatorType,
     RunRequest,
 )
-from dagster._core.definitions.selector import PipelineSelector
+from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.definitions.sensor_definition import DefaultSensorStatus, SensorExecutionData
 from dagster._core.definitions.utils import validate_tags
 from dagster._core.errors import DagsterError
 from dagster._core.host_representation.code_location import CodeLocation
-from dagster._core.host_representation.external import ExternalPipeline, ExternalSensor
+from dagster._core.host_representation.external import ExternalJob, ExternalSensor
 from dagster._core.host_representation.external_data import ExternalTargetData
 from dagster._core.instance import DagsterInstance
 from dagster._core.scheduler.instigation import (
     InstigatorState,
     InstigatorStatus,
     InstigatorTick,
     SensorInstigatorData,
     TickData,
     TickStatus,
 )
-from dagster._core.storage.pipeline_run import DagsterRun, DagsterRunStatus, RunsFilter
+from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus, RunsFilter
 from dagster._core.storage.tags import RUN_KEY_TAG, SENSOR_NAME_TAG
 from dagster._core.telemetry import SENSOR_RUN_CREATED, hash_name, log_action
 from dagster._core.workspace.context import IWorkspaceProcessContext
 from dagster._scheduler.stale import resolve_stale_or_missing_assets
 from dagster._utils import DebugCrashFlags, SingleInstigatorDebugCrashFlags
 from dagster._utils.error import SerializableErrorInfo, serializable_error_info_from_exc_info
 from dagster._utils.merger import merge_dicts
@@ -586,67 +586,91 @@
     if sensor_runtime_data.captured_log_key:
         context.add_log_info(sensor_runtime_data.captured_log_key)
 
     assert isinstance(sensor_runtime_data, SensorExecutionData)
 
     if sensor_runtime_data.dynamic_partitions_requests:
         for request in sensor_runtime_data.dynamic_partitions_requests:
+            existent_partitions = []
+            nonexistent_partitions = []
+            for partition_key in request.partition_keys:
+                if instance.has_dynamic_partition(request.partitions_def_name, partition_key):
+                    existent_partitions.append(partition_key)
+                else:
+                    nonexistent_partitions.append(partition_key)
+
             if isinstance(request, AddDynamicPartitionsRequest):
-                instance.add_dynamic_partitions(
-                    request.partitions_def_name,
-                    request.partition_keys,
-                )
-                context.logger.info(
-                    "Added partition keys to dynamic partitions definition"
-                    f" '{request.partitions_def_name}': {request.partition_keys}"
-                )
+                if nonexistent_partitions:
+                    instance.add_dynamic_partitions(
+                        request.partitions_def_name,
+                        nonexistent_partitions,
+                    )
+                    context.logger.info(
+                        "Added partition keys to dynamic partitions definition"
+                        f" '{request.partitions_def_name}': {nonexistent_partitions}"
+                    )
+
+                if existent_partitions:
+                    context.logger.info(
+                        "Skipping addition of partition keys for dynamic partitions definition"
+                        f" '{request.partitions_def_name}' that already exist:"
+                        f" {existent_partitions}"
+                    )
             elif isinstance(request, DeleteDynamicPartitionsRequest):
-                # TODO add a bulk delete method to the instance
-                for partition in request.partition_keys:
-                    instance.delete_dynamic_partition(request.partitions_def_name, partition)
-
-                context.logger.info(
-                    "Deleted partition keys from dynamic partitions definition"
-                    f" '{request.partitions_def_name}': {request.partition_keys}"
-                )
+                if existent_partitions:
+                    # TODO add a bulk delete method to the instance
+                    for partition in existent_partitions:
+                        instance.delete_dynamic_partition(request.partitions_def_name, partition)
+
+                    context.logger.info(
+                        "Deleted partition keys from dynamic partitions definition"
+                        f" '{request.partitions_def_name}': {existent_partitions}"
+                    )
+
+                if nonexistent_partitions:
+                    context.logger.info(
+                        "Skipping deletion of partition keys for dynamic partitions definition"
+                        f" '{request.partitions_def_name}' that do not exist:"
+                        f" {nonexistent_partitions}"
+                    )
             else:
                 check.failed(f"Unexpected action {request.action} for dynamic partition request")
     if not sensor_runtime_data.run_requests:
-        if sensor_runtime_data.pipeline_run_reactions:
-            for pipeline_run_reaction in sensor_runtime_data.pipeline_run_reactions:
-                origin_run_id = check.not_none(pipeline_run_reaction.pipeline_run).run_id
-                if pipeline_run_reaction.error:
+        if sensor_runtime_data.dagster_run_reactions:
+            for run_reaction in sensor_runtime_data.dagster_run_reactions:
+                origin_run_id = check.not_none(run_reaction.dagster_run).run_id
+                if run_reaction.error:
                     context.logger.error(
                         f"Got a reaction request for run {origin_run_id} but execution errorred:"
-                        f" {pipeline_run_reaction.error}"
+                        f" {run_reaction.error}"
                     )
                     context.update_state(
                         TickStatus.FAILURE,
                         cursor=sensor_runtime_data.cursor,
-                        error=pipeline_run_reaction.error,
+                        error=run_reaction.error,
                     )
                     # Since run status sensors have side effects that we don't want to repeat,
                     # we still want to update the cursor, even though the tick failed
                     context.set_should_update_cursor_on_failure(True)
                 else:
-                    # Use status from the PipelineRunReaction object if it is from a new enough
-                    # version (0.14.4) to be set (the status on the PipelineRun object itself
+                    # Use status from the DagsterRunReaction object if it is from a new enough
+                    # version (0.14.4) to be set (the status on the DagsterRun object itself
                     # may have since changed)
                     status = (
-                        pipeline_run_reaction.run_status.value
-                        if pipeline_run_reaction.run_status
-                        else check.not_none(pipeline_run_reaction.pipeline_run).status.value
+                        run_reaction.run_status.value
+                        if run_reaction.run_status
+                        else check.not_none(run_reaction.dagster_run).status.value
                     )
-                    # log to the original pipeline run
+                    # log to the original dagster run
                     message = (
                         f'Sensor "{external_sensor.name}" acted on run status '
                         f"{status} of run {origin_run_id}."
                     )
                     instance.report_engine_event(
-                        message=message, pipeline_run=pipeline_run_reaction.pipeline_run
+                        message=message, dagster_run=run_reaction.dagster_run
                     )
                     context.logger.info(
                         f"Completed a reaction request for run {origin_run_id}: {message}"
                     )
                     context.update_state(
                         TickStatus.SUCCESS,
                         cursor=sensor_runtime_data.cursor,
@@ -686,28 +710,28 @@
         else:
             run_request = raw_run_request
 
         target_data: ExternalTargetData = check.not_none(
             external_sensor.get_target_data(run_request.job_name)
         )
 
-        pipeline_selector = PipelineSelector(
+        job_subset_selector = JobSubsetSelector(
             location_name=code_location.name,
             repository_name=sensor_origin.external_repository_origin.repository_name,
-            pipeline_name=target_data.pipeline_name,
+            job_name=target_data.job_name,
             solid_selection=target_data.solid_selection,
             asset_selection=run_request.asset_selection,
         )
-        external_pipeline = code_location.get_external_pipeline(pipeline_selector)
+        external_job = code_location.get_external_job(job_subset_selector)
         run = _get_or_create_sensor_run(
             context,
             instance,
             code_location,
             external_sensor,
-            external_pipeline,
+            external_job,
             run_request,
             target_data,
             existing_runs_by_key,
         )
 
         if isinstance(run, SkippedSensorRun):
             skipped_runs.append(run)
@@ -786,22 +810,22 @@
     runs_with_run_keys = instance.get_runs(filters=RunsFilter(tags={RUN_KEY_TAG: run_keys}))
 
     # filter down to runs with run_key that match the sensor name and its namespace (repository)
     valid_runs: List[DagsterRun] = []
     for run in runs_with_run_keys:
         # if the run doesn't have a set origin, just match on sensor name
         if (
-            run.external_pipeline_origin is None
+            run.external_job_origin is None
             and run.tags.get(SENSOR_NAME_TAG) == external_sensor.name
         ):
             valid_runs.append(run)
         # otherwise prevent the same named sensor across repos from effecting each other
         elif (
-            run.external_pipeline_origin is not None
-            and run.external_pipeline_origin.external_repository_origin.get_selector_id()
+            run.external_job_origin is not None
+            and run.external_job_origin.external_repository_origin.get_selector_id()
             == external_sensor.get_external_origin().external_repository_origin.get_selector_id()
             and run.tags.get(SENSOR_NAME_TAG) == external_sensor.name
         ):
             valid_runs.append(run)
 
     existing_runs = {}
     for run in valid_runs:
@@ -813,22 +837,22 @@
 
 
 def _get_or_create_sensor_run(
     context: SensorLaunchContext,
     instance: DagsterInstance,
     code_location: CodeLocation,
     external_sensor: ExternalSensor,
-    external_pipeline: ExternalPipeline,
+    external_job: ExternalJob,
     run_request: RunRequest,
     target_data: ExternalTargetData,
     existing_runs_by_key: Mapping[str, DagsterRun],
 ) -> Union[DagsterRun, SkippedSensorRun]:
     if not run_request.run_key:
         return _create_sensor_run(
-            instance, code_location, external_sensor, external_pipeline, run_request, target_data
+            instance, code_location, external_sensor, external_job, run_request, target_data
         )
 
     run = existing_runs_by_key.get(run_request.run_key)
 
     if run:
         if run.status != DagsterRunStatus.NOT_STARTED:
             # A run already exists and was launched for this run key, but the daemon must have
@@ -840,69 +864,69 @@
                 f"`{run_request.run_key}` for {external_sensor.name}"
             )
             return run
 
     context.logger.info(f"Creating new run for {external_sensor.name}")
 
     return _create_sensor_run(
-        instance, code_location, external_sensor, external_pipeline, run_request, target_data
+        instance, code_location, external_sensor, external_job, run_request, target_data
     )
 
 
 def _create_sensor_run(
     instance: DagsterInstance,
     code_location: CodeLocation,
     external_sensor: ExternalSensor,
-    external_pipeline: ExternalPipeline,
+    external_job: ExternalJob,
     run_request: RunRequest,
     target_data: ExternalTargetData,
 ) -> DagsterRun:
     from dagster._daemon.daemon import get_telemetry_daemon_session_id
 
     external_execution_plan = code_location.get_external_execution_plan(
-        external_pipeline,
+        external_job,
         run_request.run_config,
         step_keys_to_execute=None,
         known_state=None,
         instance=instance,
     )
     execution_plan_snapshot = external_execution_plan.execution_plan_snapshot
 
-    pipeline_tags = validate_tags(external_pipeline.tags or {}, allow_reserved_tags=False)
+    job_tags = validate_tags(external_job.tags or {}, allow_reserved_tags=False)
     tags = merge_dicts(
-        merge_dicts(pipeline_tags, run_request.tags),
+        merge_dicts(job_tags, run_request.tags),
         DagsterRun.tags_for_sensor(external_sensor),
     )
     if run_request.run_key:
         tags[RUN_KEY_TAG] = run_request.run_key
 
     log_action(
         instance,
         SENSOR_RUN_CREATED,
         metadata={
             "DAEMON_SESSION_ID": get_telemetry_daemon_session_id(),
             "SENSOR_NAME_HASH": hash_name(external_sensor.name),
-            "pipeline_name_hash": hash_name(external_pipeline.name),
+            "pipeline_name_hash": hash_name(external_job.name),
             "repo_hash": hash_name(code_location.name),
         },
     )
 
     return instance.create_run(
-        pipeline_name=target_data.pipeline_name,
+        job_name=target_data.job_name,
         run_id=None,
         run_config=run_request.run_config,
-        solids_to_execute=external_pipeline.solids_to_execute,
+        solids_to_execute=external_job.solids_to_execute,
         step_keys_to_execute=None,
         status=DagsterRunStatus.NOT_STARTED,
         solid_selection=target_data.solid_selection,
         root_run_id=None,
         parent_run_id=None,
         tags=tags,
-        pipeline_snapshot=external_pipeline.pipeline_snapshot,
+        job_snapshot=external_job.job_snapshot,
         execution_plan_snapshot=execution_plan_snapshot,
-        parent_pipeline_snapshot=external_pipeline.parent_pipeline_snapshot,
-        external_pipeline_origin=external_pipeline.get_external_origin(),
-        pipeline_code_origin=external_pipeline.get_python_origin(),
+        parent_job_snapshot=external_job.parent_job_snapshot,
+        external_job_origin=external_job.get_external_origin(),
+        job_code_origin=external_job.get_python_origin(),
         asset_selection=frozenset(run_request.asset_selection)
         if run_request.asset_selection
         else None,
     )
```

### Comparing `dagster-1.3.2/dagster/_daemon/types.py` & `dagster-1.3.3/dagster/_daemon/types.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_daemon/workspace.py` & `dagster-1.3.3/dagster/_daemon/workspace.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_generate/download.py` & `dagster-1.3.3/dagster/_generate/download.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_generate/generate.py` & `dagster-1.3.3/dagster/_generate/generate.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_generate/templates/PROJECT_NAME_PLACEHOLDER/README.md` & `dagster-1.3.3/dagster/_generate/templates/PROJECT_NAME_PLACEHOLDER/README.md`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_grpc/__generated__/api_pb2.py` & `dagster-1.3.3/dagster/_grpc/__generated__/api_pb2.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_grpc/__generated__/api_pb2_grpc.py` & `dagster-1.3.3/dagster/_grpc/__generated__/api_pb2_grpc.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_grpc/__init__.py` & `dagster-1.3.3/dagster/_grpc/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -19,28 +19,28 @@
     GrpcServerProcess as GrpcServerProcess,
 )
 from .types import (
     CanCancelExecutionRequest as CanCancelExecutionRequest,
     CanCancelExecutionResult as CanCancelExecutionResult,
     CancelExecutionRequest as CancelExecutionRequest,
     CancelExecutionResult as CancelExecutionResult,
-    ExecuteExternalPipelineArgs as ExecuteExternalPipelineArgs,
+    ExecuteExternalJobArgs as ExecuteExternalJobArgs,
     ExecuteRunArgs as ExecuteRunArgs,
     ExecuteStepArgs as ExecuteStepArgs,
     ExecutionPlanSnapshotArgs as ExecutionPlanSnapshotArgs,
     ExternalJobArgs as ExternalJobArgs,
     ExternalScheduleExecutionArgs as ExternalScheduleExecutionArgs,
     GetCurrentImageResult as GetCurrentImageResult,
+    JobSubsetSnapshotArgs as JobSubsetSnapshotArgs,
     ListRepositoriesInput as ListRepositoriesInput,
     ListRepositoriesResponse as ListRepositoriesResponse,
     LoadableRepositorySymbol as LoadableRepositorySymbol,
     NotebookPathArgs as NotebookPathArgs,
     PartitionArgs as PartitionArgs,
     PartitionNamesArgs as PartitionNamesArgs,
     PartitionSetExecutionParamArgs as PartitionSetExecutionParamArgs,
-    PipelineSubsetSnapshotArgs as PipelineSubsetSnapshotArgs,
     ResumeRunArgs as ResumeRunArgs,
     SensorExecutionArgs as SensorExecutionArgs,
     ShutdownServerResult as ShutdownServerResult,
     StartRunResult as StartRunResult,
 )
 from .utils import get_loadable_targets as get_loadable_targets
```

### Comparing `dagster-1.3.2/dagster/_grpc/client.py` & `dagster-1.3.3/dagster/_grpc/client.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,21 +20,21 @@
 from dagster._utils.error import serializable_error_info_from_exc_info
 
 from .__generated__ import DagsterApiStub, api_pb2
 from .server import GrpcServerProcess
 from .types import (
     CanCancelExecutionRequest,
     CancelExecutionRequest,
-    ExecuteExternalPipelineArgs,
+    ExecuteExternalJobArgs,
     ExecutionPlanSnapshotArgs,
     ExternalScheduleExecutionArgs,
+    JobSubsetSnapshotArgs,
     PartitionArgs,
     PartitionNamesArgs,
     PartitionSetExecutionParamArgs,
-    PipelineSubsetSnapshotArgs,
     SensorExecutionArgs,
 )
 from .utils import default_grpc_timeout, max_rx_bytes, max_send_bytes
 
 CLIENT_HEARTBEAT_INTERVAL = 1
 
 DEFAULT_GRPC_TIMEOUT = default_grpc_timeout()
@@ -281,15 +281,15 @@
 
         return "".join([chunk.serialized_chunk for chunk in chunks])
 
     def external_pipeline_subset(self, pipeline_subset_snapshot_args):
         check.inst_param(
             pipeline_subset_snapshot_args,
             "pipeline_subset_snapshot_args",
-            PipelineSubsetSnapshotArgs,
+            JobSubsetSnapshotArgs,
         )
 
         res = self._query(
             "ExternalPipelineSubsetSnapshot",
             api_pb2.ExternalPipelineSubsetSnapshotRequest,
             serialized_pipeline_subset_snapshot_args=serialize_value(pipeline_subset_snapshot_args),
         )
@@ -441,31 +441,31 @@
             api_pb2.CanCancelExecutionRequest,  # type: ignore
             timeout=timeout,
             serialized_can_cancel_execution_request=serialize_value(can_cancel_execution_request),
         )
 
         return res.serialized_can_cancel_execution_result
 
-    def start_run(self, execute_run_args: ExecuteExternalPipelineArgs):
-        check.inst_param(execute_run_args, "execute_run_args", ExecuteExternalPipelineArgs)
+    def start_run(self, execute_run_args: ExecuteExternalJobArgs):
+        check.inst_param(execute_run_args, "execute_run_args", ExecuteExternalJobArgs)
 
         with DagsterInstance.from_ref(execute_run_args.instance_ref) as instance:  # type: ignore  # (possible none)
             try:
                 res = self._query(
                     "StartRun",
                     api_pb2.StartRunRequest,  # type: ignore
                     serialized_execute_run_args=serialize_value(execute_run_args),
                 )
                 return res.serialized_start_run_result
 
             except Exception:
-                pipeline_run = instance.get_run_by_id(execute_run_args.pipeline_run_id)
+                dagster_run = instance.get_run_by_id(execute_run_args.run_id)
                 instance.report_engine_event(
                     message="Unexpected error in IPC client",
-                    pipeline_run=pipeline_run,
+                    dagster_run=dagster_run,
                     engine_event_data=EngineEventData.engine_error(
                         serializable_error_info_from_exc_info(sys.exc_info())
                     ),
                 )
                 raise
 
     def get_current_image(self):
```

### Comparing `dagster-1.3.2/dagster/_grpc/compile.py` & `dagster-1.3.3/dagster/_grpc/compile.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_grpc/impl.py` & `dagster-1.3.3/dagster/_grpc/impl.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,163 +1,163 @@
 """Workhorse functions for individual API requests."""
 
 import os
 import sys
 from contextlib import contextmanager
-from typing import Generator, Iterator, Optional, Sequence, Tuple, Union
+from typing import Any, Generator, Iterator, Optional, Sequence, Tuple, Union
 
 import pendulum
 
 import dagster._check as check
 from dagster._core.definitions import ScheduleEvaluationContext
 from dagster._core.definitions.events import AssetKey
 from dagster._core.definitions.job_definition import JobDefinition
 from dagster._core.definitions.multi_dimensional_partitions import MultiPartitionsDefinition
 from dagster._core.definitions.partition import (
     DynamicPartitionsDefinition,
     PartitionedConfig,
     PartitionsDefinition,
 )
-from dagster._core.definitions.reconstruct import ReconstructablePipeline
+from dagster._core.definitions.reconstruct import ReconstructableJob
 from dagster._core.definitions.repository_definition import RepositoryDefinition
 from dagster._core.definitions.sensor_definition import SensorEvaluationContext
 from dagster._core.errors import (
     DagsterExecutionInterruptedError,
     DagsterRunNotFoundError,
     PartitionExecutionError,
     ScheduleExecutionError,
     SensorExecutionError,
     user_code_error_boundary,
 )
 from dagster._core.events import DagsterEvent, EngineEventData
 from dagster._core.execution.api import create_execution_plan, execute_run_iterator
-from dagster._core.host_representation import external_pipeline_data_from_def
+from dagster._core.host_representation import external_job_data_from_def
 from dagster._core.host_representation.external_data import (
+    ExternalJobSubsetResult,
     ExternalPartitionConfigData,
     ExternalPartitionExecutionErrorData,
     ExternalPartitionExecutionParamData,
     ExternalPartitionNamesData,
     ExternalPartitionSetExecutionParamData,
     ExternalPartitionTagsData,
-    ExternalPipelineSubsetResult,
     ExternalScheduleExecutionErrorData,
     ExternalSensorExecutionErrorData,
     job_name_for_external_partition_set_name,
 )
 from dagster._core.instance import DagsterInstance
 from dagster._core.instance.ref import InstanceRef
 from dagster._core.snap.execution_plan_snapshot import (
     ExecutionPlanSnapshotErrorData,
     snapshot_from_execution_plan,
 )
-from dagster._core.storage.pipeline_run import DagsterRun
+from dagster._core.storage.dagster_run import DagsterRun
 from dagster._grpc.types import ExecutionPlanSnapshotArgs
 from dagster._serdes import deserialize_value
 from dagster._serdes.ipc import IPCErrorMessage
 from dagster._seven import nullcontext
 from dagster._utils import start_termination_thread
 from dagster._utils.error import serializable_error_info_from_exc_info
 from dagster._utils.interrupts import capture_interrupts
 
-from .types import ExecuteExternalPipelineArgs
+from .types import ExecuteExternalJobArgs
 
 
 class RunInSubprocessComplete:
     """Sentinel passed over multiprocessing Queue when subprocess is complete."""
 
 
 class StartRunInSubprocessSuccessful:
     """Sentinel passed over multiprocessing Queue when launch is successful in subprocess."""
 
 
 def _report_run_failed_if_not_finished(
     instance: DagsterInstance, pipeline_run_id: str
 ) -> Generator[DagsterEvent, None, None]:
     check.inst_param(instance, "instance", DagsterInstance)
-    pipeline_run = instance.get_run_by_id(pipeline_run_id)
-    if pipeline_run and (not pipeline_run.is_finished):
-        yield instance.report_run_failed(pipeline_run)
+    dagster_run = instance.get_run_by_id(pipeline_run_id)
+    if dagster_run and (not dagster_run.is_finished):
+        yield instance.report_run_failed(dagster_run)
 
 
 def core_execute_run(
-    recon_pipeline: ReconstructablePipeline,
-    pipeline_run: DagsterRun,
+    recon_job: ReconstructableJob,
+    dagster_run: DagsterRun,
     instance: DagsterInstance,
     inject_env_vars: bool,
     resume_from_failure: bool = False,
 ) -> Generator[DagsterEvent, None, None]:
-    check.inst_param(recon_pipeline, "recon_pipeline", ReconstructablePipeline)
-    check.inst_param(pipeline_run, "pipeline_run", DagsterRun)
+    check.inst_param(recon_job, "recon_job", ReconstructableJob)
+    check.inst_param(dagster_run, "pipeline_run", DagsterRun)
     check.inst_param(instance, "instance", DagsterInstance)
 
     if inject_env_vars:
         try:
             location_name = (
-                pipeline_run.external_pipeline_origin.location_name
-                if pipeline_run.external_pipeline_origin
+                dagster_run.external_job_origin.location_name
+                if dagster_run.external_job_origin
                 else None
             )
 
             instance.inject_env_vars(location_name)
         except Exception:
             yield instance.report_engine_event(
                 "Error while loading environment variables.",
-                pipeline_run,
+                dagster_run,
                 EngineEventData.engine_error(serializable_error_info_from_exc_info(sys.exc_info())),
             )
-            yield from _report_run_failed_if_not_finished(instance, pipeline_run.run_id)
+            yield from _report_run_failed_if_not_finished(instance, dagster_run.run_id)
             raise
 
     # try to load the pipeline definition early
     try:
         # add in cached metadata to load repository more efficiently
-        if pipeline_run.has_repository_load_data:
+        if dagster_run.has_repository_load_data:
             execution_plan_snapshot = instance.get_execution_plan_snapshot(
-                check.not_none(pipeline_run.execution_plan_snapshot_id)
+                check.not_none(dagster_run.execution_plan_snapshot_id)
             )
-            recon_pipeline = recon_pipeline.with_repository_load_data(
+            recon_job = recon_job.with_repository_load_data(
                 execution_plan_snapshot.repository_load_data,
             )
-        recon_pipeline.get_definition()
+        recon_job.get_definition()
     except Exception:
         yield instance.report_engine_event(
             "Could not load pipeline definition.",
-            pipeline_run,
+            dagster_run,
             EngineEventData.engine_error(serializable_error_info_from_exc_info(sys.exc_info())),
         )
-        yield from _report_run_failed_if_not_finished(instance, pipeline_run.run_id)
+        yield from _report_run_failed_if_not_finished(instance, dagster_run.run_id)
         raise
 
     # Reload the run to verify that its status didn't change while the pipeline was loaded
-    pipeline_run = check.not_none(
-        instance.get_run_by_id(pipeline_run.run_id),
-        f"Pipeline run with id '{pipeline_run.run_id}' was deleted after the run worker started.",
+    dagster_run = check.not_none(
+        instance.get_run_by_id(dagster_run.run_id),
+        f"Pipeline run with id '{dagster_run.run_id}' was deleted after the run worker started.",
     )
 
     try:
         yield from execute_run_iterator(
-            recon_pipeline, pipeline_run, instance, resume_from_failure=resume_from_failure
+            recon_job, dagster_run, instance, resume_from_failure=resume_from_failure
         )
     except (KeyboardInterrupt, DagsterExecutionInterruptedError):
-        yield from _report_run_failed_if_not_finished(instance, pipeline_run.run_id)
+        yield from _report_run_failed_if_not_finished(instance, dagster_run.run_id)
         yield instance.report_engine_event(
             message="Run execution terminated by interrupt",
-            pipeline_run=pipeline_run,
+            dagster_run=dagster_run,
         )
         raise
     except Exception:
         yield instance.report_engine_event(
             (
                 "An exception was thrown during execution that is likely a framework error, "
                 "rather than an error in user code."
             ),
-            pipeline_run,
+            dagster_run,
             EngineEventData.engine_error(serializable_error_info_from_exc_info(sys.exc_info())),
         )
-        yield from _report_run_failed_if_not_finished(instance, pipeline_run.run_id)
+        yield from _report_run_failed_if_not_finished(instance, dagster_run.run_id)
         raise
 
 
 @contextmanager
 def _instance_from_ref_for_dynamic_partitions(
     instance_ref: Optional[InstanceRef], partitions_def: PartitionsDefinition
 ) -> Iterator[Optional[DagsterInstance]]:
@@ -167,41 +167,39 @@
     with DagsterInstance.from_ref(instance_ref) if (
         instance_ref and (_partitions_def_contains_dynamic_partitions_def(partitions_def))
     ) else nullcontext() as instance:
         yield instance
 
 
 def _run_in_subprocess(
-    serialized_execute_run_args,
-    recon_pipeline,
-    termination_event,
+    serialized_execute_run_args: str,
+    recon_pipeline: ReconstructableJob,
+    termination_event: Any,
     subprocess_status_handler,
     run_event_handler,
-):
+) -> None:
     start_termination_thread(termination_event)
     try:
-        execute_run_args = deserialize_value(
-            serialized_execute_run_args, ExecuteExternalPipelineArgs
-        )
+        execute_run_args = deserialize_value(serialized_execute_run_args, ExecuteExternalJobArgs)
 
         with (
             DagsterInstance.from_ref(execute_run_args.instance_ref)
             if execute_run_args.instance_ref
             else nullcontext()
         ) as instance:
             instance = check.not_none(instance)  # noqa: PLW2901
-            pipeline_run = instance.get_run_by_id(execute_run_args.pipeline_run_id)
+            dagster_run = instance.get_run_by_id(execute_run_args.run_id)
 
-            if not pipeline_run:
+            if not dagster_run:
                 raise DagsterRunNotFoundError(
                     "gRPC server could not load run {run_id} in order to execute it. Make sure that"
                     " the gRPC server has access to your run storage.".format(
-                        run_id=execute_run_args.pipeline_run_id
+                        run_id=execute_run_args.run_id
                     ),
-                    invalid_run_id=execute_run_args.pipeline_run_id,
+                    invalid_run_id=execute_run_args.run_id,
                 )
 
             pid = os.getpid()
 
     except:
         serializable_error_info = serializable_error_info_from_exc_info(sys.exc_info())
         event = IPCErrorMessage(
@@ -215,39 +213,37 @@
         return
 
     subprocess_status_handler(StartRunInSubprocessSuccessful())
 
     run_event_handler(
         instance.report_engine_event(
             f"Started process for run (pid: {pid}).",
-            pipeline_run,
+            dagster_run,
             EngineEventData.in_process(pid),
         )
     )
 
     # This is so nasty but seemingly unavoidable
     # https://amir.rachum.com/blog/2017/03/03/generator-cleanup/
     closed = False
     try:
-        for event in core_execute_run(
-            recon_pipeline, pipeline_run, instance, inject_env_vars=False
-        ):
+        for event in core_execute_run(recon_pipeline, dagster_run, instance, inject_env_vars=False):
             run_event_handler(event)
     except GeneratorExit:
         closed = True
         raise
     except:
         # Relies on core_execute_run logging all exceptions to the event log before raising
         pass
     finally:
         if not closed:
             run_event_handler(
                 instance.report_engine_event(
                     f"Process for run exited (pid: {pid}).",
-                    pipeline_run,
+                    dagster_run,
                 )
             )
         subprocess_status_handler(RunInSubprocessComplete())
         instance.dispose()
 
 
 def start_run_in_subprocess(
@@ -271,20 +267,18 @@
 ):
     try:
         definition = repo_def.get_maybe_subset_job_def(
             job_name,
             op_selection=solid_selection,
             asset_selection=frozenset(asset_selection) if asset_selection else None,
         )
-        external_pipeline_data = external_pipeline_data_from_def(definition)
-        return ExternalPipelineSubsetResult(
-            success=True, external_pipeline_data=external_pipeline_data
-        )
+        external_job_data = external_job_data_from_def(definition)
+        return ExternalJobSubsetResult(success=True, external_job_data=external_job_data)
     except Exception:
-        return ExternalPipelineSubsetResult(
+        return ExternalJobSubsetResult(
             success=False, error=serializable_error_info_from_exc_info(sys.exc_info())
         )
 
 
 def get_external_schedule_execution(
     repo_def: RepositoryDefinition,
     instance_ref: Optional[InstanceRef],
@@ -417,17 +411,18 @@
         ) = _get_job_partitions_and_config_for_partition_set_name(repo_def, partition_set_name)
 
         with _instance_from_ref_for_dynamic_partitions(instance_ref, partitions_def) as instance:
             with user_code_error_boundary(
                 PartitionExecutionError,
                 lambda: f"Error occurred during the evaluation of the `run_config_for_partition` function for partition set {partition_set_name}",
             ):
-                run_config = partitioned_config.get_run_config_for_partition_key(
+                partitions_def.validate_partition_key(
                     partition_key, dynamic_partitions_store=instance
                 )
+                run_config = partitioned_config.get_run_config_for_partition_key(partition_key)
                 return ExternalPartitionConfigData(name=partition_key, run_config=run_config)
     except Exception:
         return ExternalPartitionExecutionErrorData(
             serializable_error_info_from_exc_info(sys.exc_info())
         )
 
 
@@ -470,16 +465,19 @@
         # the instance when necessary for dynamic partitions: https://github.com/dagster-io/dagster/issues/12440
 
         with _instance_from_ref_for_dynamic_partitions(instance_ref, partitions_def) as instance:
             with user_code_error_boundary(
                 PartitionExecutionError,
                 lambda: f"Error occurred during the evaluation of the `tags_for_partition` function for partitioned config on job '{job_def.name}'",
             ):
+                partitions_def.validate_partition_key(
+                    partition_name, dynamic_partitions_store=instance
+                )
                 tags = partitioned_config.get_tags_for_partition_key(
-                    partition_name, job_name=job_def.name, dynamic_partitions_store=instance
+                    partition_name, job_name=job_def.name
                 )
                 return ExternalPartitionTagsData(name=partition_name, tags=tags)
 
     except Exception:
         return ExternalPartitionExecutionErrorData(
             serializable_error_info_from_exc_info(sys.exc_info())
         )
@@ -502,15 +500,15 @@
                 job_def,
                 run_config=args.run_config,
                 step_keys_to_execute=args.step_keys_to_execute,
                 known_state=args.known_state,
                 instance_ref=args.instance_ref,
                 repository_load_data=repo_def.repository_load_data,
             ),
-            args.pipeline_snapshot_id,
+            args.job_snapshot_id,
         )
     except:
         return ExecutionPlanSnapshotErrorData(
             error=serializable_error_info_from_exc_info(sys.exc_info())
         )
 
 
@@ -528,40 +526,34 @@
 
     try:
         with _instance_from_ref_for_dynamic_partitions(instance_ref, partitions_def) as instance:
             with user_code_error_boundary(
                 PartitionExecutionError,
                 lambda: f"Error occurred during the partition generation for partitioned config on job '{job_def.name}'",
             ):
-                all_partitions = partitions_def.get_partitions(dynamic_partitions_store=instance)
-                partitions = [
-                    partition for partition in all_partitions if partition.name in partition_names
-                ]
+                all_partition_keys = partitions_def.get_partition_keys(
+                    dynamic_partitions_store=instance
+                )
+                partition_keys = [key for key in all_partition_keys if key in partition_names]
 
             partition_data = []
-            for partition in partitions:
+            for key in partition_keys:
 
                 def _error_message_fn(partition_name: str):
                     return (
                         lambda: f"Error occurred during the partition config and tag generation for '{partition_name}' in partitioned config on job '{job_def.name}'"
                     )
 
-                with user_code_error_boundary(
-                    PartitionExecutionError, _error_message_fn(partition.name)
-                ):
-                    run_config = partitioned_config.get_run_config_for_partition_key(
-                        partition.name, instance
-                    )
-                    tags = partitioned_config.get_tags_for_partition_key(
-                        partition.name, instance, job_name=job_def.name
-                    )
+                with user_code_error_boundary(PartitionExecutionError, _error_message_fn(key)):
+                    run_config = partitioned_config.get_run_config_for_partition_key(key)
+                    tags = partitioned_config.get_tags_for_partition_key(key, job_name=job_def.name)
 
                 partition_data.append(
                     ExternalPartitionExecutionParamData(
-                        name=partition.name,
+                        name=key,
                         tags=tags,
                         run_config=run_config,
                     )
                 )
 
             return ExternalPartitionSetExecutionParamData(partition_data=partition_data)
```

### Comparing `dagster-1.3.2/dagster/_grpc/protos/api.proto` & `dagster-1.3.3/dagster/_grpc/protos/api.proto`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_grpc/server.py` & `dagster-1.3.3/dagster/_grpc/server.py`

 * *Files 6% similar despite different names*

```diff
@@ -22,16 +22,20 @@
 import dagster._check as check
 import dagster._seven as seven
 from dagster._core.code_pointer import CodePointer
 from dagster._core.definitions.reconstruct import ReconstructableRepository
 from dagster._core.definitions.repository_definition import RepositoryDefinition
 from dagster._core.errors import DagsterUserCodeUnreachableError
 from dagster._core.host_representation.external_data import (
+    ExternalJobSubsetResult,
+    ExternalPartitionExecutionErrorData,
     ExternalRepositoryErrorData,
-    external_pipeline_data_from_def,
+    ExternalScheduleExecutionErrorData,
+    ExternalSensorExecutionErrorData,
+    external_job_data_from_def,
     external_repository_data_from_def,
 )
 from dagster._core.host_representation.origin import ExternalRepositoryOrigin
 from dagster._core.instance import DagsterInstance, InstanceRef
 from dagster._core.libraries import DagsterLibraryRegistry
 from dagster._core.origin import DEFAULT_DAGSTER_ENTRY_POINT, get_python_environment_entry_point
 from dagster._core.types.loadable_target_origin import LoadableTargetOrigin
@@ -62,25 +66,25 @@
     start_run_in_subprocess,
 )
 from .types import (
     CanCancelExecutionRequest,
     CanCancelExecutionResult,
     CancelExecutionRequest,
     CancelExecutionResult,
-    ExecuteExternalPipelineArgs,
+    ExecuteExternalJobArgs,
     ExecutionPlanSnapshotArgs,
     ExternalScheduleExecutionArgs,
     GetCurrentImageResult,
     GetCurrentRunsResult,
+    JobSubsetSnapshotArgs,
     ListRepositoriesResponse,
     LoadableRepositorySymbol,
     PartitionArgs,
     PartitionNamesArgs,
     PartitionSetExecutionParamArgs,
-    PipelineSubsetSnapshotArgs,
     SensorExecutionArgs,
     ShutdownServerResult,
     StartRunResult,
 )
 from .utils import get_loadable_targets, max_rx_bytes, max_send_bytes
 
 EVENT_QUEUE_POLL_INTERVAL = 0.1
@@ -383,143 +387,186 @@
     def ExecutionPlanSnapshot(self, request, _context):
         execution_plan_args = deserialize_value(
             request.serialized_execution_plan_snapshot_args,
             ExecutionPlanSnapshotArgs,
         )
 
         execution_plan_snapshot_or_error = get_external_execution_plan_snapshot(
-            self._get_repo_for_origin(
-                execution_plan_args.pipeline_origin.external_repository_origin
-            ),
-            execution_plan_args.pipeline_origin.pipeline_name,
+            self._get_repo_for_origin(execution_plan_args.job_origin.external_repository_origin),
+            execution_plan_args.job_origin.job_name,
             execution_plan_args,
         )
         return api_pb2.ExecutionPlanSnapshotReply(
             serialized_execution_plan_snapshot=serialize_value(execution_plan_snapshot_or_error)
         )
 
     def ListRepositories(self, request, _context) -> api_pb2.ListRepositoriesReply:  # type: ignore
         if self._serializable_load_error:
             return api_pb2.ListRepositoriesReply(  # type: ignore
                 serialized_list_repositories_response_or_error=serialize_value(
                     self._serializable_load_error
                 )
             )
-        loaded_repositories = check.not_none(self._loaded_repositories)
-        response = ListRepositoriesResponse(
-            loaded_repositories.loadable_repository_symbols,
-            executable_path=self._loadable_target_origin.executable_path
-            if self._loadable_target_origin
-            else None,
-            repository_code_pointer_dict=loaded_repositories.code_pointers_by_repo_name,
-            entry_point=self._entry_point,
-            container_image=self._container_image,
-            container_context=self._container_context,
-            dagster_library_versions=DagsterLibraryRegistry.get(),
-        )
+        try:
+            loaded_repositories = check.not_none(self._loaded_repositories)
+            serialized_response = serialize_value(
+                ListRepositoriesResponse(
+                    loaded_repositories.loadable_repository_symbols,
+                    executable_path=self._loadable_target_origin.executable_path
+                    if self._loadable_target_origin
+                    else None,
+                    repository_code_pointer_dict=loaded_repositories.code_pointers_by_repo_name,
+                    entry_point=self._entry_point,
+                    container_image=self._container_image,
+                    container_context=self._container_context,
+                    dagster_library_versions=DagsterLibraryRegistry.get(),
+                )
+            )
+        except Exception:
+            serialized_response = serialize_value(
+                serializable_error_info_from_exc_info(sys.exc_info())
+            )
 
         return api_pb2.ListRepositoriesReply(  # type: ignore
-            serialized_list_repositories_response_or_error=serialize_value(response)
+            serialized_list_repositories_response_or_error=serialized_response
         )
 
     def ExternalPartitionNames(self, request, _context) -> api_pb2.ExternalPartitionNamesReply:  # type: ignore
-        partition_names_args = deserialize_value(
-            request.serialized_partition_names_args,
-            PartitionNamesArgs,
-        )
-        return api_pb2.ExternalPartitionNamesReply(  # type: ignore
-            serialized_external_partition_names_or_external_partition_execution_error=serialize_value(
+        try:
+            partition_names_args = deserialize_value(
+                request.serialized_partition_names_args,
+                PartitionNamesArgs,
+            )
+            serialized_response = serialize_value(
                 get_partition_names(
                     self._get_repo_for_origin(partition_names_args.repository_origin),
                     partition_names_args.partition_set_name,
                 )
             )
+        except Exception:
+            serialized_response = serialize_value(
+                ExternalPartitionExecutionErrorData(
+                    serializable_error_info_from_exc_info(sys.exc_info())
+                )
+            )
+
+        return api_pb2.ExternalPartitionNamesReply(  # type: ignore
+            serialized_external_partition_names_or_external_partition_execution_error=serialized_response
         )
 
     def ExternalNotebookData(self, request, _context) -> api_pb2.ExternalNotebookDataReply:  # type: ignore
         notebook_path = request.notebook_path
         check.str_param(notebook_path, "notebook_path")
         return api_pb2.ExternalNotebookDataReply(content=get_notebook_data(notebook_path))  # type: ignore
 
     def ExternalPartitionSetExecutionParams(self, request, _context):
-        args = deserialize_value(
-            request.serialized_partition_set_execution_param_args,
-            PartitionSetExecutionParamArgs,
-        )
+        try:
+            args = deserialize_value(
+                request.serialized_partition_set_execution_param_args,
+                PartitionSetExecutionParamArgs,
+            )
 
-        instance_ref = args.instance_ref if args.instance_ref else self._instance_ref
-
-        serialized_data = serialize_value(
-            get_partition_set_execution_param_data(
-                self._get_repo_for_origin(args.repository_origin),
-                partition_set_name=args.partition_set_name,
-                partition_names=args.partition_names,
-                instance_ref=instance_ref,
+            instance_ref = args.instance_ref if args.instance_ref else self._instance_ref
+
+            serialized_data = serialize_value(
+                get_partition_set_execution_param_data(
+                    self._get_repo_for_origin(args.repository_origin),
+                    partition_set_name=args.partition_set_name,
+                    partition_names=args.partition_names,
+                    instance_ref=instance_ref,
+                )
+            )
+        except Exception:
+            serialized_data = serialize_value(
+                ExternalPartitionExecutionErrorData(
+                    serializable_error_info_from_exc_info(sys.exc_info())
+                )
             )
-        )
 
         yield from self._split_serialized_data_into_chunk_events(serialized_data)
 
     def ExternalPartitionConfig(self, request, _context):
-        args = deserialize_value(request.serialized_partition_args, PartitionArgs)
+        try:
+            args = deserialize_value(request.serialized_partition_args, PartitionArgs)
 
-        instance_ref = args.instance_ref if args.instance_ref else self._instance_ref
+            instance_ref = args.instance_ref if args.instance_ref else self._instance_ref
 
-        serialized_data = serialize_value(
-            get_partition_config(
-                self._get_repo_for_origin(args.repository_origin),
-                args.partition_set_name,
-                args.partition_name,
-                instance_ref=instance_ref,
+            serialized_data = serialize_value(
+                get_partition_config(
+                    self._get_repo_for_origin(args.repository_origin),
+                    args.partition_set_name,
+                    args.partition_name,
+                    instance_ref=instance_ref,
+                )
+            )
+        except Exception:
+            serialized_data = serialize_value(
+                ExternalPartitionExecutionErrorData(
+                    serializable_error_info_from_exc_info(sys.exc_info())
+                )
             )
-        )
 
         return api_pb2.ExternalPartitionConfigReply(
             serialized_external_partition_config_or_external_partition_execution_error=serialized_data
         )
 
     def ExternalPartitionTags(self, request, _context) -> api_pb2.ExternalPartitionTagsReply:  # type: ignore
-        partition_args = deserialize_value(request.serialized_partition_args, PartitionArgs)
+        try:
+            partition_args = deserialize_value(request.serialized_partition_args, PartitionArgs)
 
-        instance_ref = (
-            partition_args.instance_ref if partition_args.instance_ref else self._instance_ref
-        )
+            instance_ref = (
+                partition_args.instance_ref if partition_args.instance_ref else self._instance_ref
+            )
 
-        serialized_data = serialize_value(
-            get_partition_tags(
-                self._get_repo_for_origin(partition_args.repository_origin),
-                partition_args.partition_set_name,
-                partition_args.partition_name,
-                instance_ref=instance_ref,
+            serialized_data = serialize_value(
+                get_partition_tags(
+                    self._get_repo_for_origin(partition_args.repository_origin),
+                    partition_args.partition_set_name,
+                    partition_args.partition_name,
+                    instance_ref=instance_ref,
+                )
+            )
+        except Exception:
+            serialized_data = serialize_value(
+                ExternalPartitionExecutionErrorData(
+                    serializable_error_info_from_exc_info(sys.exc_info())
+                )
             )
-        )
 
         return api_pb2.ExternalPartitionTagsReply(  # type: ignore
             serialized_external_partition_tags_or_external_partition_execution_error=serialized_data
         )
 
     def ExternalPipelineSubsetSnapshot(
         self, request: Any, _context
     ) -> api_pb2.ExternalPipelineSubsetSnapshotReply:  # type: ignore
-        pipeline_subset_snapshot_args = deserialize_value(
-            request.serialized_pipeline_subset_snapshot_args,
-            PipelineSubsetSnapshotArgs,
-        )
-
-        return api_pb2.ExternalPipelineSubsetSnapshotReply(  # type: ignore
-            serialized_external_pipeline_subset_result=serialize_value(
+        try:
+            job_subset_snapshot_args = deserialize_value(
+                request.serialized_pipeline_subset_snapshot_args,
+                JobSubsetSnapshotArgs,
+            )
+            serialized_external_pipeline_subset_result = serialize_value(
                 get_external_pipeline_subset_result(
                     self._get_repo_for_origin(
-                        pipeline_subset_snapshot_args.pipeline_origin.external_repository_origin
+                        job_subset_snapshot_args.job_origin.external_repository_origin
                     ),
-                    pipeline_subset_snapshot_args.pipeline_origin.pipeline_name,
-                    pipeline_subset_snapshot_args.solid_selection,
-                    pipeline_subset_snapshot_args.asset_selection,
+                    job_subset_snapshot_args.job_origin.job_name,
+                    job_subset_snapshot_args.solid_selection,
+                    job_subset_snapshot_args.asset_selection,
+                )
+            )
+        except Exception:
+            serialized_external_pipeline_subset_result = serialize_value(
+                ExternalJobSubsetResult(
+                    success=False, error=serializable_error_info_from_exc_info(sys.exc_info())
                 )
             )
+
+        return api_pb2.ExternalPipelineSubsetSnapshotReply(  # type: ignore
+            serialized_external_pipeline_subset_result=serialized_external_pipeline_subset_result
         )
 
     def _get_serialized_external_repository_data(self, request):
         try:
             repository_origin = deserialize_value(
                 request.serialized_repository_python_origin,
                 ExternalRepositoryOrigin,
@@ -546,15 +593,15 @@
         try:
             repository_origin = deserialize_value(
                 request.serialized_repository_origin,
                 ExternalRepositoryOrigin,
             )
 
             job_def = self._get_repo_for_origin(repository_origin).get_job(request.job_name)
-            ser_job_data = serialize_value(external_pipeline_data_from_def(job_def))
+            ser_job_data = serialize_value(external_job_data_from_def(job_def))
             return api_pb2.ExternalJobReply(serialized_job_data=ser_job_data)  # type: ignore
         except Exception:
             return api_pb2.ExternalJobReply(  # type: ignore
                 serialized_error=serialize_value(
                     serializable_error_info_from_exc_info(sys.exc_info())
                 )
             )
@@ -591,46 +638,60 @@
 
             yield api_pb2.StreamingChunkEvent(
                 sequence_number=i,
                 serialized_chunk=serialized_data[start_index:end_index],
             )
 
     def ExternalScheduleExecution(self, request, _context):
-        args = deserialize_value(
-            request.serialized_external_schedule_execution_args,
-            ExternalScheduleExecutionArgs,
-        )
-        serialized_schedule_data = serialize_value(
-            get_external_schedule_execution(
-                self._get_repo_for_origin(args.repository_origin),
-                args.instance_ref,
-                args.schedule_name,
-                args.scheduled_execution_timestamp,
-                args.scheduled_execution_timezone,
+        try:
+            args = deserialize_value(
+                request.serialized_external_schedule_execution_args,
+                ExternalScheduleExecutionArgs,
+            )
+            serialized_schedule_data = serialize_value(
+                get_external_schedule_execution(
+                    self._get_repo_for_origin(args.repository_origin),
+                    args.instance_ref,
+                    args.schedule_name,
+                    args.scheduled_execution_timestamp,
+                    args.scheduled_execution_timezone,
+                )
+            )
+        except Exception:
+            serialized_schedule_data = serialize_value(
+                ExternalScheduleExecutionErrorData(
+                    serializable_error_info_from_exc_info(sys.exc_info())
+                )
             )
-        )
 
         yield from self._split_serialized_data_into_chunk_events(serialized_schedule_data)
 
     def ExternalSensorExecution(self, request, _context):
-        args = deserialize_value(
-            request.serialized_external_sensor_execution_args,
-            SensorExecutionArgs,
-        )
+        try:
+            args = deserialize_value(
+                request.serialized_external_sensor_execution_args,
+                SensorExecutionArgs,
+            )
 
-        serialized_sensor_data = serialize_value(
-            get_external_sensor_execution(
-                self._get_repo_for_origin(args.repository_origin),
-                args.instance_ref,
-                args.sensor_name,
-                args.last_completion_time,
-                args.last_run_key,
-                args.cursor,
+            serialized_sensor_data = serialize_value(
+                get_external_sensor_execution(
+                    self._get_repo_for_origin(args.repository_origin),
+                    args.instance_ref,
+                    args.sensor_name,
+                    args.last_completion_time,
+                    args.last_run_key,
+                    args.cursor,
+                )
+            )
+        except Exception:
+            serialized_sensor_data = serialize_value(
+                ExternalSensorExecutionErrorData(
+                    serializable_error_info_from_exc_info(sys.exc_info())
+                )
             )
-        )
 
         yield from self._split_serialized_data_into_chunk_events(serialized_sensor_data)
 
     def ShutdownServer(self, request, _context) -> api_pb2.ShutdownServerReply:  # type: ignore
         try:
             self._shutdown_once_executions_finish_event.set()
             return api_pb2.ShutdownServerReply(  # type: ignore
@@ -704,26 +765,26 @@
                         message="Tried to start a run on a server after telling it to shut down",
                         serializable_error_info=None,
                     )
                 )
             )
 
         try:
-            execute_external_pipeline_args = deserialize_value(
+            execute_external_job_args = deserialize_value(
                 request.serialized_execute_run_args,
-                ExecuteExternalPipelineArgs,
+                ExecuteExternalJobArgs,
             )
-            run_id = execute_external_pipeline_args.pipeline_run_id
+            run_id = execute_external_job_args.run_id
 
             # reconstructable required for handing execution off to subprocess
             recon_repo = check.not_none(self._loaded_repositories).reconstructables_by_name[
-                execute_external_pipeline_args.pipeline_origin.external_repository_origin.repository_name
+                execute_external_job_args.job_origin.external_repository_origin.repository_name
             ]
-            recon_pipeline = recon_repo.get_reconstructable_pipeline(
-                execute_external_pipeline_args.pipeline_origin.pipeline_name
+            recon_job = recon_repo.get_reconstructable_job(
+                execute_external_job_args.job_origin.job_name
             )
 
         except:
             return api_pb2.StartRunReply(  # type: ignore
                 serialized_start_run_result=serialize_value(
                     StartRunResult(
                         success=False,
@@ -737,27 +798,27 @@
 
         event_queue = self._mp_ctx.Queue()
         termination_event = self._mp_ctx.Event()
         execution_process = self._mp_ctx.Process(
             target=start_run_in_subprocess,
             args=[
                 request.serialized_execute_run_args,
-                recon_pipeline,
+                recon_job,
                 event_queue,
                 termination_event,
             ],
         )
 
         with self._execution_lock:
             execution_process.start()
             self._executions[run_id] = (
                 # Cast here to convert `SpawnProcess` from event into regular `Process`-- not sure
                 # why not recognized as subclass, multiprocessing typing is a little rough.
                 cast(multiprocessing.Process, execution_process),
-                check.not_none(execute_external_pipeline_args.instance_ref),
+                check.not_none(execute_external_job_args.instance_ref),
             )
             self._termination_events[run_id] = termination_event
 
         success = None
         message = None
         serializable_error_info = None
 
@@ -1189,22 +1250,25 @@
         cwd: Optional[str] = None,
         log_level: str = "INFO",
         env: Optional[Dict[str, str]] = None,
         wait_on_exit=False,
     ):
         self.port = None
         self.socket = None
+        self._waited = False
+        self._shutdown = False
+        self._heartbeat = heartbeat
+        self._server_process = None
 
         self.loadable_target_origin = check.opt_inst_param(
             loadable_target_origin, "loadable_target_origin", LoadableTargetOrigin
         )
         check.bool_param(force_port, "force_port")
         check.int_param(max_retries, "max_retries")
         check.opt_int_param(max_workers, "max_workers")
-        self._heartbeat = check.bool_param(heartbeat, "heartbeat")
         check.int_param(heartbeat_timeout, "heartbeat_timeout")
         check.invariant(heartbeat_timeout > 0, "heartbeat_timeout must be greater than 0")
         check.opt_str_param(fixed_server_id, "fixed_server_id")
         check.int_param(startup_timeout, "startup_timeout")
         check.invariant(
             max_workers is None or max_workers > 1 if heartbeat else True,
             (
@@ -1246,20 +1310,21 @@
                 log_level=log_level,
                 env=env,
             )
 
         if server_process is None:
             raise CouldNotStartServerProcess(port=self.port, socket=self.socket)
         else:
-            self.server_process = server_process
+            self._server_process = server_process
 
         self._wait_on_exit = wait_on_exit
 
-        self._waited = False
-        self._shutdown = False
+    @property
+    def server_process(self):
+        return check.not_none(self._server_process)
 
     @property
     def pid(self):
         return self.server_process.pid
 
     def wait(self, timeout=30):
         self._waited = True
@@ -1272,32 +1337,36 @@
     def __exit__(self, _exception_type, _exception_value, _traceback):
         self.shutdown_server()
 
         if self._wait_on_exit:
             self.wait()
 
     def shutdown_server(self):
-        if not self._shutdown:
+        if self._server_process and not self._shutdown:
             self._shutdown = True
             if self.server_process.poll() is None:
                 try:
                     self.create_client().shutdown_server()
                 except DagsterUserCodeUnreachableError:
                     pass
 
     def __del__(self):
-        if not self._shutdown and not self._heartbeat:
+        if self._server_process and self._shutdown is False and not self._heartbeat:
             warnings.warn(
                 "GrpcServerProcess without a heartbeat is being destroyed without signalling to the"
                 " server that it should shut down. This may result in server processes living"
                 " longer than they need to. To fix this, wrap the GrpcServerProcess in a"
                 " contextmanager or call shutdown_server on it."
             )
 
-        if not self._waited and os.getenv("STRICT_GRPC_SERVER_PROCESS_WAIT"):
+        if (
+            self._server_process
+            and not self._waited
+            and os.getenv("STRICT_GRPC_SERVER_PROCESS_WAIT")
+        ):
             warnings.warn(
                 "GrpcServerProcess is being destroyed without waiting for the process to "
                 + "fully terminate. This can cause test instability."
             )
 
     def create_client(self):
         from dagster._grpc.client import DagsterGrpcClient
```

### Comparing `dagster-1.3.2/dagster/_grpc/server_watcher.py` & `dagster-1.3.3/dagster/_grpc/server_watcher.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_grpc/types.py` & `dagster-1.3.3/dagster/_grpc/types.py`

 * *Files 13% similar despite different names*

```diff
@@ -6,233 +6,255 @@
 from dagster._core.code_pointer import CodePointer
 from dagster._core.definitions.events import AssetKey
 from dagster._core.execution.plan.state import KnownExecutionState
 from dagster._core.execution.retries import RetryMode
 from dagster._core.host_representation.external_data import DEFAULT_MODE_NAME
 from dagster._core.host_representation.origin import (
     CodeLocationOrigin,
-    ExternalPipelineOrigin,
+    ExternalJobOrigin,
     ExternalRepositoryOrigin,
 )
 from dagster._core.instance.ref import InstanceRef
-from dagster._core.origin import PipelinePythonOrigin, get_python_environment_entry_point
+from dagster._core.origin import JobPythonOrigin, get_python_environment_entry_point
 from dagster._serdes import serialize_value, whitelist_for_serdes
 from dagster._utils.error import SerializableErrorInfo
 
 
-@whitelist_for_serdes
+@whitelist_for_serdes(
+    storage_field_names={
+        "job_origin": "pipeline_origin",
+        "job_snapshot_id": "pipeline_snapshot_id",
+    }
+)
 class ExecutionPlanSnapshotArgs(
     NamedTuple(
         "_ExecutionPlanSnapshotArgs",
         [
-            ("pipeline_origin", ExternalPipelineOrigin),
+            ("job_origin", ExternalJobOrigin),
             ("solid_selection", Sequence[str]),
             ("run_config", Mapping[str, object]),
             ("step_keys_to_execute", Optional[Sequence[str]]),
-            ("pipeline_snapshot_id", str),
+            ("job_snapshot_id", str),
             ("known_state", Optional[KnownExecutionState]),
             ("instance_ref", Optional[InstanceRef]),
             ("asset_selection", Optional[AbstractSet[AssetKey]]),
             ("mode", str),
         ],
     )
 ):
     def __new__(
         cls,
-        pipeline_origin: ExternalPipelineOrigin,
+        job_origin: ExternalJobOrigin,
         solid_selection: Sequence[str],
         run_config: Mapping[str, object],
         step_keys_to_execute: Optional[Sequence[str]],
-        pipeline_snapshot_id: str,
+        job_snapshot_id: str,
         known_state: Optional[KnownExecutionState] = None,
         instance_ref: Optional[InstanceRef] = None,
         asset_selection: Optional[AbstractSet[AssetKey]] = None,
         mode: str = DEFAULT_MODE_NAME,
     ):
         return super(ExecutionPlanSnapshotArgs, cls).__new__(
             cls,
-            pipeline_origin=check.inst_param(
-                pipeline_origin, "pipeline_origin", ExternalPipelineOrigin
-            ),
+            job_origin=check.inst_param(job_origin, "job_origin", ExternalJobOrigin),
             solid_selection=check.opt_sequence_param(
                 solid_selection, "solid_selection", of_type=str
             ),
             run_config=check.mapping_param(run_config, "run_config", key_type=str),
             mode=check.str_param(mode, "mode"),
             step_keys_to_execute=check.opt_nullable_sequence_param(
                 step_keys_to_execute, "step_keys_to_execute", of_type=str
             ),
-            pipeline_snapshot_id=check.str_param(pipeline_snapshot_id, "pipeline_snapshot_id"),
+            job_snapshot_id=check.str_param(job_snapshot_id, "job_snapshot_id"),
             known_state=check.opt_inst_param(known_state, "known_state", KnownExecutionState),
             instance_ref=check.opt_inst_param(instance_ref, "instance_ref", InstanceRef),
             asset_selection=check.opt_nullable_set_param(
                 asset_selection, "asset_selection", of_type=AssetKey
             ),
         )
 
 
-def _get_entry_point(origin: PipelinePythonOrigin):
+def _get_entry_point(origin: JobPythonOrigin):
     return (
         origin.repository_origin.entry_point
         if origin.repository_origin.entry_point
         else get_python_environment_entry_point(origin.executable_path)
     )
 
 
-@whitelist_for_serdes
+@whitelist_for_serdes(
+    storage_field_names={
+        "job_origin": "pipeline_origin",
+        "run_id": "pipeline_run_id",
+    }
+)
 class ExecuteRunArgs(
     NamedTuple(
         "_ExecuteRunArgs",
         [
             # Deprecated, only needed for back-compat since it can be pulled from the PipelineRun
-            ("pipeline_origin", PipelinePythonOrigin),
-            ("pipeline_run_id", str),
+            ("job_origin", JobPythonOrigin),
+            ("run_id", str),
             ("instance_ref", Optional[InstanceRef]),
             ("set_exit_code_on_failure", Optional[bool]),
         ],
     )
 ):
     def __new__(
         cls,
-        pipeline_origin: PipelinePythonOrigin,
-        pipeline_run_id: str,
+        job_origin: JobPythonOrigin,
+        run_id: str,
         instance_ref: Optional[InstanceRef],
         set_exit_code_on_failure: Optional[bool] = None,
     ):
         return super(ExecuteRunArgs, cls).__new__(
             cls,
-            pipeline_origin=check.inst_param(
-                pipeline_origin,
-                "pipeline_origin",
-                PipelinePythonOrigin,
+            job_origin=check.inst_param(
+                job_origin,
+                "job_origin",
+                JobPythonOrigin,
             ),
-            pipeline_run_id=check.str_param(pipeline_run_id, "pipeline_run_id"),
+            run_id=check.str_param(run_id, "run_id"),
             instance_ref=check.opt_inst_param(instance_ref, "instance_ref", InstanceRef),
             set_exit_code_on_failure=(
                 True
                 if check.opt_bool_param(set_exit_code_on_failure, "set_exit_code_on_failure")
                 is True
                 else None
             ),  # for back-compat
         )
 
     def get_command_args(self) -> Sequence[str]:
-        return _get_entry_point(self.pipeline_origin) + [
+        return _get_entry_point(self.job_origin) + [
             "api",
             "execute_run",
             serialize_value(self),
         ]
 
 
-@whitelist_for_serdes
+@whitelist_for_serdes(
+    storage_field_names={
+        "job_origin": "pipeline_origin",
+        "run_id": "pipeline_run_id",
+    }
+)
 class ResumeRunArgs(
     NamedTuple(
         "_ResumeRunArgs",
         [
-            # Deprecated, only needed for back-compat since it can be pulled from the PipelineRun
-            ("pipeline_origin", PipelinePythonOrigin),
-            ("pipeline_run_id", str),
+            # Deprecated, only needed for back-compat since it can be pulled from the DagsterRun
+            ("job_origin", JobPythonOrigin),
+            ("run_id", str),
             ("instance_ref", Optional[InstanceRef]),
             ("set_exit_code_on_failure", Optional[bool]),
         ],
     )
 ):
     def __new__(
         cls,
-        pipeline_origin: PipelinePythonOrigin,
-        pipeline_run_id: str,
+        job_origin: JobPythonOrigin,
+        run_id: str,
         instance_ref: Optional[InstanceRef],
         set_exit_code_on_failure: Optional[bool] = None,
     ):
         return super(ResumeRunArgs, cls).__new__(
             cls,
-            pipeline_origin=check.inst_param(
-                pipeline_origin,
-                "pipeline_origin",
-                PipelinePythonOrigin,
+            job_origin=check.inst_param(
+                job_origin,
+                "job_origin",
+                JobPythonOrigin,
             ),
-            pipeline_run_id=check.str_param(pipeline_run_id, "pipeline_run_id"),
+            run_id=check.str_param(run_id, "run_id"),
             instance_ref=check.opt_inst_param(instance_ref, "instance_ref", InstanceRef),
             set_exit_code_on_failure=(
                 True
                 if check.opt_bool_param(set_exit_code_on_failure, "set_exit_code_on_failure")
                 is True
                 else None
             ),  # for back-compat
         )
 
     def get_command_args(self) -> Sequence[str]:
-        return _get_entry_point(self.pipeline_origin) + [
+        return _get_entry_point(self.job_origin) + [
             "api",
             "resume_run",
             serialize_value(self),
         ]
 
 
-@whitelist_for_serdes
-class ExecuteExternalPipelineArgs(
+@whitelist_for_serdes(
+    storage_name="ExecuteExternalPipelineArgs",
+    storage_field_names={
+        "job_origin": "pipeline_origin",
+        "run_id": "pipeline_run_id",
+    },
+)
+class ExecuteExternalJobArgs(
     NamedTuple(
-        "_ExecuteExternalPipelineArgs",
+        "_ExecuteExternalJobArgs",
         [
-            ("pipeline_origin", ExternalPipelineOrigin),
-            ("pipeline_run_id", str),
+            ("job_origin", ExternalJobOrigin),
+            ("run_id", str),
             ("instance_ref", Optional[InstanceRef]),
         ],
     )
 ):
     def __new__(
         cls,
-        pipeline_origin: ExternalPipelineOrigin,
-        pipeline_run_id: str,
+        job_origin: ExternalJobOrigin,
+        run_id: str,
         instance_ref: Optional[InstanceRef],
     ):
-        return super(ExecuteExternalPipelineArgs, cls).__new__(
+        return super(ExecuteExternalJobArgs, cls).__new__(
             cls,
-            pipeline_origin=check.inst_param(
-                pipeline_origin,
-                "pipeline_origin",
-                ExternalPipelineOrigin,
+            job_origin=check.inst_param(
+                job_origin,
+                "job_origin",
+                ExternalJobOrigin,
             ),
-            pipeline_run_id=check.str_param(pipeline_run_id, "pipeline_run_id"),
+            run_id=check.str_param(run_id, "run_id"),
             instance_ref=check.opt_inst_param(instance_ref, "instance_ref", InstanceRef),
         )
 
 
-@whitelist_for_serdes
+@whitelist_for_serdes(
+    storage_field_names={
+        "job_origin": "pipeline_origin",
+        "run_id": "pipeline_run_id",
+    }
+)
 class ExecuteStepArgs(
     NamedTuple(
         "_ExecuteStepArgs",
         [
-            # Deprecated, only needed for back-compat since it can be pulled from the PipelineRun
-            ("pipeline_origin", PipelinePythonOrigin),
-            ("pipeline_run_id", str),
+            # Deprecated, only needed for back-compat since it can be pulled from the DagsterRun
+            ("job_origin", JobPythonOrigin),
+            ("run_id", str),
             ("step_keys_to_execute", Optional[Sequence[str]]),
             ("instance_ref", Optional[InstanceRef]),
             ("retry_mode", Optional[RetryMode]),
             ("known_state", Optional[KnownExecutionState]),
             ("should_verify_step", Optional[bool]),
         ],
     )
 ):
     def __new__(
         cls,
-        pipeline_origin: PipelinePythonOrigin,
-        pipeline_run_id: str,
+        job_origin: JobPythonOrigin,
+        run_id: str,
         step_keys_to_execute: Optional[Sequence[str]],
         instance_ref: Optional[InstanceRef] = None,
         retry_mode: Optional[RetryMode] = None,
         known_state: Optional[KnownExecutionState] = None,
         should_verify_step: Optional[bool] = None,
     ):
         return super(ExecuteStepArgs, cls).__new__(
             cls,
-            pipeline_origin=check.inst_param(
-                pipeline_origin, "pipeline_origin", PipelinePythonOrigin
-            ),
-            pipeline_run_id=check.str_param(pipeline_run_id, "pipeline_run_id"),
+            job_origin=check.inst_param(job_origin, "job_origin", JobPythonOrigin),
+            run_id=check.str_param(run_id, "run_id"),
             step_keys_to_execute=check.opt_nullable_sequence_param(
                 step_keys_to_execute, "step_keys_to_execute", of_type=str
             ),
             instance_ref=check.opt_inst_param(instance_ref, "instance_ref", InstanceRef),
             retry_mode=check.opt_inst_param(retry_mode, "retry_mode", RetryMode),
             known_state=check.opt_inst_param(known_state, "known_state", KnownExecutionState),
             should_verify_step=check.opt_bool_param(
@@ -245,15 +267,15 @@
         return base64.b64encode(zlib.compress(serialize_value(self).encode())).decode()
 
     def get_command_args(self, skip_serialized_namedtuple: bool = False) -> Sequence[str]:
         """Get the command args to run this step. If skip_serialized_namedtuple is True, then get_command_env should
         be used to pass the args to Click using an env var.
         """
         return (
-            _get_entry_point(self.pipeline_origin)
+            _get_entry_point(self.job_origin)
             + ["api", "execute_step"]
             + (
                 ["--compressed-input-json", self._get_compressed_args()]
                 if not skip_serialized_namedtuple
                 else []
             )
         )
@@ -438,36 +460,39 @@
             ),
             partition_set_name=check.str_param(partition_set_name, "partition_set_name"),
             partition_names=check.sequence_param(partition_names, "partition_names", of_type=str),
             instance_ref=check.opt_inst_param(instance_ref, "instance_ref", InstanceRef),
         )
 
 
-@whitelist_for_serdes
-class PipelineSubsetSnapshotArgs(
+@whitelist_for_serdes(
+    storage_name="PipelineSubsetSnapshotArgs",
+    storage_field_names={
+        "job_origin": "pipeline_origin",
+    },
+)
+class JobSubsetSnapshotArgs(
     NamedTuple(
-        "_PipelineSubsetSnapshotArgs",
+        "_JobSubsetSnapshotArgs",
         [
-            ("pipeline_origin", ExternalPipelineOrigin),
+            ("job_origin", ExternalJobOrigin),
             ("solid_selection", Optional[Sequence[str]]),
             ("asset_selection", Optional[Sequence[AssetKey]]),
         ],
     )
 ):
     def __new__(
         cls,
-        pipeline_origin: ExternalPipelineOrigin,
+        job_origin: ExternalJobOrigin,
         solid_selection: Sequence[str],
         asset_selection: Optional[Sequence[AssetKey]] = None,
     ):
-        return super(PipelineSubsetSnapshotArgs, cls).__new__(
+        return super(JobSubsetSnapshotArgs, cls).__new__(
             cls,
-            pipeline_origin=check.inst_param(
-                pipeline_origin, "pipeline_origin", ExternalPipelineOrigin
-            ),
+            job_origin=check.inst_param(job_origin, "job_origin", ExternalJobOrigin),
             solid_selection=check.sequence_param(solid_selection, "solid_selection", of_type=str)
             if solid_selection
             else None,
             asset_selection=check.opt_sequence_param(
                 asset_selection, "asset_selection", of_type=AssetKey
             ),
         )
```

### Comparing `dagster-1.3.2/dagster/_grpc/utils.py` & `dagster-1.3.3/dagster/_grpc/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_loggers/__init__.py` & `dagster-1.3.3/dagster/_loggers/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_module_alias_map.py` & `dagster-1.3.3/dagster/_module_alias_map.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_scheduler/scheduler.py` & `dagster-1.3.3/dagster/_scheduler/scheduler.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,32 +10,32 @@
 from typing import TYPE_CHECKING, Dict, List, Mapping, Optional, cast
 
 import pendulum
 
 import dagster._check as check
 from dagster._core.definitions.run_request import RunRequest
 from dagster._core.definitions.schedule_definition import DefaultScheduleStatus
-from dagster._core.definitions.selector import PipelineSelector
+from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.definitions.utils import validate_tags
 from dagster._core.errors import DagsterUserCodeUnreachableError
 from dagster._core.host_representation import ExternalSchedule
 from dagster._core.host_representation.code_location import CodeLocation
-from dagster._core.host_representation.external import ExternalPipeline
+from dagster._core.host_representation.external import ExternalJob
 from dagster._core.instance import DagsterInstance
 from dagster._core.scheduler.instigation import (
     InstigatorState,
     InstigatorStatus,
     InstigatorTick,
     InstigatorType,
     ScheduleInstigatorData,
     TickData,
     TickStatus,
 )
 from dagster._core.scheduler.scheduler import DEFAULT_MAX_CATCHUP_RUNS, DagsterSchedulerError
-from dagster._core.storage.pipeline_run import DagsterRun, DagsterRunStatus, RunsFilter
+from dagster._core.storage.dagster_run import DagsterRun, DagsterRunStatus, RunsFilter
 from dagster._core.storage.tags import RUN_KEY_TAG, SCHEDULED_EXECUTION_TIME_TAG
 from dagster._core.telemetry import SCHEDULED_RUN_CREATED, hash_name, log_action
 from dagster._core.workspace.context import IWorkspaceProcessContext
 from dagster._scheduler.stale import resolve_stale_or_missing_assets
 from dagster._seven.compat.pendulum import to_timezone
 from dagster._utils import DebugCrashFlags, SingleInstigatorDebugCrashFlags
 from dagster._utils.error import serializable_error_info_from_exc_info
@@ -623,22 +623,22 @@
             else:
                 run_request = raw_run_request.with_replaced_attrs(
                     asset_selection=stale_assets, stale_assets_only=False
                 )
         else:
             run_request = raw_run_request
 
-        pipeline_selector = PipelineSelector(
+        job_subset_selector = JobSubsetSelector(
             location_name=schedule_origin.external_repository_origin.code_location_origin.location_name,
             repository_name=schedule_origin.external_repository_origin.repository_name,
-            pipeline_name=external_schedule.pipeline_name,
+            job_name=external_schedule.job_name,
             solid_selection=external_schedule.solid_selection,
             asset_selection=run_request.asset_selection,
         )
-        external_pipeline = code_location.get_external_pipeline(pipeline_selector)
+        external_job = code_location.get_external_job(job_subset_selector)
 
         run = _get_existing_run_for_request(instance, external_schedule, schedule_time, run_request)
         if run:
             if run.status != DagsterRunStatus.NOT_STARTED:
                 # A run already exists and was launched for this time period,
                 # but the scheduler must have crashed or errored before the tick could be put
                 # into a SUCCESS state
@@ -657,15 +657,15 @@
                 )
         else:
             run = _create_scheduler_run(
                 instance,
                 schedule_time,
                 code_location,
                 external_schedule,
-                external_pipeline,
+                external_job,
                 run_request,
             )
 
         _check_for_debug_crash(debug_crash_flags, "RUN_CREATED")
 
         if run.status != DagsterRunStatus.FAILURE:
             try:
@@ -702,83 +702,83 @@
     runs_filter = RunsFilter(tags=tags)
     existing_runs = instance.get_runs(runs_filter)
 
     # filter down to match schedule namespace (repository)
     matching_runs = []
     for run in existing_runs:
         # if the run doesn't have an origin consider it a match
-        if run.external_pipeline_origin is None:
+        if run.external_job_origin is None:
             matching_runs.append(run)
         # otherwise prevent the same named schedule (with the same execution time) across repos from effecting each other
         elif (
             external_schedule.get_external_origin().external_repository_origin.get_selector_id()
-            == run.external_pipeline_origin.external_repository_origin.get_selector_id()
+            == run.external_job_origin.external_repository_origin.get_selector_id()
         ):
             matching_runs.append(run)
 
     if not len(matching_runs):
         return None
 
     return matching_runs[0]
 
 
 def _create_scheduler_run(
     instance: DagsterInstance,
     schedule_time: datetime.datetime,
     code_location: CodeLocation,
     external_schedule: ExternalSchedule,
-    external_pipeline: ExternalPipeline,
+    external_job: ExternalJob,
     run_request: RunRequest,
 ) -> DagsterRun:
     from dagster._daemon.daemon import get_telemetry_daemon_session_id
 
     run_config = run_request.run_config
     schedule_tags = run_request.tags
 
     external_execution_plan = code_location.get_external_execution_plan(
-        external_pipeline,
+        external_job,
         run_config,
         step_keys_to_execute=None,
         known_state=None,
     )
     execution_plan_snapshot = external_execution_plan.execution_plan_snapshot
 
     tags = merge_dicts(
-        validate_tags(external_pipeline.tags, allow_reserved_tags=False) or {},
+        validate_tags(external_job.tags, allow_reserved_tags=False) or {},
         schedule_tags,
     )
 
     tags[SCHEDULED_EXECUTION_TIME_TAG] = to_timezone(schedule_time, "UTC").isoformat()
     if run_request.run_key:
         tags[RUN_KEY_TAG] = run_request.run_key
 
     log_action(
         instance,
         SCHEDULED_RUN_CREATED,
         metadata={
             "DAEMON_SESSION_ID": get_telemetry_daemon_session_id(),
             "SCHEDULE_NAME_HASH": hash_name(external_schedule.name),
             "repo_hash": hash_name(code_location.name),
-            "pipeline_name_hash": hash_name(external_pipeline.name),
+            "pipeline_name_hash": hash_name(external_job.name),
         },
     )
 
     return instance.create_run(
-        pipeline_name=external_schedule.pipeline_name,
+        job_name=external_schedule.job_name,
         run_id=None,
         run_config=run_config,
-        solids_to_execute=external_pipeline.solids_to_execute,
+        solids_to_execute=external_job.solids_to_execute,
         step_keys_to_execute=None,
-        solid_selection=external_pipeline.solid_selection,
+        solid_selection=external_job.solid_selection,
         status=DagsterRunStatus.NOT_STARTED,
         root_run_id=None,
         parent_run_id=None,
         tags=tags,
-        pipeline_snapshot=external_pipeline.pipeline_snapshot,
+        job_snapshot=external_job.job_snapshot,
         execution_plan_snapshot=execution_plan_snapshot,
-        parent_pipeline_snapshot=external_pipeline.parent_pipeline_snapshot,
-        external_pipeline_origin=external_pipeline.get_external_origin(),
-        pipeline_code_origin=external_pipeline.get_python_origin(),
+        parent_job_snapshot=external_job.parent_job_snapshot,
+        external_job_origin=external_job.get_external_origin(),
+        job_code_origin=external_job.get_python_origin(),
         asset_selection=frozenset(run_request.asset_selection)
         if run_request.asset_selection
         else None,
     )
```

### Comparing `dagster-1.3.2/dagster/_scheduler/stale.py` & `dagster-1.3.3/dagster/_scheduler/stale.py`

 * *Files 4% similar despite different names*

```diff
@@ -20,17 +20,15 @@
     run_request: RunRequest,
     instigator: Union[ExternalSensor, ExternalSchedule],
 ) -> Sequence[AssetKey]:
     asset_graph = ExternalAssetGraph.from_workspace(context.create_request_context())
     asset_selection = (
         run_request.asset_selection
         if run_request.asset_selection is not None
-        else asset_graph.get_materialization_asset_keys_for_job(
-            check.not_none(instigator.pipeline_name)
-        )
+        else asset_graph.get_materialization_asset_keys_for_job(check.not_none(instigator.job_name))
     )
     resolver = CachingStaleStatusResolver(context.instance, asset_graph)
     stale_or_unknown_keys: List[AssetKey] = []
     for asset_key in asset_selection:
         if resolver.get_status(asset_key) in [StaleStatus.STALE, StaleStatus.MISSING]:
             stale_or_unknown_keys.append(asset_key)
     return stale_or_unknown_keys
```

### Comparing `dagster-1.3.2/dagster/_serdes/__init__.py` & `dagster-1.3.3/dagster/_serdes/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_serdes/config_class.py` & `dagster-1.3.3/dagster/_serdes/config_class.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_serdes/ipc.py` & `dagster-1.3.3/dagster/_serdes/ipc.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_serdes/serdes.py` & `dagster-1.3.3/dagster/_serdes/serdes.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_serdes/utils.py` & `dagster-1.3.3/dagster/_serdes/utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_seven/__init__.py` & `dagster-1.3.3/dagster/_seven/__init__.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_seven/abc.py` & `dagster-1.3.3/dagster/_seven/abc.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_seven/compat/pendulum.py` & `dagster-1.3.3/dagster/_seven/compat/pendulum.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/__init__.py` & `dagster-1.3.3/dagster/_utils/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -45,14 +45,16 @@
 
 import packaging.version
 from typing_extensions import Literal, TypeAlias, TypeGuard
 
 import dagster._check as check
 import dagster._seven as seven
 
+from .internal_init import IHasInternalInit as IHasInternalInit
+
 if sys.version_info > (3,):
     from pathlib import Path
 else:
     from pathlib2 import Path
 
 if TYPE_CHECKING:
     from dagster._core.definitions.definitions_class import Definitions
@@ -295,15 +297,15 @@
     except subprocess.CalledProcessError as exc:
         if return_code != 0:
             if exc.returncode == return_code:
                 return
         raise
 
 
-def check_cli_execute_file_pipeline(path, pipeline_fn_name, env_file=None):
+def check_cli_execute_file_job(path, pipeline_fn_name, env_file=None):
     from dagster._core.test_utils import instance_for_test
 
     with instance_for_test():
         cli_cmd = [
             sys.executable,
             "-m",
             "dagster",
@@ -730,7 +732,11 @@
         return definitions_or_repository.get_repository_def()
     elif definitions_or_repository:
         return definitions_or_repository
     elif repository:
         return repository
     else:
         return None
+
+
+def xor(a, b):
+    return bool(a) != bool(b)
```

### Comparing `dagster-1.3.2/dagster/_utils/alert.py` & `dagster-1.3.3/dagster/_utils/alert.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,27 +13,29 @@
     from dagster._core.definitions.run_status_sensor_definition import RunFailureSensorContext
     from dagster._core.definitions.selector import JobSelector, RepositorySelector
     from dagster._core.definitions.unresolved_asset_job_definition import (
         UnresolvedAssetJobDefinition,
     )
 
 
-def _default_failure_email_body(context) -> str:
+def _default_failure_email_body(context: "RunFailureSensorContext") -> str:
+    from dagster._core.host_representation.external_data import DEFAULT_MODE_NAME
+
     return "<br>".join(
         [
-            f"Pipeline {context.pipeline_run.pipeline_name} failed!",
-            f"Run ID: {context.pipeline_run.run_id}",
-            f"Mode: {context.pipeline_run.mode}",
+            f"Pipeline {context.dagster_run.job_name} failed!",
+            f"Run ID: {context.dagster_run.run_id}",
+            f"Mode: {DEFAULT_MODE_NAME}",
             f"Error: {context.failure_event.message}",
         ]
     )
 
 
 def _default_failure_email_subject(context) -> str:
-    return f"Dagster Run Failed: {context.pipeline_run.pipeline_name}"
+    return f"Dagster Run Failed: {context.pipeline_run.job_name}"
 
 
 EMAIL_MESSAGE = """From: {email_from}
 To: {email_to}
 MIME-Version: 1.0
 Content-type: text/html
 Subject: {email_subject}
@@ -124,22 +126,22 @@
             Defaults to "Dagster Run Failed: <job_name>".
         smtp_host (str): The hostname of the SMTP server. Defaults to "smtp.gmail.com".
         smtp_type (str): The protocol; either "SSL" or "STARTTLS". Defaults to SSL.
         smtp_port (Optional[int]): The SMTP port. Defaults to 465 for SSL, 587 for STARTTLS.
         name: (Optional[str]): The name of the sensor. Defaults to "email_on_job_failure".
         dagit_base_url: (Optional[str]): The base url of your Dagit instance. Specify this to allow
             messages to include deeplinks to the failed run.
-        monitored_jobs (Optional[List[Union[JobDefinition, GraphDefinition, PipelineDefinition, RepositorySelector, JobSelector]]]):
+        monitored_jobs (Optional[List[Union[JobDefinition, GraphDefinition, JobDefinition, RepositorySelector, JobSelector]]]):
             The jobs that will be monitored by this failure sensor. Defaults to None, which means the alert will
             be sent when any job in the repository fails. To monitor jobs in external repositories,
             use RepositorySelector and JobSelector.
         monitor_all_repositories (bool): If set to True, the sensor will monitor all runs in the
             Dagster instance. If set to True, an error will be raised if you also specify
             monitored_jobs or job_selection. Defaults to False.
-        job_selection (Optional[List[Union[JobDefinition, GraphDefinition, PipelineDefinition,  RepositorySelector, JobSelector]]]):
+        job_selection (Optional[List[Union[JobDefinition, GraphDefinition, JobDefinition,  RepositorySelector, JobSelector]]]):
             (deprecated in favor of monitored_jobs) The jobs that will be monitored by this failure
             sensor. Defaults to None, which means the alert will be sent when any job in the repository fails.
         default_status (DefaultSensorStatus): Whether the sensor starts as running or not. The default
             status can be overridden from Dagit or via the GraphQL API.
 
     Examples:
         .. code-block:: python
@@ -154,15 +156,15 @@
             def my_repo():
                 return [my_job + email_on_run_failure]
 
         .. code-block:: python
 
             def my_message_fn(context: RunFailureSensorContext) -> str:
                 return (
-                    f"Job {context.pipeline_run.pipeline_name} failed!"
+                    f"Job {context.pipeline_run.job_name} failed!"
                     f"Error: {context.failure_event.message}"
                 )
 
             email_on_run_failure = make_email_on_run_failure_sensor(
                 email_from="no-reply@example.com",
                 email_password=os.getenv("ALERT_EMAIL_PASSWORD"),
                 email_to=["xxx@example.com"],
@@ -188,15 +190,15 @@
         default_status=default_status,
         monitor_all_repositories=monitor_all_repositories,
     )
     def email_on_run_failure(context: RunFailureSensorContext):
         email_body = email_body_fn(context)
         if dagit_base_url:
             email_body += (
-                f'<p><a href="{dagit_base_url}/instance/runs/{context.pipeline_run.run_id}">View in'
+                f'<p><a href="{dagit_base_url}/instance/runs/{context.dagster_run.run_id}">View in'
                 " Dagit</a></p>"
             )
 
         message = EMAIL_MESSAGE.format(
             email_to=",".join(email_to),
             email_from=email_from,
             email_subject=email_subject_fn(context),
```

### Comparing `dagster-1.3.2/dagster/_utils/backcompat.py` & `dagster-1.3.3/dagster/_utils/backcompat.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/backoff.py` & `dagster-1.3.3/dagster/_utils/backoff.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/cached_method.py` & `dagster-1.3.3/dagster/_utils/cached_method.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/caching_instance_queryer.py` & `dagster-1.3.3/dagster/_utils/caching_instance_queryer.py`

 * *Files 0% similar despite different names*

```diff
@@ -7,24 +7,23 @@
     Mapping,
     Optional,
     Sequence,
     Union,
     cast,
 )
 
-import dagster._check as check
 from dagster._core.definitions.asset_graph import AssetGraph
 from dagster._core.definitions.data_version import (
     DataVersion,
     extract_data_version_from_entry,
 )
 from dagster._core.definitions.events import AssetKey, AssetKeyPartitionKey
 from dagster._core.events import DagsterEventType
 from dagster._core.instance import DagsterInstance, DynamicPartitionsStore
-from dagster._core.storage.pipeline_run import (
+from dagster._core.storage.dagster_run import (
     DagsterRun,
     RunRecord,
 )
 from dagster._core.storage.tags import PARTITION_NAME_TAG
 from dagster._utils.cached_method import cached_method
 
 if TYPE_CHECKING:
@@ -446,15 +445,15 @@
 
     def is_asset_planned_for_run(
         self, run_id: str, asset: Union[AssetKey, AssetKeyPartitionKey]
     ) -> bool:
         """Returns True if the asset is planned to be materialized by the run."""
         run = self._get_run_by_id(run_id=run_id)
         if not run:
-            check.failed("")
+            return False
 
         if isinstance(asset, AssetKeyPartitionKey):
             asset_key = asset.asset_key
             if run.tags.get(PARTITION_NAME_TAG) != asset.partition_key:
                 return False
         else:
             asset_key = asset
```

### Comparing `dagster-1.3.2/dagster/_utils/dagster_type.py` & `dagster-1.3.3/dagster/_utils/dagster_type.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from typing import Any
 
 from dagster._core.definitions.events import Failure, TypeCheck
 from dagster._core.definitions.graph_definition import GraphDefinition
-from dagster._core.definitions.pipeline_base import InMemoryPipeline
+from dagster._core.definitions.job_base import InMemoryJob
 from dagster._core.errors import DagsterInvariantViolationError
 from dagster._core.execution.api import create_execution_plan
-from dagster._core.execution.context_creation_pipeline import scoped_pipeline_context
+from dagster._core.execution.context_creation_job import scoped_job_context
 from dagster._core.instance import DagsterInstance
 from dagster._core.types.dagster_type import resolve_dagster_type
 
 from .typing_api import is_typing_type
 
 
 def check_dagster_type(dagster_type: Any, value: Any) -> TypeCheck:
@@ -37,21 +37,21 @@
                 "Must pass in a type from dagster module. You passed {dagster_type} "
                 "which is part of python's typing module."
             ).format(dagster_type=dagster_type)
         )
 
     dagster_type = resolve_dagster_type(dagster_type)
 
-    pipeline = InMemoryPipeline(GraphDefinition(node_defs=[], name="empty").to_job())
-    pipeline_def = pipeline.get_definition()
+    job = InMemoryJob(GraphDefinition(node_defs=[], name="empty").to_job())
+    job_def = job.get_definition()
 
     instance = DagsterInstance.ephemeral()
-    execution_plan = create_execution_plan(pipeline)
-    pipeline_run = instance.create_run_for_pipeline(pipeline_def)
-    with scoped_pipeline_context(execution_plan, pipeline, {}, pipeline_run, instance) as context:
+    execution_plan = create_execution_plan(job)
+    dagster_run = instance.create_run_for_job(job_def)
+    with scoped_job_context(execution_plan, job, {}, dagster_run, instance) as context:
         type_check_context = context.for_type(dagster_type)
         try:
             type_check = dagster_type.type_check(type_check_context, value)
         except Failure as failure:
             return TypeCheck(success=False, description=failure.description)
 
         if not isinstance(type_check, TypeCheck):
```

### Comparing `dagster-1.3.2/dagster/_utils/error.py` & `dagster-1.3.3/dagster/_utils/error.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/external.py` & `dagster-1.3.3/dagster/_utils/external.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,34 +1,34 @@
 from typing import Optional, Sequence
 
 import dagster._check as check
-from dagster._core.definitions.selector import PipelineSelector
+from dagster._core.definitions.selector import JobSubsetSelector
 from dagster._core.host_representation import CodeLocation
-from dagster._core.host_representation.external import ExternalPipeline
-from dagster._core.host_representation.origin import ExternalPipelineOrigin
+from dagster._core.host_representation.external import ExternalJob
+from dagster._core.host_representation.origin import ExternalJobOrigin
 
 
-def external_pipeline_from_location(
+def external_job_from_location(
     code_location: CodeLocation,
-    external_pipeline_origin: ExternalPipelineOrigin,
+    external_job_origin: ExternalJobOrigin,
     solid_selection: Optional[Sequence[str]],
-) -> ExternalPipeline:
+) -> ExternalJob:
     check.inst_param(code_location, "code_location", CodeLocation)
-    check.inst_param(external_pipeline_origin, "external_pipeline_origin", ExternalPipelineOrigin)
+    check.inst_param(external_job_origin, "external_pipeline_origin", ExternalJobOrigin)
 
-    repo_name = external_pipeline_origin.external_repository_origin.repository_name
-    pipeline_name = external_pipeline_origin.pipeline_name
+    repo_name = external_job_origin.external_repository_origin.repository_name
+    job_name = external_job_origin.job_name
 
     check.invariant(
         code_location.has_repository(repo_name),
         f"Could not find repository {repo_name} in location {code_location.name}",
     )
     external_repo = code_location.get_repository(repo_name)
 
-    pipeline_selector = PipelineSelector(
+    pipeline_selector = JobSubsetSelector(
         location_name=code_location.name,
         repository_name=external_repo.name,
-        pipeline_name=pipeline_name,
+        job_name=job_name,
         solid_selection=solid_selection,
     )
 
-    return code_location.get_external_pipeline(pipeline_selector)
+    return code_location.get_external_job(pipeline_selector)
```

### Comparing `dagster-1.3.2/dagster/_utils/forked_pdb.py` & `dagster-1.3.3/dagster/_utils/forked_pdb.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/hosted_user_process.py` & `dagster-1.3.3/dagster/_utils/hosted_user_process.py`

 * *Files 13% similar despite different names*

```diff
@@ -7,31 +7,31 @@
 These should only be invoked from contexts where we know this
 to be the case.
 """
 
 from typing import TYPE_CHECKING
 
 import dagster._check as check
-from dagster._core.definitions.reconstruct import ReconstructablePipeline, ReconstructableRepository
-from dagster._core.host_representation import ExternalPipeline, ExternalRepository
+from dagster._core.definitions.reconstruct import ReconstructableJob, ReconstructableRepository
+from dagster._core.host_representation import ExternalJob, ExternalRepository
 from dagster._core.host_representation.external_data import (
-    external_pipeline_data_from_def,
+    external_job_data_from_def,
     external_repository_data_from_def,
 )
-from dagster._core.origin import PipelinePythonOrigin, RepositoryPythonOrigin
+from dagster._core.origin import JobPythonOrigin, RepositoryPythonOrigin
 
 if TYPE_CHECKING:
     from dagster._core.definitions.repository_definition import RepositoryDefinition
     from dagster._core.host_representation.handle import RepositoryHandle
 
 
-def recon_pipeline_from_origin(origin: PipelinePythonOrigin) -> ReconstructablePipeline:
-    check.inst_param(origin, "origin", PipelinePythonOrigin)
+def recon_job_from_origin(origin: JobPythonOrigin) -> ReconstructableJob:
+    check.inst_param(origin, "origin", JobPythonOrigin)
     recon_repo = recon_repository_from_origin(origin.repository_origin)
-    return recon_repo.get_reconstructable_pipeline(origin.pipeline_name)
+    return recon_repo.get_reconstructable_job(origin.job_name)
 
 
 def recon_repository_from_origin(origin: RepositoryPythonOrigin) -> "ReconstructableRepository":
     check.inst_param(origin, "origin", RepositoryPythonOrigin)
     return ReconstructableRepository(
         origin.code_pointer,
         origin.container_image,
@@ -43,22 +43,22 @@
 
 def external_repo_from_def(
     repository_def: "RepositoryDefinition", repository_handle: "RepositoryHandle"
 ) -> ExternalRepository:
     return ExternalRepository(external_repository_data_from_def(repository_def), repository_handle)
 
 
-def external_pipeline_from_recon_pipeline(
-    recon_pipeline, solid_selection, repository_handle, asset_selection=None
+def external_job_from_recon_job(
+    recon_job, solid_selection, repository_handle, asset_selection=None
 ):
     if solid_selection or asset_selection:
-        sub_pipeline = recon_pipeline.subset_for_execution(
+        sub_recon_job = recon_job.subset_for_execution(
             solid_selection=solid_selection, asset_selection=asset_selection
         )
-        pipeline_def = sub_pipeline.get_definition()
+        job_def = sub_recon_job.get_definition()
     else:
-        pipeline_def = recon_pipeline.get_definition()
+        job_def = recon_job.get_definition()
 
-    return ExternalPipeline(
-        external_pipeline_data_from_def(pipeline_def),
+    return ExternalJob(
+        external_job_data_from_def(job_def),
         repository_handle=repository_handle,
     )
```

### Comparing `dagster-1.3.2/dagster/_utils/indenting_printer.py` & `dagster-1.3.3/dagster/_utils/indenting_printer.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/interrupts.py` & `dagster-1.3.3/dagster/_utils/interrupts.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/log.py` & `dagster-1.3.3/dagster/_utils/log.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/merger.py` & `dagster-1.3.3/dagster/_utils/merger.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/net.py` & `dagster-1.3.3/dagster/_utils/net.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/schedules.py` & `dagster-1.3.3/dagster/_utils/schedules.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,22 +1,42 @@
 import datetime
+import functools
 from typing import Iterator, Optional, Sequence, Union
 
 import pendulum
 import pytz
-from croniter import croniter
+from croniter import croniter as _croniter
 
 import dagster._check as check
 from dagster._seven.compat.pendulum import to_timezone
 
 
+class CroniterShim(_croniter):
+    """Lightweight shim to enable caching certain values that may be calculated many times."""
+
+    @classmethod
+    @functools.lru_cache(maxsize=128)
+    def expand(cls, *args, **kwargs):
+        return super().expand(*args, **kwargs)
+
+
+def _exact_match(cron_expression: str, dt: datetime.datetime) -> bool:
+    """The default croniter match function only checks that the given datetime is within 60 seconds
+    of a cron schedule tick. This function checks that the given datetime is exactly on a cron tick.
+    """
+    cron = CroniterShim(
+        cron_expression, dt + datetime.timedelta(microseconds=1), ret_type=datetime.datetime
+    )
+    return dt == cron.get_prev()
+
+
 def is_valid_cron_string(cron_string: str) -> bool:
-    if not croniter.is_valid(cron_string):
+    if not CroniterShim.is_valid(cron_string):
         return False
-    expanded, _ = croniter.expand(cron_string)
+    expanded, _ = CroniterShim.expand(cron_string)
     # dagster only recognizes cron strings that resolve to 5 parts (e.g. not seconds resolution)
     return len(expanded) == 5
 
 
 def is_valid_cron_schedule(cron_schedule: Union[str, Sequence[str]]) -> bool:
     return (
         is_valid_cron_string(cron_schedule)
@@ -34,32 +54,15 @@
 ) -> Iterator[datetime.datetime]:
     """Generator of datetimes >= start_timestamp for the given cron string."""
     timezone_str = execution_timezone if execution_timezone else "UTC"
 
     utc_datetime = pytz.utc.localize(datetime.datetime.utcfromtimestamp(start_timestamp))
     start_datetime = utc_datetime.astimezone(pytz.timezone(timezone_str))
 
-    date_iter = croniter(cron_string, start_datetime)
-
-    # Go back one iteration so that the next iteration is the first time that is >= start_datetime
-    # and matches the cron schedule
-    next_date = date_iter.get_prev(datetime.datetime)
-
-    if not croniter.match(cron_string, next_date):
-        # Workaround for upstream croniter bug where get_prev sometimes overshoots to a time
-        # that doesn't actually match the cron string (e.g. 3AM on Spring DST day
-        # goes back to 1AM on the previous day) - when this happens, advance to the correct
-        # time that actually matches the cronstring
-        next_date = date_iter.get_next(datetime.datetime)
-
-    check.invariant(start_offset <= 0)
-    for _ in range(-start_offset):
-        next_date = date_iter.get_prev(datetime.datetime)
-
-    cron_parts, nth_weekday_of_month = croniter.expand(cron_string)
+    cron_parts, nth_weekday_of_month = CroniterShim.expand(cron_string)
 
     is_numeric = [len(part) == 1 and part[0] != "*" for part in cron_parts]
     is_wildcard = [len(part) == 1 and part[0] == "*" for part in cron_parts]
 
     delta_fn = None
     should_hour_change = False
     expected_hour = None
@@ -79,14 +82,37 @@
         elif is_numeric[0] and all(is_wildcard[1:]):  # hourly
             delta_fn = lambda d, num: d.add(hours=num)
             should_hour_change = True
 
     if is_numeric[1]:
         expected_hour = int(cron_parts[1][0])
 
+    date_iter = CroniterShim(cron_string, start_datetime)
+    if delta_fn is not None and start_offset == 0 and _exact_match(cron_string, start_datetime):
+        # In simple cases, where you're already on a cron boundary, the below logic is unnecessary
+        # and slow
+        next_date = start_datetime
+        # This is already on a cron boundary, so yield it
+        yield to_timezone(pendulum.instance(next_date), timezone_str)
+    else:
+        # Go back one iteration so that the next iteration is the first time that is >= start_datetime
+        # and matches the cron schedule
+        next_date = date_iter.get_prev(datetime.datetime)
+
+        if not CroniterShim.match(cron_string, next_date):
+            # Workaround for upstream croniter bug where get_prev sometimes overshoots to a time
+            # that doesn't actually match the cron string (e.g. 3AM on Spring DST day
+            # goes back to 1AM on the previous day) - when this happens, advance to the correct
+            # time that actually matches the cronstring
+            next_date = date_iter.get_next(datetime.datetime)
+
+        check.invariant(start_offset <= 0)
+        for _ in range(-start_offset):
+            next_date = date_iter.get_prev(datetime.datetime)
+
     if delta_fn is not None:
         # Use pendulums for intervals when possible
         next_date = to_timezone(pendulum.instance(next_date), timezone_str)
         while True:
             curr_hour = next_date.hour
 
             next_date_cand = delta_fn(next_date, 1)
@@ -140,21 +166,21 @@
 ) -> Iterator[datetime.datetime]:
     """Generator of datetimes < end_timestamp for the given cron string."""
     timezone_str = execution_timezone if execution_timezone else "UTC"
 
     utc_datetime = pytz.utc.localize(datetime.datetime.utcfromtimestamp(end_timestamp))
     end_datetime = utc_datetime.astimezone(pytz.timezone(timezone_str))
 
-    date_iter = croniter(cron_string, end_datetime)
+    date_iter = CroniterShim(cron_string, end_datetime)
 
     # Go forward one iteration so that the next iteration is the first time that is < end_datetime
     # and matches the cron schedule
     next_date = date_iter.get_next(datetime.datetime)
 
-    cron_parts, _ = croniter.expand(cron_string)
+    cron_parts, _ = CroniterShim.expand(cron_string)
 
     is_numeric = [len(part) == 1 and part[0] != "*" for part in cron_parts]
     is_wildcard = [len(part) == 1 and part[0] == "*" for part in cron_parts]
 
     # Special-case common intervals (hourly/daily/weekly/monthly) since croniter iteration can be
     # much slower than adding a fixed interval
     if all(is_numeric[0:3]) and all(is_wildcard[3:]):  # monthly
```

### Comparing `dagster-1.3.2/dagster/_utils/tags.py` & `dagster-1.3.3/dagster/_utils/tags.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from collections import defaultdict
 from typing import TYPE_CHECKING, Any, Dict, Mapping, Sequence, Tuple, Union
 
 from dagster import _check as check
 
 if TYPE_CHECKING:
     from dagster._core.execution.plan.step import ExecutionStep
-    from dagster._core.storage.pipeline_run import DagsterRun
+    from dagster._core.storage.dagster_run import DagsterRun
 
 
 class TagConcurrencyLimitsCounter:
     """Helper object that keeps track of when the tag concurrency limits are met."""
 
     _key_limits: Dict[str, int]
     _key_value_limits: Dict[Tuple[str, str], int]
```

### Comparing `dagster-1.3.2/dagster/_utils/temp_file.py` & `dagster-1.3.3/dagster/_utils/temp_file.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/test/__init__.py` & `dagster-1.3.3/dagster/_utils/test/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -17,31 +17,31 @@
     InputMapping,
     JobDefinition,
     OpDefinition,
     OutputMapping,
 )
 from dagster._core.definitions.dependency import Node
 from dagster._core.definitions.executor_definition import in_process_executor
+from dagster._core.definitions.job_base import InMemoryJob
 from dagster._core.definitions.logger_definition import LoggerDefinition
-from dagster._core.definitions.pipeline_base import InMemoryPipeline
 from dagster._core.definitions.resource_definition import ScopedResourcesBuilder
 from dagster._core.execution.api import create_execution_plan
 from dagster._core.execution.context.system import PlanExecutionContext
-from dagster._core.execution.context_creation_pipeline import (
+from dagster._core.execution.context_creation_job import (
     create_context_creation_data,
     create_execution_data,
     create_executor,
     create_log_manager,
     create_plan_data,
 )
 from dagster._core.execution.execute_in_process_result import ExecuteInProcessResult
 from dagster._core.instance import DagsterInstance
 from dagster._core.scheduler import Scheduler
-from dagster._core.storage.pipeline_run import DagsterRun
-from dagster._core.utility_solids import create_stub_op
+from dagster._core.storage.dagster_run import DagsterRun
+from dagster._core.utility_ops import create_stub_op
 from dagster._serdes import ConfigurableClass
 
 # re-export
 from ..temp_file import (
     get_temp_dir as get_temp_dir,
     get_temp_file_handle as get_temp_file_handle,
     get_temp_file_handle_with_data as get_temp_file_handle_with_data,
@@ -53,27 +53,27 @@
 
 def create_test_pipeline_execution_context(
     logger_defs: Optional[Mapping[str, LoggerDefinition]] = None
 ) -> PlanExecutionContext:
     loggers = check.opt_mapping_param(
         logger_defs, "logger_defs", key_type=str, value_type=LoggerDefinition
     )
-    pipeline_def = GraphDefinition(
+    job_def = GraphDefinition(
         name="test_legacy_context",
         node_defs=[],
     ).to_job(executor_def=in_process_executor, logger_defs=logger_defs)
     run_config: Dict[str, Dict[str, Dict]] = {"loggers": {key: {} for key in loggers}}
-    pipeline_run = DagsterRun(pipeline_name="test_legacy_context", run_config=run_config)
+    dagster_run = DagsterRun(job_name="test_legacy_context", run_config=run_config)
     instance = DagsterInstance.ephemeral()
-    execution_plan = create_execution_plan(pipeline=pipeline_def, run_config=run_config)
+    execution_plan = create_execution_plan(job=job_def, run_config=run_config)
     creation_data = create_context_creation_data(
-        InMemoryPipeline(pipeline_def),
+        InMemoryJob(job_def),
         execution_plan,
         run_config,
-        pipeline_run,
+        dagster_run,
         instance,
     )
     log_manager = create_log_manager(creation_data)
     scoped_resources_builder = ScopedResourcesBuilder()
     executor = create_executor(creation_data)
 
     return PlanExecutionContext(
```

### Comparing `dagster-1.3.2/dagster/_utils/test/mysql_instance.py` & `dagster-1.3.3/dagster/_utils/test/mysql_instance.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/test/postgres_instance.py` & `dagster-1.3.3/dagster/_utils/test/postgres_instance.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/test/schedule_storage.py` & `dagster-1.3.3/dagster/_utils/test/schedule_storage.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/timing.py` & `dagster-1.3.3/dagster/_utils/timing.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/typing_api.py` & `dagster-1.3.3/dagster/_utils/typing_api.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster/_utils/yaml_utils.py` & `dagster-1.3.3/dagster/_utils/yaml_utils.py`

 * *Files identical despite different names*

### Comparing `dagster-1.3.2/dagster.egg-info/PKG-INFO` & `dagster-1.3.3/dagster.egg-info/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: dagster
-Version: 1.3.2
+Version: 1.3.3
 Summary: The data orchestration platform built for productivity.
 Author: Elementl
 Author-email: hello@elementl.com
 License: Apache-2.0
 Project-URL: Homepage, https://dagster.io
 Project-URL: GitHub, https://github.com/dagster-io/dagster
 Project-URL: Changelog, https://github.com/dagster-io/dagster/releases
```

### Comparing `dagster-1.3.2/dagster.egg-info/SOURCES.txt` & `dagster-1.3.3/dagster.egg-info/SOURCES.txt`

 * *Files 1% similar despite different names*

```diff
@@ -18,16 +18,16 @@
 dagster.egg-info/requires.txt
 dagster.egg-info/top_level.txt
 dagster/_api/__init__.py
 dagster/_api/get_server_id.py
 dagster/_api/list_repositories.py
 dagster/_api/notebook_data.py
 dagster/_api/snapshot_execution_plan.py
+dagster/_api/snapshot_job.py
 dagster/_api/snapshot_partition.py
-dagster/_api/snapshot_pipeline.py
 dagster/_api/snapshot_repository.py
 dagster/_api/snapshot_schedule.py
 dagster/_api/snapshot_sensor.py
 dagster/_check/README.md
 dagster/_check/__init__.py
 dagster/_cli/__init__.py
 dagster/_cli/api.py
@@ -75,22 +75,21 @@
 dagster/_core/libraries.py
 dagster/_core/log_manager.py
 dagster/_core/nux.py
 dagster/_core/origin.py
 dagster/_core/telemetry.py
 dagster/_core/telemetry_upload.py
 dagster/_core/test_utils.py
-dagster/_core/utility_solids.py
+dagster/_core/utility_ops.py
 dagster/_core/utils.py
 dagster/_core/container_context/__init__.py
 dagster/_core/container_context/config.py
 dagster/_core/definitions/__init__.py
 dagster/_core/definitions/asset_graph.py
 dagster/_core/definitions/asset_graph_subset.py
-dagster/_core/definitions/asset_group.py
 dagster/_core/definitions/asset_in.py
 dagster/_core/definitions/asset_layer.py
 dagster/_core/definitions/asset_out.py
 dagster/_core/definitions/asset_reconciliation_sensor.py
 dagster/_core/definitions/asset_selection.py
 dagster/_core/definitions/asset_sensor_definition.py
 dagster/_core/definitions/assets.py
@@ -112,14 +111,15 @@
 dagster/_core/definitions/freshness_policy_sensor_definition.py
 dagster/_core/definitions/graph_definition.py
 dagster/_core/definitions/hook_definition.py
 dagster/_core/definitions/hook_invocation.py
 dagster/_core/definitions/inference.py
 dagster/_core/definitions/input.py
 dagster/_core/definitions/instigation_logger.py
+dagster/_core/definitions/job_base.py
 dagster/_core/definitions/job_definition.py
 dagster/_core/definitions/load_assets_from_modules.py
 dagster/_core/definitions/logger_definition.py
 dagster/_core/definitions/logger_invocation.py
 dagster/_core/definitions/materialize.py
 dagster/_core/definitions/multi_asset_sensor_definition.py
 dagster/_core/definitions/multi_dimensional_partitions.py
@@ -130,15 +130,14 @@
 dagster/_core/definitions/op_definition.py
 dagster/_core/definitions/op_invocation.py
 dagster/_core/definitions/output.py
 dagster/_core/definitions/partition.py
 dagster/_core/definitions/partition_key_range.py
 dagster/_core/definitions/partition_mapping.py
 dagster/_core/definitions/partitioned_schedule.py
-dagster/_core/definitions/pipeline_base.py
 dagster/_core/definitions/policy.py
 dagster/_core/definitions/reconstruct.py
 dagster/_core/definitions/resolved_asset_deps.py
 dagster/_core/definitions/resource_annotation.py
 dagster/_core/definitions/resource_definition.py
 dagster/_core/definitions/resource_invocation.py
 dagster/_core/definitions/resource_requirement.py
@@ -184,15 +183,15 @@
 dagster/_core/execution/__init__.py
 dagster/_core/execution/api.py
 dagster/_core/execution/asset_backfill.py
 dagster/_core/execution/backfill.py
 dagster/_core/execution/build_resources.py
 dagster/_core/execution/bulk_actions.py
 dagster/_core/execution/compute_logs.py
-dagster/_core/execution/context_creation_pipeline.py
+dagster/_core/execution/context_creation_job.py
 dagster/_core/execution/execute_in_process.py
 dagster/_core/execution/execute_in_process_result.py
 dagster/_core/execution/execute_job_result.py
 dagster/_core/execution/execution_result.py
 dagster/_core/execution/host_mode.py
 dagster/_core/execution/job_backfill.py
 dagster/_core/execution/memoization.py
@@ -247,16 +246,16 @@
 dagster/_core/host_representation/code_location.py
 dagster/_core/host_representation/external.py
 dagster/_core/host_representation/external_data.py
 dagster/_core/host_representation/grpc_server_registry.py
 dagster/_core/host_representation/grpc_server_state_subscriber.py
 dagster/_core/host_representation/handle.py
 dagster/_core/host_representation/historical.py
+dagster/_core/host_representation/job_index.py
 dagster/_core/host_representation/origin.py
-dagster/_core/host_representation/pipeline_index.py
 dagster/_core/host_representation/represented.py
 dagster/_core/instance/__init__.py
 dagster/_core/instance/config.py
 dagster/_core/instance/ref.py
 dagster/_core/launcher/__init__.py
 dagster/_core/launcher/base.py
 dagster/_core/launcher/default_run_launcher.py
@@ -275,39 +274,39 @@
 dagster/_core/selector/__init__.py
 dagster/_core/selector/subset_selector.py
 dagster/_core/snap/__init__.py
 dagster/_core/snap/config_types.py
 dagster/_core/snap/dagster_types.py
 dagster/_core/snap/dep_snapshot.py
 dagster/_core/snap/execution_plan_snapshot.py
+dagster/_core/snap/job_snapshot.py
 dagster/_core/snap/mode.py
 dagster/_core/snap/node.py
-dagster/_core/snap/pipeline_snapshot.py
 dagster/_core/storage/DEVELOPING.md
 dagster/_core/storage/__init__.py
 dagster/_core/storage/asset_value_loader.py
 dagster/_core/storage/base_storage.py
 dagster/_core/storage/captured_log_manager.py
 dagster/_core/storage/cloud_storage_compute_log_manager.py
 dagster/_core/storage/compute_log_manager.py
 dagster/_core/storage/config.py
 dagster/_core/storage/daemon_cursor.py
+dagster/_core/storage/dagster_run.py
 dagster/_core/storage/db_io_manager.py
 dagster/_core/storage/file_manager.py
 dagster/_core/storage/fs_io_manager.py
 dagster/_core/storage/input_manager.py
 dagster/_core/storage/io_manager.py
 dagster/_core/storage/legacy_storage.py
 dagster/_core/storage/local_compute_log_manager.py
 dagster/_core/storage/mem_io_manager.py
 dagster/_core/storage/memoizable_io_manager.py
 dagster/_core/storage/noop_compute_log_manager.py
 dagster/_core/storage/output_manager.py
 dagster/_core/storage/partition_status_cache.py
-dagster/_core/storage/pipeline_run.py
 dagster/_core/storage/root.py
 dagster/_core/storage/root_input_manager.py
 dagster/_core/storage/sql.py
 dagster/_core/storage/sqlite.py
 dagster/_core/storage/sqlite_storage.py
 dagster/_core/storage/tags.py
 dagster/_core/storage/temp_file_manager.py
@@ -520,14 +519,15 @@
 dagster/_utils/caching_instance_queryer.py
 dagster/_utils/dagster_type.py
 dagster/_utils/error.py
 dagster/_utils/external.py
 dagster/_utils/forked_pdb.py
 dagster/_utils/hosted_user_process.py
 dagster/_utils/indenting_printer.py
+dagster/_utils/internal_init.py
 dagster/_utils/interrupts.py
 dagster/_utils/log.py
 dagster/_utils/merger.py
 dagster/_utils/net.py
 dagster/_utils/partitions.py
 dagster/_utils/schedules.py
 dagster/_utils/tags.py
```

### Comparing `dagster-1.3.2/dagster.egg-info/requires.txt` & `dagster-1.3.3/dagster.egg-info/requires.txt`

 * *Files 6% similar despite different names*

```diff
@@ -60,15 +60,15 @@
 types-pyOpenSSL
 types-python-dateutil
 types-PyYAML
 types-pytz
 types-requests
 types-simplejson
 types-six
-types-sqlalchemy
+types-sqlalchemy==1.4.53.34
 types-tabulate
 types-tzlocal
 types-toml
 
 [ruff]
 ruff==0.0.255
```

### Comparing `dagster-1.3.2/setup.py` & `dagster-1.3.3/setup.py`

 * *Files 1% similar despite different names*

```diff
@@ -143,15 +143,15 @@
             "types-pyOpenSSL",  # version will be resolved against pyOpenSSL
             "types-python-dateutil",  # version will be resolved against python-dateutil
             "types-PyYAML",  # version will be resolved against PyYAML
             "types-pytz",  # version will be resolved against pytz
             "types-requests",  # version will be resolved against requests
             "types-simplejson",  # version will be resolved against simplejson
             "types-six",  # needed but not specified by grpcio
-            "types-sqlalchemy",  # version will be resolved against sqlalchemy
+            "types-sqlalchemy==1.4.53.34",  # later versions introduce odd errors
             "types-tabulate",  # version will be resolved against tabulate
             "types-tzlocal",  # version will be resolved against tzlocal
             "types-toml",  # version will be resolved against toml
         ],
         "ruff": [
             "ruff==0.0.255",
         ],
```

